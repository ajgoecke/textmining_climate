Die meisten SST-Messungen werden von fahrenden Schiffen, Bojen oder Argo-Floats durchgeführt, der Referenzmittelwert wird an einem bestimmten Ort von einer Vielzahl von Instrumenten und in einer Vielzahl von Tiefen ermittelt. Im Fall von HadSST wird die Referenz für 5° mal 5° Breiten- und Längengrad „Gitterzellen“ berechnet. Die Zellen überdecken 308.025 Quadratkilometer am Äquator, ein Quadrat, das auf einer Seite 556 Kilometer lang ist. Der Abstand zwischen den einzelnen Längengraden wird kleiner, je näher wir uns den Polen nähern, aber bei 40° nördlicher oder südlicher Breite sind 5° Längengrad immer noch 425 Kilometer. Diese „Referenzzellen“ sind riesige Gebiete in den mittleren und niedrigen Breiten, aber sie sind klein in der Nähe der Pole.
Erschwerend kommt hinzu, dass die Technologie, die in den Referenzzeiträumen 1961-1990 oder 1971-2000 verwendet wurde, weit weniger genau ist als die heute durchgeführten Messungen. Tatsächlich korrigiert die NOAA die in den frühen 2000er Jahren eingeführten Argo-Float- und Driftbojen um das 6,8-fache im Vergleich zu den Schiffsdaten (Huang, et al., 2017). Das Hadley Centre sagt, dass Argo-Floats ihre Unsicherheit um 30 % reduzieren (Kennedy, Rayner, Atkinson, & Killick, 2019). Während der beiden Referenzperioden stammten fast alle Daten von Schiffen. Das bedeutet, dass die größere Ungenauigkeit der Messungen, relativ zu heute, in den 30-jährigen Referenzzeiträumen signifikant ist. Man könnte annehmen, dass die zusätzliche Unsicherheit zufällig ist, aber das ist wahrscheinlich nicht der Fall.
An Land können alle Messungen während des Referenzzeitraumes von der gleichen Wetterstation stammen. Diese Wetterstation kann sich die ganze Zeit über an genau demselben Ort befunden haben. Es gibt ernsthafte Probleme mit vielen landgestützten Wetterstationen, wie von Fall, Watts und Kollegen dokumentiert (Fall, et al., 2011), aber zumindest sind die Wetterstationen nicht ständig in Bewegung. Landgestützte Stationen sind fest, aber ihre Höhenlagen sind alle unterschiedlich und da die Lufttemperatur eine Funktion der Höhe ist, ist die Erzeugung von Anomalien zur Erkennung von Veränderungen und Trends sehr sinnvoll. Wetterstationen, auf dem Meer und an Land, sind ungleichmäßig verteilt, so dass eine Rasterung der Werte notwendig ist, wenn die Abdeckung nicht ausreicht. In einigen Gebieten, wie z. B. den Conterminous United States (CONUS), gibt es so viele Wetterstationen, dass eine Rasterung unnötig [beim EIKE in deutscher Übersetzung hier] ist und, wenn sie durchgeführt wird, sogar die Genauigkeit des berechneten durchschnittlichen Temperaturtrends verringern kann.
CONUS nimmt eine Fläche von 3,1 Millionen Quadratmeilen ein mit 11.969 Wetterstationen im GHCN (Global Historical Climatology Network). Das sind etwa 260 Quadratmeilen pro Station. Jede Station liefert ungefähr 365 Beobachtungen pro Jahr, in einigen Fällen sogar mindestens 4,4 Millionen Beobachtungen. Dies entspricht etwa 1,4 Beobachtungen pro Quadratmeile. Die Abdeckung ist ausreichend, die Stationen befinden sich an festen Standorten und sind einigermaßen genau. Der Ozean umfasst 139,4 Millionen Quadratmeilen. Im Jahr 2018 hatte HadSST insgesamt 18.470.411 Beobachtungen. Das sind etwa 0,13 Beobachtungen pro Quadratmeile oder 9 % der Abdeckung im Gebiet der kontinentalen USA.
Jede Berechnung einer Durchschnittstemperatur oder eines Temperaturtrends sollte so nah wie möglich an den ursprünglichen Messungen vorgenommen werden. Es sollten nur die erforderlichen Korrekturen und Datenmanipulationen vorgenommen werden. Mehr ist nicht besser. Die Messungen der Meeresoberflächentemperatur sind bereits auf eine Meerestiefe von 20 cm korrigiert. Ihre Referenztiefe ändert sich nicht. Die Quelle und die Qualität der Messungen an jedem Ozeanstandort ändern sich ständig. Die Berechnung der Referenztemperatur erfolgt nicht von einer einzigen Plattform, nicht einmal von einem einzigen Gerätetyp oder in einer einzigen Tiefe, so dass die Referenz sehr fehleranfällig ist und schwere Unstimmigkeiten aufweist. Wer kann schon sagen, dass die Referenztemperatur, die von den Messungen abgezogen wird, genauso genau ist wie die Messung? Es ist allgemein anerkannt, dass Bojen- und Argo-Float-Daten genauer sind als Schiffsdaten und 2018 sind die Bojen- und Float-Daten zahlreicher, das Gegenteil war von 1961-1990 der Fall (Huang, et al., 2017).
Auf den ersten Blick glauben wir, dass die Umwandlung genauer Messungen in ungenaue Anomalien ein unnötiger und verwirrender Schritt ist, der vermieden werden sollte. Als nächstes fassen wir zusammen, wie die Anomalien berechnet werden.
HadSST-Anomalien
Zunächst werden die In-situ-Messungen einer Qualitätsprüfung unterzogen, und die verbleibenden Messungen werden in 1° x 1° Breiten- und Längengrade sowie 5-Tage-Zeitabschnitte unterteilt. Der 5-Tage-Bereich wird als Pentade bezeichnet. Es gibt immer 73 Pentaden in einem Jahr, so dass Schaltjahre eine 6-tägige „Pentade“ haben (Kennedy, Rayner, Atkinson, & Killick, 2019). Die Pentaden werden zu Pseudo-Monaten gruppiert und durch Monatswerte aus teilweise mit Eis bedeckten Zellen ergänzt. Schließlich wird jede Ein-Grad-Pentade in eine Anomalie umgewandelt, indem ihr Mittelwert vom Mittelwert 1961-1990 subtrahiert wird. Die Ein-Grad-Pentad-Anomalien werden als „Superbeobachtungen“ bezeichnet (Rayner, et al., 2006). Schließlich werden die Ein-Grad-Pentaden mit einem gewichteten „korrigierten Mittel“ zu einem monatlichen Fünf-Grad-Gitter kombiniert, welches das grundlegende HadSST-Produkt darstellt. Vor der Berechnung des monatlichen Mittelwertes für die Fünf-Grad-Gitterzelle wird versucht, alle Messungen auf eine Tiefe von 20 cm zu korrigieren.
Während der letzten zwanzig Jahre enthielt die durchschnittliche besiedelte Fünf-Grad-Zelle 761 Beobachtungen, was einer Beobachtung alle 404 Quadratkilometer am Äquator entspricht. Wir halten dies subjektiv für eine gute Abdeckung und betrachten die besiedelten Zellen als solide Werte. Wie wir jedoch in unserem letzten Beitrag gesehen haben, enthält nicht jede Fünf-Grad-Zelle im Weltozean einen Gitterwert oder Beobachtungen. In runden Zahlen ausgedrückt, weisen nur 37 % der Weltozeanzellen im Jahr 2018 monatliche Werte auf, das sind 8.186 monatliche Ozeanzellen von 22.084. Man beachte, dass die polaren Zellen, die den Großteil der Zellen ohne Werte ausmachen, im Vergleich zu den Zellen in den mittleren und unteren Breitengraden flächenmäßig klein sind. Daher ist die Fläche, die von den besiedelten Zellen abgedeckt wird, viel größer als 8.186/22.084 oder 37 % des Ozeans. Ich habe die abgedeckte Fläche nicht berechnet, aber es ist wahrscheinlich mehr als die Hälfte des Weltozeans.
ERSST-Anomalien
Die grundlegenden, bei der Erstellung des ERSST-Datensatzes verwendeten Einheiten sind monatliche Bereiche von 2°x2° Breiten- und Längengraden. Für jedes Feld wird ein Durchschnitt der Jahre 1971 bis 2000 aus qualitätskontrollierten Messungen berechnet. Dieser Mittelwert wird von jeder Messung in diesem Bereich subtrahiert, um eine Anomalie zu erzeugen. Danach werden die verschiedenen Messungen (Schiff, Boje und Argo) angepasst, um den globalen Durchschnittsunterschied in ihren Werten zu berücksichtigen. Die angepassten Werte werden dann zu monatlichen 2°x2°-„Superbeobachtungen“ gemittelt. Bojen- und Argo-Daten werden um das 6,8-fache der Schiffsbeobachtungen gewichtet (Huang, et al., 2017). Seit dem Jahr 2000 dominieren Argo- und Bojendaten den ERSST-Datensatz, sowohl in Qualität als auch in Quantität. Dies ist in Abbildung 1 unseres letzten Beitrags leicht zu erkennen, da die von Argo dominierten mehrjährigen Temperaturschätzungen der Universität Hamburg und des NOAA MIMOC über die ERSST-Linie fallen. Dies wird auch von Huang, et al. bestätigt (Huang, et al., 2017).
Die für ERSST verwendeten 2°x2°-Zellen sind am Äquator 49.324 Quadratkilometer groß. Sobald der ERSST-Gitterprozess abgeschlossen ist und die Interpolationen, Extrapolationen und Ausfüllungen abgeschlossen sind, sind 10.988 Zellen von 11.374 Ozeanzellen gefüllt. Nur 3% sind Null, man vergleiche dies mit den 63% Null-Gitterzellenwerten in HadSST. Die Anzahl der Beobachtungen pro Zelle war in den Datensätzen, die ich von NOAA heruntergeladen habe, nicht verfügbar, aber das ist in ihrem Datensatz weniger wichtig, da sie einen komplizierten Gitteralgorithmus verwenden, um die Zellenwerte zu berechnen.
Die Begründung zur Erzeugung von SST-Anomalien
In den primären HadSST- oder ERSST-Referenzen wird keine Begründung für die Erstellung von SST-Anomalien angeboten, die ich gesehen habe. Sie nehmen es einfach kommentarlos in ihr Verfahren auf. Ein Grund, den wir uns vorstellen können ist, dass Anomalien es einfacher machen, die SSTs mit terrestrischen Aufzeichnungen zu kombinieren. Anomalien werden an Land aufgrund der Höhenunterschiede der Wetterstationen benötigt. Aber das hilft uns nicht bei unserer Aufgabe, die darin besteht, den durchschnittlichen globalen Ozeantemperaturtrend zu bestimmen. Landtemperaturen sind recht variabel, machen aber nur 29 % der Erdoberfläche aus.
In der WUWT-Diskussion zu meinem letzten Beitrag sagte Nick Stokes (sein Blog ist hier):
„Nur ein weiterer in einer endlosen Reihe von Gründen, warum man niemals absolute Temperaturen mitteln sollte. Sie sind zu inhomogen, und sie sind der Art und Weise ausgeliefert, wie auch immer Ihre Stichprobe ausgearbeitet wurde. Man mache das nicht, sondern man nehme zuerst die Anomalien. Sie sind viel homogener, und der ganze Kram mit Masken und fehlenden Gittern spielt keine Rolle. Das ist es, was jeder vernünftige Wissenschaftler tut.
Es stimmt also, dass die Durchschnittstemperatur schlecht definiert ist. Aber wir haben eine ausgezeichnete Vorstellung davon, ob sie sich erwärmt oder abkühlt. Das ergibt sich aus der durchschnittlichen Anomalie.“
Obwohl die Referenzperioden, 1961-1990 für HadSST und 1970-2000 für ERSST mit deutlich schlechteren und weniger konsistenten Daten berechnet wurden, als wir sie heute haben, sollen wir also immer noch Anomalien verwenden, weil sie homogener sind und weil „jeder vernünftige Wissenschaftler es tut“? Macht Homogenität die Anomalien genauer oder weniger genau? Nick sagt, dass Anomalien die Erkennung von Trends ermöglichen, unabhängig davon, wie sich das Gebiet oder die Messungen im Laufe der Zeit verändert haben. Aber die Anomalien mischen Post-Argo-Daten mit Prä-Argo-Daten.
Wie wir im letzten Beitrag gesehen haben, zeigen die Anomalien einen steigenden Temperaturtrend, aber die Messungen, gewichtet mit den Argo- und Driftbojendaten um das 6,8-fache, zeigen einen sinkenden Temperaturtrend. Was sollen wir glauben? Die neueren Messungen sind eindeutig genauer. Huang, et al. nennen die Argo-Daten „einige der besten verfügbaren Daten“. Warum werden diese guten Daten absichtlich herabgestuft, indem minderwertige Referenzmittel von den Messungen subtrahiert werden?
Nick erklärt, dass die Anomalien einen steigenden Temperaturtrend zeigen, weil sich seiner Meinung nach das Klima tatsächlich erwärmt. Er glaubt, dass die gemessenen Temperaturen eine Abkühlung zeigen, weil sich die Abdeckung der kalten Regionen mit der Zeit verbessert und dies einen künstlichen Abkühlungstrend erzeugt. Der Abkühlungstrend ist in Abbildung 1 zu sehen, die eine Darstellung der gemessenen HadSST- und ERSST-Temperaturen über derselben Ozeanregion zeigt. Nur 18% der Weltozeanzellen, im Jahr 2018, sind in Abbildung 1 dargestellt, hauptsächlich in den mittleren Breiten. Die in Abbildung 1 dargestellte Ozeanfläche ist viel größer als 18 %, da die fehlenden nördlichen und südlichsten Zellen kleinere Gebiete abdecken.
Der Plot unten zeigt fast den gesamten Ozean, unter Verwendung des ERSST-Gitters, das nur 3% Nullzellen hat. Die Zellen sind größtenteils mit interpolierten und extrapolierten Werten gefüllt. Die gemessenen Temperaturen sind stark gewichtet zugunsten der hochwertigsten Argo- und Bojenmessungen.
Der ERSST-Trend von 1,6 Grad pro Jahrhundert liegt nahe dem Trend, der in den HadSST- und ERSST-Anomalien zu sehen ist, wie aus Abbildung 3 hervorgeht:
Nick hat also einen Punkt. Abbildung 2 zeigt den ERSST-Trend, der größtenteils aus extrapolierten und interpolierten Daten besteht, aber fast den gesamten Ozean repräsentiert. Er zeigt eine Erwärmung von 1,6°/Jahrhundert. Dies liegt nahe an den 1,7°C/Jahrhundert, die von den HadSST-Anomalien und den ERSST-Anomalien gezeigt werden. Die eigentliche Frage ist, warum die HadSST-Anomalien, die dieselben Daten wie in Abbildung 1 verwenden und dasselbe Ozeangebiet abdecken, zunehmen? ERSST ist konsistent zwischen den Messungen und den Anomalien und HadSST ist es nicht, wie ist das passiert? Nick würde sagen, es ist die kontinuierliche Hinzufügung von polaren Daten, ich bin mir da nicht so sicher. Die Anzahl der besiedelten ERSST-Zellen nimmt nicht viel zu, und sie tendiert auch im HadSST-Gebiet nach unten.
Es ist wahrscheinlicher, dass sich die von HadSST abgedeckte Ozeanfläche abkühlt und der globale Ozean sich leicht erwärmt. Wenn das CO2 die Erwärmung verursacht und global ansteigt, warum nehmen dann die Temperaturen der Ozeane in den mittleren und niedrigen Breiten ab und die Polarregionen erwärmen sich? Siehe den letzten Beitrag, um Karten des Teils der Ozeane zu sehen, der von HadSST abgedeckt wird. Eine der Karten aus diesem Beitrag ist in Abbildung 4 dargestellt. Die weißen Bereiche in Abbildung 4 haben keine Werte im HadSST-Gitter, dies sind die Bereiche, die nicht zu Abbildung 1 beitragen. Das farbige Gebiet in Abbildung 4 zeigt eine abnehmende Ozeantemperatur.
Erkennen wir durch die Verwendung von Anomalien einen zugrunde liegenden globalen Trend? Oder verdecken die Anomalien eine zugrunde liegende Komplexität? Man betrachte die zusätzlichen Informationen, die wir durch die Verwendung der tatsächlichen Temperaturen aufgedeckt haben. Ein Großteil des Ozeans kühlt sich ab. Global gesehen erwärmt sich der Ozean vielleicht um 1,6 bis 1,7 Grad pro Jahrhundert, kaum etwas, worüber man sich Sorgen machen müsste.
Ein weiterer zu berücksichtigender Faktor ist, dass die Anzahl der HadSST-Beobachtungen von 2000 bis 2010 stark gestiegen ist, nach 2010 sind sie einigermaßen stabil. Dies ist in Abbildung 5 zu sehen. Der Temperaturrückgang in Abbildung 1 ist jedoch sehr gleichmäßig.
Schlussfolgerungen
In einem Punkt sind sich alle einig: Der Trend der Meeresoberflächentemperatur ist die wichtigste Einzelvariable bei der Messung des Klimawandels. Es sollte richtig und mit den besten Daten gemacht werden. Die Verwendung von minderwertigen Daten aus dem 20. Jahrhundert, um Anomalien zu berechnen, erzeugt einen Trend, der mit dem ERSST-Gitter übereinstimmt, was eine vernünftige Schätzung dessen ist, was global passiert, aber es gibt so viel Interpolation und Extrapolation in der Schätzung, dass wir nicht sicher sein können. Der Teil des Ozeans, für den wir genügend Daten haben, das HadSST-Gebiet, zeigt einen abnehmenden Trend. Das ist etwas, was man bei der Verwendung von Anomalien nicht sieht. Der abnehmende Trend ist auch in den ERSST-Daten über dem gleichen Gebiet zu sehen. Dies deutet darauf hin, dass es sich nicht um die Hinzufügung von neuen polaren Daten im Laufe der Zeit handelt, sondern um einen echten Trend für diesen Teil des Weltozeans.
Wahrscheinlich steigt die SST des gesamten Ozeans leicht an, mit der unauffälligen Rate von etwa 1,6°C/Jahrhundert. Dies zeigt sich in den Anomalien und in der ERSST-Darstellung. Aber dies ignoriert die offensichtliche Komplexität des Trends. In dem Teil des Ozeans mit den besten Daten sinkt die Temperatur. Unterm Strich wissen wir nicht sehr viel darüber, was die Ozeantemperaturen tun und wo es passiert. Da der Trend der Ozeantemperatur die wichtigste Variable bei der Feststellung des Klimawandels ist, wissen wir auch nicht viel über den Klimawandel. Nick hatte Recht, dass Anomalien in der Lage waren, den wahrscheinlichen Trend herauszupicken, vorausgesetzt, dass ERSST korrekt ist, aber durch die Verwendung von Anomalien wurden wichtige Details verschleiert.
Link: https://wattsupwiththat.com/2020/12/20/sea-surface-temperature-anomalies/
Übersetzt von Chris Frey EIKE
Kann man nicht absolute Angaben (die man ja bedarfsweise auch „mitteln“ könnte….) machen mit der Angabe der zugehörigen Meßunsicherheiten? Das Bild wäre wohl zu verheerend und würde die klimaalarmistischen Schlußfolgerungen zu schnell als Märchen entlarven.
Anomalie war für mich bisher im biologischen Sinn eine Fehlbildung, also eine tatsächliche „Abweichung“ vom „Normalen“. Soll uns beim Klima suggeriert werden, dass Temperaturen Fehlbildungen sind?
Wir bauen u.a. solche Fühler (mit kontinuierlicher Meßwicklung!!!) ….., zwar nur bis zu 20 /25 m Länge, aber das Ergebnis Ihres Gedankenexperiments wäre vertrauenswürdiger als das ganze Gedöns, was gegenwärtig veranstaltet wird.