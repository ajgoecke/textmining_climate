Der NOAA-Klimawissenschaftler und Aktivist Gavin Schmidt stellte die Arbeit von Dr. Christy in Frage und behauptete, dass seine Arbeit „parteiisch“ war und auf sehr schwammigen statistischen Argumenten beruhe, und dass Christy falsch dargestellt hatte, wie sich die Modelle machen. Diese Behauptungen des Wissenschaftlers in Diensten der Regierung Dr. Schmidt erregten das Interesse des Statistik-Experten Steven McIntyre, der einer der prominentesten Experten war bei der Entlarvung der betrügerischen Wissenschaft (Betrug bei den Proxys) und der falschen Mathematik (Statistik-Fehler), die hinter dem infamen und inzwischen vernichtend widerlegten, tausend Jahre langen Temperaturprofil stand, was unter der Bezeichnung „Hockeyschläger“ bekannt ist (hier, pdf).
Mr.McIntyre begutachtete die Behauptungen von Dr. Schmidt (hier) und fand heraus, dass seine Analyse, die das von Schmidt gezeigte Diagramm evaluiert, mit dem er seine Behauptungen gegen Schmidt vermeintlich untermauerte. McIntyre schrieb als Ergebnis dieser Evaluierung: „Zuerst diskutierte ich den Effekt einiger Fingerspielchen und zeigte dann, dass Schmidts Diagramm nach Entfernung der Fingerspielchen und im Vergleich mit statistischen Verteilungen Christys Arbeit eher bestätigt als ihm widerspricht“.
Außerdem zeigte Mr. McIntyre die Ergebnisse von Experten seiner Begutachtung der statistischen Ergebnisse von Dr. Christy, denen zufolge die Klimamodelle tatsächlich eine „Über-Erwärmung“ zeigten bei ihren Projektionen. Im Einzelnen:
● Ein Modelllauf ist wärmer als der gemessene Trend über mehr als 99,5% der Zeit;
● Ein Modelllauf ist wärmer als ein gemessener Trend um über 0,1°C pro Dekade während etwa 88% der Zeit;
● und er ist wärmer als ein gemessener Trend um über 0,2°C pro Dekade während über 41% der Zeit.
McIntyre folgert:
Unter dem Strich steht, dass Schmidts Diagramm Christy überhaupt nicht widerspricht und Schmidts Vorwürfe gegen Christy, dass sein Diagramm „parteiisch“ war, nicht einmal ansatzweise stützt.
Die Klimawissenschaftlerin Dr. Judith Curry hat eine neue Präsentation zu Klimathemen vorbereitet (mit 56 Folien; hier, pdf) in der sie viele klimawissenschaftliche Themen ansprach einschließlich der globalen Temperaturen und der immer größer werdenden Differenz zwischen aktuellen Temperaturmessungen und den erheblich warm-übertreibenden Temperaturprojektionen der Klimamodelle.
In ihrem Vortrag zeigt sie, dass der jüngste IPCC-Klimabericht AR 5 (2013) Informationen präsentierte, die zeigen (Folie 24), wie sehr Klimamodelle Projektionen der globalen Temperaturen im Vergleich zu tatsächlich gemessenen Daten jene erheblich überbetonen und übertreiben. Die von Dr. Christy bei der Anhörung im Kongress gezeigten Daten bzgl. der Übertreibungen der Klimamodelle hinsichtlich der globalen Temperaturen sind ebenfalls Bestandteil ihres Vortrags (Folie 25).
Zusätzlich zu diesen Übertreibungen der Klimamodelle der globalen Temperaturprojektionen haben diese Modelle auch versagt, was das Verhalten und den Einfluss großer natürlicher Klimavariationen angeht wie etwa ENSO, was in dem WUWT-Beitrag mit dem Titel [übersetzt] „Wieder einmal hat El Nino nicht das getan, was vorhergesagt war. Warum?“ (hier)
In seinem Beitrag schreibt Dr. Tim Ball:
„Das IPCC behauptete mit einer Sicherheit von 90%, dass die globale Erwärmung menschlichem CO2 geschuldet ist. Fehlende Daten in Kombination mit Auslassungen oder fehlendem Verständnis für grundlegende Prozesse sind die Hauptgründe, warum alle Prophezeiungen der Vergangenheit, der Gegenwart und der Zukunft falsch sind. Das Gleiche gilt für wesentliche Ereignisse innerhalb des Systems Erde-Atmosphäre, wie El Nino oder ENSO. Wie dieser Tage immer wieder gesagt wird: falls die Prophezeiungen falsch sind, ist die Wissenschaft falsch“.
Natürlich auftretende El Nino-Ereignisse haben und werden weiterhin globale Temperaturen und Temperaturtrends beeinflussen, wie sie es schon unzählige Male zuvor getan haben (hier).
In ihrem Vortrag zeigt Dr. Curry globale Temperaturdaten, die belegen, dass natürliche Klimavariationen in Verbindung mit dem starken El Nino von 1997/98 und 2015/16 ebenso wie kleinere El Nino-Ereignisse erheblichen Einfluss auf steigende globale Temperaturen und Temperaturtrends haben (Folie 13). Einige Klimaalarmisten haben behauptet, dass anthropogene CO2-Emissionen den jüngsten Temperaturanstieg und steigende Temperaturtrends ausgelöst haben, aber diese Behauptungen ignorieren auf unzulässige Weise den bedeutenden El Nino-Einfluss auf die jüngsten Temperaturen.
Der Einfluss der El Nino-Ereignisse zeigt sich bei Temperaturmessungen sowohl an der Erdoberfläche als auch in der freien Atmosphäre (Folie 14).
Klimaalarmistische Medien wie die New York Times drehen immer weiter die Leier bzgl. der jüngsten rekordhohen Temperaturen des Jahres 2016 als durch anthropogene CO2-Emissionen ausgelöst (hier). Allerdings basieren diese alarmistischen Behauptungen auf einer absichtlichen Marginalisierung der Bedeutung des starken El Nino 2015/16 als treibende Kraft hinter dieser jüngsten Erwärmung, wie aus Dr. Christys Präsentation ganz klar hervorgeht.
Eine Analyse der globalen Temperaturdaten zeigt eindeutig die Übertreibung der projizierten Temperaturen seitens der Klimamodelle im Vergleich zu tatsächlichen Messungen, wie die Arbeiten sowohl von Dr. Christy als auch von Dr. Curry zeigen. Außerdem tritt der bedeutende Einfluss natürlicher Klimaereignisse wie El Ninos auf die jüngsten globalen Temperaturen und Temperaturtrends klar hervor, was jedoch Dr. Ball zufolge in den Klimamodellen komplett unter den Tisch fallen gelassen wird.
Klimaalarmistische Wissenschaftler und Medien trachten danach, das bewiesene Scheitern der Klimamodelle hinsichtlich valider Temperaturprojektionen herunterzuspielen und zu ignorieren, wie die unverhohlen immer weiter zunehmende Divergenz dieser Modellergebnisse von tatsächlichen Messungen enthüllt.
Dr. Curry merkt an, dass das Thema Klimawandel ein „verzwicktes Thema“ ist (Folie 46), und dass sowohl das Problem als auch die Lösung „erheblich über-vereinfacht“ worden sei. Der Erlass kostspieliger und bürokratischer klimapolitischer Maßnahmen, die auf kläglich versagenden und wissenschaftlich ungeeigneten Klimamodellen beruhen, ist einfach nicht gerechtfertigt.
Link: https://wattsupwiththat.com/2016/05/25/climate-models-dont-work/
Übersetzt von Chris Frey EIKE
als Meteorologe mit über 40 Jahren Erfahrung gratuliere ich Ihnen zu Ihrem Kommentar! Sie haben es nämlich auf den Punkt gebracht.
Für die von Ihnen angesprochene Kombination von Temperatur und Feuchtigkeit gibt es nämlich einen Parameter, mit dem ich sehr ausgiebig gearbeitet habe. Dieser Parameter ist bekannt als die „pseudopotentielle Temperatur“. Für die Wettervorhersage ist dieser Parameter drastisch bedeutsamer als einfach nur die Temperatur.
Zur Erklärung: Feuchtigkeit kommt durch Verdunstung in die Atmosphäre. Dies verbraucht Wärme, die aber gemäß des Energieerhaltungssatzes nicht verloren ist. Man nennt sie „latente Wärme“. Bei der Kondensation wird diese Wärme wieder frei. Eine feuchte maritime tropische Luftmasse hat also bei 30°C viel mehr Energie als eine Wüstenluft mit fast 40°C, aber kaum Feuchtigkeit.
Bei der Bestimmung der pseudopotentiellen Temperatur wird die Feuchtigkeit rechnerisch aus der Luft entfernt und die frei werdende latente Wärme als fühlbare Temperatur der Lufttemperatur zugeschlagen.
Weiteres würde hier zu lang werden und auch vom Thema des Beitrags wegführen. Falls Sie näheres wissen wollen, schreiben Sie mir doch eine E-Mail!
Dipl.-Met. Hans-Dieter Schmidt
hier haben Sie herrlich kurz und klar die Sache dargestellt.
Es ist die Feuchtigkeit, die relative Feuchtigkeit, die hier beachtet werden muss. Und da muss man einfach mal nachrechnen um wieviel Wasser und der beteiligten Temperatur es sich hier handelt. Und wenn ich dann weiterdenke und das ganze für Grönland kalkuliere, habe ich die Temperatur gleich doppelt! Mit Strahlung ist da nichts!
Mit freundlichen Grüßen
Winfried Zeugner
könnte man nicht eigentlich sogar sagen, dass nicht einmal die Temperatur allein zu irgend welchen prognostischen Aussagen taugt?
(Ich bezweifele zunächst, dass die Min-Max-Temperaturen irgend eine Relevanz besitzen – abgesehen für Obstbauern.)
Meiner Meinung nach sollte die Kombination Luftfeuchtigkeit/Temperatur betrachtet werden. Immerhin handelt es sich um Energieumwandlungen und -transporte. Die Energiemengen resultieren aber immer als Resultierende aus Temperatur und Luftfeuchte. Energetisch sind doch 40°C in der Libyschen Wüste ganz anders zu bewerten als im Regenwald des Kongo. Liege ich da richtig?
Herzlichst PM
Die simple Frage, ob mehr CO2 in der Luft wärmt oder kühlt, beantwortet jedes IR-Fernthermometer. Die IR-aktive Atmosphäre kühlt und wärmt nicht. Kühlen kann sie aber nur, weil sie IR-aktiv ist dank H2O und CO2, denn N2 und O2 sind IR-inaktiv.
Der Ozean ist das Treibhaus mit 16°C im Mittel übers 20. Jhdt statt 9°C über Land laut NOAA Daten im Internet.
“ Die ersten Forscher progonstizieren auch für 2017 sehr warme Temperaturen, “
Warme temperaturen gibt es nicht und was derartige Prognosen bzgl. höherer Temperaraturwerte betrifft, so ist deren Eintreffwahrscheinlichkeit unbestimmt oder derartige Prognosen US-amerikanisch vulgär bewertet: Bullshit. Entspricht in etwa den Aussagen in den ‚heiligen‘ Büchern bzgl. Himmel und Hölle und dem möglichen Erlaß der Sünden bei monetärem Wohlverhalten.
lernen Sie erst einmal, daß es keine „Globaltemperatur“ gibt.
Am besten jeden Tag 100 mal sagen_ Es gibt aus thermodynamischen gründen keine „Globaltemperatur“.
Es ist immer wieder erstaunlich, daß die Kritiker der GCM (vulgo: Klimamodelle) sich auf die arithmetisch ermittelte „Globaltemperatur“ einlassen, die in der Realität weder für die Gegenwart und erst recht nicht für die Vergangenheit ermittelt werden kann. Es gibt und gab nie genügend Meßstationen.
Einzig der lokale Vergleich zeigt, was die GCM können und was nicht. Vernünftige Meßserien in Mitteleuropa und den damals besiedelten USA gibt es erst seit maximal ca. 150 Jahren. Es reicht aber aus sich bei den USA mit der Zeit nach 1930 zu begnügen, als das COOP-Netz ausgeweitet wurde. Damit stehen 75 Jahre zur Verfügung, um einen Vergleich der Statistik und der Trends zwischen Realität und Hindcast zu tätigen. Naturgemäß ist eine Beschränkung auf die Minimum- und Maximumtemperaturen vorgegeben, denn nur die wurden flächendeckend gemessen, einmal am Tag, entweder am Morgen oder am Abend.
Was kommt dabei heraus? Die GCM können es nicht, d.h. es stimmt weder der Trend noch stimmen die absoluten Werte noch stimmt die Variabilität.
Damit sind die Behauptungen derjenigen, die den Modellen eine zuverlässige Vorhersagefähigkeit attestieren und damit Politik machen, falsifiziert. Anders gesagt: Die Modelle taugen nicht zur Prognose der Zukunft, weil sie die gemessene Vergangenheit regional nicht abbilden können. Die Statistiken stimmen nicht überein. Ob man das mit den ESM (Earth-System-Models) in absehbarer Zeit erreichen kann, darf bezweifelt werden, denn dazu müßten die Ozeanmodelle erst einmal AMO, PDO, ENSO und andere periodisch auftretende Temperaturänderungen incl. der dazugehörigen Meeresströmungen (Golfstrom) zuverlässig reproduzieren können, denn die treiben die atmosphärischen Strömungen mit an, wobei es Rückkopplungen gibt.