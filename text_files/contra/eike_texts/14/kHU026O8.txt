Heute dagegen brauchen wir beispielsweise auf einem Flug von New York nach Los Angeles detailliertere und zuverlässigere Wetterinformationen, wie z. B. ob es bei der Zwischenlandung in St. Louis schneit. Oder der Landwirt in Nebraska, der die Vorhersage für die Frühjahrsweizenproduktion in der Ukraine sehen muss. Er braucht die bestmöglichen Informationen, um besser abschätzen zu können, wie viele Hektar Winterweizen er für die heutigen globalen Märkte anbauen sollte.
Wir brauchen vor allem bessere und zuverlässigere Informationen, um zu entscheiden, welche Maßnahmen wir zur Vorbereitung auf Klimaveränderungen in Betracht ziehen sollten.
Während Wissenschaftler, Ingenieure und Software-Programmierer die Bedeutung und die Notwendigkeit dieser Datengenauigkeit kennen, ist sich die breite Öffentlichkeit nicht bewusst, wie herausfordernd diese Aufgaben sein können.
Wenn wir langfristige Klimadaten betrachten, müssen wir unter Umständen mehrere Proxies (indirekte Messgrößen, von denen wir hoffen, dass sie direkt mit dem Wetter variieren) verwenden, die eine zusätzliche Ebene von Komplexität, Kosten und Fehlerquellen hinzufügen. Einer der am häufigsten verwendeten Proxies sind die alten Temperatur- und CO2-Werte aus Eiskernproben. In den letzten paar hundert Jahren waren auch Baumringdaten eine primäre Quelle für die Jahrestemperaturen. Aber seit dem letzten halben Jahrhundert werden direkte atmosphärische Messwerte verwendet, die sehr genau und zuverlässig sind.
Aus Abbildung 1 geht hervor, dass der CO2-Gehalt ab Mitte der 1950er Jahre dramatisch anstieg. Wir haben aufgehört, Proxies zur Messung des atmosphärischen CO2-Gehalts zu verwenden, und haben begonnen, direkte Messwerte von der Mauna Loa Wetterstation auf Hawaii zu verwenden. Wir müssen uns also fragen, ob dieser dramatische Anstieg des CO2-Gehalts real war, oder ob er durch die Änderung des Messverfahrens teilweise verzerrt wurde. Oder wir haben in den frühen 1960er Jahren aufgehört, Baumringdaten zu verwenden. In der Zeit, als wir sowohl Baumring- als auch Thermometer-Aufzeichnungen hatten, wurden gewisse Diskrepanzen festgestellt. Wir können solche Änderungen in den Messungen nicht vornehmen, ohne Raum für Zweifel zu lassen.
Abbildung 1 zeigt zum Beispiel den CO2-Gehalt der Jahrtausende alten antarktischen Eisschilde. Vor Mitte der 1950er Jahre wurden die CO2-Schätzungen auf der Grundlage des CO2-Gasgehalts der Eisbohrkerne berechnet. Die auf diese Weise gemessenen CO2-Gehalte schienen über einen Zeitraum von mehreren zehntausend Jahren nie viel über 280 ppm zu steigen.
Man beachte nun, dass wir, beginnend vor etwa 6.000 Jahren, einen kleinen, aber stetigen Anstieg sehen, wenn wir von links nach rechts schauen. Und der Anstieg scheint bis Mitte der 1990er Jahre einigermaßen konstant zu sein. Hier ist die klassische Annahme, dass sowohl das CO2 als auch die Temperaturen gestiegen sind.
Kürzlich haben sich Wissenschaftler die abwärts gehende Neigung angesehen, wenn wir in den 1950er Jahren stehen und von rechts nach links schauen. Dabei stellt sich die Frage, ob das CO2 durch das enorme Gewicht der Gletscher herausgedrückt wird, während sie altern, und vielleicht auch in Kombination mit CO2, das chemisch gebunden wird, und in welchen Anteilen. Ab Mitte der 1950er Jahre sehen wir einen sehr deutlichen und schnellen Anstieg der CO2-Werte, und wir sehen die inzwischen bekannten CO2-Hockeyschläger. Ist das CO2 so schnell angestiegen, oder war es Teil der Anomalie, die durch die Änderung der Messmethoden verursacht wurde? Wir denken Letzteres.
Woher soll der Durchschnittsbürger das wissen? Wurde diese dramatische Veränderung jemals genau und verständlich erklärt? Wir wollen das erst einmal allgemeiner als „Datenintegrität“ bezeichnen.
Hier ist ein weiteres einfaches Beispiel. Wenn wir die Temperatur in der Gegend von Boston vor 200 Jahren messen wollten, hätten wir vielleicht zwanzig Thermometer an zwanzig verschiedene Orte gebracht. Wir hätten einige allgemeine Entscheidungen getroffen, einige entlang der Küste und den Rest an verschiedenen Stellen in der Stadt und auf dem Land zu platzieren – vor allem auf Bauernhöfen. Wir hätten vielleicht nur ein oder zwei in den Bergen oder Wäldern aufgestellt, weil diese Stationen bemannt sein und die Daten mehrmals am Tag aufgezeichnet werden mussten. Dann, vielleicht ein- oder zweimal pro Tag oder Woche oder Monat, könnten sie konsolidiert worden sein, um eine durchschnittliche „Boston-Temperatur“ für Oktober 1820 zu erhalten. Wie würde es aussehen, wenn die Boston-Temperatur im Oktober 1920 bzw. 2020 verglichen werden, um zu sehen, ob sie gestiegen ist oder nicht? Nun, das stellt eine ziemliche Herausforderung dar:
● In den letzten hundert Jahren könnten einige Bäume um das Thermometer herum gewachsen sein, während die Thermometer im Jahr 1920 vielleicht den ganzen Tag in der vollen Sonne standen. Was nun?
● Einige Instrumente wurden aus irgendeinem Grund verschoben, z. B. wegen einer großen Autobahnbaustelle; wie hat sich das auf die Temperaturmesswerte ausgewirkt?
● Einige Instrumente könnten nach und nach für Monate oder sogar Jahre nicht mehr kalibriert worden sein, bevor sie repariert oder ersetzt wurden. Was machen wir mit den verdächtigen Daten während des fraglichen Zeitraums? Ignorieren?
● Wenn die Instrumente ersetzt wurden, wie wurden sie ersetzt? Einige Variablen sind die gleiche Höhe über dem Boden, der gleiche Schutzkasten, Quecksilber ersetzt durch Alkoholthermometer oder Thermoelemente, usw.
● Eine Wetterstation befand sich in der Nähe einer unbefestigten Straße, bis sie 1926 mit Zement und 1963 mit Asphalt bedeckt wurde? Später wurde sie wieder zu einem Feldweg umgestaltet, als das Gebiet 2004 zu einem Naturpark wurde?
● Wie würden wir diese Temperaturen[iii] mit den Temperaturen bis zum Jahr 2020 vergleichen, kontrastieren und integrieren? Sehr unterschiedlich und sehr herausfordernd:
1) Instrumente, die einst auf einer Weide standen, befinden sich jetzt in der Nähe von Flughafenlandebahnen und Düsenabgasen!
2) Ein anderes war in der Nähe einer schattigen, sandigen Straße, die jetzt ein asphaltierter Parkplatz ist.
3) Thermoelemente haben viele Thermometer ersetzt; wie wurden die Messwerte „zusammengestoppelt“?
4) Andere Wetterstationen wurden einfach wegen der hohen Kosten für ihre Wartung aufgegeben oder durch ein ferngesteuertes Thermoelement oder Telemetrie ersetzt.
5) Wie kann man[i] die Auswirkungen der Umweltverschmutzung der 1960er bis 1990er Jahre mit dem unberührten Himmel der 1800er Jahre in Einklang bringen, wenn Wolken eine so wichtige Rolle spielen?
6) Und die Wolkendecke von 1820 war wahrscheinlich ganz anders als heute, als Folge der zunehmenden Menge an „Aerosolen“, die eine wichtige Rolle bei der Wolkenbildung, dem „Treibhaus“- und dem „Albedo“-Effekt spielen.
In den letzten Jahrzehnten, und vor allem seit der Satelliten-Ära, wurden Hunderte von erdgebundenen Wetterstationen aus verschiedenen Gründen aufgegeben, unter anderem aus Kostengründen und wegen der Zuverlässigkeit der Daten. In den letzten Jahrzehnten haben die NASA und die NOAA versucht, aktuelle und historische Wetteraufzeichnungen an Land und auf dem Meer zu „normalisieren“. Abbildung 2 zeigt zwei Sätze von genau denselben Daten! Die blaue Linie repräsentiert die tatsächlichen landbasierten Temperaturen von 1.218 Stationen in den USA, als die Messwerte aufgenommen wurden. Man vergleiche das mit der roten Linie, die genau die gleichen Temperaturaufzeichnungen darstellt, aber nachdem sie von der NOAA „normalisiert“ wurden*.
*In einem Beitrag bei Real Climate Science wird schon Ende 2016 festgestellt: „Das Problem mit der NOAA-Graphik besteht darin, dass es Fake-Daten sind. Die NOAA erzeugt den Erwärmungstrend künstlich mittels Veränderung der Daten. Die RohDaten der NOAA zeigen im vergangenen Jahrhundert keinerlei Erwärmung“.
„Normalisierung“ hat eine praktische Grundlage. Es ist ein bisschen so, als würde man die Menge des Obstes berechnen, wenn man Äpfel zu Orangen addiert. Allerdings ist der Prozess anfällig für fehlerhafte Annahmen und Ausführung. Der prominente Umweltwissenschaftler Donald Easterbrook behauptet, dass die bisherigen historischen Aufzeichnungen absichtlich manipuliert wurden, wie in Abb. 2 dargestellt. Es wurde der Vorwurf erhoben, dass diese Temperaturen verzerrt wurden, um in das aktuelle Narrativ des CO2-induzierten globalen Klimawandels zu passen. Die historischen Daten der blauen Linie wurden in den letzten Jahrzehnten mindestens viermal verändert, und nun in ihrer endgültigen Form zeigt die rote Linie einen dramatischeren, steileren Temperaturanstieg seit den 1980er Jahren, indem die Temperaturen in den vorangegangenen Jahrzehnten gesenkt wurden! Wenn wir heute aufgefordert werden, Multi-Billionen-Dollar-Entscheidungen zu treffen, die auf unserer Temperaturhistorie des letzten Jahrhunderts basieren, sind sie schwerwiegend und folgenreich geworden.
For more information we recommend our book A Hitchhikers Journey Through Climate Change, coming soon to the CFACT store at CFACT.org.
[i] http://www.clker.com/clipart-thermometer-in-beaker.html
Autoren: CFACT Senior Science Analyst Dr. Jay Lehr has authored more than 1,000 magazine and journal articles and 36 books. Jay’s new book A Hitchhikers Journey Through Climate Change written with Teri Ciccone is now available on Kindle and Amazon.
Terigi Ciccone is an Engineer, Science Enthusiast and Artist. Loves reading and travel, Naturalist, Author of the new book “A Hitchhiker’s Journey Through Climate Change.”
Link: https://www.cfact.org/2021/01/05/how-accurate-are-our-weather-and-climate-measurements/
Übersetzt von Chris Frey EIKE
7 Bemerkungen