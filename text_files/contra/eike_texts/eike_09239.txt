Die neueren CMIP6-Klimamodelle sind demzufolge eher noch schlechter. Gleichzeitig sind Land-Temperaturdaten durch verfälschende Wärmeinseleffekte z.B. in den USA zu 100% übertrieben (tatsächlich 0,13 statt 0,26 Grad/Dekade Temperaturanstieg), wie Roy Spencer und Anthony Watts nachweisen. Für Deutschland zeigen die Ergebnisse von Kowatsch und Kämpfe Ähnliches. Viele weitere Beispiele ließen sich aufführen.
Auf einer derart fragwürdigen Basis gründet der Klima-Alarm. Ganz im Gegensatz dazu die Wahrnehmung in der Öffentlichkeit: Der menschengemachte Klimawandel scheint inzwischen überall verinnerlicht, wobei unsere in der Mehrzahl rotgrünen Medien nach Kräften mithelfen. Selbst Artikel in TE sind inzwischen so abgefasst, als gäbe es an dieser „grundlegenden Erkenntnis“ nichts mehr zu rütteln. Und Grüne, die den Kindesmissbrauch vor nicht allzu langer Zeit noch schön geredet haben, setzen heute auf grüne Klima-Indoktrination von Kindern.
Beim Kinderspiegel, gefunden bei Kalte Sonne, liest es sich dann so: „Kurz: Am gegenwärtigen Klimawandel sind wir Menschen schuld, wir ganz allein.“ Man wird unwillkürlich an Goebbels erinnert: Man muss etwas nur oft genug wiederholen, dann wird es als Wahrheit geglaubt. Und die Medien, die Religionen und die Schulen helfen dabei wieder nach Kräften mit.
Der IPCC gibt für die CO2-Klimasensitivität seit neuestem eine Spanne von 1,6 bis 5,6 Grad C (zuvor 1,5 bis 4,5 Grad C) an je nach angenommener Verstärkung, aber nur mit einer Wahrscheinlichkeit von 66%. Man kann sich natürlich fragen, warum beharrt der IPCC bei der Berechnung der globalen CO2-Klimasensitivität seit Jahrzehnten auf seinen zwar rechenintensiven, aber großenteils unverstandenen Klimamodellen samt der zugehörigen großen Unsicherheiten. Es drängt sich der Verdacht auf, die Alarmforschung bewahrt sich mit Hilfe der großen Unsicherheitsspannen ganz bewusst den Spielraum für Klima-Alarm – wofür die Alarmforschung von der Politik schließlich gegründet wurde.
Nach dem Motto, was nicht mit letzter Sicherheit auszuschließen ist, kann weiterhin als Bedrohung verwendet werden. Wie z.B. die phantasievoll erfundenen Kipppunkte des Potsdamer Klimainstituts PIK. Man stelle sich vor, ein plötzlich Klima-realistischer IPCC käme zu dem Ergebnis, dass es keine ernsthafte Klima-Bedrohung durch den Menschen gibt – die Folgen wären schlichtweg undenkbar und in höchstem Maß unerwünscht!
Der Versuch, sich der Klima-Problematik mit einem alternativen Ansatz zu nähern, wurde kürzlich bei EIKE in nachfolgendem Beitrag veröffentlicht. Einige wichtige Punkte werden hier nochmals aufgegriffen – nicht zuletzt infolge der stattgefundenen Diskussion:
Anthropogener Treibhauseffekt: nach wie vor zu schwach für die Klimakatastrophe! – EIKE – Europäisches Institut für Klima & Energie (eike-klima-energie.eu)
Dort wird der Gesamtantrieb, der weiter unten noch genauer beschrieben wird, aus der Energiebilanz an der Erdoberfläche berechnet. An der Erdoberfläche, wo wir leben, wird das wärmende Sonnenlicht absorbiert, deutlich weniger hingegen in der überwiegend dünnen und kalten Atmosphäre weiter oben. Von der Erdoberfläche wird auch wieder Energie abgeben, die über die Atmosphäre, die Wolken und letztlich durch Infrarot(IR)-Strahlung den Weg zurück ins Weltall findet. Dazu siehe auch die Strahlungsgrafik von Trenberth & Kiel weiter unten.
Kirchhoff’sche Knotenpunktregel gegen IPCC-Klimamodelle
Die vielen verschiedenen positiven (und auch negativen) Antriebe in einer komplizierten Atmosphäre samt ihrer Verstärkungs- oder Abschwächungsmechanismen kann kein Mensch korrekt berechnen. Im Oberflächenmodell lassen sie sich als Antriebssumme aus der Oberflächenbilanz ermitteln.
Weshalb ist das möglich? Ganz einfach, die Antwort gibt die Kirchhoff’sche Knotenpunktregel. Nachfolgend wird eine Grafik von Wikipedia verwendet. Zu beachten ist dabei, dass der Knotenpunkt keine zusätzliche Strom- bzw. Energiequelle enthält. Die Pfeilrichtungen sind unbedeutend, sie geben nur die Zählrichtung vor. Flussrichtungen entgegen der vorgegebenen Pfeilrichtungen sind gleichbedeutend mit negativen Vorzeichen. Auch kommt man im Oberflächenmodell mit nur vier „Pfeilen“ aus.
Was ist jetzt der Trick bei der Knotenpunktregel? Wenn man gemäß der Grafik Größe und Vorzeichen von vier Pfeilen kennt oder sie anderweitig bestimmen kann, dann kann man den fünften (I1 in diesem Beispiel) aus der Summenbilanz ausrechnen, egal wie groß, komplex und unberechenbar das Netzwerk ist, das den Pfeil I1 letztlich verursacht und bestimmt. So kann man auch im Oberflächenmodell den Gesamtantrieb aus den anderen Energieflüssen berechnen, egal, wie kompliziert, komplex und unverstanden die Auswirkungen der zugehörigen Atmosphäre auf den Gesamtantrieb sind. Der Knotenpunkt steht dabei für die Erdoberfläche.
Der Mythos von der „Gegenstrahlung“
Die häufigen Diskussionen bei EIKE um die ominöse „Gegenstrahlung“ kommen nicht von ungefähr. Hierzu nochmals das Strahlungsdiagramm von Trenberth & Kiel:
Ohne „Gegenstrahlung“ wäre in diesem Strahlungsdiagramm die IR-Ausstrahlung von der Erdoberfläche in Höhe von 396 Watt/m², die mit dem Stefan-Boltzmann’schen T4-Strahlungsgesetz errechnet wird, um enorme 333 Watt/m² zu hoch. Mehr als doppelt so hoch, wie an erwärmender Sonnenenergie auf der Erdoberfläche überhaupt eintrifft, was weder von der TK-Strahlungsbilanz noch von der Energiebilanz unterstützt wird – dazu siehe auch die Grafik unten. Diese ominöse „Gegenstrahlung“, die nach T&K den größten Teil der Stefan-Boltzmann’schen Oberflächen-Ausstrahlung von 396 Watt/m² kompensieren soll, hat eine einfache Erklärung:
In der dichteren, unteren Atmosphäre und am Übergang zum Boden herrscht überwiegend ein ungerichtetes Strahlungs- und Stoßgleichgewicht ohne irgendeine Vorzugsrichtung, wobei ein Netto-Energietransport in Richtung der Temperaturgradienten stattfindet – was der klassischen Definition der Wärmeleitung in Gasen bzw. hier in Luft entspricht.
Ein Gleichgewicht, das bei T&K irreführend in die beiden gegenläufigen, großen vertikalen Strahlungskomponenten „Ausstrahlung“ und „Gegenstrahlung“ aufgesplittet wird. Obwohl diese beiden fiktiven Strahlungsflüsse in Wirklichkeit eine untrennbare Einheit bilden, die auf mikroskopischer und molekularer Ebene nicht nur in vertikale, sondern in alle Richtungen strahlen – verursacht durch unzählige Absorptions- und Emissionsprozesse.
Was dann dazu führt, dass man aus allen Richtungen eine solche „Gegenstrahlung“ empfangen und messen kann. Die direkt nach oben durchgehende IR-Strahlung, die nicht mit den Klimagasen wechselwirkt, weil die Frequenzen im durchlässigen IR-Strahlungsfenster liegen, werden bei Bewölkung von der Wolkendecke absorbiert und teilweise zurückgestrahlt. Deshalb misst man bei Bewölkung eine erhöhte „Gegenstrahlung“ aus Richtung der Wolkendecke.
Die Wärmeleitung in Luft ist aber um Größenordnungen zu niedrig (was man mit Hilfe der bekannten Wärmeleitwerte für Luft leicht nachprüfen kann), um zur Strahlungsbilanz im T&K-Diagramm und somit zu der Energiebilanz nennenswert beizutragen. Deshalb fehlt korrekterweise genau dieser Teil bei der letztlich ausgestrahlten Energie. In einer Atmosphäre, die nicht strahlungsaktiv ist, würde auch dieser Teil ungehindert ausgestrahlt und gemäß Stefan-Boltzmann’schem T4-Strahlungsgesetz die Wärmeausstrahlung um ein Vielfaches erhöhen. In Wirklichkeit ist die Atmosphäre in großen Teilen des IR-Spektrums strahlungsaktiv und somit „wärmeisolierend“- hauptsächlich dank Wasserdampf und dem Spurengas CO2.
Die verbleibende, kühlungswirksame (Netto-)Ausstrahlung von 63 Watt/m² nach T&K, die nurmehr ca. 15% einer „ungebremsten“ Stefan-Boltzmann-Ausstrahlung ausmacht, wird bei fehlender Bewölkung teilweise direkt in den Weltraum ausgestrahlt (40 Watt/m² bei T&K), weil die zugehörigen Frequenzen im atmosphärischen Fenster liegen und nicht mit den Klimagas-Molekülen wechselwirken. Der Rest (23 Watt/m² bei T&K) wird von den Klimagas-Molekülen der höheren und dünneren Atmosphäre ausgestrahlt. Letzteres zusammen mit der aufgestiegenen Konvektions- und Verdunstungswärme – die Wärmeabgabe an den Weltraum erfolgt dann letztlich durch Infrarot-Strahlung. Die relativ geringe Wärmeleitung der Luft trägt aber mit dazu bei, dass sich das Temperaturgefälle zwischen Erdoberfläche und Weltraum einstellt.
Nachfolgende realistische Darstellung der Energiebilanz der Erde ist bereits in einem Lehrbuch „Physics of Climate“ aus dem Jahr 1992 zu finden und wurde vor einigen Jahren von der US-NOAA wieder übernommen. Trotz einiger Abweichungen bei den Zahlenangaben ist diese Darstellung insgesamt klarer, kommt ohne die ominöse „Gegenstrahlung“ aus und wird deshalb hier nochmals gezeigt:
Die „geheimnisvollen“ Antriebe
Es gibt unterschiedliche Wirkmechanismen, die die Temperaturen erhöhen oder auch absenken können. Für die rechnerische Beschreibung hat sich der sog. „Antrieb“ (engl. „forcing“) als praktikabel erwiesen, der rechnerisch einer Heiz- oder Kühlleistung in Watt/m2 gleicht. Dabei handelt es sich meist um keine zusätzliche Energiequelle, sondern vielmehr um erhöhte oder verringerte Wärmeisolation, wie es auch beim anthropogenen CO2 oftmals angenommen wird.
Der Theorie nach wird die spektroskopische Erwärmung durch CO2 mittels ungerichteter IR-Emissionen und Absorptionen bei den CO2-Resonanzfrequenzen bewirkt, was eine Verringerung des Wärmetransports zur Folge hat. Verschiedentlich wird auch das Bild der rückgestrahlten IR-Energie benutzt, um die die Abstrahlung in den Weltraum verringert wird.
Beim Antriebskonzept wird jetzt so gerechnet, als würde eine Erwärmung durch entgegen gerichtete Energiezufuhr („Antrieb“) bewirkt. Obwohl diese zusätzliche Energiezufuhr oder Heizquelle in vielen Fällen nur fiktiv ist. Dies wirkt etwas irritierend, ist aber üblich und bewährt, was am Beispiel des CO2 nachfolgend gezeigt wird.
Bei CO2 errechnet man einen Strahlungsantrieb von 3,7 Watt//m2, der bei CO2-Verdoppelung wirksam wird und die Temperaturen um 1,1 Grad C (bei einigen Autoren etwas mehr) erhöht. Diesen Temperaturanstieg nennt man dann CO2-Klimasensitivität. Tatsächlich handelt es sich um einen verringerten IR-Strahlungstransport, wie folgende Grafik der in den Weltraum emittierten Infrarotstrahlung in Abhängigkeit von der Frequenz zeigt (nach Prof. Happer et al.):
Es gelangt bei den Frequenzen, bei denen das Spurengas CO2 IR-Strahlung absorbiert und emittiert, weniger IR-Strahlung in den Weltraum. Happer et al. haben diese Grafik errechnet, sie stimmt aber sehr gut mit den IR-Spektren überein, die aus dem Weltraum gemessen werden – allerdings nur über Wüsten und bei trockener Luft. Andernorts werden diese Spektren durch Aerosole und Bewölkung stark deformiert. Über der Südpolregion verkehren sich die CO2-Vertiefungen in Ausstülpungen – dort erhöht das atmosphärische CO2 die IR-Abstrahlung und wirkt somit kühlend. Was den starken Einfluss der jeweiligen atmosphärischen Bedingungen auf das Abstrahlverhalten der Klimagase deutlich macht. Und eine Ahnung davon gibt, wie schwierig es ist, die Wirkung der jeweiligen Klimagase samt etwaiger Rückkopplungen in einer realen Atmosphäre mit IPCC-Klimamodellen korrekt zu ermitteln.
Ein weiterer wichtiger Punkt wird in dieser Grafik sehr gut sichtbar, nämlich, dass eine weitere CO2-Verdoppelung, wie hier von 400 (schwarz) auf 800 ppm (rot), wegen der spektroskopischen Sättigung nur mehr sehr wenig bewirkt. Hinzu kommt der Einfluss der komplizierten Atmosphäre, der in dieser errechneten Grafik nicht sichtbar wird. Deshalb sind auch die großen Unsicherheitsspannen bei den IPCC-Klimamodellen nicht überraschend.
Oberflächenbilanz und Verdunstungswärme
Sofern durch anthropogene Klimagase, variierende Sonneneinstrahlung (So) und andere natürliche Einflüsse Änderungen in der Oberflächenbilanz auftreten, sind sie im Gesamtantrieb X enthalten – siehe nachfolgende Ergebnistabelle, die aus der eingangs zitierten Arbeit übernommen wurde:
Die ausgehende IR-Strahlung Erad dürfte nach den vorausgegangenen Abschnitten näherungsweise richtig berechnet sein. Auch trägt sie nur maximal 1 Watt/m² zum Gesamtantrieb in Höhe von ca. 7 Watt/m² bei, bezogen auf 1 Grad C Temperaturerhöhung.
Als der mit Abstand wirkungsvollste Kühlmechanismus erweist sich an der Erdoberfläche demnach die abgeführte Verdunstungswärme Evap, die laut einer vorausgegangenen EIKE-Veröffentlichung (hier) global um 7,5% je 1 Grad C Temperaturanstieg zunimmt. Dieser Wert scheint naheliegend, denn auch der Dampfdruck wächst in gleicher Weise mit der Temperatur. Und somit auch der Wasserdampfgehalt in der Atmosphäre und der Wärmeeintrag durch Verdunstung. Gefunden wurde dazu eine Pool-Tabelle, die diesen Zusammenhang tendenziell und größenordnungsmäßig bestätigt. Auch spielen die Feuchtigkeit des Untergrunds (z.B. Land oder Ozeane), der Luft und die Windverhältnisse eine große Rolle.
Über einen interessanten, neu erforschter und publizierter Kühleffekt wird in der Klimaschau von Dr. Lüning (Ausgabe 16, ab etwa 5. Minute) berichtet: In den Tropen zieht aufsteigender Wasserdampf kalte, wasserdampfhaltige Luft mit nach oben. Dieser Kühleffekt wächst exponentiell mit der Temperatur und stellt damit einen zusätzlichen, bedeutenden Klimastabilisator dar und ist eine weitere Verstärkung der Verdunstungskühlung.
Eine weitere Möglichkeit zur Überprüfung bietet die Niederschlagsbilanz. Sämtlicher Wasserdampf, der durch Verdunstung in die Atmosphäre gelangt, kehrt als Niederschlag zur Erdoberfläche zurück. Wenn bei 1 Grad C Temperaturerhöhung die Verdunstung samt mitgeführter Verdunstungswärme um 7,5% zunimmt, dann müssten die Niederschläge ebenfalls um 7,5% zunehmen.
Ganz allgemein schreibt z.B. das österreichische ZAMG (Zentralanstalt für Meteorologie und Geodynamik): „Der Gesamtniederschlag wird auf der Erde im wärmeren Klima tendenziell zunehmen.“ Und das deutsche Umweltbundesamt: „Seit 1881 hat die mittlere jährliche Niederschlagsmenge in Deutschland um rund 10% zugenommen … insbesondere sind die Winter deutlich nasser geworden.“ Das ist jetzt nur Deutschland.
Der Berliner Senat, Ressort Umwelt, führt dazu aus: „Die Niederschlagsentwicklung abzuschätzen ist mit großen Unsicherheiten behaftet. Der globale Niederschlag hat eine sehr große räumliche und zeitliche Variabilität. Über Europa haben die Niederschläge im letzten Jahrhundert um 6 bis 8 % zugenommen, wobei die Zunahme mehrheitlich (10 bis 40 %) über Nordeuropa erfolgte und im Mittelmeerraum und Südeuropa ein Rückgang um bis zu 20 % zu verzeichnen war.“
In einer Fundstelle findet man die Arbeit von L. Jäger „Die globale Niederschlagsverteilung und ihre Veränderung im 20. Jahrhundert“. Dort werden tabellarisch verschiedene Autoren und die von ihnen ermittelten globalen Niederschlagswerte zu den jeweiligen Jahren angegeben. Mittels linearer Regression erhält man aus diesen Daten einen Anstieg von 34%. Sehr wahrscheinlich ein zu hoher Wert, was Folge von vielen möglichen Fehlerquellen sein dürfte.
Vermutlich realitätsnäher sind die Anomaliewerte für die globalen Niederschläge, die von der US-Umweltbehörde EPA gemäß nachfolgender Grafik veröffentlicht wurden. Die globalen Niederschläge stiegen den EPA-Angaben zufolge mit 0,08 inches/Dekade, während sie über Festland-USA (48 Staaten) um 0,17 inches/Dekade zunahmen. Nimmt man in Anlehnung an Jäger den globalen Mittelwert mit 40 inches an, dann sind laut EPA die globalen Niederschläge, bezogen auf 40 inches, sei 1900 nur um 2,4% angestiegen.
Vergleich Oberflächenmodell und Klimamodelle
Geht man von den EPA-Daten aus, dann stellt sich die Frage, warum bei den erwarteten globalen Niederschlägen, die um 7,5% je 1 Grad Temperaturerhöhung zunehmen sollten, nur eine mittlere Zunahme von 2,4% gemessen wurde. Obwohl die globalen Temperaturen gleichzeitig um etwa 1 Grad C gestiegen sind. War der globale Temperaturanstieg nur halb so groß wie bei den publizierten Temperaturen? Dies wäre angesichts der zahlreichen Adjustierungen nicht völlig auszuschließen. Oder sind die Niederschlagsmessungen nicht zuverlässig genug? Die ungleich größere Zunahme der globalen Niederschläge bei Jäger deutet in diese Richtung.
Wenn man, wie nachfolgend, von der größeren Verlässlichkeit der EPA-Daten ausgeht, käme als Erklärung auch infrage, dass es in dem betrachteten Zeitraum einen geringeren Zuwachs bei den Niederschlägen infolge natürlicher Klimavariationen, z.B. durch Überlagerung eines negativen Niederschlag-Trends, gegeben hat. Dass solche Effekte eine Rolle spielen können, dafür gibt die erkennbare Periodizität in der EPA-Grafik erste Hinweise. Und wie bei den Temperaturen könnten auch die Niederschläge natürlichen Einflüssen mit längerer Periodendauer unterworfen sein.
Zum Vergleich wurden oben die Grafen der EPA-Niederschlagsdaten und der globalen HadCRUT4-Temperaturen in gleichem Zeitmaßstab übereinander gestellt. Dabei zeigt sich eine interessante Übereinstimmung: Wenn die globalen Niederschläge höher sind, stagnieren die globalen Temperaturen oder nehmen sogar ab und umgekehrt. Dies kann mit aller gebotenen Vorsicht als Bestätigung für das Oberflächenmodell gewertet werden.
Dies lässt den Schluss zu: Hätte es eine „normale“ Niederschlagsentwicklung mit einer größeren, 7,5%-igen Zunahme der globalen Niederschläge gegeben, wäre der Kühleffekt entsprechen größer ausgefallen und die globalen Temperaturen wären nur um die Hälfte gestiegen. Hinzu kommt als verstärkender Effekt, dass mehr Niederschläge mit mehr Bewölkung einhergehen, wodurch die Sonneneinstrahlung reduziert wird, was aber im Gesamtantrieb enthalten ist.
Träfe der Fall zu, dass die Verdunstung einschließlich der abgeführten Verdunstungswärme und somit auch die Niederschläge im Mittel nur um 2,4% (anstelle von 7,5%) ansteigen, dann würde es keine großen quantitativen Unterschiede zwischen Oberflächenmodell und den IPCC-Modellen mehr geben. Allerdings besteht weiterhin ein wichtiger qualitativer Unterschied: In den IPCC-Modellen wird vorausgesetzt, dass das anthropogene CO2 incl. Verstärkung de facto alleiniger Temperaturtreiber ist. Im Oberflächenmodell bleibt hingegen offen, wie sich der Gesamtantrieb im Einzelnen zusammensetzt.
Es spricht vieles dafür, dass andere, zumeist natürliche Erwärmungsursachen, wie schon in den voraus gegangenen Warmperioden, auch bei der neuzeitlichen Klimaerwärmung maßgeblich beteiligt sind. Das Oberflächenmodell lässt Raum für weitere Antriebe, die dann ganz oder teilweise an die Stelle des CO2-Antriebs in den IPCC-Klimamodellen treten, um den neuzeitlichen globalen Temperaturanstieg zu erklären. Und dafür gibt es viele Hinweise wie Wärmeinseleffekte, ozeanischen Oszillationen, Nord-Süd-Klimaschaukel (derzeit fehlende Erwärmung im Südpolarbereich bei zugleich stärkerer Erwärmung im Nordpolarbereich) – obwohl die CO2-Zunahme praktisch überall die gleiche ist.
Nicht wenige der natürlichen periodischen Antriebe, zu denen auch die Sonnenaktivität samt Verstärkung gehören, erreichen aktuell ihre Minima oder wechseln ihre Vorzeichen. Was die spannende Frage aufwirft, wieweit jetzt eine Phase des langsameren Temperaturanstiegs oder gar Abkühlung folgt – wie schon bei vorausgegangenen Warmperioden. Wobei man die globale Niederschlagsentwicklung nicht außer Acht lassen sollte. Wohingegen es beim IPCC nur eine Richtung gibt, nämlich aufwärts, getrieben durch die CO2-Emissionen.
Somit erleben wir in den nächsten Jahren ein spannendes Live-Experiment und gleichzeitig die Nagelprobe, was das Spurengas CO2 tatsächlich bewirkt. Wobei das CO2 in der Atmosphäre aufgrund der zunehmenden Emissionen derzeit noch ansteigt. Allerdings mit ersten Anzeichen für eine Verlangsamung, was in dem zitierten EIKE-Artikel die gepunktet eingezeichnete CO2-Anstiegskurve von Roy Spencer nahelegt – offensichtlich infolge der wachsenden CO2-Absorption durch Pflanzen und Ozeane. Was auch in der zunehmenden Begrünung der Erde und den gestiegenen Ernteerträgen sichtbar wird und Folge des höheren CO2-Partialdrucks in der Atmosphäre ist. Hinzu kommt, dass die fossilen Vorräte endlich sind – voraussichtlich wird es keine CO2-Verdoppelung mehr geben.
Ausblick
Die großen Unsicherheiten in den IPCC-Klimamodellen sowie jetzt auch das unterschätzte Potential der Verdunstungskühlung unterstreichen die Fragwürdigkeiten eines Dekarbonisierungs-Programms, das auf viele Jahrzehnte oder sogar ein ganzes Jahrhundert angelegt ist. Denn abgesehen von der Frage, wer überhaupt mitmacht, ist es genauso fraglich, was ein solches Programm bei den Temperaturen und dem Erdklima letztlich bewirken kann. Absehbar ist hingegen eine nachhaltige Beschädigung des Industriestandorts Deutschland. Auch besteht die Gefahr bei einer (Gott sei Dank eher unwahrscheinlichen) CO2-Minderung, dass der wichtige CO2-Pflanzendünger dann nicht mehr ausreicht, um die gewachsene Weltbevölkerung zu ernähren.
Für Klima-Ängstliche wäre stattdessen Geoengineering die bessere Option, wobei bereits der Eintrag von wenigen Milligramm geeigneter Aerosole in die untere Stratosphäre, pro Quadratmeter und Jahr, die Temperaturen spürbar senken würde. Und, besonders wichtig, diese Methode wäre sofort wirksam und nicht erst, wenn überhaupt, in Hundert Jahren. Und kann auch genauso schnell wieder rückgängig gemacht werden.
Auch sollte man nicht vergessen, dass mittel- bis längerfristig das Ende der Zwischeneiszeit und die Rückkehr der Eiszeit droht, was die Menschheit vor ungleich größere Probleme stellen wird. Hinzu kommen vorhersehbare, ernstere Probleme und Krisen, gegen die sich die Menschheit wappnen sollte. Während Deutschland und Europa alle Kräfte samt Billionen auf ein Klima-Phantom konzentrieren.
Aber was ist zu erwarten? Eine Kanzlerin und frühere Umweltministerin hat ein Billionen-Programm initiiert und wird zu Lebzeiten ihren historischen Fehler niemals eingestehen. Auch steht sie Al Gore, Obama und den Demokraten näher – Trump war ihr so fremd wie ein Alien. Und eine EU-von der Leyen, bisher nicht durch Können aufgefallen, setzt bei der Dekarbonisierung noch eins drauf – man kommt aus dem Staunen nicht heraus. Kein Zweifel, wir werden von Klima-hysterischen Frauen regiert – ist es höchste Zeit, die Quote nochmals zu überdenken?
Ebenfalls ganz auf Dekarbonisierung ausgerichtet wird eine staatlich geplante grüne Energiewende durchgezogen, die unlängst im Wallstreet Journal als die „dümmste Energiewende weltweit“ beschrieben wurde. Belege dafür gibt es zuhauf. Und die beiden Klima-hysterischen Frauen an der Spitze folgen den Grünen und den FfFs und setzen sich an die Spitze der Klima-Aktivisten.
Bei Corona regte sich Widerstand gegen das Maskentragen und manche Übertreibungen beim Lockdown. Weshalb hält man ausgerechnet beim Dekarbonisierungs-Wahnsinn still? Obgleich Autofahrer und Heizungsbesitzer immer dreister abkassiert werden? Und dies trotz Corona-Rezesssion? Von den weltmeisterlich steigenden Strompreisen ganz zu schweigen?
Alle Weichen sind so gestellt, dass sich das Land, so ist zu befürchten, zum dritten Mal ruiniert. Trotzdem wünscht man, schon der Nachkommen wegen, dass Deutschland weiterhin lebenswert bleibt. Dafür ist die Rückkehr von ein wenig Resthirn unerlässlich – weniger Stimmen für die Grünen wäre ein erster Indikator. Aber aus heutiger „Klima-Weltretter“ und „Vorreiter“-Sicht gleicht dieser Wunsch dem Hoffen auf ein großes Wunder!
Das ist falsch. Die bei den IPCC reports berücksichtigten Klimamodelle sind allesamt globale Zirkulationsmodelle, die alle die anderen Klimatreiber ebenfalls implementiert haben. Das interne Klimarauschen zeigen auch die Klimamodelle. Was glauben Sie, woher sonst die Schwankungen in den Temperturkurven in der Abb. oben herkämen?
Das ist nicht richtig. Klimamodelle sind keine Diagramme, sondern Computerprogramme basierend auf dem Lösen der Navier-Stokes-Gleichungen für Atmosphäre und Meere und zusätzliche physikalische Effekte, die das Wetter bestimmen.
Meine IT Kenntnisse sind nicht besonder fundiert, aber ich habe mein ganzes Geld über mehrere Jahrzehnte damit gemacht, Programmierer zu triezen, dass ihre Algorithmen gefälligst das errechnen, was der Kunde erwartet, nicht was der Programmierer selbst für richtig hält. Jedes Computerprogramm errechnet exakt das, wofür es bezahlt wird, der Entwickler muss es nur umsetzen.
Entwickler von Klimamodelle werden dafür bezahlt, dass sie eine Erwärmung durch CO2 errechnen, das tun sie dann auch. Für das IPCC erst Recht. Genau so einfach kann man ein Klimamodell entwickeln, dass eine Abkühlung vorhersagt.
Bezahlt aber keiner.
Allgemein ist dies außer als gültiges Prinzip allerdings nicht im Detail spezifizierbar. Aber natürlich kann man jedes Verhalten unter diesem Gesichtspunkt analysieren. Je besser die Kenntnis aller beteiligten Prozesse ist, desto besser kann man Abschätzungen auf Verhaltensplausibilität machen.
Untersucht man also z. B. einen beliebigen Punkt der Erdoberfläche, wirken viele unterschiedliche Prozesse dreidimensional. Es sind sowohl dynamische Einflüsse als auch rel. statische Eigenschaften. Dynamisch sind. z. B. Einstrahlung, Oberflächentemperatur, Lufttemperatur, Luftfeuchtigkeit, Wind, Strömung, Konvektion, Abstrahlung, Verdunstung, usw. Rel. statisch sind Oberflächenmaterial, -farbe, Luftzusammensetzung, usw.
All diese Dinge kann man zeitkonsistent messen und damit eine Verhaltenstheorie für diesen Punkt ansetzen, bei der die Summe über alle Energien Null ist. Tut man das für konkrete Punkte der Oberfläche, zeigt sich lediglich, daß die bekannten Gesetze der Physik offensichtlich stimmen. Ein Hinweis auf eine weitere Energiequelle außer der Sonne ist nicht feststellbar.
Schwieriger wird diese Analyse, wenn man einen Punkt der Atmosphäre z. B. in 2 m Höhe analysiert, jenen Ort also, wo eigentlich die von der Klimatologie als wesentlich betrachtete Temperatur gemessen wird. Welche Energiebilanz herrscht an so einem Punkt, der physikalisch aus Luft besteht, welche aber federleicht beweglich ist und laminar oder turbulent sein kann? Hier wirken viele Einflüsse dreidimensional und mit Gradienten. Zeitkonsistent messen kann man Temperatur, Luftfeuchtigkeit und Wind (Stärke, Richtung). Die treibenden Ursachen für diese Meßwerte kann man an diesem Ort aber nicht feststellen.
Deshalb sehe ich es auch als unmöglich an, für „alle Punkte“ der Erdatmosphäre ein konsistentes Abbild aufgrund von Navier-Stokes etc. zu ermitteln, und schon gar nicht, auf dieses Abbild sinnvolle Prognosen aufsetzen zu können, was die sog. Klimamodelle aber alle versuchen. Zusätzlich scheitern die Modelle an der Frage, wie genau wird die Wirkung von CO2 modelliert? Auf diese Frage gibt nämlich auch IPCC keine brauchbare Antwort.
Fazit Modelle: Code Garbage in – Ergebnis Garbage out …
Sie schreiben im vorliegenden Text, 1. Satz im 4. Abs. unter der K&T-Abbildung, Zitat:
„Was dann dazu führt, dass man aus allen Richtungen eine solche ,Gegenstrahlung‘ empfangen und messen kann.“
Zur „Gegenstrahlung“ und deren „Messung“ hatte ich gerade 5 Widersprüche formuliert, die in der nachfolgenden Diskussion nicht ausgeräumt, sondern vielmehr bestätigt worden sind.
Meine Frage an Sie: Wo und wie wird die sogenannte „Gegenstrahlung“ eindeutig gemessen?
U. Weber schrieb am 7. MÄRZ 2021 UM 22:54
Es diskutiert doch kaum noch jemand mit Ihnen, da Sie eh nicht auf Nachfragen auf Ihre Thesen eingehen. Also können Sie kaum aus fehlendem Widerspruch auf eine Korrektheit Ihrer Annahmen schließen. Wenn ich nicht schon aufgegeben hätte, Sie etwas zu fragen, dann hätte ich sicherlich zum … 10. male nachgefragt, wieso der Subtrahent in ihrer „Stefan-Boltzmann-Umgebungsgleichung“
kein Ausdruck für eine Strahlung aus der Atmosphäre ist. Eine Frage, auf die Sie bewusst nie eingehen.
Und die Frage nach dem Messgerät wurde Ihnen von Herrn Holtz schon beantwortet (27. FEBRUAR 2021 UM 11:34). Sie mögen die Antwort nur nicht.
Auch mit Speicherelementen (z.B. Kondensator), die an den Knoten eines elektrischen Netzwerkes angeschlossen sind, gilt der Knotenpunktsatz. Damit auch in analogen, z.B. thermischen Netzwerken für Leistungsfluss und Temperaturdifferenz. Das ist jetzt zwar Formalismus, der mit dem Anliegen des Artikels nicht so sehr viel zu tun hat, aber diese „Nebensächlichkeit“ sollte schon korrekt dargestellt werden. Der Vorzeichenfehler in der Knotengleichung am Anfang des Artikels für I3 ist übrigens noch immer drin …
Folgt man den IPCC-Modellen, dann würde bei fehlender oder relativ geringer Zunahme der Verdunstungskühlung das CO2 das Temperaturgeschehen dominieren. Verstärkt würde die vom CO2 verursachte Temperaturerhöhung mit IPCC-typischen großen, aber ziemlich unbestimmten Faktoren. Bei der vergleichenden Bewertung gerät man leicht ins Schwimmen: Klimasensitivität, CO2-Antrieb, letzterer aber zuzüglich Verstärkung, wobei die Verstärkung wiederum ein positiver Antrieb ist, der von der Temperatur und somit letztlich vom CO2 abhängt. Eine CO2-Abhängigkeit wie beschrieben dürfte immerhin gewährleisten, dass es keinen run away-Effekt gibt.
Halbwegs klar stellt sich die Lage für die Grenzfälle dar:
1) Große Zunahme der Verdunstungskühlung mit der Temperatur: Das Temperaturgeschehen wird weitgehend von der Verdunstungskühlung gemäß Oberflächenmodell bestimmt.
2) Die Verdunstungkühlung nimmt nur wenig oder gar nicht zu: Die Temperaturentwicklung würde letztlich von den IPCC-Modellen (wenn man ihnen folgt) dominiert und allenfalls geringfügig von den verbleibenden Kühleinflüssen des Oberflächenmodells verringert.
Zwischen diesen Grenzfällen dürfte es kontinuierliche Übergänge geben.
Bitte hier nur unter vollem Klarnamen posten, siehe Regeln.
Joo!
Und wie kommt das Methan auf die Monde???
Damit sind die Argumente der sog. „Fachwelt“ doch schon zerschossen…
„Möglichkeiten für geeignete Gegenmaßnahmen, falls notwendig…“
CO2 kann die Temperaturen der Erdoberfläche nicht beeinflussen, ergo sind „Gegenmaßnahmen“ überflüssig/schädlich und dienen lediglich der Profitgier von „Wissenschaftlern“/Beratern/Großunternehmen und der Profilierungssucht ideologisierter Politdeppen.
2) Ich bin mir inzwischen ziemlich sicher, dass vor allem Wasserdampf und in geringerem Umfang das Spurengas CO2 die Erde wärmer machen. Hauptbeweis sind für mich die IR-Spektrogramme mit ihren charakteristischen Dellen, aus dem Weltraum gemessen. Auch gehen nur so die im Artikel gezeigten Energie- und Strahlungsbilanzen auf. Es wäre natürlich nach wie vor ein Hit, wenn es einen Nachweis für Ihre These gäbe – die Postulierung alleine genügt aber nicht! Und auch die Thermodynamik wird eine „erhöhte Wärmeisolierung“ durch strahlungsaktive „Klimagase“ nicht verbieten. Sonst müssten die Heizungsmonteure damit aufhören, Warmwasserleitungen mit Wärmeisolierungen einzuhüllen. Eine ganz andere Frage ist, wie weit der nurmehr geringe Zusatzeffekt des anthropogenen CO2 sich in einer komplizierten Atmosphäre bemerkbar macht – siehe auch die riesige Unsicherheitsspanne bei den IPCC-Modellen, die zwar Verstärkungseffekte kennen, aber offenbar keine Abschwächung.
Doch!
Über den 2ten Hauptsatz!!!
Es freut mich ehrlich, wenn ich hier lese, dass auch Andere schon derartiges publiziert haben. Davon wußte ich nichts, weil ich altersmäßig aus der Literatur-line heraus bin. Der Vorhalt, dass die Mehrheit der Wissenschaftler die Ansicht nicht teilt, erinnert mich an das CO2- Argument von der Gültigkeit der Mehrheit oder der Erde als Scheibe auch mehrheitlich damals. Mehrheit sagt alles, beweist nichts. Trotdem, Ihre Beiträge gefallen mir immer wieder sehr.