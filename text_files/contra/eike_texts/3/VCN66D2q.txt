Es geht um folgende Aussagen:
Im AR 5 des IPCC aus dem Jahr 2013 heiÃŸt es:
Gleichgewichts-KlimasensitivitÃ¤t (ECS) liegt wahrscheinlich im Bereich 1,5Â°C bis 4,5Â°C (hohes Vertrauen). Extrem unwahrscheinlich ist ein Wert kleiner als 1Â°C (hohes Vertrauen), und sehr unwahrscheinlich ein Wert Ã¼ber 6Â°C (mittleres Vertrauen).
Auf Seite 17 liest man:
Es ist extrem wahrscheinlich, dass Ã¼ber die HÃ¤lfte der beobachteten Zunahme der globalen mittleren Temperatur von 1951 bis 2010 der anthropogenen Zunahme von Treibhausgas-Konzentrationen und anderen anthropogenen Faktoren zusammen geschuldet ist.
Soon, Conolly und Conolly (â€SCC15â€œ) kÃ¶nnen sehr gut begrÃ¼ndet zeigen, dass die ECS bei einer Verdoppelung von CO2 weniger als 0,44Â°C betrÃ¤gt. AuÃŸerdem ist deren SchÃ¤tzung der KlimasensitivitÃ¤t in Bezug auf Variationen der solaren Gesamt-Einstrahlung (TSI) grÃ¶ÃŸer als die SchÃ¤tzung des IPCC. Folglich sind die anthropogenen Treibhausgase ihrer SchÃ¤tzung zufolge kein dominanter Treiber des Klimas. Begleitende Informationen der drei Autoren einschlieÃŸlich der von ihnen verwendeten Daten kÃ¶nnen hier heruntergeladen werden.
Aus allen Satellitendaten geht hervor, dass der Output der Sonne mit der Sonnenflecken-AktivitÃ¤t variiert. Ein Sonnenflecken-Zyklus dauert im Mittel 11 Jahre, variiert jedoch von 8 bis 14 Jahren. Nimmt die Zahl der Sonnenflecken zu, steigt auch der solare Output, und umgekehrt. Satellitenmessungen stimmen darin Ã¼berein, dass die Variation vom Spitzen- zum Minimumwert etwa 2 W/mÂ² betrÃ¤gt. Die Satellitenmessungen stimmen nicht Ã¼berein hinsichtlich der Menge der solaren Gesamtstrahlung bei 1 AU [AU = Astronomical Unit = der mittlere Abstand der Erde von der Sonne], zeigen sie doch eine Differenz von 14 W/mÂ², und der Grund fÃ¼r diese Diskrepanz ist unbekannt, aber jeder Satellit zeigt den gleichen Trend Ã¼ber einen Sonnenfleckenzyklus (siehe folgende Abbildung:)
Vor dem Jahr 1979 standen uns lediglich am Boden geschÃ¤tzte Werte der TSI zur VerfÃ¼gung, die alle nur auf indirekten Messungen oder â€Proxysâ€œ beruhten. Darunter waren Sonnenbeobachtungen, vor allem Art, GrÃ¶ÃŸe, Form und Anzahl von Sonnenflecken, die LÃ¤nge von Solarzyklen, die Aufzeichnung kosmogener Isotope in Eisbohrkernen, Baumring-Analysen mit der C14-Methode und andere. In der Literatur gibt es viele TSI-Rekonstruktionen aus Proxys, von denen einige in der folgenden Abbildung gezeigt sind (aus SCC15 Abbildung 8):
Jene, die hÃ¶here SonnenaktivitÃ¤t anzeigen, sind links zu sehen. Sie wurden vom IPCC bei der Berechnung des menschlichen Einflusses auf das Klima auÃŸen vor gelassen. Mit der Auswahl der geringe TSI anzeigenden Aufzeichnungen rechts war man in der Lage zu sagen, dass die Sonne kaum Einfluss hat und die jÃ¼ngste ErwÃ¤rmung hauptsÃ¤chlich den Menschen zur Ursache hatte. Der AR 5 des IPCC zeigte in seiner Abbildung SPM.5 (unten), dass der gesamte anthropogene Strahlungsantrieb (relativ zum Jahr 1750) 2,29 W/mÂ² betrug, derjenige der Sonne aber nur 0,05 W/mÂ².
Folglich geht das IPCC davon aus, dass der Strahlungsantrieb der Sonne seit 1750 relativ konstant ist. Dies ist konsistent mit den Rekonstruktionen der geringen SonnenaktivitÃ¤t in der rechten HÃ¤lfte der Abbildung 8 in SCC15, nicht jedoch mit den Rekonstruktionen auf der linken Seite.
Die Autoren des Kapitels â€The Physical Science Basisâ€œ im AR 5 des IPCC mÃ¶gen wirklich glauben, dass die TSI-VariabilitÃ¤t seit 1750 gering ist. Aber dies spricht sie nicht frei davon, andere gut belegte und begutachtete TSI-Rekonstruktionen zu betrachten, die eine viel grÃ¶ÃŸere VariabilitÃ¤t zeigen. Insbesondere hÃ¤tte man die Rekonstruktion nach Hoyt and Schatten, 1993 berÃ¼cksichtigen sollen. Diese Rekonstruktion, modifiziert von Scafetta und Willson 2014 (Summary hier) hat den Test mit der Zeit sehr gut bestanden.
Temperatur an der ErdoberflÃ¤che
Der Hauptdatensatz zum Studium der Temperaturen an der ErdoberflÃ¤che weltweit ist der monatliche Datensatz des Global Historical Climatology Network (GHCN). Es wird verwaltet von der National Oceanic and Atmospheric Administration (NOAA) National Climatic Data Center (NCDC). GegenwÃ¤rtig sind die Daten hier einsehbar. Es gibt viele Probleme bei den Messungen der Temperatur Ã¼ber lange ZeitrÃ¤ume. LÃ¤ndliche Stationen werden stÃ¤dtisch, Ausstattung oder Aufstellungsorte kÃ¶nnen verÃ¤ndert bzw. verlagert werden.
Longhurst 2015 schreibt auf Seite 77:
â€¦eine grundlegende Ãœbersicht (hier) des Grades, bis zu dem diese Messungen in den USA von Wetterstationen korrekt platziert und betrieben wurden, stammt von einer Gruppe von 600 Mitarbeitern des Blogs Climate Audit: ,â€¦an den in bester Lage aufgestellten Stationen weist die tÃ¤gliche Temperaturspanne keinen Trend im Jahrhundert-ZeitmaÃŸstab aufâ€˜ â€¦ die relativ kleine Anzahl korrekt aufgestellter Stationen zeigte eine geringere langfristige ErwÃ¤rmung als das Mittel aller US-Stationen. â€¦das Mittel aller Stationen in den obersten beiden Kategorien wies fast gar keinen langzeitlichen Trend auf (0,032Â°C pro Jahrzehnt wÃ¤hrend des 20.Jahrhunderts). Fall, et al., 2011).
Die GHCN-Daten sind vom NCDC in Rohformat und â€homogenisiertâ€œ verfÃ¼gbar. Das NCDC glaubt, dass der homogenisierte Datensatz einen Stations-Bias korrigiert hÃ¤tte einschlieÃŸlich des WÃ¤rmeinsel-Effektes, und zwar mittels statistischer Verfahren. Zwei der Autoren von SCC15, Dr. Ronan Connolly und Dr. Michael Connolly, haben die Temperaturaufzeichnungen von NOAA/NCDC USA und global nÃ¤her untersucht. Sie haben einen maximalen mÃ¶glichen Temperatureffekt berechnet infolge VerstÃ¤dterung; im NOAA-Datensatz, adjustiert um einen Bias der Beobachtungszeit. Dieser Temperatureffekt ergab sich zu 0.5Â°C pro Jahrhundert (voll stÃ¤dtisch â€“ voll lÃ¤ndliche Stationen). Ihre Analyse zeigt also, dass die NOAA-Adjustierungen der Aufzeichnungen immer noch einen stÃ¤dtischen Bias hinterlassen relativ zu vollstÃ¤ndig lÃ¤ndlichen Stationen. Der US-Datensatz enthÃ¤lt 272 von 1218 voll lÃ¤ndliche Stationen (23,2%). Bei Verwendung des US-Datensatzes kann der Bias also abgeschÃ¤tzt werden.
Der globale Datensatz ist problematischer. Im globalen Datensatz gibt es 173 Stationen mit Daten aus 95 der letzten 100 Jahre, aber nur acht davon sind voll lÃ¤ndlich, und nur eine davon befindet sich auf der SÃ¼dhemisphÃ¤re. Man kombiniere dies mit Problemen sich Ã¤ndernder Instrumentierung, anderem Personal, Verlagerungen der Instrumente, anderen WetterhÃ¼tten â€“ und die Genauigkeit der gesamten globalen Temperaturaufzeichnung ist fraglich. Wenn wir berÃ¼cksichtigen, dass die SchÃ¤tzung der globalen ErwÃ¤rmung im AR 5 von 1880 bis 2012 0,85Â°C Â± 0,2Â°C betrÃ¤gt, kann man leicht sehen, warum es Zweifel darÃ¼ber gibt, wie viel ErwÃ¤rmung es tatsÃ¤chlich gegeben hat.
AuÃŸerdem: WÃ¤hrend die GHCN-OberflÃ¤chentemperaturen und die mittels Satellit gemessenen Temperaturen der unteren TroposphÃ¤re hinsichtlich ihrer absoluten Werte mehr oder weniger Ã¼bereinstimmen, zeigen sie unterschiedliche Trends. Dies gilt vor allem fÃ¼r die Studie von Karl, et al. 2015 (die den Stillstand â€zerschlagenâ€œ hat) und in diesem Jahr von der NOAA Ã¼bernommen worden ist. Der NOAA NCEI-Datensatz von Januar 2001 zeigt einen Trend von +0,09Â°C pro Dekade, und die Satelliten-DatensÃ¤tze der unteren TroposphÃ¤re (sowohl RSS als auch UAH) einen solchen von minus 0,02Â°C bis minus 0,04Â°C pro Dekade (hier). Beide Trends liegen innerhalb der Fehlerbandbreite und sind daher statistisch gesehen Null-Trends. Aber ist der Trend unterschiedlich wegen der zahlreichen â€Korrekturenâ€œ wie in SCC15 sowie Connolly and Connolly 2014 beschrieben? Der Trend ist so gering, dass es unmÃ¶glich ist, sich diesbezÃ¼glich sicher zu sein, aber die umfangreichen und zahlreichen Korrekturen seitens der NOAA sind verdÃ¤chtig. Ich persÃ¶nlich vertraue den Satellitenmessungen viel mehr als den Temperaturmessungen an der OberflÃ¤che. Aber jene sind kÃ¼rzer und reichen lediglich bis 1979 zurÃ¼ck.
Die IPCC-Berechnung des menschlichen Einflusses auf das Klima
Bindoff et al. 2013 haben zahlreiche Klimamodelle mit vier Komponenten entwickelt, zwei natÃ¼rlichen und zwei anthropogenen. Die beiden natÃ¼rlichen Komponenten waren vulkanische AbkÃ¼hlung und solare VariabilitÃ¤t. Die beiden anthropogenen Komponenten waren ErwÃ¤rmung durch Treibhausgase, hauptsÃ¤chlich anthropogenes CO2 und Methan, sowie anthropogene Aerosole, die die AtmosphÃ¤re kÃ¼hlen. Sie haben mit diesen Modellen die globalen Temperaturen von 1860 bis 2012 ,nachhergesagtâ€˜. Ergebnis: alle vier Komponenten zeigten gute Ãœbereinstimmung mit den Messungen, aber wenn man sie ohne die beiden anthropogenen Komponenten laufen lÃ¤sst wie im CMIP5-Multimodell funktionierte die Nachhersage nur von 1860 bis 1950. Auf der Grundlage dieses Vergleichs kam der AR 5 zu der Schlussfolgerung:
Ãœber die HÃ¤lfte der beobachteten Temperaturzunahme von 1950 bis 2010 ist sehr wahrscheinlich der beobachteten Zunahme anthropogener Treibhausgas-Konzentrationen geschuldet.
Der vom IPCC herangezogene Beweis fÃ¼r diese Schlussfolgerung wird in ihrer Abbildung 10.1 illustriert, auszugsweise oben gezeigt. Die obere Graphik (a) zeigt die GHCN-Temperaturaufzeichnung in schwarz und das Ensemble-Mittel von CMIP5 in rot. Dieser Lauf enthielt anthropogene und natÃ¼rliche â€Antriebeâ€œ. Die untere Graphik (b) enthÃ¤lt nur natÃ¼rliche â€Antriebeâ€œ. Von 1961 oder so bis heute passt das nicht sehr gut. Falls wir davon ausgehen, dass ihre Modelle alle oder fast alle Auswirkungen auf das Klima enthalten, natÃ¼rliche und anthropogene, ist ihre Schlussfolgerung angebracht.
WÃ¤hrend das einfache Vier-Komponenten-Modell des IPCC gut zur gesamten GHCN-Aufzeichnung passen mag (die rote Linie in obigen Graphiken) fÃ¼r alle Stationen, sieht es nicht so gut aus, wenn man nur lÃ¤ndliche Stationen heranzieht:
Wieder ist das CMIP5-Modell in rot gezeigt. Graphik (a) ist das gesamte Modell mit natÃ¼rlichen und anthropogenen â€Antriebenâ€œ, (b) enthÃ¤lt nur die natÃ¼rlichen und (c) nur die Treibhausgas-Antriebe. Keiner dieser ModelllÃ¤ufe passt zu lÃ¤ndlichen Stationen, welche die geringste Wahrscheinlichkeit aufweisen, von stÃ¤dtischen EinflÃ¼ssen betroffen zu sein. Der Leser wird sich erinnern, dass Bindoff et al. die Rekonstruktionen mit geringer TSI ausgewÃ¤hlt haben, gezeigt in der rechten HÃ¤lfte der SCC15-Abbildung 8. FÃ¼r eine vollstÃ¤ndigere Kritik von Bindoff et al. siehe hier (vor allem Abschnitt 3).
Die TSI von Soon et al. im Vergleich zu meist lÃ¤ndlicher Temperatur-Rekonstruktion
Wie also sieht es aus, wenn eine der hoch variablen TSI-Rekonstruktionen, im Besonderen die von Hoyt and Schatten 1993, aktualisiert von Scafetta and Willson 2014, verglichen wird mit den Temperaturaufzeichnungen lÃ¤ndlicher Stationen aus SCC15?
Dies ist Abbildung 27 aus SCC15. Darin werden sÃ¤mtliche lÃ¤ndlichen Aufzeichnungen (aus China, den USA, Irland und einem Komposit der NordhemisphÃ¤re) verglichen mit der TSI, wie sie von Scafetta und Wilson berechnet worden ist. Der Vergleich ist fÃ¼r alle sehr gut fÃ¼r das 20. Jahrhundert. Die lÃ¤ndlichen Temperaturaufzeichnungen sollten die bestmÃ¶gliche Aufzeichnungen fÃ¼r diesen Zweck sein: falls die TSI sehr gut zu ihnen passt, muss der Einfluss anthropogenen CO2â€² und Methans logischerweise gering sein. Die ErwÃ¤rmung der Arktis nach dem Jahr 2000 scheint ein wenig verstÃ¤rkt; dies kÃ¶nnte einem PhÃ¤nomen mit der Bezeichnung â€Polar Amplificationâ€œ geschuldet sein.
Diskussion des neuen Modells und der Berechnung des ECS
Eine Korrelation kleinster Quadrate zwischen der TSI in Abbildung 27 und der lÃ¤ndlichen Temperaturaufzeichnung zeigt, dass eine Ã„nderung von 1 W/mÂ² eine Ã„nderung der Lufttemperatur auf der NordhemisphÃ¤re um 0,211Â°C fÃ¼hren sollte (die Neigung der Linie). Vielleicht erreichen wir nicht ganz zufÃ¤llig einen Wert von 0,209Â°C unter der Voraussetzung, dass die Sonne die dominante WÃ¤rmequelle ist. Das heiÃŸt, falls die mittlere Temperatur der Erde 288 K betrÃ¤gt und ohne die Sonne bei 4 K liegen wÃ¼rde, betrÃ¤gt der Unterschied infolge der Sonne 284 K. Kombiniert man dies mit einer mittleren TSI von 1361 W/mÂ², bedeutet dies, dass 1/1361 0,0735% sind und dass diese 0,0735% von 284 sich zu 0,209Â°C pro W/mÂ² ergibt. Ziemlich cool, aber dies beweist nicht, dass die TSI das Klima dominiert. Es zeigt vielmehr, dass Bindoff et al. 2013 die falsche TSI-Rekonstruktion und vielleicht die falsche Temperaturaufzeichnung verwendet haben kÃ¶nnten. Mir persÃ¶nlich erscheinen die TSI-Rekonstruktion in SCC15 und die lÃ¤ndlichen Temperaturaufzeichnungen genauso gÃ¼ltig wie jene von Bindoff et al. 2013. Dies bedeutet, dass die von Bindoff und dem IPCC geÃ¤uÃŸerte Annahme, dass anthropogene Treibhausgase Ã¼ber die HÃ¤lfte der ErwÃ¤rmung von 1951 bis 2010 verursacht habe, fragwÃ¼rdig ist. Die fundierte Alternative im SCC15 ist genauso plausibel.
Das SCC15-Modell scheint zu funktionieren, zumindest mit den verfÃ¼gbaren Daten. Also sollten wir in der Lage sein, eine SchÃ¤tzung der AGW-Komponente zu berechnen. Falls wir die oben beschriebene lÃ¤ndliche Temperatur-Rekonstruktion vom Modell subtrahieren und die Residuen evaluieren (unter der Annahme, dass diese der anthropogene Beitrag zur ErwÃ¤rmung sind), kommen wir auf eine maximale anthropogene Auswirkung (ECS) von 0,44Â°C bei einer Verdoppelung des CO2-Gehaltes. Das ist substantiell geringer als die vom IPCC vorhergesagten 1,5Â°C bis 4,5Â°C. Bindoff et al. 2013 behaupten ebenfalls, dass ein Wert unter 1Â°C extrem unwahrscheinlich ist (Hervorhebung von ihnen). Ich denke, dass zumindest der Passus â€extrem unwahrscheinlichâ€œ in jener Studie problematisch ist. Die SchÃ¤tzung von SCC15 mit 0,44Â°C ist Ã¤hnlich der von Idso 1998 abgeleiteten SchÃ¤tzung von 0,4Â°C. Es gibt zahlreiche Studien aus jÃ¼ngerer Zeit, die ECS-Werte berechnen am Ã¤uÃŸerten unteren Ende der IPCC-Bandbreite und sogar noch niedriger. 14 dieser Studien sind hier aufgelistet. Darunter ist auch die Eckpfeiler-Studie von Lewis and Curry und natÃ¼rlich die klassische Studie von Lindzen and Choi 2011.
Ist CO2 dominant oder die TSI?
Danach fÃ¼hren SCC15 ein interessantes Gedankenexperiment durch. Was ist, falls CO2 der dominante Treiber der ErwÃ¤rmung ist? Nehmen wir das mal einen Moment an und berechnen die ECS. Dabei extrahieren sie einen ECS-Wert von 2,52Â°C, welcher in der unteren HÃ¤lfte der vom IPCC gegebenen Bandbreite zwischen 1,5Â°C und 4,5Â°C liegt. Allerdings fÃ¼hrt dieses Verfahren zu Residuen unter den Modelldaten, die immer noch sehr viel â€Strukturâ€œ oder Information enthalten. Mit anderen Worten, dieses Modell erklÃ¤rt die Daten nicht. Man vergleiche die beiden Plots der Residuen hier:
Der obere Plot zeigt die Residuen des Modells, das annimmt, dass anthropogenes CO2 der dominante Faktor bei einer TemperaturÃ¤nderung ist. Der untere Plot zeigt Residuen aus dem Vergleich der TSI (und nichts sonst) mit einer TemperaturÃ¤nderung. Eine beachtliche Anzahl von â€Strukturâ€œ oder Information verbleibt im oberen Plot. Dies zeigt, dass das Modell nur sehr wenig der VariabilitÃ¤t erklÃ¤rt hat. Im zweiten Plot bleibt nur wenig Struktur Ã¼brig, und einiges davon kann dem CO2, geschuldet sein, aber der Effekt ist sehr gering. Dies ist ein Ã¼berzeugender qualitativer Beweis, dass die TSI die Temperatur dominant beeinflusst und CO2 nur einen geringen Einfluss hat.
Die AGW-BefÃ¼rworter sind sehr emsig dabei, die Beweislast der Gemeinschaft der Skeptiker aufzubÃ¼rden. Die Hypothese, dass der Mensch die meiste ErwÃ¤rmung von 1951 bis 2010 verursacht hat, ist die zu beweisende Position. Die traditionelle und etablierte Hypothese lautet, dass KlimaÃ¤nderungen natÃ¼rlichen Ursprungs sind. Diese Hypothesen sind hier geplottet:
Dies ist Abbildung 31 aus SCC15. Der obere Plot (a) zeigt die Temperaturrekonstruktion der NordhemisphÃ¤re (blau) von SCC15 im Vergleich zur atmosphÃ¤rischen CO2-Konzentration (rot). Beides passt kaum zusammen. Der zweite Plot (b) passt die CO2-Konzentration an die Temperaturaufzeichnung an und dann die Residuen an die TSI â€“ auch das passt kaum zusammen. Der dritte Plot (c) vergleicht die Temperatur allein mit der TSI, und das passt viel besser. Der vierte Plot schlieÃŸlich (d) passt die TSI an die Temperaturaufzeichnung an und die Residuen an CO2, und hier passt alles am besten zusammen.
Es folgt die Diskussion dieser Plots aus SCC15:
Dies zeigt, dass zumindest seit 1881 die Temperaturtrends der NordhemisphÃ¤re primÃ¤r beeinflusst worden sind durch Ã„nderungen der Gesamt-Sonneneinstrahlung TSI und nicht durch atmosphÃ¤rische CO2-Konzentrationen. Man beachte aber, dass dieses Ergebnis nicht einen sekundÃ¤ren Beitrag durch atmosphÃ¤risches CO2 ausschlieÃŸt. TatsÃ¤chlich ist der Korrelations-Koeffizient fÃ¼r Modell 4 (d) etwas besser als fÃ¼r Modell 3 (c), (also ~0,50 zu ~0,48). Wie oben angesprochen zeigt Modell 4 (d) jedoch, dass Ã„nderungen des atmosphÃ¤rischen CO2â€² verantwortlich sind fÃ¼r hÃ¶chstens ~0,12Â°C (von insgesamt 0,85Â°C) im Zeitraum 1880 bis 2012. Das heiÃŸt, CO2 hat bislang nur einen sehr mÃ¤ÃŸigen Einfluss auf nordhemisphÃ¤rische Temperaturtrends.
Der letzte Absatz aus SCC15 lautet:
Als wir unser neues (Temperatur-)Komposit mit einer der Rekonstruktionen hoher solarer VariabilitÃ¤t der TSI verglichen, was von den Nachhersagen des CMIP5 nicht berÃ¼cksichtigt worden war, fanden wir eine bemerkenswert gute Ãœbereinstimmung. Falls die Rekonstruktion von Hoyt & Schatten und unsere neue SchÃ¤tzung des nordhemisphÃ¤rischen Temperaturtrends akkurat ist, scheint es, als ob man den grÃ¶ÃŸten Teil der Temperaturtrends seit mindestens 1881 mit der solaren VariabilitÃ¤t erklÃ¤ren kann, wobei die atmosphÃ¤rischen Treibhausgas-Konzentrationen hÃ¶chstens einen geringen Beitrag leisten. Dies widerspricht der jÃ¼ngsten Behauptung des IPCC, dass das meiste der Temperaturtrends seit den fÃ¼nfziger Jahren Ã„nderungen der atmosphÃ¤rischen Treibhausgas-Konzentrationen geschuldet ist (Bindoff et al. 2013).
Schlussfolgerungen
SCC15 zufolge ergibt sich also ein maximales ECS bei einer Verdoppelung von CO2 von 0,44Â°C. Die Studie zeigt auch, dass von der ErwÃ¤rmung um 0,85Â°C seit Ende des 19. Jahrhunderts nur etwa 0,12Â°C anthropogenen Effekten geschuldet sind, zumindest auf der NordhemisphÃ¤re, von wo die besten Daten vorliegen. Dies ist ebenfalls ein maximaler anthropogener Effekt, wenn wir viele andere Faktoren wie eine variierende Albedo (Wolken, Eis usw.) sowie WÃ¤rmetransport-Zyklen in Ozeanen ignorieren.
WÃ¤hrend die Korrelation zwischen der neuen Temperatur-Rekonstruktion von SCC15 und der TSI-Rekonstruktion von Hoyt und Schatten sehr gut ist, bleibt der genaue Mechanismus, wie TSI-Variationen das Erdklima beeinflussen unbekannt. In SCC15 werden zwei Optionen angesprochen, nÃ¤mlich einmal die Zirkulation von WÃ¤rme in den Ozeanen und zum anderen der WÃ¤rmetransport zwischen TroposphÃ¤re und StratosphÃ¤re. MÃ¶glicherweise spielen beide Mechanismen eine Rolle in unserem sich stÃ¤ndig Ã¤ndernden Klima.
Die TSI-Rekonstruktion nach Hoyt und Schatten wurde vor Ã¼ber 20 Jahren entwickelt und scheint immer noch zu gelten. Dies kann man von keinem einzigen der IPCC-Klimamodelle behaupten.
Die Konstruktion einer Temperaturaufzeichnung an der ErdoberflÃ¤che ist sehr schwierig, weil sich genau hier AtmosphÃ¤re, Festland und Ozeane berÃ¼hren. GewÃ¶hnlich gibt es hier die hÃ¶chsten Temperaturgradienten im gesamten System, zum Beispiel den â€skinâ€ effect [?]. Misst man die â€OberflÃ¤chenâ€œ-Temperatur am Boden? Einen Meter Ã¼ber Grund? Ein Inch [ca. 2,5 cm] Ã¼ber dem Wasser der Ozeane? Oder ein Inch unter der Ozean-OberflÃ¤che in der warmen Schicht? All diese Temperaturen werden in dem MaÃŸstab, Ã¼ber den wir hier sprechen, immer erhebliche Unterschiede aufweisen, wenige Zehntelgrad Celsius. Die OberflÃ¤che der Erde befindet sich niemals im Temperatur-Gleichgewicht.
Aus Essex et al. 2007:
WÃ¤hrend die globale mittlere Temperatur an der ErdoberflÃ¤che nichts weiter ist als ein Mittel Ã¼ber Temperaturen, wird es als Temperatur betrachtet, als ob eine Mitteltemperatur tatsÃ¤chlich die Temperatur selbst ist und als ob ein sich auÃŸer Gleichgewicht befindendem Klimasystem nur eine Temperatur aufweist. Aber eine Mitteltemperatur, zusammengestellt aus einem nicht im Gleichgewicht befindlichen Feld ist keine Temperatur. AuÃŸerdem muss kaum erwÃ¤hnt werden, dass die Erde eben nicht nur einfach eine Temperatur hat. Sie befindet sich nicht im thermodynamischen Gleichgewicht â€“ weder in sich selbst noch mit seiner Umgebungâ€œ.
Aus Longhurst 2015:
Eine fundamentale TÃ¤uschung bei der Verwendung dieser Zahl ist die Vermutung, dass kleine Ã„nderungen der Lufttemperatur an der ErdoberflÃ¤che eine Akkumulation oder einen Verlust von WÃ¤rme auf dem Planeten bedeuten infolge der Existenz von Treibhausgasen in der AtmosphÃ¤re; und mit einigen EinschrÃ¤nkungen ist dies auf dem Festland eine vernÃ¼nftige Vermutung. Aber Ã¼ber den Ozeanen und damit Ã¼ber 70% der ErdoberflÃ¤che bewirkt eine Ã„nderung der Lufttemperatur wenige Meter Ã¼ber der WasseroberflÃ¤che allenfalls eine sich Ã¤ndernde Vertikalbewegung im Ozean als Reaktion sich Ã¤ndernde WindverhÃ¤ltnisse an der OberflÃ¤che. Daraus folgt, dass Ã„nderungen der Wassertemperatur (und solchen der Lufttemperatur weniger Meter darÃ¼ber) nicht notwendigerweise signifikante Ã„nderungen des globalen WÃ¤rmegehaltes reprÃ¤sentieren, obwohl genau diese Vermutung immer wieder geÃ¤uÃŸert wird.
Allerdings reichen Satellitenbeobachtungen nur bis zum Jahr 1979 zurÃ¼ck und Messungen der globalen Lufttemperatur bis zum Jahr 1880 oder sogar noch weiter. Der Zeitraum von 1979 bis heute ist zu kurz, um irgendwelche bedeutsamen Schlussfolgerungen zu ziehen angesichts der LÃ¤nge sowohl solarer Zyklen als auch WÃ¤rmeverteilungs-Zyklen in den Ozeanen. Selbst der Zeitraum von 1880 bis heute ist noch ziemlich kurz. Wir haben nicht die benÃ¶tigten Daten, um zu irgendwelchen gesicherten Ergebnissen zu kommen. Die Wissenschaft ist definitiv nicht settled.
Link: http://wattsupwiththat.com/2015/10/08/a-short-summary-of-soon-connolly-and-connolly-2015-re-evaluating-the-role-of-solar-variability-on-northern-hemisphere-temperature-trends-since-the-19th-century/
Ãœbersetzt von Chris Frey EIKE
Nein, machte ich nicht. Zumal das auch nichts mit dem â€Treibhaus-Effektâ€œ zu tun hat, nur ganz nebenbei.
Das Erd-System ist kein statisch-konservatives System, wo der Energie-Input und Energie-Output in jedem Zeitintervall gleich ist. Nur in einem statisch-konservatives System gilt: Energie-Input(t) = Energie-Output(t). Bei dynamischen und dissipativen Systemen mit externen EinflÃ¼ssen treten immer Divergenzen (bzw. dynamische Divergenzen) zwischen Input und Output auf, das lÃ¤sst sich nicht vermeiden. In einem dynamisch und dissipativen System gilt: Energie-Input(t) + div(t,in) = Energie-Output(t) + div(t,out).
Und die â€KlimasensitivitÃ¤tâ€œ ist eigentlich die Divergenz-Betrachtung zwischen den energetischen Input und Output fÃ¼r das dynamische und dissipative System Erde. Nun liegt es an der Messtechnik, wie genau oder ungenau solche dynamisch-bedingten Divergenzen bestimmt werden kÃ¶nnen. Die Divergenz kann sich natÃ¼rlich Ã¤ndern, je nachdem, wie die externen EinflÃ¼sse schwanken bzw. im Inneren des Systems dissipative Strukturen ausgebildet oder zerstÃ¶rt werden. Gut, man kann das auch als systemische Fluktuations-GrÃ¶ÃŸe oder dynamische Divergenz-GrÃ¶ÃŸe eines realen Systems bezeichnen.
Das Problem liegt daran, dass man leider nur unvollstÃ¤ndige Informationen Ã¼ber ein dynamisches System hat, wie zum Beispiel:
+ Anzahl der Freiheitsgrade unbekannt
+ meist nur eine oder wenige Variablen gemessen
+ Rauschen
+ endlicher Beobachtungszeitraum
+ endliche Datengenauigkeit
Das kann natÃ¼rlich auch zu Fehl-Interpretationen der Werte fÃ¼hren, falls man div(t,in) oder div(t,out) getrennt betrachtet, denn es gilt: Energie-Input(t) â€“ Energie-Output(t) = div(t,out) â€“ div(t,in).
Mfg
Werner Holtz
â€und zu @#7: besso keks, auch â€ein wenig CO2-Strahlung ist NICHT daâ€œ ,
das kann man leicht messen.â€œ
Hallo Herr Dr. Paul,
manchmal bin ich zu gutmÃ¼tigâ€¦
Sie haben aber Recht: man soll in der Diskussion um die Ã–kofaschistenphysik keinen mm zurÃ¼ckweichen.
MfG
Das ist nicht nur unzulÃ¤ssig, sondern falsch.
Es ist doch nun wirklich nicht so schwer zu verstehen, dass es zwar einen ganz erheblichen AtmosphÃ¤reneffekt gibt,
das zeigt der Vergleich mit dem Erdmond ohne AtmosphÃ¤re mit dem gleichen Abstand zur Sonne,
aber,
dass z.B. Wasser die ErdoberflÃ¤chentemperatur senkt und nicht erhÃ¶ht.
a)Wasser ENTZIEHT der ErdoberflÃ¤che beim Verdunsten WÃ¤rme, die sie von der Sonne erhÃ¤lt und b) als Wolke reduziert Wasser die Energiezufuhr von der Sonne.
und zu @#7: besso keks, auch â€ein wenig CO2-Strahlung ist NICHT daâ€œ ,
das kann man leicht messen.
Der physikalische Effekt von CO2 (0,04% der wasserfreien Luft) in der TroposphÃ¤re beschrÃ¤nkt sich auf auf die Absorption im 15Âµm-Bereich in der AbsorptionslÃ¤nge von maximal einigen 100 Metern von der OberflÃ¤che. Danach gibt es keine 15Mm-Strahlen mehr.
Mir hat noch keiner exakt vorgerechnet wieviel â€WÃ¤rmeâ€œ dabei im Bereich dieser AbsorptionslÃ¤nge frei wird, nach Gerlich als Temperatur der 100% AtmosphÃ¤re nicht messbar.
Und was macht diese WÃ¤rme?
Sie fÃ¼hrt prinzipiell bei dem bekannt hohen Ausdehnungskoeffizient und der minimalen kinetischen ViskositÃ¤t der Luft zu einer Beschleunigung der aufwÃ¤rts gerichteten Luft- zirkulation.
Aber nicht zu einer ErhÃ¶hung der ErdoberflÃ¤chentemperatur.
Was ist nun der â€AtmosphÃ¤reneffektâ€œ?
cum grano salis:
1) Die Sonne strahlt DURCH die AtmosphÃ¤re auf die ErdoberflÃ¤che,
2) Die ErdoberflÃ¤che gibt einen erheblichen Teil davon materiell durch Konvektion an die AtmosphÃ¤re ab (=KÃ¼hlung).
3) Dieser Teil ist der WÃ¤rmespeicher fÃ¼r die Nacht (+ globale Zirkulation), denn die AtmosphÃ¤re ist zum Vakuum des Weltraums perfekt isoliert, sie strahlt nicht (im Gegensatz zur ErdoberflÃ¤che).
Die â€Gegenstrahlungstheorieâ€œ
ist grob FALSCHE Kindergartenphysik und hat nicht das geringste mit seriÃ¶ser â€Wissenschaftâ€œ zu tun.
mfG
Ein GCM ist nur dann brauchbar, wenn es die regionalen Entwicklungen der bodennahen Temperatur vernÃ¼nftig abbildet, nÃ¤mlich da, wo das MeÃŸnetz hinreichend dicht ist.
Die StrÃ¶mungsmuster der AtmosphÃ¤re mit ihren langen Wellen werden von der meridionalen Temperaturdifferenz erzeugt und nicht von der â€globalenâ€œ Mitteltemperatur. Die spielt natÃ¼rlich auch eine Rolle, Ã¼ber den Wasserdampf, also der meridionalen latenten Energiedifferenzen (Differenzen der pseudopotentiellen Temperatur).
FDas Problem mit diesem Datensatz ist, daÃŸ er nicht konsistent ist und die Stationen nicht reprÃ¤sentativ fÃ¼r die Region sind.
Es gibt in den USA das wesentliche dichtere COOP-MeÃŸnetz, welches genutzt werden mÃ¼ÃŸte, um die ReprÃ¤sentativitÃ¤t der einen GHCN-Station festzustellen und zu normieren, heiÃŸt deren systematische Abweichungen vom normierten FlÃ¤chenmittel des dichteren Stationsnetzes zu bestimmen und so zu â€homogenisierenâ€œ.
â€Nun seien Sie mal nicht so streng.â€œ
Hallo Herr Estermeier,
unabhÃ¤ngig davon, daÃŸ wir in der Sache eh einig sind,
der Trend geht zu KlimasensivitÃ¤t = 0.
Das zeigt ja auch der neue Beitrag von Herrn Dr. Koelle.
Herr Holtz, den ich aufgrund seiner kompetenten BeitrÃ¤ge hier sehr schÃ¤tze kommt nun auf sagenhafte dT(2*CO2) = 0,0355K.
Wie will man das Ã¼berhaupt messen kÃ¶nnen?
Und warum? ğŸ˜‰
Sollte es einen tatsÃ¤chlichen Wert in dieser GrÃ¶ÃŸenordnung geben (ein wenig Strahlung ist wohl da), dann wÃ¤re zumindest erklÃ¤rt, warum keine Korrelation von T und CO2 feststellbar ist.
Auch gut
MfG
Nun seien Sie mal nicht so streng.
Ich hab da so ein Gedankenspiel ganz ohne dieses Strahlungs-/Gegenstrahlungs-GedÃ¶ns.
Nehmen wir mal an wir hÃ¤tten eine AtmosphÃ¤re ohne CO2, dann wÃ¼rde sich das â€freie Fensterâ€œ der Erdabstrahlung um diese 15mikro-Bande erweitern. TemperaturmÃ¤ÃŸig dÃ¼rfte das wohl keine groÃŸe Auswirkung haben. Nun haben wir aber dieses MolekÃ¼l in der Luft und der freie Durchmarsch ist nicht gegeben. Also wird diese vom CO2-MolekÃ¼l absorbierte Energie zusammen mit der â€restlichenâ€œ warmen Luft nach oben getragen. Ich glaub das nennt man Thermik ğŸ˜‰
Ob nun dieses CO2 MolekÃ¼lchen unterwegs seine Erregung durch stuppsen oder strahlen mal verliert und danach eventuell von einem Nachbarn wieder in der richtigen Frequenz angeregt wird, spielt eigentlich keine Rolle. Es ist ein Geben und Nehmen bis in eine HÃ¶he, wo Stuppsen vor Strahlen eher unwahrscheinlich ist. Ab hier kann Herr Stehlik weiter erzÃ¤hlen.
Interessante Ausarbeitung und Schlussfolgerungen!
Zitat: Eine Korrelation kleinster Quadrate zwischen der TSI in Abbildung 27 und der lÃ¤ndlichen Temperaturaufzeichnung zeigt, dass eine Ã„nderung von 1 W/mÂ² eine Ã„nderung der Lufttemperatur auf der NordhemisphÃ¤re um 0,211Â°C fÃ¼hren sollte (die Neigung der Linie). Vielleicht erreichen wir nicht ganz zufÃ¤llig einen Wert von 0,209Â°C unter der Voraussetzung, dass die Sonne die dominante WÃ¤rmequelle ist. Das heiÃŸt, falls die mittlere Temperatur der Erde 288 K betrÃ¤gt und ohne die Sonne bei 4 K liegen wÃ¼rde, betrÃ¤gt der Unterschied infolge der Sonne 284 K. Kombiniert man dies mit einer mittleren TSI von 1361 W/mÂ², bedeutet dies, dass 1/1361 0,0735% sind und dass diese 0,0735% von 284 sich zu 0,209Â°C pro W/mÂ² ergibt.
Man sollte dabei aber bedenken, dass diese Temperatur-Ã„nderung von ca. 0,21 Grad alle Bestandteile der AtmosphÃ¤re betrifft. Damit ergibt sich zwanglÃ¤ufig fÃ¼r das CO2 ein noch viel geringer Einfluss. Der Einfluss des Wassers in all seinen AggregatzustÃ¤nden in der AtmosphÃ¤re betrÃ¤gt ca. 90%, damit bleibt fÃ¼r das CO2 nicht mehr viel Ã¼brig.
Auch meine einigen Berechnungen aus den ERBE und CERES Daten ergeben eine â€KlimasensitivitÃ¤tâ€œ bei Verdoppelung der CO2 Konzentration von gerade mal dT = 0,355K inklusive den Wassereinfluss in der AtmosphÃ¤re.
dT = 0,511K*ln(c/c0) = 0,511K*ln(2) = 0,355K (1,85 W/m^2)
oder
dT = 0,21K + 0,21K*ln(c/c0) = 0,355K
Wenn man das Ergebnis inklusive Wassereinfluss nur auf das reine CO2 bezieht, ergibt sich eine nur CO2-bedingte TemperaturÃ¤nderung von gerade mal dT(2*CO2) = 0,0355K.
Mfg
Werner Holtz
LÃ¤cherlich und so Ã¼berflÃ¼ssig wie ein Kropf!
Zur Frage des Skin-Effekts â€“ leider gibt es wohl wenige lÃ¤ngerfristige und keine groÃŸrÃ¤umigen Messungen von Gesteins-/Bodentemperaturen in z.B. 3 und (gleichzeitig) 5m Tiefe.
â€â€¦bleibt der genaue Mechanismus, wie TSI-Variationen das Erdklima beeinflussen unbekanntâ€œ
Es sind ja mehrere Hypothesen dazu vorhanden:
â€“ neben den genannten vertikalen Transporten in den Fluiden Tiefenwasser und Luft (StratosphÃ¤re) ja noch direkte (stÃ¤rkere Strahlungsabsorption der stÃ¤rker mit dem Sonnenzyklus schwankenden Strahlungsanteile im WassermolekÃ¼l) und indirekte (Sonnenwind und kosmische Strahlung) Wirkung auf Wolkenbildung und -AuflÃ¶sung sowie weitereâ€¦z.B. Wechselwirkungen der Magnetfelder und StrÃ¶mungen von LadungstrÃ¤gern im Meer und im Erdinneren und des Sonnenmagnetfeldes bis zu Strahlungsanteilen, deren Messung (und Wechselwirkungsbeurteilung) problematisch ist (Neutrinos)â€¦ein weiteres Feld als schnÃ¶des CO2;-)
Ein klaren Ergebnis scheuen wie der Teufel Weihwasser und das schreibe ich als Atheist.
MfG
ErgÃ¤nzend mÃ¶chte ich auf das Maodell von Prof. Harde verweisen, das hier nicht erwÃ¤hnt wurde, aber zu Ã¤hnlich niedrigen KlimasensitivitÃ¤ten kommt. Darin wird auch nicht bestritten, dass die sogenannten Treibhausgase durchaus Klimawirksam sind. Allerdings bei weitem nicht in dem MaÃŸ, wie es das IPCC behauptet.
Der Artikel zeigt, dass die TSI Varianz und die damit verbundene ErklÃ¤rung weit stÃ¤rker ist. Das war mir neu. Ich bin frÃ¼her von den niedrigen SchÃ¤tzdaten ausgegangen, auf die das IPCC verweist. Allerdings erscheint mir dieser Ansatz nun immer weniger haltbar.
Ein kleines Argumentationsproblem ensteht aber im Kontext durch einen Konflikt zwischen TSI-ErklÃ¤rung und Wolkenbildung nach Svensmark.
Nach Svensmart ist eine hohe TSI-Varianz nicht erforderlich, denn durch die kosmische Strahlung und deren Steuerung des Sonnenmagnetfeldes sollte die ErklÃ¤rung weitgehend erfolgen. Hier aber wird die TSI-Varianz als weitgehende ErklÃ¤rung heran gezogen. Dies macht den Svensmark Ansatz Ã¼berflÃ¼ssig, denn es bliebe nicht mehr genÃ¼gend beobachtbare und ansonsten unerklÃ¤rte Varianz Ã¼brig, die Svensmark erklÃ¤ren kÃ¶nnte.