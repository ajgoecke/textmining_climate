Das Zitat oben von Stefan Rahmstorf am 12.2.18[1] ist ein Beispiel zur Behauptung warum Anomalien genauer sind als die ihnen zugrunde liegenden Absolutwerte. Er hat bis heute nicht begriffen, dass er in diesem Beispiel Absolutwerte misst und diese als Anomalien ausgibt. Klimaanomalien werden jedoch nicht gemessen, sondern aus den Absolutwerten mit all ihren Fehlern berechnet. Und da gilt nun mal das Gesetz von der Fehlerfortpflanzung. Er betreibt also â€“ bewusst oder unbewusst- Etikettenschwindel.
Teil 1 hier und Teil 2 hier
Anomalien und sprunghafter Fehler
Machen wir dazu die Probe aufs Exempel, indem wir einen Anomalienverlauf aus einem (kÃ¼nstlichen) sinusfÃ¶rmigen Temperaturverlauf von 1850 bis 2009 erzeugen. Blau sei der Anomalienverlauf ohne Fehler. Die Anomalie verlÃ¤uft fast eben, wie die blaue Trendlinie anzeigt. Ab 1940 wird nun ein Fehler von + 1 K eingefÃ¼gt. GemÃ¤ÃŸ Rechenanweisung w.o. wird dann aus beiden Werten fÃ¼r alle Jahre (x) die Differenz gebildet. Ab 1940 hebt sich der Fehler auf. Beide VerlÃ¤ufe gehen ineinander Ã¼ber. Vor 1940 jedoch wird allein durch den Rechenprozess die Temperaturanomalie um 1 k abgesenkt. Wir sehen, die Annahme von vorhin gilt nur fÃ¼r die Zeit nach 1940. Vorher nicht. LÃ¤sst man Excel eine Trendgerade durch diese Werte legen, dann sehen wir, dass sich beide erheblich unterscheiden.
Abbildung 8 Ein systematischer Fehler von + 1 K tritt ab 1940 sprunghaft auf, weil z.B. die Station neu gestrichen wurde. Von dieser VerÃ¤nderung sind das â€Station Normalâ€œ wie alle aktuellen Werte ab 1940 betroffen. Ab 1940 gleicht sich der Fehler aus, vorher aber nicht. Der Trend verschiebt sich.
Daran Ã¤ndert sich auch nichts, wenn wir den Eintritt des Fehler auf spÃ¤ter verlegen. Wie das nÃ¤chste Bild zeigt. Dort werden die Kurven Anomalie 1 und 3 genannt.
Abbildung 9 Ein systematischer Fehler von + 1 K tritt jetzt 1980 sprunghaft auf, weil z.B. die Station neu gestrichen wurde. Von dieser VerÃ¤nderung sind das â€Station Normalâ€œ zur HÃ¤lfte und alle aktuellen Werte ab 1980 betroffen. Der Fehler gleicht sich nicht mehr aus, weder vorher noch nachher. Der Trend verschiebt sich.
Auch hier hebt sich der Fehler nicht auf, sondern ist weiter voll vorhanden und wirksam, natÃ¼rlich erst, nachdem er auftritt. Der Unterschied zum ersten Beispiel ist, dass nun Ã¼berhaupt keine â€wahreâ€œ Temperaturanomalie mehr gezeigt wird, sondern nur noch die fehlerbehaftete Summe.
Schleichender Fehler
Genauso entwickelt sich das Ergebnis, wenn man anstatt (oder zusÃ¤tzlich) einen schleichenden Fehler in den zuvor fehlerfreien Verlauf einbringt. Ich habe das in der folgenden Abbildung getan. Dort wurde von Anfang an ein schleichender systematischer Fehler von +0,1 K/Dekade eingebracht, wie er z.B. vom stÃ¤dtischen WÃ¤rmeinseleffekt hervorgerufen werden kann.
Abbildung 10 Ein systematischer Fehler von + 1 K tritt schleichend ab Beginn auf, weil z.B. die Station altert. Von dieser VerÃ¤nderung sind das â€Station Normalâ€œ entsprechend seinem linearen Anteil ebenso wie alle aktuellen Werte von Anfang an betroffen. Der Fehler gleicht sich nicht mehr aus, weder vorher noch nachher. Der Trend verschiebt sich.
Wir sehen einen schÃ¶n ansteigenden Verlauf (zuvor war er fast gerade) â€“ verursacht allein durch den schleichenden systematischen Fehler- z.B den UHI. Nur kann jetzt Ã¼berhaupt nicht unterschieden werden, ob ein systematischer Fehler vorliegt, oder ob sich die Umgebungstemperatur z.B. durch den Treibhauseffekt erhÃ¶ht hat.
Man kÃ¶nnte nun beanstanden, dass die FehlergrÃ¶ÃŸe in diesen Beispielen etwas hoch gewÃ¤hlt wurde. Dem ist aber nicht so, wie die zahlreichen Untersuchungen z.B. von Watts (http://www.surfacestations.org/) zeigen. Denn Fehler dieser Art gab und gibt es zahlreich. Sie werden durch Stationsverlegungen, Thermometertausch, Ã„nderung der Farbbeschichtung der Station, Ã„nderung des Algorithmus fÃ¼r die Berechnung des Mittelwertes u.v.a. mehr eingebracht. Es wÃ¤re nun vielleicht mÃ¶glich den Anstieg im obigen Beispiel als AusreiÃŸer zu erkennen, weil er einmalig und sprunghaft -wenn auch konstant- auftritt, und ihn durch entsprechende Rechnungen zu kompensieren. Das geschieht aber nur sehr, sehr selten, weil sich bei den abertausenden von DatensÃ¤tzen der Vergangenheit kaum jemand diese MÃ¼he macht, bzw. machen kann
Kein Fehlerausgleich mÃ¶glich
Eine Korrektur unterbleibt hauptsÃ¤chlich deswegen, weil man die Binsenweisheit (siehe Brohan et al 2006) von zuvor glaubt, dass sich der Fehler bei Anomalienbildung von selbst ausgleicht. Das ist aber, wie wir gesehen haben, grottenfalsch!
Eine Korrektur unterbleibt aber auch in den allermeisten FÃ¤llen deshalb, weil die dazu erforderlichen sog. â€Metadatenâ€œ fehlen und auch nicht mehr herbeigeschafft werden kÃ¶nnen. Diese beschreiben die Umgebungsbedingungen, MaÃŸnahmen, Algorithmen und vieles anderes, was in und um die Station Ã¼ber den Zeitraum passiert ist. (Siehe dazu bspw. Harrys Read Me Files des Meteorologen und Programmierers bei der CRU Harry: â€HARRY_READ_Me.txt.â€œ z.B. hier . Diese ist 274 Seiten lang. Die dazugehÃ¶rige Datenbasis enthÃ¤lt Ã¼ber 11.000 Dateien aus den Jahren 2006 bis 2009[2])
Allgemein gilt daher, die Annahme, dass sich bei Anomalienbildung die Fehler aufheben, ist nur dann richtig, wenn der gemeinsame, gleich groÃŸe und richtungsgleiche Fehler vor dem Beginn der untersuchten Zeitspanne eintritt und dann so bleibt. In unserem Falle also vor 1850. Das liegt jedoch weder in unserem Ermessen, noch haben wir davon Kenntnis, sondern es wird allein durch die RealitÃ¤t bestimmt. Deshalb kann festgehalten werden, dass diese simple Fehlerkorrekturmethode in aller Regel nicht anwendbar ist. Angewendet wird sie aber von so gut wie allen -auch IPCC- Klimatologen trotzdem.
Zusammenfassung
In der Statistik ist es eine gÃ¤ngige Methode Werte von div. Variablen mit Referenzwerten eben dieser Variablen zu vergleichen, um auf diese Weise bei eventuellen Abweichungen u.U. Ã„hnlichkeiten im Verlauf oder sogar Hinweise auf mÃ¶gliche Ursache und Wirkungsbeziehungen zu bekommen. Allerdings muss man sich immer im Klaren darÃ¼ber sein, wie sehr diese Methode von den Randbedingungen abhÃ¤ngt. Es wird gezeigt, dass eine schlichte Anomalienbildung keineswegs ausreichend ist, um schwer bestimmbare variable oder konstante systematische Fehler herauszurechnen. Im Gegenteil, man mÃ¼sste in jedem Fall diese Fehler bestimmen, sie quantifizieren und einordnen, um sie dann evtl. mehr oder weniger gut rechnerisch ausgleichen zu kÃ¶nnen. In der Klimatologie ist diese EinschrÃ¤nkung in Bezug auf die SchwÃ¤chen der Anomalienbildung offensichtlich nicht nur nicht bekannt, sondern wird auch â€“ auf den ersten Anschein hin- negiert.
Der berÃ¼hmte Physiker und NobelpreistrÃ¤ger Dick Feynman wÃ¼rde sagen: â€Sie halten sich selbst zum Narrenâ€œ. Nur so lÃ¤sst sich erklÃ¤ren, dass auch hochangesehene Forscher diese simplen ZusammenhÃ¤nge oft nicht beachten. Ihre Ergebnisse sind dadurch entsprechend falsch und damit unbrauchbar, bzw. mit wesentlich grÃ¶ÃŸeren Fehlern (Unsicherheiten) behaftet als angegeben.
Anhang.
Zur behaupteten Genauigkeit
Die berechnete Globaltemperatur im letzten Jahrhundert hat sich, gemÃ¤ÃŸ Aussage des Intergovernmental Panel of Climate Change (IPCC) um ca. 0,6 Â° bis 0,7Â° C erhÃ¶ht, wie uns im Bericht TAR 2001(Third Assesment Report) mitgeteilt wurde. Um diese Aussage treffen zu kÃ¶nnen, mÃ¼ssen VerÃ¤nderungen Ã¼ber lange ZeitrÃ¤ume mit einer Genauigkeit von < 1/10 Â°C ermittelt, erfasst, dokumentiert und verdichtet werden. Das englische Klimazentrum CRU (Climate Research Unit) -siehe Abbildung 1- zeigt sogar einen Anstieg von 0,8 Â°C mit einem Vertrauensintervall bei 95% von -0,09 bis +0,11 Â°C (Jahr 1905) bis Â± 0,08 Â° (Jahr 2005.).[3]
Dem steht aber entgegen, dass selbst bei Verwendung der bestgewarteten Messstationen und von gut trainierten Meteorologen so genau wie mÃ¶glich abgelesenen Temperaturwerte, diese nur die Bestimmung von Tagesmittelwerten mit einer von Genauigkeit Â± 2 bis Â± 3 K erlauben. Zitat des Meteorologen und Statistikers JÃ¼rgen Pelz
JÃ¼rgen Pelz: â€Anmerkungen zur PrÃ¼fung von Daten und Ergebnissen von Modellrechnungen unter Verwendung der Statistik und der ,Informationstheorieâ€œ Beilage zur Berliner Wetterkarte vom 7.12.1995; S. 5
â€Will man beispielsweise die Tagesmitteltemperatur auf Â± 0.1 K genau ermitteln, darf der Abstand der Messungen nicht grÃ¶sser als 15 Minuten sein. GenÃ¼gt eine Genauigkeit von Â± 2 bis 3 K, reichen die Klimatermine.â€œ [Pelz, 1995b][4]
Trotzdem behaupten die Wissenschaftler der Climate Research Unit (CRU) der University von East Anglia, welche die CRU Hadley Reihe produzieren[5]: â€How accurate are the hemispheric and global averages? Annual values are approximately accurate to +/- 0.05Â°C (two standard errors) for the period since 1951. They are about four times as uncertain during the 1850s, with the accuracy improving gradually between 1860 and 1950 except for temporary deteriorations during data-sparse, wartime intervals. Estimating accuracy is a far from a trivial task as the individual grid-boxes are not independent of each other and the accuracy of each grid-box time series varies through time (although the variance adjustment has reduced this influence to a large extent). The issue is discussed extensively by Folland et al. (2001a, b) and Jones et al. (1997). Both Folland et al. (2001a,b) references extend discussion to the estimate of accuracy of trends in the global and hemispheric series, including the additional uncertainties related to homogenity corrections.â€
[1] Quelle: â€Verwirrspiel um die absolute globale Mitteltemperaturâ€œ https://scilogs.spektrum.de/klimalounge/verwirrspiel-um-die-absolute-globale-mitteltemperatur/ (hier)
[2] Details entnommen aus â€šBotch after botch after botchâ€˜ Leaked â€šclimategateâ€˜ documents show huge flaws in the backbone of climate change science By LORRIE GOLDSTEIN (hier)
[3] Diese Darstellung der Zeitreihe der mittleren Globaltemperatur kommt auf vielfÃ¤ltige Weise in Ã¶ffentlichen Berichten des IPCC AR 4 vor. So z.B. Im Summary for Policymakers SPM auf Seite 19, In den FAQÂ´s des Berichtes der Workung Group 1 Fig. 3.1 auf S 104. In der Technical Summary des Berichtes der Working Group 1 (WG1-TS) als Fiure TS.6 auf Seite 37 usw.
[4] Pelz, J b (1995) Anmerkungen zur PrÃ¼fung von Daten und Ergebnissen von Modellrechnungen unter Verwendung der Statistik und der Informationstheorie. Beilage zur Berliner Wetterkarte 7.12.1995
[5] Quelle http://www.cru.uea.ac.uk/cru/data/temperature/#datter (hier)
FÃ¼r alle die diese Arbeit am StÃ¼ck lesen wollen hier das pdf dazu Die schwierige nimmer endende Fehlerdiskussion
Nicht nur das!
Messen kann man nÃ¤mlich nur meÃŸbare Werte. Die Temperaturwerte, um die es hier geht, sind aber nicht meÃŸbar, sondern es sind Rechenergebnisse! Und ich mÃ¶chte einmal den â€MeÃŸaufbauâ€œ sehen, mit der man Differenzen von Rechenergebnissen â€messenâ€œ kann, deren Basiswerte aus verschiedenen Jahrhunderten stammen â€¦
wÃ¤re es vielleicht mÃ¶glich, die internen Verweise im Artikel mit tatsÃ¤chlichen URLs zu unterfÃ¼ttern? Manch geneigter Leser mag verlockt sein, sich an den Referenzen zu versuchen. Hoffend auf baldige Abhilfe verbleibt meine Wenigkeit
mfG
H.Lodsch
Offensichtlich waren einige der links nicht mehr erreichbar. Soweit mÃ¶glich habe ich die aktuellen noch erreichbaren unterlegt. Mit freundlichen GrÃ¼ÃŸen
M.L.
ich bin jetzt etwas enttÃ¤uscht, weil ich auf die Stelle gewartet habe, wo mit den TrivialitÃ¤ten Schluss ist und dann endlich die Punkte kommen, Ã¼ber die man diskutieren kann.
NatÃ¼rlich verursachen Stationswechsel und andere Ã„nderungen Fehler bei Verwendung der Rohdaten. Aber niemand berechnet ja Differenzen von Rohdatenzeitreihen. Die meisten Arbeitsgruppen verwenden homogenisierte Daten, Best macht das nicht, die setzen auf Kriging.
Schleichende Effekte wie WÃ¤rmeinseleffekt sind ebenfalls bekannt. Statt damit zu langweilen, dass es das gibt, wÃ¤re interessanter gewesen zu diskutieren, wie man versucht, diese Effekte zu quantifizieren und zu korrigieren.
Ausgangspunkt der letzten Diskussion war ja, warum Anomalien prÃ¤ziser gemessen werden kÃ¶nnen als absolute Temperaturmittel. Da hat mich besonders enttÃ¤uscht, dass der Elefant im Raum nicht mal ErwÃ¤hnung fand, nÃ¤mlich:
Man stelle sich vor, man hat eine Messtation im Tal, eine auf eine Berg. Der Unterschied in den absoluten Temperaturen ist wegen der HÃ¶henabhÃ¤ngigkeit groÃŸ, die Mittelung wegen dieser AbhÃ¤ngigkeit schwierig. Die ErwÃ¤mung dagegen (die Anomalie) ist dagegen Ã¼ber viel grÃ¶ÃŸere, regionale Bereiche, praktisch dieselbe.
Glauben Sie, Sie hÃ¤tten etwas entdeckt, was der Wissenschaft bislang unbekannt ist? Glauben Sie, Sie kÃ¶nnten alle Verfahren der Temperaturreihenbestimmung widerlegen? Dann beteiligen Sie sich an der wissenschaftlichen Diskussion:
Reichen Sie ein Paper ein. Leute, die gÃ¤ngige Meinungen Ã¼ber Bord werfen konnten, sind dadurch BerÃ¼hmtheiten geworden.
Danke fÃ¼r Ihre EindrÃ¼cke, und wirklich, wirklich, wirklich, es tut mir schrecklich leid, dass ich so einen profunden Fachmann wie Sie es sind gelangweilt habe. Mea Culpa! Mea maxima culpa.
Und auch dass ich Ihr tolles Berg- und Tal Beispiel nicht gebracht hatte, den Elefant im Raum wie sie ihn zu nennen pflegen, tut mir schrecklich leid. Ich hatte zwar darÃ¼ber berichtet, dass die Bildung von Anomalien durchaus das Erkennen Ã¤hnlicher Trends ermÃ¶glicht, habe das aber wohl so gut im Text versteckt, dass Sie diesen Hinweis nicht entdecken konnten. Auch das meine alleinige Schuld. Leider kann man daraus nicht den Schluss ziehen, dass Anomalien genauer sind als ihre Komponenten.
Im Ã¼brigen hatte ich schon des Ã¶fteren auf diesen link verwiesen, peer reviewed, wie verlangt.
Es ist natÃ¼rlich meine Schuld, dass Ihro Gnaden da noch nicht reingucken konnten. Auch dafÃ¼r bitte ich nachtrÃ¤glich um Entschuldigung. Wie konnte ich nur den NÃ¼rnberger Trichter vergessen und auf eigene ÃœberprÃ¼fung hoffen.
Auch hatte ich des Ã¶fteren auf die grundlegenden Arbeiten von Dr. Pat Frank verwiesen. siehe hier, hier und hier.â€œ Auch, dass Sie die Ã¼bersehen haben, ist natÃ¼rlich meine Schuld.
Beste GrÃ¼ÃŸe
Ihr untertÃ¤nigster
M.L.
Sie schreiben:
â€Auch hatte ich des Ã¶fteren auf die grundlegenden Arbeiten von Dr. Pat Frank verwiesen. siehe hier, hier und hier.â€œ Auch, dass Sie die Ã¼bersehen haben, ist natÃ¼rlich meine Schuld.â€œ
Doch, ich hatte dort kommentiert, mein dort benutzter Name funktionierte damals aber plÃ¶tzlich nicht mehr. MerkwÃ¼rdig, dass solche technischen Fehler mmer nur bei Leuten passiert, die anderer Meinung sind als Sie. Aber Sie versichern ja regelmÃ¤ÃŸig, es gibt keine Zensur. Woran liegt es?
PS:
Wer etwas mitzuteilen hat von wissenschaftlichem Wert, der wÃ¼rde etwas besseres finden als E&E. Kein Wissenschaftler liest, was dort erscheint.
Aber trotzdem meine GlÃ¼ckwÃ¼nsche zu Ihrem Erfolg dort, das Peer Review war sicherlich ganz schÃ¶n hart ğŸ˜‰
Ich wÃ¼rde aber lieber Ã¼ber Inhalte sprechen als zu streiten, ich versuche das nochmals:
Wenn ihr Ziel ist, den Anbietern von Temperaturzeitreihen Fehler nachzuweisen, dann mÃ¼ssen Sie schon das kritisieren, was diese tun. Jeder kennt die Problematik der Verwendung von Rohdaten, man verwendet daher homogeniserte Daten. Diese Problematik verursacht durch StationsÃ¤nderungen etc. zeigen Sie hier schÃ¶n auf, dafÃ¼r ein Lob.
Nun wundert mich folgendes:
Hier klingt es immer so, als sei die Verwendung von Rohdaten der Goldstandard und die EindÃ¤mmung der beschriebenen Fehler durch homogenisierte Daten wird hier wÃ¶rtlich oft â€Betrugâ€œ genannt. Wie passt das zusammen?
Ich erinnere mich an eine Arbeit von LÃ¼decke et al., publiziert in einem namhaften Journal, wo Spektralzerlegung von 5 langen Temperaturzeitreihen durchgefÃ¼hrt wurden. Von den Rohdaten Ã¼brigens, trotz Standort- und Instrumentenwechseln.
Wie passt das zusammen? Sie kritisieren immer nur die, die um diese Fehler wissen und die diese Fehler angehen, sind das nicht die falschen Adressaten ihrer Botschaft?
Sie weichen aus, Herr LÃ¶ffler, zur Sache kommt von Ihnen nichts.
Und Ihre (abwertende) Meinung zu E&E ist eigentlich auch nicht von Interesse.
Zur Arbeit von LÃ¼decke et al.
Wie ich in meinen VortrÃ¤gen ausfÃ¼hrte und auch in manchen meiner BeitrÃ¤ge zum Thema, handelt es sich bei den von mir untersuchten systematischen Fehlern um statische oder semistatische EinflÃ¼sse, d.h. sie treten schleichend auf (Beispiel: Alterung) oder sprunghaft (Beispiel Standortwechsel, Neuanstrich etc.) und verbleiben dann so.
LÃ¼decke et al untersuchten periodische Ã„nderungen und die bilden sich ab, weil sie sich den Mittelwerten Ã¼berlagern, vergleichbar wie eine Amplitudenmodulation. Sowohl bei den errechneten Mittelwerten, als auch beim umhÃ¼llenden Unsicherheitsband. Daher kann eine solche Studie zu nÃ¼tzlichen Erkenntnissen kommen, jedenfalls in Bezug auf Periodendauern, weniger auf die HÃ¶he der Amplitude.
sehe ich genauso. Mehr als billiges ZweifelsÃ¤hen kommt hier nicht, wer Fakten fordert, wird angemscht und abgesÃ¤gt. Selbst einfachste wissenschaftliche Tatsachen werden dÃ¤monisiert.
Wahrscheinlich haben auch Sie keine Ahnung von der Messerei und der Statistik, sonst wÃ¼rden Sie nicht solche Formulierungen wÃ¤hlen.
Zweifel und damit das â€ZweifelsÃ¤enâ€œ sind bitter nÃ¶tig, weil die Kritik der Messreihen auf wissenschaftlicher Basis bei den Klimahysterikern nicht erfolgt. Bei den Temperaturen sind die eigentlichen Thermometer nicht mal das grÃ¶ÃŸte Problem bei den messtechnischen Unsicherheiten, sondern die Anwendung bzw. die Bedingungen â€drumherumâ€œ. Ein berÃ¼hrend messendes Thermometer misst immer nur die eigene Temperatur, selbst das scheint Ihnen nicht klar zu sein.
Ich selbst halte als Messtechniker mit Ã¼ber 40 Jahren sehr praktischer Erfahrung auch nichts von den â€Homogenisierungenâ€œ, weil die fast immer sehr subjektive EinschÃ¤tzungen zur Basis haben, da kann man zu viel in die gewÃ¼nschte Richtung manipulieren. Bei WI-Effekten oder anderen EinflÃ¼ssen z.B. auf die MesshÃ¼ttten (Farbe, Pflegezustand usw.) weiss man zwar die Richtung der VerfÃ¤lschungen, aber niemals den genauen Wert, erst recht nicht nach 100 Jahren. Was man recht sicher weiÃŸ, dass die Messunsicherheit wesentlich grÃ¶ÃŸer ist als laienhaft vermutet. Und damit sind die ganzen Klimamodellierungen wertlose Computerspiele â€¦.
sie meinen vereinfachte unwissenschaftliche Behauptungen werden daemonisiert!
Sie haben sich aus unerfindlichen GrÃ¼nden nicht zu der Behauptung von Herrn Loeffler geÃ¤uÃŸert, wo er behauptet das:
â€â€¦.Anomalien prÃ¤ziser gemessen werden kÃ¶nnen als absolute Temperaturmittel.â€œ
Betrachten sie das wissenschaftliche Tatsache?
koennen sie bitte eine wissenschaftliche Arbeit nennen und verlinken die bestÃ¤tigt, das sich die Temperaturen im Tal genau so verhalten wie die Temperaturen auf dem Berg?
Solch eine Arbeit sollte auch in der Lage sein die HÃ¶he der Abweichungen darzustellen. Davon auszugehen, das es keine gibt, so wie sie, ist unwissenschaftlich und fahrlÃ¤ssig.
Gleiche Arbeiten sollte es geben Ã¼ber verschiedene Regionen, vielleicht mit einem engeren standardisierten Messnetz, um zu bestÃ¤tigen, was sie sagen das:
â€Die ErwÃ¤rmung dagegen (die Anomalie) ist dagegen Ã¼ber viel grÃ¶ÃŸere, regionale Bereiche, praktisch dieselbe.â€œ
Sie sollten, ordentlich und sorgfÃ¤ltig recherchieren und Ã¤uÃŸern. Dieser Satz bezeugt das sie immer noch nicht wissen worum es geht und wo ihre Denkfehler anfangen:
â€Ausgangspunkt der letzten Diskussion war ja, warum Anomalien prÃ¤ziser gemessen werden kÃ¶nnen als absolute Temperaturmittel.â€œ
NEIN!
Anomalien werden nicht gemessen.
Anomalien werden aus gemessenen Temperaturen errechnet.
Temperaturmittel werden auch nicht gemessen, diese werden auch berechnet.
Das einzige was gemessen wird sind Temperaturen.
Sie sollten Ihre Aussagen noch mal mit den obigen Fakten abgleichen. Vielleicht ergibt sich ja dann eine sinnvolle Diskussion. Bisher jedenfalls haben sie keinen ordentlichen Beitrag geleistet.
Sie haben vÃ¶llig recht.
Wenn Begriffe wahllos durcheinander geworfen werden, dann kÃ¶nnen nur (hÃ¶flich gesagt) MissverstÃ¤ndnisse daraus erwachsen.
Gestatten Sie mir noch eine ErgÃ¤nzung zum Thema Homogenisierung:
â€Ãœber Land werden manche ermittelten Zeitreihen, sofern mÃ¶glich, auf InhomogenitÃ¤ten untersucht. Findet man InhomogenitÃ¤ten, und dies setzt erhebliches detektivisches GespÃ¼r, Geduld, KÃ¶nnen und Zeit voraus, d.h. signifikante Abweichungen, die systematische Fehler vermuten lassen, dann mÃ¼ssen diese Zeitreihen korrigiert (im meteorologischen Sprachgebrauch â€homogenisiertâ€œ) werden bevor sie weiter verarbeitet werden kÃ¶nnen. D.h. sie werden als absolute Werte mit den Werten einer als fehlerfrei angesehenen Zeitreihe verglichen, d.h. voneinander abgezogen. Stimmen beide Zeitreihen dann 1:1, d.h. ohne den gesuchten Fehler Ã¼berein, bleibt als Restterm dieses Vergleiches nur der Fehler in seinem Verlauf Ã¼brig. Er kann dann zur Korrektur verwendet werden. Stimmen beide nicht exakt Ã¼berein, und das ist der Normalfall, bleibt eine Restdifferenz zusÃ¤tzlich zum Fehler Ã¼brig und verfÃ¤lscht mehr oder weniger stark das Ergebnis. Dieses wird aber in der Praxis oft nicht erkannt. Es kann schwerlich unterschieden werden, was Signal bzw. was Fehler ist. Die Konsequenz daraus ist, dass in diesem Fall mit der Homogenisierung der fehlerhaften Zeitreihe GrÃ¶ÃŸe und Verlauf der Referenzzeitreihe aufgeprÃ¤gt wird. Ihre Bestimmung wird damit wertlos. Das evtl. vorhandene Signal verschwindet.
Quelle meine Diss. Seite 80-81.
Wer diese Aussage widerlegen mÃ¶chte kann dies hier gern versuchen.
Und auch das sollte jedem zu denken geben:
â€œ Der Klimatologe und CRU Programmierer Ian â€Harryâ€œ Harris, unter dem Namen â€Harryâ€œ bekannt geworden, war beauftragt, die DatensÃ¤tze der historischen Daten der WMO in einem dazu zu schreibenden Programm auszuwerten. Er Ã¤uÃŸerte in seinen Anmerkungen zu seinen Programm-Codes schwerste Bedenken bezÃ¼glich die QualitÃ¤t der zu bearbeitenden WMO DatensÃ¤tze und schrieb dazu u.a. in seine Programmcodes zur Berechnung der globalen Temperaturzeitreihe:
â€œ[The] hopeless state of their (CRU) database. No uniform data integrity, itâ€™s just a catalogue of issues that continues to grow as theyâ€™re foundâ€¦I am very sorry to report that the rest of the databases seem to be in nearly as poor a state as Australia was. There are hundreds if not thousands of pairs of dummy stations, one with no WMO and one with, usually overlapping and with the same station name and very similar coordinates. I know it could be old and new stations, but why such large overlaps if thatâ€™s the case? (241)â€¦.â€œBut what are all those monthly files? DONâ€™T KNOW, UNDOCUMENTED. Wherever I look, there are datafiles, no info about what they are other than their names. And thatâ€™s useless â€¦â€œ (Page 17)- â€Itâ€™s botch after botch after botch.â€œ (18)-â€The biggest immediate problem was the loss of an hourâ€™s edits to the program, when the network died â€¦ noexplanation from anyone, I hope itâ€™s not a return to last yearâ€™s troubles â€¦ This surely is the worst project Iâ€™veever attempted. Eeeek.â€œ (31)- â€As far as I can see, this renders the (weather) station counts totally meaningless.â€œ (57)- â€COBAR AIRPORT AWS (data from an Australian weather station) cannot start in 1962, it didnâ€™t open until1993!â€œ (71)- â€You canâ€™t imagine what this has cost me â€” to actually allow the operator to assign false WMO (WorldMeteorological Organization) codes!! But what else is there in such situations? Especially when dealing with aâ€™Masterâ€˜ database of dubious provenance â€¦â€œ (98)- â€So with a somewhat cynical shrug, I added the nuclear option â€“ to match every WMO possible, and turnthe rest into new stations â€¦ In other words what CRU usually do. It will allow bad databases to passunnoticed, and good databases to become bad â€¦â€œ (98-9).
Damit wird nachvollziehbar klar, dass die damit befassten Wissenschaftler sehr viel FleiÃŸ und auch Improvisation und Intuition in die Bearbeitung der zu behandelnden historischen, lÃ¼cken- â€“ und fehlerhaften DatensÃ¤tze stecken mussten. Umso erstaunlicher ist die proklamierte Genauigkeit der Aussagen.â€œ
Quelle ebenda S 54/55
Mit freundlichen GrÃ¼ÃŸen
M.L.
mir sind diese UnzulÃ¤nglichkeiten von Daten sehr wohl bekannt. Beruflich beschÃ¤ftige ich mich sowohl mit Temperaturmessungen und deren Auswertung als auch mit groÃŸen DatensÃ¤tzen aus unterschiedlichen Quellen.
Danke an dieser Stelle fÃ¼r ihre unermÃ¼dliche Arbeit und AufklÃ¤rung.
Gern geschehen.
Wenn es nicht auch noch SpaÃŸ machen wÃ¼rde, hÃ¤tte ich ob der allgemeinen Ignoranz die mir immer wieder entgegenschlÃ¤gt, siehe so manche Kommentare, schon lÃ¤ngst aufgegeben.
Mit freundlichen GrÃ¼ÃŸen
M.L.
â€Sie sollten, ordentlich und sorgfÃ¤ltig recherchieren und Ã¤uÃŸern. Dieser Satz bezeugt das sie immer noch nicht wissen worum es geht und wo ihre Denkfehler anfangen:â€œ
FÃ¤llt Ihnen etwas auf? Sie bitten mich um Quellen, es sind also Sie selbst, der nicht recherchiert hat. Bei mir ist das etwas anders: Sie kÃ¶nnen davon ausgehen, dass ich nur darÃ¼ber schreibe, wo ich informiert bin.
Das grundlegende Paper zu absoluten mittleren Temperaturen ist von Jones et al. 1999: https://www.st-andrews.ac.uk/~rjsw/papers/Jones-etal-1999.pdf
Auf der GISS-Seite gibt es Material mit weiteren Links.
Ãœber welche RÃ¤ume sind Anomalien vergleichbar und representativ?
Das haben die Leute von GISS in einem paper untersucht. Auf der GISS-Seite finden Sie das, ich suche jetzt nicht fÃ¼r Sie heraus.
Name und Erscheinungsjahr wird Herr Limburg sicherlich sofort nennen kÃ¶nnen, er ist ja schlieÃŸlich der groÃŸartige Experte.
PS:
Es gibt ein â€technischesâ€œ Problem. Ich versuche mal einen neuen Namen, vielleicht klappt es ja jetzt.
danke fuer den Link zum Jones Papier.
Auf Seite 5 finden sie den folgenden Satz:
â€we can calculate the average large-scale SE in a similar manner to the calculation of the large-scale average temperature anomalies.â€œ
Dort steht also, das Anomalien berechnet werden. Punkt!
Das Paper beantwortet meine Frage nicht. Ich fragte nach einer Untersuchung die beweist, das eine lineare Interpolation wirklich anwendbar ist. Jones benutzt Zeit und Raeumlich Lineare Interpolation. Und das fuer massiv grosse Gebiete, die keine Temperaturmessstellen haben. Allein die Anwendung der linearen Methode ist kein Beweis, das diese Methode richtig ist.
Und dann schauen sie mal Figure 3 an. Das sind Isolinien. Wie kommt man von spaerlichen Messungen auf Isolinien? Im Ozean! Ich bitte sie! Dort gibt es keine festen Temperaturmessstellen.
Faehrt der Dampfer mit dem Wetter mit, benutzt man seine Daten nitt!
Aber die Autoren in der hier verlinkten Links vermÃ¶gen es nicht, von diesen Fehlern ausgehend eine nachvollziehbaren mathematisch- methodische Beweiskette zu konstruieren, um damit unzweifelhaft zu belegen, warum die von CRU, GISS, WMO, u.a. angegebenen Fehlerangaben bei der globalen Anomalie zu eng seien. Es bleibt nur bei unzusammenhÃ¤ngendem Gefasel.
Man muss nicht nur lesen kÃ¶nnen, sondern auch verstehen kÃ¶nnen. Am letzteren mangelt es offensichtlich bei Ihnen.
Machen Sie sich nichts draus. Dieses Schicksal teilen Sie mit Millionen unserer Landsleute.
Bei meiner Suche nach Substanziellem in Ihren Schriften fiel mir Ihre Abbildung der Abweichungen der unterschiedlichen Tagesmittelmethoden auf die Monatsmittel auf. Je nach Tagesmittelungsmethode kÃ¶nnen dann die Monatsmittel des gleichen Rohdatensatzes um einige Zehntelgrad abweichen, am stÃ¤rksten ist der Unterschied zwischen der Tagesmittel = (Max+Min)/2 Berechnung und der Tagesmittelberechnung aus den 24 Stundentemperaturen von zwischen 0,5 und 1 Grad im Monatsmittel.
Nun besteht das Problem, dass von einigen alten Stationsaufzeichnungen z.B. in den USA nur Monats- oder Tagesmittel berechnet nach der Formal Tagesmittel = (Max+Min)/2 Ã¼berliefert sind. Diese â€Min-Max-Monatsmittelâ€œ sind daher nicht vergleichbar mit Monatsmitteln aus 24 Stundentemperaturen und Monatsmitteln aus 24 Stundentemperaturen sind nicht Ã¼berliefert.
Stimmen Sie mir nun zu, daÃŸ mit der obigen Ermittlung der Differenzen in den Monatsmitteln nach den verschiedenen Methoden an heutigen Stationen eine Korrektur fÃ¼r die alten abgeleitet werden kann und damit die Monatsmittel in die heutige 24 Stundenmethode umrechnen kann?
Dies ist nicht exakt mÃ¶glich, aber den Restfehler kann man groÃŸzÃ¼gig (also unter Annahme extremer Auswirkungen der tÃ¤glichen Temperaturkurven) abschÃ¤tzen und er ist geringer als die so angebrachte systematische Korrektur. Somit sind die alten Daten mit den heutigen â€“ zumindest was die Methode der Tagesmittelbildung angeht- vergleichbar gemacht worden.
Nein, das kann man nicht. Das kÃ¶nnte man nur dann, wenn alle anderen Randbedingungen gleich und vor allem bekannt gewesen wÃ¤ren. Sie sind aber beides nicht. AuÃŸerdem wurde das m.W.n auch nicht versucht.
Das bedeutet, dass sie fÃ¼r einen systematischen Fehler sorgen, den ich in Algrorithmusfehler getauft habe und dessen GrÃ¶ÃŸe ich in dieser Arbeit versucht habe zu quantifizieren.
CRU,GISS,WMO verwenden die gleichen Messdaten von Wetter-Stationen. Diese deckten bzw. decken die OberflÃ¤che nicht gut ab. Diesen Fehler kann man schlecht abschÃ¤tzen wenn man keine Daten hat. In dieser Hinsicht sind Satelliten-Daten, die eine bessere FlÃ¤chen-Abdeckung haben, eine wertvolle ErgÃ¤nzung.
Haben Sie sich einmal die Fehlerangabe von CRU angeschaut? Sie finden sie unter
https://www.metoffice.gov.uk/hadobs/hadcrut4/data/current/time_series/HadCRUT.4.6.0.0.monthly_ns_avg.txt
FÃ¼r 202002 geben sie als Anomalie 0,999 und ein Unsicherheit-Intervall von 0,867..1,137, also +/- 0,14 Â°C an. Allerdings ist dies kein globales Mittel da nicht die ganze OberflÃ¤che abgedeckt ist.Wie viele Mess-Stationen gibt es im Inland von GrÃ¶nland, bzw. nÃ¶rdlich von 85Â°N? Im Inland der Antarktis gibt es auch sehr wenige Stationen. Amundsen Scott ist eine viel besuchte Forschungsstation mit Flugfeld.
Vergleich: Gistemp 202002 1,25 Â°C (1951-1980), Wert bezogen auf (1961-1990) 1,139 Â°C. Dies liegt schon auÃŸerhalb des von CRU angegebenen Unsicherheit-Intervalls.
Vergleichs-Daten von Berkeley Earth bzw. Cowtan and Way liegen nicht vor. Neuere Daten von HADCRUT 4.6 liegen nicht vor.
WÃ¤rmeinsel-Effekte kann man nicht korrigieren, das ist eine VerfÃ¤lschung von gemessenen Temperaturen. Ich bin sehr skeptisch bei den verschiedenen Verfahren
fehlende Daten von nicht besiedelten Gebieten durch Extrapolation von Daten aus besiedelten Gebieten zu gewinnen. HÃ¤ufig verwendet man Ozean-Temperaturen um
Land-Temperaturen zu schÃ¤tzen. Das geht schief.
In ihrer E&E Arbeit S118 Fig 2 sieht man doch, wie die Monatsmittel der Station Puchheim von einer Tagesmittelmethode in die andere umgerechnet werden mÃ¼ssen. Der Zeitraum von 9 Jahren ist lang genug, um fÃ¼r diese Station und benachbarte Stationen monatliche Korrekturen fÃ¼r die historischen Daten anbringen zu kÃ¶nnen, um diese auf eine vergleichbare Tagesmittelmethode umzurechnen.
1. Das ist richtig, gilt aber zunÃ¤chst mal nur fÃ¼r diese Station.
2. Damit ist es nur ein Hinweis, wie groÃŸ die Unterschiede schon bei dieser gut gepflegten Station sind, gelten also zunÃ¤chst mal nicht fÃ¼r andere Stationen, mit einer EinschrÃ¤nkung, er ist sehr wahrscheinlich fÃ¼r den Rest der Welt grÃ¶ÃŸer.
2. Um sie weltweit zu verwenden, brÃ¤uchten sie die Randbedingungen vorher und nachher, die Sie nicht haben. Das ist ja die Krux. Schauen Sie sich die HARRY Readme Dateien an.
4. Und weil das so ist addiert sich zu jeder Mittelwertbildung eben dieser Unsicherheit dazu.
Ja, aber was Sie da verknÃ¼pfen basiert nur auf emotionalen EindrÃ¼cken. Der mathematische Nachweis fehlt nach wie vor.
Was ist denn der korrespondierende Fehler, der sich aus dem Zitat dieses Harrys ergibt? Aus der Prosa mÃ¼ssen Sie einen Fehlerbeitrag bestimmen, sonst bleibt das Zitat nur eine emotionale und qualitativ wertlose Aussage.
Zudem lassen sich die Tagesmittelkorrekturen schon auf mit Unsicherheitsgrenzen auf vergangene Klimate und benachbarte Stationen anwenden (punkt 3 +4). Bedenken Sie, dass die Differenzen aus den tÃ¤glichen TemperaturverlÃ¤ufen bedingt sind. Diese zeigen ein weitgehend stations- und zeitstationÃ¤res Spektrum. D.h. die ZusammenhÃ¤nge bei Puchberg sind im Rahmen von meteorologisch plausibel abschÃ¤tzbaren Genauigkeiten auch an anderen Stationen und zu vergangenen Zeiten anwendbar! Weltweit nicht, aber zumindest in der gleichen Klimazone. Aber neben der Station puchberg gibt es ja weltweit noch viel mehr, die eine solche Umrechnung historischen daten zulassen, es sind alle, die heute Ã¼ber mehrere Jahre stÃ¼ndlich und min max aufzeichnen, denn diese liefern automatisch auch ihre eigene Korrektur ihrer verschiedenen Tagesmittel nach 24 stunden methode gegen min+max/2 und Mannheimer Stunden.
1. Warum vermengen Sie eigentlich stÃ¤ndig die Themen? Die ganze Serie beschÃ¤ftigt sich mit den QualiÃ¤tsmÃ¤ngeln historischen Temperaturdaten und Sie kommen mit den modernen 24 Stundenmessungen. Was soll das?
2. Sie spekulieren, dass sich die Tagesmittelkorrekturen auch auf vergangene Klimate anwenden lassen kÃ¶nnten, weil es neben Puchberg noch andere Stationen etc. etc. etc. gÃ¤be.
Statt zu spekulieren, dass es so sein kÃ¶nnte, nennen Sie doch bitte Ross und Reiter und zitieren Belege, Quellen, papers wo das versucht wurde. Oder â€“ wenn Sie denn schon keine finden â€“ dann machen Sie es doch bitte selber, denn so schwer kann das ja nicht sein, wenn Sie Ihren eigenen Worten glauben.
die historischen Daten kann man ja nur auf die neuen 24 Stunden methode umrechnen, indem man Zusammenhang zwischen den Ergebnissen der verschiedenen Methoden kennt. Den bekommt man aus den vornehmlich moderneren Daten, die Ergebnisse mit beiden Methoden zulassen. Dieser zusammenhang besteht auch fÃ¼r die historischen Daten (in meteorologisch plausibel abschÃ¤tzbaren Grenzen)!
Aus der â€Eichungâ€œ des Umrechnungsmechanismus mit rezenten Daten erfolgt die Umrechnung der historischen Daten. Ist doch klar, anders geht es ja nicht!
Dass dieser zusammenhang grundsÃ¤tzlich besteht, folgt daraus, dass das historische Wetter tÃ¤gliche TemperaturverlÃ¤ufe hatte, die in der Form nicht grundsÃ¤tzlich anders waren als heute. Und da die Unterschiede in den Tagesmittelmethoden nur bedingt sind durch das Spektrum der TagesverlÃ¤ufe, sind die beobachtbaren Unterschiede ein (in meteorologisch plausibel bestimmbaren Grenzen) ein auch historisch zutreffendes Charakteristikum der Station und benachbarter Stationen. Ich gehe davon aus, daÃŸ Sie auch schon selbst festgestellt haben, daÃŸ dieser von ihnen genannte â€Algorithmusfehlerâ€œ an verschiedenen Stationen vergleichbare GrÃ¶ÃŸe und Systematik hat und damit als â€universelleâ€œ Korrektur verwendet werden kann.
Dann machen Sie das bitte und wenn Sie fertig sind, dann melden Sie sich bitte.
wenn ich sie richtig verstehe, denken sie das man mit den heutige 24 Stunden Daten, den Verlauf von historischen Aufzeichnungen eichen kann oder sollte.
Fuers Erstere haben sie das Problem klimatische Aenderungen von systematischen Fehlern zu Unterscheiden. Um den Fehler zu kennen, muessen sie also die klimatische Aenderung kennen. Diese wiederumg versuchen sie aus den Temperaturmessungen herrauszulesen.
Da beisst sich die Katze in den Schwanz. Aber sie sind jetzt schlauer. Endlich wissen sie wie die Klimafolgeforschung das Problem praktisch geloest hat.
Die geht naemlich davon aus, das CO2 fuer einen Temperaturanstieg verantwortlich ist. Damit sind alle Temperatursteigerungen in den historischen Daten erklaerbar und man kann davon ausgehen, das die Fehler unbedeutend und deshalb nicht interessant sind.
Ich denke sie sollten ihre Meinung auch bei der Klimafolgenforschung kund tun. Bitte berichten sie ueber die Antwort.
Die â€altenâ€œ meteorologischen Glasthermometer hatten meist eine 0,2 K â€“ Teilung. Der halbwegs geÃ¼bte Ableser schafft durchaus die 50 mK zu schÃ¤tzen. FrÃ¼here Versuche in EichÃ¤mtern haben gezeigt, dass sehr gute Leute, deren Hauptaufgabe die Kalibrierung war, auch die Zwanzigstel zwischen den Teilstrichen reproduzierbar ablesen konnten (in unserem Fall 10 mK). Ich traue mir heute noch die Zehntel zwischen den Teilstrichen zu.
Das ist aber nur die Ablesung! Zu jedem Thermometer gab es einen WerkprÃ¼fschein, meist mit Korrekturangaben alle 10 Grad. Dabei durfte von Punkt zu Punkt nur eine bestimmte Ã„nderung der Korrektur auftreten. Bevor also aus einer Ablesung eine Temperatur wird, sind gemÃ¤ÃŸ der Kalibrierdaten Korrekturen anzubringen. Wie konsequent wurde das gemacht??? Wie wurden die Thermometer messtechnisch Ã¼berwacht? Wurde z.B regelmÃ¤ÃŸig am Eispunkt gemessen, um Driften zu erkennen? Wurden die Einsatzfristen zwischen Nachkalibrierungen eingehalten? Wurde Ã¼berhaupt nachkalibriert?
FÃ¼r die heutigen elektrischen FÃ¼hler und die Folgetechnik trifft Ã¼brigens das gleiche â€Primboriumâ€œ fÃ¼r die Richtighaltung und RÃ¼ckfÃ¼hrbarkeit zu! Nur weil der Mensch nicht mehr ablesen muÃŸ, wird es nicht automatisch genauer oder sicherer.
Aus meiner Erfahrung sind also fÃ¼r die Ã¼blichen meteorologischen Temperaturmessungen kaum bessere Messunsicherheiten als Â± 1 K zu erwarten. Die Anomalienbildung sind tatsÃ¤chlich nur mathematische Spielchen die aus messtechnischer Sicht verboten sind, wenn man daraus eine Verringerung von Fehlern erwartet.
Danke, Herr Tengler fÃ¼r dieses LehrstÃ¼ck aus der praktischen Messtechnik. BG M.L.
Temperaturabweichungen entsprechend der Rahmstorfschen HÃ¼tte auf dem Berg kann man nicht messen. Ein MaÃŸband kann man am Fundament der HÃ¼tte anlegen und von da aus die HÃ¼ttenhÃ¶he bis zum Dachfirst bestimmen.
Es gibt kein Thermometer, dem man eine Temperatur aus der Vergangenheit beibringen kann, damit es dann nur die Differenz zur Gegenwart misst und anzeigt.
Das HÃ¼ttenbeispiel von Rahmstorf zeigt, mit welcher Hinterlist dieser Mann die Menschen hintergeht.
Absoluter Schwachsinn und eine UnmÃ¶glichkeit, Temperatur-Anomalien zu messen. Das sind reine Computerspiele, die aber unter Irrtumserregung als Messungen verkauft werden.
Und dieses LÃ¼gengebilde wird dann auch noch als angeblich besonders genau dargestellt. Schande Ã¼ber derartige sog. Wissenschaftler. Sie ziehen die seriÃ¶se Wissenschaft vorsÃ¤tz-lich in den Dreck!
â€Fuers Erstere haben sie das Problem klimatische Aenderungen von systematischen Fehlern zu Unterscheiden.â€œ
Hallo, hier geht es weder um klimatische Ã„nderungen noch um systematische Fehler, sondern um die Umrechnung von historischen Daten auf eine einheitliche Methode des Tagesmittels, hier als 24 Stundenmittel. Die unterschiedlichen Tagesmittel sind ja nicht als systematischer Fehler gegenÃ¼ber einer â€Sollmethodeâ€œ zu sehen.
â€Ich denke sie sollten ihre Meinung auch bei der Klimafolgenforschung kund tun. Bitte berichten sie ueber die Antwort.â€œ
Was ich schreibe ist nicht neu, sondern wird in der Klimaforschung seit Beginn an praktiziertâ€¦ Wenn es inzwischen vielfÃ¤ltige Verfahren in der Klimatologie bzw. Statistik dazu gibt.
Denken Sie aber nur mal, woher die Mannheimer Stunden kommen: Schon 1780 war den Meteorologen klar, dass man mit den drei Ablesezeitpunkten und der gewÃ¤hlten Gewichtung 1-1-2 eine praktikable Approximation fÃ¼r den (eigentlich gesuchten) Mittelwert der Tagestemperaturkurve bekommt. Integrieren von kontinuierlichen Messkurven Ã¼ber den Tag ging damals eben noch nicht. Also schuf man sich damit ein einfaches Regressionsverfahren zur nÃ¤herungsweisen Bestimmung.
Heute ist es natÃ¼rlich mit EDV ein Kinderspiel, das Tagesmittel per 3 oder n Ablesepunkten und Regression mit denselben besser zu approximieren.
Ich versuche Ihnen nur klar zu machen, daÃŸ die Differenzen durch verschiedene Tagesmittelmethoden nicht als Fehler zu werten sind, wenn diese Differenzen durch Korrekturen (â€geeichtâ€œ mit heutigen Daten) der historischen Daten reduziert werden. Ihr â€Algorithmusfehlerâ€œ ist signifikant (aber freilich nicht perfekt) behebbar.
Sie machen nichts klar, Sie spekulieren.
Suchen Sie nach Literatur, die Ihre Spekulation beweist, oder machen Sie es selbst.
Sie werden feststellen, dass Sie nicht die Metadaten haben, die Ihnen sagen welche Verfahren wo, wann wie oft etc. eingesetzt. Und das ist nur ein systematischer Fehler von vielen, die sich im Nachhinein nicht mehr korrigieren lassen. D
as sagt z.B. -wenn ich es richtig in Erinnerung habe â€“ Tom Karl oder Petersen, bei ihren durchaus ehrenwerten Versuchen diese Fehler zu definieren, ihre GrÃ¶ÃŸe und ihre Richtung fÃ¼r eine mÃ¶gliche Kompensation zu bestimmen.
gucken Sie mal in Tabelle 1 in A SIMPLE METHOD FOR ESTIMATING DAILY AND MONTHLY MEANTEMPERATURES FROM DAILY MINIMA AND MAXIMA
https://rmets.onlinelibrary.wiley.com/doi/pdf/10.1002/joc.1363
Die Autoren kommen an anderen Stationen zu Ã¤hnlichen Beziehungen zwischen den unterschiedlichen Tagesmittelmethoden wie Sie in E&E in Fig 2 und 3.
Ihr â€Algorithmusfehlerâ€œ ist also (bedingt) behebbbar bzw. reduzierbar.
So ergibt sich das Monatmittel historischer Daten nach der heutigen 24 Stundenmethode aus den historisch verfÃ¼gbaren Daten, die das Tagesmittel nach = das (Tmax+Tmin)/2 berechnet haben als
Monatsmittel (24 Std) = Monatsmittel (Min-Max) minus 0,24-0,3 K
(siehe Ihre Fig 3 und im obigen paper Tabelle 1 bias bei Tavg.).
Der â€Algorithmusfehlerâ€œ ist dann von 0,3 K auf 0,05 K (Unsicherheit der Umrechnung zwischen 0,24 und 0,3 K) oder so reduziert worden.
Ã„hnlich die Umrechnung Mannheimer Stunden etc.
Dazu benÃ¶tigt man keine Metadaten, denn wie und wo die Station die historischen Daten gemessen hat, ist unwichtig, man rechnet nur die Temperaturmittel nach damaliger Methode auf die heutige Methode am originalen Standort um.
Bei Anomalien entfÃ¤llt der â€Algorithmusfehlerâ€œ sowieso, denn da interessieren konstante Differenzen ja eh nicht.
1. Bitte und zum letzten Mal, zeigen Sie Arbeiten, bei denen die lokalen Temperaturdaten fÃ¼r die weltweite Verdichtung, nach Ihren Ideen korrigiert wurden.
2. Sie haben meinen Beitrag zu den Zeitreihen aus Anomalien nicht gelesen oder verstanden.Konstante Fehler fallen nur raus, wenn sie vor Beginn der Messreihe entstanden sind. Das gilt aber nicht fÃ¼r die angewendeten Algorithmen, die wurden oft mitten drin geÃ¤ndert. Und das mÃ¼ssen Sie wissen, sonst klappt das nicht.
nur um MissverstÃ¤ndnisse zu vermeiden:
mir ist klar, dass viele historische Temperaturreihen schlecht dokumentiert sind und einen Haufen Probleme bereiten, wenn man daraus Informationen zum Temperaturverlauf er Vergangenheit gewinnen mÃ¶chte. Aus diesem Grund ist der Fehlerbereich um die globale Anomalie dort auch grÃ¶ÃŸer als heute.
NatÃ¼rlich ist es klar, dass ein nicht dokumentierter Wechsel in der Tagesmittel-Methode eine InhomogenitÃ¤t in der Reihe erzeugt und es historische Reihen gibt, die man nicht mehr auf Tagesmittel der absoluten Temperatur nach der 24 Stunden Methode korrigieren kann, weil nicht klar ist, nach welcher Methode damals die Tagesmittel berechnet wurden. Aber es gibt eben auch Ã¼berlieferte Reihen, mit denen man das kann.
Die ganze Diskussion um die Reduzierung des â€Algorithmusfehlersâ€œ entfÃ¤llt allerdings, wenn man sowieso nur Anomalien betrachtet. Gerade deswegen
sind Anomalien auch vergleichbarer als absolute Reihen, denn egal welche Tagesmittelmethode Sie nehmen: die Reihen zeigen den selben Trend! Immer natÃ¼rlich vorausgesetzt, dass die Reihe homogen ist. Aber das ist ein anderes Thema.
zu Ihrer 1.: Ich kenne keine VerÃ¶ffentlichung, die nun Monatsmittel nach verschiedenen Tagesmittelmethoden umrechnet. Das liegt wohl daran, dass die meisten eben gleich nur Anomalien betrachten, wo ein konstanter bias keine Rolle spielt.
Wenn Sie allerdings absolute Temperaturreihen haben wollen â€“ das war ja Ihre Anfrage, mÃ¼ssen Sie dies betrachten.
Mich alleine interessiert, aus welcher Fehlerrechnung nun herauskommt, dass das Fehlerband der globalen Temperaturanomalie heute (schmal) wie historisch (breiter) von HADLEY, GISS, WMO etc. zu gering wÃ¤re. Es gibt meines Wissens keine konkrete Berechnung dazu, die auf ein anderes Resultat kÃ¤me. In Ihren verlinkten papern betrachten Sie ja nur TeilbeitrÃ¤ge der Fehler aber die Integration in einen daraus resultierenden Fehler in der globalen Anomalie fehlt.
Sie wollen oder sie kÃ¶nnen es nicht begreifen.
Es geht um die Fehlerfortpflanzung.
Die Fehler (es geht hier vor allem um systematische Fehler) verschwinden eben nicht, wenn man aus den Werten, egal welchen Anomalien bildet, sondern bleiben da, addieren sich mit der berÃ¼hmten Quadratwurzel aus der Summe Ihrer Quadrate, und haben ein um ein bis zwei GrÃ¶ÃŸenordnungen hÃ¶heres Gewicht als vorher.
Es sei denn, Sie hÃ¤tten sie zuvor einzeln oder als Gruppe sauber isoliert, ihre GrÃ¶ÃŸe und Richtung und die Zeit wann und wie lange sie aufgetreten sind, bestimmt und sie dann gegen gerechnet â€“ also korrigiert.
Das ist aber nur in wenigen SonderfÃ¤llen geschehen. Die GrÃ¼nde sind nachvollziehbar, aber tun eigentlich nichts zur Sache. Beim weitaus grÃ¶ÃŸten Teil der Daten ist das eben nicht geschehen.
In jeder anderen naturwissenschaftlichen Disziplin nimmt man diese Situation zur Kenntnis und umhÃ¼llt dann die Anomalie oder die Zeitreihe davon, mit einem Unsicherheitsband, das die GrÃ¶ÃŸe der Fehler wiedergibt. Nur in der â€Klimaforschungâ€œ passiert das nicht. Stattdessen weicht man auf Wahrscheinlichkeitsbetrachtungen aus, und bestimmt irgendwelche Sigmawerte. Das ist aber ein ganz anderer Ponyhof.
NatÃ¼rlich kann man versuchen Vergleichsmessungen und deren Ergebnisse auf frÃ¼here Daten Ã¼bertragen. Das wird aber ganz selten so gemacht. Wenn Sie also wollen dann machen Sie das bitte. Es genÃ¼gt ein moderner Computer, ein bisschen Programmierpraxis, eine Menge Know How und viel, viel Zeit. Nur zu!
Wenn Sie damit fertig sind kommen Sie wieder. Und wenn dann alles stimmt, was Sie so herausgefunden haben, dann kriegen Sie einen Orden.
Meine Aufgabe und auch die Dissertation war, diese MÃ¤ngel herauszuarbeiten, sie zu quantifizieren sowie eine grobe AbschÃ¤tzung zu erstellen, Ã¼ber die MindestgrÃ¶ÃŸe. Die finden Sie dort, ebenso wie in meinem Vortrag. Meine Aufgabe war nicht, diese Aufgabe den Klimaforschern abzunehmen, dazu gab es weder die MÃ¶glichkeit, noch die Notwendigkeit.
Das ist mein letzter Wort in dieser Angelegenheit.
Das war doch die Dissertation, mit der Sie durchgefallen sind.
Mir scheint, Sie werden nie begreifen, wo Ihre Fehler lagen.
Sie sind zwar unwissend oder bewusst lÃ¼gend, aber pampig. Passt zusammen.
Wahr ist, dass die UniversitÃ¤t die Ablehnung meiner Dissertation zurÃ¼ck genommen hat, und sich fÃ¼r Ihr Verhalten mir gegenÃ¼ber, bzw. dem ihrer Gremien entschuldigen musste.
M.L.
Wieder einmal wird klar, auf welch â€solidenâ€œ Beinen diese â€Klimaforschungâ€œ steht. Hinzu kommen deren hÃ¶chst fragwÃ¼rdige Klimamodelle samt ewig falscher und Ã¼bertriebener Alarmprognosen â€“ KlimaGate und Mannâ€™schem Hockey Stick-Betrug vervollstÃ¤ndigen das ziemlich unerfreuliche Bild! Doch die Klimakatastrophen-HÃ¶rigen schlucken alles, was diese Alarmisten-Truppe produziert â€“ mit Ratio hat das nichts mehr zu tun.
Fehler wie in den Abbildungen 8 bis 10 sind ja nicht auszuschlieÃŸen. Bevor Klimadaten weiterverarbeitet werden sie daher auf HomogenitÃ¤t geprÃ¼ft. Die Verfahren sind bekannt. Wieso sollten die Autoren, die damit globale Mitteltemperaturen berechnen, das nicht wissen? Es ist anzunehmen, daÃŸ die nur homogenisierte Reihen verarbeiten bzw. die Homogenisierung selbst vornehmen.
Ihre Annahme trÃ¼gt leider. Lesen Sie bitte die angegebene Literatur. Hier finden Sie noch viel mehr, https://www.eike-klima-energie.eu/publikationen/michael-limburg/.
Eine oberflÃ¤chliche Suche nach entsprechender Literatur liefert schnell z.B. den in Teil 1 von mir verlinkten Artikel zur paarweisen Homogenisierung in GHCN oder zum Artikel: â€Homogenization of Temperature Data â€“ An Assessmentâ€œ in dem steht:
Das deckt sich mit der Anmerkung von Sverre Petersen. Die Bildung von Anomalien soll die in Abbildung 8 bis 10 dargestellten Fehler nicht beseitigen. Dass die das nicht kÃ¶nnen, damit haben sie recht. DafÃ¼r werden andere Methoden angewendet.
1. Welche?
2. Bitte Quellen zu den RAW Data. Keine Meinungen.
die Antwort vom admin (Hr. Limburg?) ist in der Tat widersprÃ¼chlich. Der link dort fÃ¼hrt u.a. zur Diss. Limburg. Dort wird klar zitiert:
Dissertation_5-4-2bLit_01.pdf
S.15, FuÃŸnote 17
Das wird auch in Zukunft schwierig bleiben, denn das fÃ¼r die OriginaldatensÃ¤tze verantwortliche britische Hadley Center schrieb kÃ¼rzlich in einer mail (http://rogerpielkejr.blogspot.com/2009/08/we-lost-original-data.html ) an Prof. R. Pielke (12.8.09). â€We are not in a position to supply data for a particular country not covered by the example agreements referred to earlier, as we have never had sufficient resources to keep track of the exact source of each individual monthly value. Since the 1980s, we have merged the data we have received into existing series or begun new ones, so it is impossible to say if all stations within a particular country or if all of an individual record should be freely available. Data storage availability in the 1980s meant that we were not able to keep the multiple sources for some sites, only the station series after adjustment for homogeneity issues. We, therefore, do not hold the original raw data but only the value-added (i.e. quality controlled and homogenized) data.â€œ Mit anderen Worten, die OriginaldatensÃ¤tze sind verschwunden und somit der Forschung nicht mehr zugÃ¤nglich
Und S. 44
Bewertung der amerikanischen Messstationen auf S. 2845 â€â€¦One thousand two hundred twenty-one homogeneity adjusted stations in the United States were computed using a different technique. These are high quality rural stations taken directly from the U.S. Historical Climatology Network (U.S. HCN; Easterling et al.1996a), a sister project to GHCN. These data were adjusted using a metadata approach as part of the creation of the U.S. HCN and their adjusted time series were directly incorporated into GHCN. For climate analysis confined to the United States, the U.S. HCN is the preferred dataset because its stations are well distributed, mostly rural stations that were selected based upon their location and their station history metadata.â€œ (Hervorhebungen vom Autor)
Hier steht doch, daÃŸ z.B. das Hadley Center quality controlled and homogenized Temperatur-DatensÃ¤tze verwendet. Und Stationsdaten im das GHCN sind auch homogeneity adjusted.
Dann noch Tabelle S. 70
1 Fehlerbenennung: Instrumentenfehler 0,1 â€“ 0,2 Â°C, MaÃŸnahme zur Fehlerbewertung: Keine, von gelegentlichen Ausnahmen abgesehen
2 Fehlerbenennung: Ungleiche, nicht regelkonforme Aufstellung von WetterhÃ¼tten, verÃ¤nderte Landnutzung, UHI 1-5 Â°C MaÃŸnahme zur Fehlerbewertung: Wenige bekannt, sehr aufwendige Homogenisierung, Metadaten w.w. kaum bekannt, Pauschale Korrekturen im 0,1Â°C Bereich
Auch in seiner Tabelle gibt er zu, dass Homogenisieren eine Methode der Klimaforscher ist.
Dann noch S. 29
ZusÃ¤tzlich muss die HomogenitÃ¤t, der Messungen gesichert sein. Homogenisierung bedeutet, die Messungen mÃ¼ssen von nicht-klima bestimmten EinflÃ¼ssen bereinigt sein, und die Messverfahren und -regime mÃ¼ssen fÃ¼r die Vergleichszeiten und -flÃ¤chen standardisiert sein. All diese Voraussetzungen waren aber in frÃ¼hen historischen
Phasen nicht gegeben, die erzielbare Messgenauigkeit betrug lt. SchÃ¶nwiese damals nur ca. 1Â° C.
Also wieder die BestÃ¤tigung, daÃŸ homogenisiert wird. Wo SchÃ¶nwiese das schreibt und ob sich dieses Zitat auf die Behauptung anwenden lÃ¤ÃŸt, lÃ¤ÃŸt sich nicht prÃ¼fen, denn die genaue Quelle wird nicht genannt.
Auch Limburg muss daher davon ausgehen, daÃŸ die Klimaleute homogenisierte Reihen verarbeiten bzw. die Homogenisierung selbst vornehmen und daher die in den Abbildungen skizzierten Fehler den Klimatologen sowohl bekannt sind und durch Datenaufbereitung gerade eliminiert werden sollen.
Das hat doch niemand bestritten. Nur muss man die ganze Geschichte kennen, die Homogenisierung ist der verstÃ¤ndliche aber verzweifelte Versuch, Fehler, die in den Nachbarstationen mit Sicherheit vorgekommen sind, auf Verdacht zu kompensieren.
Auch nach Bekanntwerden der WattÂ´schen Ergebnisse hat die US WetterbehÃ¶rde versucht, die offensichtlichen Fehler per Homogenisierung zu mindern, bzw. auszumerzen. Das ging aber meistens schief, weil sie die Vergleichsdaten gar nicht haben.
Sie sollten sich mit dieser Frage ausfÃ¼hrlicher beschÃ¤ftigen.
Mit freundlichen GrÃ¼ÃŸen
M.L.
also Sie meinen, Homogenisierung ist notwendig, kann aber nicht mit der notwendigen Genauigkeit erreicht werden, um in eine Fehlerangabe von wenigen Zehntel Grad bei der globalen Temperaturanomalie zu resultieren?
Aber wo ist diese Rechnung, der Beweis?
Die von Ihnen beschriebenen Fehlerquellen sind ja Klimaleuten bekannt. Statt also Bekanntes ausfÃ¼hrlich zu beschrieben und mit ausgewÃ¤hlten Einzelzitaten zu schmÃ¼cken, sollten Sie mal lieber Ihre Entdeckung darlegen, und mathematisch beweisen, warum die Fehlerangaben falsch sind. All diese Leute geben in ihren papern Fehlerquellen an, Sie zitieren die ja. Aber es fehlt bei Ihren AusfÃ¼hrungen der Beweis, daÃŸ die Leute trotz quantitativer Angaben zu Fehlerquellen und der Angabe eines resultierenden Fehler die Fehlerrechnung falsch machten.
Dazu mÃ¼sssen Sie die Prozess der Datenverarbeitung der Temperaturreihen wie ihn Brohan, Jones, Hansen und andere gemacht haben, selbst im Detail nachvollziehen und zeigen, an welchen Stellen genau diese etwas falsch machten.
Es nÃ¼tzt aber nichts, dass den Klimaleuten die Fehlerquellen bekannt sind, wie Sie schreiben, was sie im Ã¼brigen in fast allen FÃ¤llen nur dem Typ nach sind. Denn sie kennen oft nicht die wirkliche Art, die GrÃ¶ÃŸe und die Richtung dieser Fehler. Und haben auch keinerlei Chancen diese bei den historischen Daten nachtrÃ¤glich zu bestimmen. Dazu fehlen so gut wie sÃ¤mtliche Metadaten.
Und genau das ist ja das Problem. Den Text aus HARRY READ.Me haben Sie offensichtlich nicht gelesen, oder nicht zur Kenntnis genommen.
Und genau deswegen wurde ja die Homogenisierung erfunden.
Sie kÃ¶nnen sich gerne die umfangreiche BeweisfÃ¼hrung in meiner Dissertationsschrift z.b. ab S 141 anschauen. Vorab nur eine FuÃŸnote daraus.
Zum Thema der Homogenisierung: Aus â€Klimarekonstruktion der instrumentellen Periode â€“ Probleme und LÃ¶sungen fÃ¼r den GroÃŸraum Alpenâ€œ Reinhard BÃ¶hm Zentralanstalt fÃ¼r Meteorologie und Geodynamik, Wien S. 6 â€¦.Problem, an dem alle entsprechenden mathematisch-statistischen Methoden leiden, die ja in ihrem Kern auf demselben Grundprinzip beruhen: Man berechnet Differenz- oder Quotientenreihen hochkorrelierter Nachbarreihen, testet sie auf abrupte SprÃ¼nge, die statistisch signifikant sind, und eliminiert diese unter der Annahme der angenommenen zeitlichen StationaritÃ¤t der Differenzen (Quotienten). Da Ã¼blicherweise alle Reihen irgendwann nicht- klimatologische SprÃ¼nge haben, gilt es noch das Problem der Zuordnung zu lÃ¶sen, welche der Reihen die infizierten und welche die Referenzreihen fÃ¼r ein betrachtetes Subintervall mit einer Sprungstelle sind. Das kann man mit statistischen WahrscheinlichkeitsÃ¼berlegungen abklÃ¤ren, indem man in regionalen Subgruppen von typischerweise 10 Reihen alle Reihen mit allen anderen testet. Die sich ergebende Entscheidungsmatrix (typischerweise 10*10) liefert dann recht eindeutige Ergebnisse, wenn die SprÃ¼nge nicht alle zur selben (Ã¤hnlichen) Zeit erfolgen.
Und Seite (12)- 156: Das oft gehÃ¶rte Argument, dass bei Verwendung genÃ¼gend vieler Einzelreihen die InhomogenitÃ¤ten in der Mittelreihe als â€random effectâ€œ verschwinden wÃ¼rden, ist nicht zutreffend. Es gibt sehr wohl systematische InhomogenitÃ¤ten, die auch grÃ¶ÃŸere Gebiete betreffenâ€œ
Und dazu muss man wissen, dass das Projekt â€Histalpâ€œ Ã¼ber die Klimaentwicklung der Alpen ein hÃ¶chst anspruchsvolles, aufwendiges, langfristiges und teures Projekt war, dass nur in wirklich gut bestÃ¼ckten Regionen, die perfekt gewartete Stationen aufwiesen, durchgefÃ¼hrt werden konnten. UnmÃ¶glich â€“ wie HARRY das so verzweifelt beschreibt- das nachtrÃ¤glich fÃ¼r die restliche Welt durchzufÃ¼hren.
Das gilt auch fÃ¼r den â€Goldstandardâ€œ USA
Zitat aus meiner Fehlertabelle S 137 (und das ist nur eines von mehreren Beispielen)
siehe NOAA CRN Class 2 same as Class 1 with the following differences. Surrounding vegetation less than 25 centimeters. Artificial leating soure es within 30 meters. No shading for a SUfi elevation greater than 5Â°.Referenz US
Fehlerart Grob, Systematisch Selten berÃ¼cksichtigt, Homogenisierung aufwendig, lÃ¼cken- und fehlerhaft. S. Beispiele D Ìaleo Central Park New York [Dâ€™Aleo, 2008 #18863]
Das es Homogenisierung der Daten gibt ist bekannt. Wie wirksam diese ist, sei eine andere Frage. Oder auch wofÃ¼r man diese nutzen kann.
Hier ein kleines Praxisbeispiel in Englisch. Da sie auch in Englisch zitieren lasse ich das mal so stehen:
https://ipa.org.au/publications-ipa/bureau-cooling-the-past-to-declare-record-heat
Es geht um die ACORN-SAT version 2, Temperatur Database und entsprechende â€Homogenisierungenâ€œ.
Vielleicht interessant dann auch dieser Artikel:
https://jennifermarohasy.com/2019/02/changes-to-darwins-climate-history-are-not-logical/
Man muss leider aufmerksam verfolgen was wirklich passiert.
Das Herr Rahmstorf unrecht hat kann man mit diesem Absatz feststellen:
â€Das Zitat oben von Stefan Rahmstorf am 12.2.18[1] ist ein Beispiel zur Behauptung warum Anomalien genauer sind als die ihnen zugrunde liegenden Absolutwerte. Er hat bis heute nicht begriffen, dass er in diesem Beispiel Absolutwerte misst und diese als Anomalien ausgibt. Klimaanomalien werden jedoch nicht gemessen, sondern aus den Absolutwerten mit all ihren Fehlern berechnet. â€
Ich stimme Ihnen voll zu.
Die behautptete Genauigkeit in der Globaltemperaturmessung von +-0.05 Grad C entspricht der A b l e s e g e n a u i g k e i t von guten Thermometern in der Meteorologie (siehe Hupfer e.a. â€Witterung und Klima, Eine EinfÃ¼hrung in die Meteorologie und Klimatologieâ€œ). Diese Temperatur in der MeÃŸhÃ¼tte hat aber zunÃ¤chst nichts mit der â€klimatisch relevantenâ€œ AuÃŸentemperatur zu tun.
Am problematischsten sind natÃ¼rlich die Ã„nderungen in der Umgebung der MeÃŸstelle, und hier besonders der Stadtinseleffekt (UHI), der auch noch eine logarithmischer AbhÃ¤ngigkeit von der Einwohnerzahl hat. Demnach sind besonders kleine wachsende StÃ¤dte kritisch.
Nimmt man eine typische Formel (nach Hupfer z.B. die â€Kanadische Formelâ€œ, u=3.5 m/s), dann ist fÃ¼r eine Zunahme der Einwohnerzahl von 10000 der maximale UHI-Effekt:
â€“ in einer Kleinstadt von 10000 Einwohnern 0.58 Grad C
â€“ und bei einer GroÃŸstadt von 100 000 Einwohnern fÃ¼r die selbe Zunahme 0.08 Grad C.
Ein mittlerer UHI_Effekt kann mit etwa einem Drittel dieses Wertes abgeschÃ¤tzt werden.
Ausgerechnet die kleinen StÃ¤dte, die meistens noch als lÃ¤ndlich â€ruralâ€œ angesehen werden, zeigen also bei ihrem Wachstum die grÃ¶ÃŸten UHI-Effekte.
Die Definition von â€ruralâ€œ von Phil Jones e.a in in seinem Artikel â€Assessment of urbanisation effects in time series of surface air temperatures over Landâ€œ, auf den sich das IPCC bezieht, ist vÃ¶llig daneben. Als schlimmstes Beispiel sind hier nur die chinesischen StÃ¤dte angegeben:
â€Eastern China: Rural < 0.1 million (after statistics 1984)."
â€“ sind 0.1 Million Einwohner wirklich noch "rural"??
â€“ und wie stark sind gerade in China diese StÃ¤dte seit 1984 gewachsen?
Man kann nur festhalten: Seine Behauptung ebenda "It is unlikely, that â€¦ could increase the overall urban bias above 0.050C during the twentieth century." ist geradezu abenteuerlich!
Fazit ist, daÃŸ gerade bei den Bodenmessungen die nichtklimatischen EinflÃ¼sse unmÃ¶glich herauszukorrigieren sind, und daÃŸ sie fÃ¼r Klimaanalysen genaugenommen nicht taugen. Am besten lÃ¤ÃŸt man die Finger davon.
MfG
G.Wedekind