Ein Schmuddelthema der Klimadiskussion ist die nachträgliche Veränderung von Messdaten in den offiziellen Temperaturzeitreihen. Während die entsprechenden Forscher ihren regelmäßigen Eingriff in die Datenbanken als “Korrektur” und “notwendige Anpassung” bezeichnen, sehen einige Skeptiker darin plumpe Manipulation. Wie so immer im Leben, findet sich die Wahrheit wohl irgendwo in der Mitte. Wir haben bereits mehrfach über die Problematik hier im Blog berichtet. Im heutigen Beitrag wollen wir neue Analysen und Publikationen aus diesem hochsensiblen Bereich vorstellen.
Im Juni 2017 fasste eine Gruppe um James Wallace III ihre Untersuchungsergebnisse zu Datenveränderungen in den wichtigsten Temperaturdatenbanken zusammen. Dabei erkannten sie, dass im Laufe der Zeit natürliche Zyklen in der Temperaturentwicklung der letzten 150 Jahre systematisch händisch abgemildert wurden, was das Vertrauen in die Daten untergräbt. Das pdf der Studie finden Sie hier. Die Bedenken der Wallace-Gruppe bekräftigen Kritikpunkte, die Ross McKitrick bereits 2010 auf SSRN vorbrachte.
Der HadCRUT-Datensatz wird vom Hadley Centre des UK Met Office sowie der Climatic Research Unit (CRU) of the University of East Anglia und bezieht sich auf die globale Temperaturentwiclung de letzten 150 Jahre. Immer wieder werden neue Versionen erstellt, mittlerweile ist man bei HadCRUT4 angelangt. Die Tendenz der nachträglichen Datenveränderungen wird in einem direkten Vergleich von HadCRUT3 und HadCRUT4 deutlich (via Woodfortrees) (Abb. 1):
Gut zu sehen: Die nachträglichen Veränderungen der Archivdaten haben den “Hiatus” der letzten 15 Jahre in eine Phase leichter Erwärmung von etwa 0,1°C verwandelt. Nicht gerade die feine englische Art, um die unbequeme Erwärmungspause aus der Welt zu schaffen. Leider enden die HadCRUT-Daten im Jahr 2015, so dass man den Vergleich nicht bis heute (2017) verlängern kann. Im Jahr 2012 brachte die IPCC-nahe Plattform Realclimate einen weiter zurückreichenden Vergleich von HadCRUT3 und HadCRUT4 (Abb. 2):
Zu erkennen: Die modernen Temperaturen wurden um etwa ein Zehntel Grad hochgesetzt, während die Temperaturen um 1900 nahezu unverändert blieben. Unterm Strich führte dies zu einer nachträglich produzierten Versteilung der Erwärmung, sozusagen “anthropogen”, denn von Wissenschaftlern selber am Schreibtisch erzeugt.
Die Datenveränderungen gehen unterdessen weiter, auch nach 2015. Im Stil der Salamitaktik wird die Erwärmung immer weiter künstlich versteilt. Ole Humlum bringt in seinem monatlichen Newsletter Climate4You die jeweils aktuellen Klimadaten. Unter anderem vergleicht er die verschiedenen Versionen der Datensätze miteinander. Hier die kürzlichen Veränderungen des GISS-Datensatzes, der vom bekennenden Klimaaktivisten Gavin Schmidt verantwortet werden. In rot die Vorversion aus dem Mai 2015, in blau die aktuellen Daten (Abb. 3). Ergebnis: Wieder eine Salamischeibe: Erwärmung um ein halbes Zehntelgrad versteilt.
Nächstes Beispiel: NCDC-Datensatz, wo sich das gleiche Bild bietet (Abb. 4).
Lange galten die Satellitendatensätze UAH und RSS als zuverlässiger als die Bodendatensätze, die ständig nachjustiert werden. Zumindest für die RSS-Daten gilt dies mittlerweile nicht mehr, denn auch hier hat man nun mit dem Verändern der Daten begonnen (Abb. 5). Auch hier beträgt die künstliche Versteilung jetzt 0,1°C. Man wundert sich, dass ähnliche Korrekturen durchgeführt wurden, obwohl die Messverfahren und Begründungen äußerst unterschiedlich sein sollten. Die RSS-Änderungen wurden in einem Paper von Mears & Wentz (2017) u.a. mit dem Absinken der Satellitenbahn begründet.
Die RSS-Datenveränderungen kommen nicht ganz unerwartet. Der UAH-Satellitendatenexperte Roy Spencer hatte bereits zu Jahresbeginn 2017 vermutet, dass RSS auf Druck der anderen Temperaturdatenbanken Änderungen durchführen würde. Um die Unabhängigkeit der verschiedenen Temperaturdatensysteme ist es offenbar nicht gut bestellt. Vielmehr herrscht Gruppendenken vor. In einem unaufgeregten, lesenswerten Blogbeitrag kommentierte Roy Spencer die RSS-Veränderungen und erläuterte, weshalb er ihnen kritisch gegenübersteht.
Die Temperaturdatenveränderungen der verschiedenen Systeme ist bedenklich. Letztendlich handelt es sich um einen Änderungsbetrag von vielleicht ein oder maximal zwei Zehntelgrad. Irgendwann werden die Justierungen aufhören müssen. Bei einer von den Modellen prognostizierten Erwärmung von zwei Zehntelgrad pro Jahrzehnt wird der Zeitpunkt kommen, wo der Spielraum der Datenmassage voll ausgereizt ist. Bis dahin sollten wir die Vorgänge kritisch begleiten, die in den Medien unbeachtet bleiben.
Link: http://www.kaltesonne.de/temperaturen-der-letzten-150-jahre-wenn-messdaten-nachtraglich-geandert-werden/
Dieser Beitrag ist zuerst im Blog „die Kalte Sonne“ erschienen.
2 Bemerkungen