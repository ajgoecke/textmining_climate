Um Folgendes geht es:
Manipulation von globalen Temperaturdaten:
Tausende nicht-städtische Messorte wurden ausgesondert
Seit 1998 wurden 0,3°C Wärme hinzugefügt, um den ,Stillstand‘ zu beseitigen
Von dem Trend 1880 bis 1950 wurden 0,5°C Wärme subtrahiert
Im Verlauf der letzten paar Jahrzehnte haben es die drei Hauptbetreiber von Datensätzen der globalen Temperatur vom 19. Jahrhundert bis zur Gegenwart – NOAA, NASA und HadCRUT – erfolgreich geschafft, diese Temperaturaufzeichnungen so zu frisieren, dass sie zu den Ergebnissen der Klimamodelle passen. Genauer, es gab konzertierte Bemühungen, die Vergangenheit kälter zu machen – vor allem die Warmperiode von den zwanziger bis zu den vierziger Jahren – und die Temperaturwerte aus jüngeren Jahrzehnten zu erwärmen, vor allem nach dem Jahr 1950. Auf diese Weise erscheint ein Trend einer starken linearen Erwärmung, der ähnlich aussieht wie die lineare Form anthropogener CO2-Emissionen im 20. und 21. Jahrhundert. Passen die beiden Verläufe besser zusammen, hilft das, eine Kausalität zu implizieren, und diese vorgebliche, in Kausalität umgewandelte Koinzidenz kann dann herangezogen werden, um politische Maßnahmen zu rechtfertigen, die fossile Treibstoffe eliminieren sollen.
Seit den siebziger Jahren wurden 75% aller GHCN-Temperatur-Messpunkte ausgesondert.
Eines der am wenigsten erwähnten Mittel, die zu diesem „Aussehen“ der Temperaturkurve führt, war die tendenziöse und umfassende Aussonderung Tausender Wetterstationen und Messpunkten in abgelegenen Gebieten, auf Bergen und/oder nicht-städtischen Stellen seit den siebziger Jahren. Alle diese Stationen zeigen nicht den von den Modellen prophezeiten Erwärmungstrend, sind sie doch nicht betroffen von der Nähe zu künstlichen oder nicht-klimatischen Heizquellen (befestigte Straßen, Gebäude, Maschinen, Industrie usw.), wie es bei urbanen Messpunkten der Fall ist. (Wie weiter unten detailliert erläutert, kann die Aufstellung von Thermometern nahe urbanen Heizquellen einen Warm-Bias zwischen 0,1°C und 0,4°C pro Jahrzehnt hervorrufen).
Falls eine in krassem Missverhältnis stehende Anzahl NICHT-urbaner Wetterstationen aus dem globalen Temperaturarchiv entfernt werden, erhalten die urban aufgestellten Thermometer ein viel größeres Gewicht als vor der Entfernung der nicht-städtischen Messpunkte. Darum wird eine solche Temperaturaufzeichnung viel mehr Erwärmung zeigen – obwohl diese zusätzliche Wärme nicht klimatischen Ursprungs, sondern künstlich erzeugt ist.
Und genau das ist auch geschehen. Das Global Historical Climatology Network (GHCN) ist die primäre Quelle für Aufzeichnungen von Temperaturdaten aus der ganzen Welt. NOAA, NASA und HadCRUT sind sehr stark von der GHCN-Temperaturhistorie abhängig bei der Konstruktion ihrer globalen Datensätze bis zurück zum 19. Jahrhundert. McKitrick (2010) zufolge gab es noch bis in die siebziger Jahre des vorigen Jahrhunderts hinein zwischen 5000 und 6000 GHCN-Messpunkte auf der ganzen Welt, welche zum Temperaturarchiv beitrugen. Heute (oder bis zum Jahr 2009) sind davon noch etwas über 1000 Stationen übrig geblieben – 75% aller in dem siebziger Jahre noch in Gebrauch gewesenen Thermometer sind verschwunden. Es gibt jetzt weniger Stationen, die zum GHCN beitragen, als im Jahre 1919.
Erstaunlicherweise befinden sich fast die Hälfte aller GHCN-Messpunkte (49% im Jahre 2009) auf der Welt auf (betonierten) Beton- oder Asphaltflächen auf Flughäfen!
„Es gibt drei große globale Temperatur-Historien: die kombinierte CRU-Hadley-Aufzeichnung (HadCRU), die NASA-GISS-Aufzeichnung (GISTEMP) und die NOAA-Aufzeichnung. Alle drei globalen Mittel hängen vom gleichen zugrunde liegenden Datenarchiv ab, dem Global Historical Climatology Network (GHCN). Infolge dieser Abhängigkeit vom GHCN werden die Qualitäts-Defizite auch die Qualität aller abgeleiteten Produkte beeinträchtigen.
Die Anzahl von Wetterstationen, die zum GHCN beitragen, erfuhren 1990 und dann noch einmal 2005 einen scharfen Rückgang. Die Stichprobenmenge ist seit dem Spitzenwert Anfang der siebziger Jahre um 75% gesunken und ist jetzt kleiner als zu jedweder Zeit seit 1919“.
Zunehmender Bias durch Aufstellung an Flughäfen:
„Der Kollaps der Stichprobenmenge hat den relativen Anteil von Daten, die von Flughäfen stammen, um etwa 50% zunehmen lassen (von etwa 30% in den siebziger Jahren). … Die Änderung der Menge war hinsichtlich des Typus‘ der Quelle nicht ausgewogen. So wurde die Stichprobenmenge zu Flughafen-Bedingungen hin verzerrt. Die GHCN-Daten hatten schon immer ein Übergewicht von Flughäfen, welche aus vielen Gründen ungeeignet für das Klima-Monitoring sind. Ein Problem mit Flughäfen besteht darin, dass sie oftmals nahe urbanen Plätzen liegen, die während der letzten paar Jahrzehnte gebaut worden waren, und die Zunahme des Luftverkehrs hat dazu geführt, dass Verkehr, Versieglung von Flächen, Gebäude und Abwärme zugenommen haben. Diese Einflüsse sind allesamt nur schwer aus den Temperaturaufzeichnungen zu entfernen. … Im globalen Maßstab kamen im Jahre 2009 49% aller GHCN-Daten von Flughäfen (NH 46%, SH 59%). Ende der zwanziger Jahre waren es lediglich etwas über 20%“. — McKitrick, 2010
Tom Karl von der NOAA hegte einst Bedenken hinsichtlich des Warm-Bias von Flughäfen und Städten.
Ende der achtziger Jahre dachte man, dass der Warm-Bias von 0,1°C bis 0,4°C aufgrund der Thermometer-Aufstellung auf Flughäfen oder in urbanen Gebieten die globalen Temperatursätze ernsthaft beeinträchtigen würde mit einem „substantiellen Anteil am Gesamt-Trend globaler und regionaler Temperaturen“, welche diesen Warm-Bias direkt reflektieren. Die „künstliche Erwärmung im Netzwerk der primären Stationen“ ist niemals verschwunden. Heute wird dieser Umstand einfach ignoriert.
„Karl et al. (1988) haben gezeigt, dass in einigen Städten des Sun Belt [in den westlichen USA] der Temperaturanstieg, der dem Wärmeinsel-Effekt zugeordnet werden kann, bis zu 0,3°C bis 0,4°C pro Dekade beträgt … Die künstliche Erwärmung im Netzwerk der Primärstationen beträgt relativ zu den Daten in der Division Klima fast 0,17°C während der letzten 34 Jahre (seit ~1950). Derartige Trends sind zumindest genau so groß wie jedweder der anderen beobachteten Trends in den USA (Karl 1988) oder auf dem Globus (Jones und Wigley 1987)“.
„Die Ergebnisse zeigen, dass die beiden festlands-basierten Datensätze der Temperatur in den USA über das 20. Jahrhundert (1901 bis 1984) einen urbanen Bias von +0,1°C bis +0,4°C aufweisen. … Gegenwärtig können nur grobe Schätzungen der potentiellen Auswirkungen der Verstädterung angegeben werden. Dies enthält einen urbanen Bias in den Daten von Hansen und Lebedeff (1987; NASA), der über die USA zwischen 0,3°C und 0.4°C im 20. Jahrhundert liegt. Dieser Wert ist größer als der Trend insgesamt in den USA während dieses Zeitraumes. … Unseres Wissens nach sind die USA das einzige große Gebiet, in welchem die Größenordnung dieses Bias‘ sorgfältig untersucht worden ist.
Es stellte sich heraus, dass die Größenordnung dieses urbanen Bias‘ in den beiden landbasierten Datensätzen einen substantiellen Anteil beiträgt zu dem Gesamttrend der globalen und regionalen Temperaturen“.
Kukla, Gavin, and Karl, 1986
„In städtischer Umgebung liegende Stationen in Nordamerika erwärmten sich zwischen 1941 und 1980 im Vergleich zu ländlichen Stationen (Abkühlung) mit einer mittleren Rate von etwa 0,12C pro Dekade. Säkulare Trends der Lufttemperatur, die vorherrschend aus urbanen Stationsdaten berechnet werden, haben sehr wahrscheinlich einen starken Warm-Bias. … Wir verglichen Trends der 34 städtischen/ländlichen Stationspaare … wobei die städtischen Stationen im Vergleich zur freien Landschaft während fast des gesamten Jahres eine Erwärmung zeigen.
Die jährliche mittlere Differenz zwischen den Trends beträgt etwa +0,11°C pro Dekade (nicht-klimatische Erwärmung infolge der Nähe zur Stadt). … Die mittlere Differenz zwischen Trends (zwischen urbaner bzw. ländlicher Umgebung) summieren sich zu einer jährlichen Erwärmungsrate von 0,34°C pro Dekade. … Der Grund für die merklich höhere Erwärmungsrate (könnte sein), dass die Rate nach den fünfziger Jahren zugenommen hat, entsprechend dem jüngsten starken Wachstum in der Umgebung von Flughäfen. … Unser Ergebnisse sowie auch diejenigen anderer Autoren zeigen, dass die Inhomogenität durch urbanes Wachstum erheblich ist und berücksichtigt werden muss, wenn man die Zuverlässigkeit von Temperaturaufzeichnungen abschätzt“.
Zunehmender Bias an Tiefland-Stationen
„Die stetige Zunahme (der mittleren Seehöhe von Temperaturstationen seit den achtziger Jahren) ist konsistent mit einer Verlagerung der Stationen des Netzwerkes weiter landeinwärts, ebenso wie einer zunehmenden Zahl von Stationen in den Bergen. Der Kollaps der Messpunkte im Jahre 1990 ist eindeutig sichtbar als ein drastischer Rückgang nicht nur der Anzahl, sondern auch der Seehöhe. Dies impliziert, dass abgelegene Stationen in größerer Höhe aufgegeben wurden zugunsten von Messpunkten in Tälern und an küstennahen urbanen Stellen. Dies geschah ein zweites Mal im Jahre 2005. Nun tendieren Stellen mit geringer Höhe über dem Meeresspiegel dazu, mehr von Landwirtschaft, Verstädterung und anderen Modifikationen der Landschaft betroffen zu sein. Dieser Vorgang, eine gleichbleibende Seehöhe der Messpunkte, verletzt die statistische Kontinuität. … GHCN hat immer mehr Messpunkte in höher gelegenen Gebieten aufgegeben (z. B. in Richtung der Pole) zugunsten von tiefer gelegenen Stationen. Wenn alle anderen Umstände gleich bleiben, impliziert dies, dass immer weniger Daten aus entfernt liegenden, kalten Regionen und mehr aus bewohnten, wärmeren Regionen eingehen“. — McKitrick, 2010
Die Ergebnisse: eine künstliche Erwärmung des Festlandes seit 1980:
NOAA Global Land vs. Sea
HadCRUT Land vs. Ocean Temperature Anomalies
Die NOAA fügt seit 1998 0,3°C Erwärmung (relativ zu Satelliten) hinzu
Jüngst wurde die Studie von Karl et al. (2015), das „Pause-Buster“-Paper, erneut signifikanter Kritik unterzogen durch einen anderen ehemaligen NOAA-Wissenschaftler (Tom Karl war im Jahr 2015 der Direktor der NOAA) aufgrund von Vorwürfen, dass es politischer Druck war, die Studie vor der Pariser Klimakonferenz im Dezember 2015 an die Presse zu leiten ohne die vorschriftsmäßigen Qualitäts-Checks. Der Grund dafür war offensichtlich: Falls man den unbequemen Stillstand der globalen Erwärmung, über den im IPCC-Bericht 2013 berichtet worden war, eliminieren könnte, wäre dies ein bedeutender Vorgang, der die Regierungschefs zu Versprechungen ermutigen könnte, CO2-Emissionen zu reduzieren. Unglücklicherweise sind die zur Berechnung des neuen Trends herangezogenen Temperaturdaten in der NOAA-Veröffentlichung „verloren gegangen“ aufgrund eines schadhaften Computers, der „vollständig abgestürzt“ sei, so dass es kaum die Chance gibt die Studie einer unabhängigen Replikation oder Verifikation zu unterziehen.
Seitdem hat die New York Times eine Verteidigung der NOAA-Kontroverse ausgegeben mit der Behauptung, dass der Trend von 1998 bis 2014 von Karl et al. (2015) durch andere Wissenschaftler unabhängig verifiziert worden sei, ebenso wie durch Satellitendaten, die zeigen, dass der Trend von +0,11°C pro Dekade (+0,2°C insgesamt) zwischen 1998 und 2014 in allen Datensätzen konsistent war.
Diese Behauptung ist natürlich Unsinn. Mittels der verfügbaren Rohdaten und dem WoodForTrees interactive tool erkennt man, dass die Trend-Diskrepanz für den betrachteten Zeitraum 1998 bis 2014 fast 0,3°C beträgt, wenn man den jüngst erzeugten NOAA-Trend mit Satellitendaten (RSS) vergleicht. Es gibt sogar eine Differenz von 0,5°C zwischen den Endpunkten der Trendlinien von NOAA/NASA GISS sowie RSS (Dezember 2014). Die aus den Satellitendaten hervorgehende Abkühlung von -0,1°C wurde von Karl et al. (2015) in eine Erwärmung von +0,2°C umgewandelt. Fast augenblicklich nach deren Veröffentlichung wurde der neue Erwärmungstrend 1998 bis 2014 von der NASA und HadCRUT gleichermaßen akzeptiert, was dazu führte, dass alle drei Datensätzen jetzt eine signifikante Erwärmung zeigen, während sich zuvor ein Stillstand, ja sogar eine geringe Abkühlung zeigte.
HadCRUT radiert die leichte Abkühlung von 1998 bis 2012 einfach aus mittels Änderung der Versionen
Die Änderung [politisch] unpassender Temperaturtrends gerade rechtzeitig vor einem Ereignis von großer Bedeutung für die internationale Politik und Öffentlichkeit gab es auch früher schon.
Der kombinierte Datensatz von HadCRUT) – welcher den IPCC-Berichten zugrunde liegt – wurde im März 2012 einer Revision von Version 3 zu Version 4 unterzogen. Dies war etwa ein Jahr vor der geplanten Veröffentlichung des jüngsten IPCC-Berichtes erfolgt (2013). Zu jener Zeit (Anfang 2012) war es für das Paradigma ziemlich unbequem, dass sich bei HadCRUT4 zwischen 1998 und 2012 ein leichter Abkühlungstrend zeigte, wie die Graphik unten zeigt (Rohdaten von HadCRUT3 und HadCRUt4 von WoodForTrees).
Graphiken des IPCC, die einen leichten Abkühlungstrend seit 1998 zeigten, wären für diejenigen Politiker inakzeptabel gewesen, die die Dringlichkeit des Kampfes gegen eine gefährliche globale Erwärmung betonen wollten. Also wurden pünktlich zur Ausgabe des IPCC-Berichtes 2013 dem HadCRUT-Trend etwa 0,1°C Erwärmung hinzugefügt. Damit sollte die leichte Abkühlung in etwas transformiert werden, was das IPCC einen „Stillstand“ der Erwärmung nannte. Um den in HadCRUT3 auftretenden leichten Abkühlungstrend zu entfernen, wurden die jüngeren Anomalien in HadCRUT4 erwärmt (um 0,1°C bis 0,2°C), während die Wärme der Vergangenheit (besonders um das Jahr 1998) unangetastet gelassen wurde. Der Effekt war, dass die Gegenwart wärmer und die Vergangenheit kälter gemacht wurden.
Quelle: WoodForTrees
IPCC-Analyse (2013) des „Stillstandes“ der Erwärmung von 1998 bis 2012
Im Zeitraum 1998 bis 2011 zeigen 111 der 114 Klimamodell-Simulationen einen Erwärmungstrend, der größer ist als der beobachtete Trend.
Während des im Jahre 1998 beginnenden 15-jährigen Zeitraumes liegt das Ensemble der HadCRUT4 GMST-Trends unter fast allen von Modellen simulierten Trends.
Fast alle historischen Simulationen der CMIP5-Modelle reproduzieren nicht den beobachteten jüngsten Erwärmungs-Stillstand.
NASA hat seit den neunziger Jahren etwa 0,5°C von der Erwärmung 1880 bis 1950 subtrahiert
Noch im Jahre 1990 war weithin akzeptiert, dass der globale Temperaturtrend, wie er von der NASA angegeben wurde (Hansen und Lebedeff 1987) zwischen 1880 und 1950 einen Anstieg um 0,5°C zeigte.
Die Untersuchung sehr langer Aufzeichnungen (z. B. Amsterdam von 1682 bis 1930 sowie Brest seit 1807) hat gezeigt, dass es zwischen dem Ende des 19. und Mitte des 20. Jahrhunderts zu einer Beschleunigung von 0,9 mm pro Jahr gekommen war. Da diese Beschleunigung mit der jüngsten Änderung der globalen Temperatur (ein Anstieg um 0,5°C) zwischen 1880 und 1950 korreliert mit weniger bedeutenden Änderungen vor und nach diesem Zeitraum (Jones et al. 1986 sowie Hansen & Lebedeff 1987) und mit einem markanten Abschmelzen von Gletschern der Mittleren Breiten wurde sie interpretiert als korrespondierend mit einem eustatischen Anstieg.
Dieser Anstieg der globalen Temperaturen um 0,5°C zwischen 1880 und 1950 (sowie 0,6°C zwischen 1880 und 1940) erscheint klar in der NASA GISS-Graphik aus dem Jahr 1987:
Schneider, S. H. 1989. The greenhouse effect: Science and policy. Science 243: 771-81.
Heute ist es für die Datensätze der globalen Temperatur von HadCRUT, NASA und NOAA nicht mehr akzeptabel, einen starken Erwärmungstrend während der ersten Hälfte des 20. Jahrhunderts graphisch darzustellen. Grund hierfür waren die CO2-Emissionen, die damals keine Änderungen zeigten und vernachlässigbar waren im Vergleich zu heute während dieser abrupten Erwärmungsperiode, wie hier gezeigt:
Um also die Unbequemlichkeit eines nicht-anthropogenen Erwärmungstrends in modernen Zeiten zu eliminieren, haben die NASA und NOAA die gesamte oder fast die gesamte Erwärmung von 0,5°C zwischen 1880 und 1950 eliminiert. Falls Rohdaten der Temperatur in der Vergangenheit nicht zu dem Narrativ passen, dass menschliche CO2-Emissionen den Klimawandel treiben, müssen die Rohdaten eben verändert werden. Auf diese Weise erhält man das Paradigma am Leben.
Link: http://notrickszone.com/2017/02/13/more-data-manipulation-by-noaa-nasa-hadcrut-cooling-the-past-warming-the-present/
Übersetzt von Chris Frey EIKE
Wegen Faschin eine etwas vrezögerte Antwort:
Es belibt bei den alternative facts.
Ich hatte im Web keinen Hinweis auf eine Beheizung der Rollflächen gefunden. Mittlerweile habe ich die dritte Auskunft, diesmal vom Bereichsleiter Winterdienst:
Ihr Verweis darauf, dass die Verwaltung mir gegenüber nicht die Wahrheit sagen muss, komentiere ich hier nicht weiter. Aber ich bleibe dabei: Sie liefern hier alternative Fakten, in München spricht man von Legenden.
Ach ne, wirklich?!?
Die (De-)Qulaifizierung als „Alternative Fakten“ nehme ich gerne zurück, wenn mir jemand 5 Deutsche Flughafenstationen (Wetterstationen aus dem GHCN-Netz) zeigt, die nicht wie im Standard vorgegeben über einer Grasfläche, sondern über Asphalt oder Beton messen (weniger als 4m Abstand zu größeren Betonflächen lasse ich gerne als „über Beton gemessen“ gelten).
warum geben Sie sich eigentlich nicht ein wenig mehr Mühe, wenn Sie hier auf Eike kommentieren? Wenn Sie so etwas „raushauen“ wie die obigen 2 Kommentare, kann man Sie doch auch mit viel Empathie nicht Ernst nehmen! Wie wäre es, wenn Sie einen Kommentar, den Sie unbedingt loswerden wollen, erst einmal eine Stunde zur Seite legen und dann noch mal darüber nachdenken, ob er sinnvoll ist? Dann wäre Ihnen das übliche Mißgeschick wie hier wahrscheinlich nicht passiert. So kann man nur verwundert den Kopf schütteln, wenn man feststellt, dass Sie
– einen Abstand von 4 m anscheinend für ausreichend halten, um einen Wärmeinseleffekt auszuschließen und
– nicht über Bezeichnungen wie „betonierte Betonfläche“ stolpern und einfach mal im Originalartikel nachschauen, um dann festzustellen dass dort gar nicht von Betonflächen gesprochen wird.
So bleibt bei Ihren Kommentaren oftmals nur die Frage „Dumm oder Troll?“ – wollen Sie das wirklich?
MfG
PS: Ich habe von Ihnen auch schon vereinzelt richtig gute Kommentare gelesen – vielleicht gelingt es Ihnen ja, so ein Niveau mal in einen höheren Prozentbereich zu heben.
Astonishingly, as many as half (49% as of 2009) of the weather stations across the globe used by the GHCN are now located on the (paved) grounds of airports.
Ich finde Herr Frey hat diesen Satz recht treffend übersetzt und die Intention des Autoren ist klar.
Ihre Kritik an meinen 4 Metern Distanz ist berechtigt. Ich hätte auch 10 oder 50m schreiben können. Auf den Flughäfen mit hohem Verkehrsaufkommen liegen (in Deutschland) die Wetterstationen in aller Regel mehr als 100m von der nächsten Rollbahn entfernt.
Der Autor versucht den Eindruck zu erwecken, als würde an den Flughafenmessstellen über befestigtem Grund gemessen: Das ist BS.
Und wen Lieschen Müller oder Roland Dumb dies liest, dann glaubt er dies womöglich. Da sind ja schon ganz andere auf Schmonzes hereingefallen: ich sage nur : Schweden 17.02.2017.
ich verstehe die Kritik an der Verwendung der Flughafenmessstellen: diese sind durch den Flugbetrieb beeinträchtigt. Nur habe ich Zweifel, dass der Einfluss des Flugbetriebs so hoch ist, wie es bei EIKE schon gemutmaßt wurde. Die Frage die sich mir stellt: Wie viele DWD-Messstellen liegen auf großen Flughäfen (mehr als 100 Flugbewegungen/d im Schnitt)?
Nicht einmal 1% der DWD Stationen sind es.
Ich habe mir mal die Lage von 25 DWD-Stationen auf den Flugfeldern angesehen: von 25 Stationen war nur bei drei Stationen der Mindestabstand zu befestigten Flächen (10m) unterschritten. Nur die Berliner Stationen lagen näher als 100m von der nächsten Rollbahn entfernt.
MfG
Und ob 10m Abstand ausreichen?
Das glauben Sie nicht wirklich, oder?
ich sprach von den deutschen Flughäfen.
Können Sie einen Flughafen mit Landebahnheizung nennen? Der Abstand zu den Landebahnen liegt in der Regel über 100m bei den DWD Flugplatzstationen.
Zu Ihrer Frage nach 10m Abstand zu befestigten Flächen:
Besser wäre ein größerer Abstand, aber der Einfluss auf die 2m-Lufttemperatur dürfte bei 10m Abstand zu befestigten Flächen (z.B. kleinere befestigte Straßen) dürfte eher gering sein. Aber keine Sorge, bei den meisten von mir geprüften Flugplatz-Stationen ist der Abstand wesentlich größer.
22. Februar 2017 um 17:22
Der Sinn einer Flugplatzstation besteht darin den Piloten die Verhältnisse für die Start- und Landeberechnungen möglichst präzise mitteilen zu können. Als Referenz für das Umland sind diese Stationen ungeeignet. Die Station EDHL ist als Klimastation ungeeignet, weil von betonierten und asphaltierten Flächen geradezu umzingelt. Am Tage zu warm und in der Nacht zu kühl.
Alternative Fakten?!?
Selbst wenn dies Stimmen sollte: Abstand der Wetterstation zum Rollfeld ist dort mehr als 400m. Aber bis Sie einen Beleg bringen bleibt es für mich ein „alternativer Fakt“.
Jaja…
Laberlaberlaber
MUC ist in D übrigens nicht der einzige.
Warum weiß ich es?
Weil ich da gearbeitet habe und u.a. die Heizölkostenrechnung gesehen habe.
Bis Sie einen Beleg bringen bleibt es für mich ein „alternativer Fakt“.
Aber möglicherweise können Sie Ihre „Tatsachen“behauptung auch belegen. Ich hatte keinen Beleg für ein Beheizungssystem der Runways gefunden. Und Ihre vage Aussage ist und bleibt ein netter Versuch, kein Beleg.
Insbesnodere nach dieser Mail von der MUC-Betreibergesellschft bleibe ichbis auf weiteres bei meiner Einschätzung:
Heute vermutlich nicht.
Im Sommer auch nicht.
Aber bei Glättegefahr, Schnee und Nebel.
Ich weiß das.
nachdem die Antwort aus München interpretationsspieleraum ließ (siehe Ihre Anmerkung vom 23. FEBRUAR 2017 UM 16:06) hatte ich nochmals bei der MUC Betreibergesellschaft nachgefragt ob es am Airport MUC Einrichtungen zu Beheizung des Startbahnbelags gibt.
Die Antwort war eindeutig.
Also bleibe ich dabei: Sie verbreiten bezüglich MUC „alternative Fakten“.
Nebenbei: Mir ist sehr wohl bewusst, dass der Flughafen Dessau einst eine beheizbare Startbahn hatte.
Besso keks, Ihre subjektive Wahrnehmung hat sich auch an anderer Stelle als falsch erwiesen, wenn an diese objektiven Kriterien angelegt werden. Aber es war interessant mit welchen schlagkräftigen Argumenten Sie hier aufwarten („Ich weiß das“).
MfG
Ketterer
P.S. Ja Herr Heinzow, ich bin auch der Meinung, dass DWD-Stationen auf Flugplätzen (wie auch viele andere DWD-Stationen) mit einer gesunden Skepsis betrachtet werden sollten. Ich kenne eine (mittlerweile nicht mehr aktive) DWD-Station, deren Regenmesser nicht verlegt wurde, nachdem das in der Nähe stehende Bäumchen „erwachsen“ geworden war und mit seinem Laubwerk den Hellmann abschirmte.
Sie ist Ihnen gegenüber auch nicht verpflichtet die Wahrheit zu sagen.
fragen Sie doch einfach mal in Ihrem Bekanntenkreis herum, wer denn weiß,
– was es mit „climategate“ auf sich hat,
– dass es seit 20 Jahren keine signifikante Erwärmung gibt,
– dass die Temperaturdaten seit Jahren Richtung Erwärmung manipuliert werden (von Ph. Jones über M. Mann und GISS bis zu Karl et. lol.)
– dass die Eisbärenpopulation in den letzten Jahrzehnten stark zugenommen hat,
– dass es nicht mehr Extremwetter gibt usw. usf.
Sie werden feststellen, dass die deutsche Zipfelmütze keinerlei Ahnung vom Thema hat, was auch kein Wunder ist, denn Politik und Medien tun ja alles, um eine Information des Bürgers zu vermeiden.
D.h. die Hinweise, die Sie zu der Erkenntnis führten, dass man nur verar… wird, haben die meisten Deutschen noch nie in ihrem Leben zur Kenntnis nehmen können!
MfG
natürlich wird von dem Medien nichts Gegenteiliges veröffentlicht. Ja nicht einmal die Aussagen des IPCC z.B. hinsichtlich kein Anstieg der Extremwetter oder der sogenannten Pause werden von den Medien gebracht, weil dies wohl die armen Bürger verunsichern würde.
Zu den deutschen Daten: Die sind rechtmäßig erhoben und Nachkorrekturen konnte ich noch nicht erkennen, da ich das Archiv von früher kopiert habe (Stand 2010) und nun regelmäßig fortschreibe. Aber die DWD Daten sind sehr stark wärmeinselbehaftet. Eine Korrektur haben bereits im Jahre 2010 Leistenschneider/Kowatsch geliefert, die inzwischen längst durch singuläre Stationen in der freien Natur eine ´gute Bestätigung gefunden haben. Und danach gilt: Die Jahrestemperaturen stagnieren/fallen seit 1998, die Wintertemperturen fallen seit 1988 und stagnieren schon 10 Jahre früher. Also 20 Jahre bei den Jahresmitteln und zumindest 30 Jahre beim Winter keine Erwärmung mehr. Einer der Gründe für das unterschiedliche Verhalten ist, dass im Sommer der Wärmeinseleffekt höher ist als im Winter. Vereinfacht ausgedrückt: Im Winter bleibt der Beton in der Stadt kalt, im Sommer speichert er die Sonnenwärme. Im Winter wird der viel kleinere WI hauptsächlich durch die zusätzlichen Heizungen bestimmt. Hier als Beispiel die ländliche Station Neugersdorf, deren Einwohnerzahl seit 30 Jahren gleich geblieben ist und somit kaum einen zusätzlichen WI entwickelt hat. (Außer öffentliche Gebäude und Straßenbau). Im Sommer ist Neugersdorf somit leicht WI-behaftet, da viel öffentlich verbaut, trockengelegt und betoniert wurde. (Aufbau Ost) Die Trendlinien sind für das Jahresmittel 20 Jahre: y = – 0,003x (stagnierend), für 30 Jahre Winter: y= – 0,06x (fallend) und für 40 Jahre Winter: y = – 0,009x. (stagnierend) Von einer Klimaerwärmung ist in der Oberlausitz in der freien Fläche, das sind 90% des Landes in der Gegenwart nichts zu erkennen. Aber die Klimalüge wird weitergehen, weil es dumme Deutsche gibt, die Fakten nicht wahrhaben wollen. Unwissende glauben einer
Sie haben sich auf das Thema Wärmeinseln spezialisiert . Ich teile Ihre Auffassung, , dass das ein ganz wichtiger Punkt in der Klimaerwärmungsdiskussion ist.
In Dresden gibt es vor dem Neustädter Bahnhof eine Wetter-Messstation. Gleichzeitig gibt es auch einen großen freien Platz. Diesen Platz ist jetzt zubetoniert beziehungsweise asphaltiert. Das war nicht immer so. Vor etwa zehn Jahren (den genauen Zeitpunkt habe ich nicht parat) gab es in der Mitte des Platzes eine große grüne Rasenfläche. Da kommt bei Menschen mit unserer Denkweise doch sofort die Frage auf, ist die Umwandlung des Platzes in den Temperaturwerten der Messstation nachweisbar? Ich würde mich sehr freuen , wenn Sie dieser Frage nachgehen würden. Wenn ich Ihnen dabei helfen kann, bitte melden.
Mit freundlichen Grüßen ,
Gerhard Kühn