Lewis/Curry (2018) kommen zum Ergebnis:
1,3°C für eine Verdopplung des CO2-Gehaltes der Atmosphäre bis etwa zum Ende dieses Jahrhunderts (Transient Climate Response), 1,7°C für ein langfristiges Gleichgewicht (ECS) etwa im Zeitraum 2150 bis 2200. Die Zahlen reagieren kaum empfindlich auf die Wahl von Zeitfenstern, sie schwanken nur sehr wenig, ob man 1870…2016 auswertet oder 1930…2016. Es gab eine ganze Reihe von Vorläuferarbeiten auch anderer Autoren, die ebenfalls etwa diese recht geringen Werte fanden. Auch Arbeiten, die historische Zeiträume (letztes glaziales Maximum bis vorindustriell) unter die Lupe nahmen, widersprechen diesen niedrigen Zahlen nicht.
Wie wir schon häufiger ausgeführt haben, laufen die Klimamodelle zu heiß, sie rechnen mit einer zu hohen ECS- im Mittel liegen sie bei 3°C. Dass diese Modelle nicht einmal die vergangenen 30 Jahre richtig wiedergeben können und daher die Modelle künstlich für diese Zeit mit einer um ein Drittel und mehr verringerten Sensitivität rechnen, hat Steve Koonin (Under Secretary for Science unter Präsident Obama von 2009 bis 2011) vor geraumer Zeit auf einem Hearing der American Physical Society (S. 255) offenbart. Das IPCC nennt das scaling (WG 1, Chapter 10, S. 882), auf deutsch was nicht passt, wird passend gemacht. Denn für die Zukunft rechnen die Modelle dann wieder mit der um ein Drittel höheren Sensitivität.
Können die IPCC-Modelle vor der Empirie gerettet werden?
Wenn Modelle und Wirklichkeit nicht zusammenpassen, sollten eigentlich Wissenschaftler eher ihre Modelle in Frage stellen. Das hieße, die viel dramatischeren Sensitivitäts- Abschätzungen der letzten IPCC-Modellbetrachtungen – 1,86°C für TCR und 3°C für ECS – müssten über den Haufen geworfen werden. Die IPCC-Wissenschaftler stellen sich eher die Frage, wie können die IPCC Modelle mit ihren besorgniserregenden Projektionen vor der Empirie gerettet werden? Denn daran hängt ja der ganze Alarmismus, der die westlichen Gesellschaften prägt, von Fridays for Future bis zur CO2-Steuer.
Ein Schlüsselargument bisher geht so: Modelle sagen eine andere räumliche Verteilung der Erwärmung der Ozeane voraus als das, was wir beobachten. Es könnte also durchaus sein, so Aktivisten, dass die Abweichung eine „Laune der Natur“ wäre, eine interne Variabilität, und nach Beendigung dieser eher zufälligen Episode die Erwärmung „modellkonform“ viel stärker wird im globalen Maßstab. Und daher versucht das IPCC mit allem Krampf, im nächsten Bericht wieder eine viel zu hohe CO2-Sensitivität durchzudrücken.
Hier nun leisten zwei aktuelle Arbeiten Aufklärung. Um es vorweg zu nehmen: Die Beobachtungen der Erwärmungsrate sind korrekt, die abweichenden Muster der Klimamodelle entstehen durch ihre Unzulänglichkeiten, und die Muster werden sich auch nicht ändern.
Die IPCC-Modelle sehen beispielsweise als Ergebnis des menschgemachten CO2-Antriebs eine recht gleichmäßige Erwärmung des tropischen Pazifiks. Die Beobachtungen jedoch stellen eine bedeutend stärkere Erwärmung des westlichen tropischen Pazifiks gegenüber dem östlichen fest.
In Dong et al (2019) weisen die Autoren nach, dass, wenn sich die konvektiven Regionen mit vielen Wolken des westlichen Pazifiks stärker erwärmen als die mit kaum Konvektion des Ostpazifiks, die globale Gesamterwärmung deutlich weniger ausgeprägt ist. Die Konvektion im westlichen tropischen Pazifik führt dazu, dass es eine verstärkte Abstrahlung von Wärme in den Weltraum gibt, die dortige Erwärmung also viel effektiver abgebaut werden kann, als dies bei einer stärkeren Erwärmung des östlichen Pazifiks mit geringerer Konvektion möglich wäre. Es ist also ein klarer physikalischer Mechanismus, der dazu führt, dass die beobachtete stärkere Erwärmung des tropischen Westpazifiks zu geringeren globalen Sensitivitäten (= stärkeres negatives globales Feedback) führt. Wieder einmal scheitern die Modelle an den Wolken!
Große Defizite in der Abbildung des Geschehens
Klimamodelle haben so große Defizite in der Abbildung des Geschehens im tropischen Pazifik, dass sie dadurch die Antwort auf den Antrieb global falsch ermitteln und die Empfindlichkeit auf den CO2-Antrieb systematisch überschätzen, wie eine zweite Arbeit von Seager et al von der Columbia University in der angesehenen Wissenschaftszeitung Nature (!) vom Juli 2019 zeigt: „The failure of state-of-the-art models to capture the correct response introduces critical error into their projections of climate change“.
Konsequenzen? Keine. Ich habe Zweifel, dass die Ergebnisse der beiden bedeutenden Arbeiten überhaupt inhaltlichen Eingang in den kommenden Sachstandsbericht des IPCC finden werden. Dann nämlich müsste man hunderte Seiten kritisch überarbeiten, die sich mit Modellprojektionen beschäftigen.
Ein Grund mehr für uns, der Empirie zu vertrauen und nicht der „Playstation Klimatologie“. Aber was soll dann aus der „Panik“ werden, die uns Fridays for Future verordnen wollen? Alles nur heiße Luft? Die Politik läuft heiß, weil die Modelle zu heiß laufen. Welche Wissenschaftler haben den Mut und sehen ihre Verantwortung, FFF und die Politik aufzuklären? Selbst wenn wir die CO2-Emissionen auf dem heutigen Niveau aufrechterhalten und nicht weiter steigen lassen, bleiben wir in diesem Jahrhundert unter 500 ppm und unterhalb von zwei Grad Erwärmung.
Lesen Sie zum Thema auch Fritz Vahrenholts Seite „Die Kalte Sonne“.
Zuerst erschienen bei der Achse des Guten
mit Bestimmtheit werden die Gletscher wieder wachsen (ich hoffe allerdings, das nicht erleben zu müssen, denn auch einem wachsenden Gletscher wird die Menschheit nichts entgegensetzen können – aber ok, der IPCC und seine Jünger natürlich schon).
Jedenfalls empfehle ich bezüglich der Gletscher dies zu konsultieren.
https://ethz.ch/de/news-und-veranstaltungen/eth-news/news/2018/11/eiszeitensimulation-macht-gletscherausdehnung-sichtbar.html
Wer lesen und verstehen kann, ersieht, dass die Gletscher sogar sehr oft sich weiter zurückgezogen haben als heute – und das ebenfalls sehr schnell.
Und wer weiters lesen kann, mag noch die beseelten Kommentare eines Herrn Knutti und seiner Mannen lesen – sie sprechen für sich.
Und wer ein wenig rundliest, liest auch über die Freude von Glaziologen und Archeologen, weil die Gletscher alte – früher freiliegende Reste – wieder freigeben.
Viel Vergnügen!
Am Beispiel Pasterze: 1990 entdeckte Heinz Slupetzky Reste einer mehr als 9000 Jahre alten Zirbe. Holzfragmente wurden von 3500 – 9000 Jahren alten Bäumen gefunden. Vor 5 Jahren kamen große Baumstücke zum Vorschein. Damals musste die Pasterze also noch kleiner als heute gewesen sein, wenn dort Zirben 300 Jahre alt werden konnten!
Das bekanntere Beispiel dürfte „Ötzi“ sein, der vor über 5000 Jahren gestorben und vom Eis bedeckt wurde und erst 1991 wieder herausgeapert ist. Er wird sich wohl kaum selbst unter den Similaun-Gletscher gegraben haben.
Genauso wie die zu wissen glauben, dass die Alpen in 100 Jahren gletscherfrei sein werden, werden die Gletscher so wie sie es seit Millionen Jahren tun, auch wieder wachsen.
Ihre Ansicht, dass sich Klimata nur in eine Richtung bewegen, ist Unfug!
Nun genau darum geht es, das Klima bewegt sich aktuell rapide in eine Richtung aufgrund des menschgemachten Klimawandels. Vielleicht sollten Sie mal (so wie ich es schon mehrmals getan habe) zu einer Klimakonferenz gehen und schauen wie viele Wissenschaftler dort über die Tatsache diskutieren ob es einen menschgemachten Klimwandel gibt oder nicht (Spoiler altert: keinen). Es ist heutzutage einfach absurd das zu leugnen, vergleichtbar mit der flat-earch Diskussion.
natürlich sind es einzelne Fälle, dass manche Gletscher früher kleiner waren. Und alle Gletscher, die sie kennen, sind natürlich keine einzelnen Fälle! Und diese Gletscher waren natürlich nie kleiner.
Und da sie offensichtlich ein Prognosen-Fan sind, anstatt dass sie sich auf die einigermaßen bekannte Vergangenheit beziehen, darf ich vorschlagen, wir hören im Jahr 2100 voneinander und stellen gemeinsam fest, ob die Alpen eisfrei sind.
Nur zum Verständnis, was ich von Extrapolationen von Statistiken halte:
Notieren sie sich die Temperaturen von Jänner bis Juli und extrapolieren sie die Regressionsgerade bis Weihnachten. Dann können sie einen neuen Hitzerekord prognostizierten.
Für Unfug bin ich auch immer zu haben.
So gut finde ich das Video auch wieder nicht. Der Typ ist mir etwas zu hektisch. Könnte ein Vorläufer von Rezo sein.
Ist für mich durch die Hektik nicht ganz herausgekommen: 3mm/Jahr Meeresspiegelanstieg durch die Erwärmung und Ausdehnung der Ozeane. Wirft er diese Aussage jetzt den Skeptikern vor oder will er sagen, dass kein Polareis schmilzt?
Wären, falls noch wer rechnen kann, 30cm/Jahrhundert – 25cm bis 2100! Wo sind jetzt die schellnhuberschen 6 Meter?
Nun auf welcher Basis wollen wir denn über die Zukunft reden anstelle von Prognosen? Kristallkugel? Jetzt ist die Zeit um etwas gegen den Klimawandel zu tun und nicht im Jahr 2100.
Und Modellrechnungen sind keine lineare Extrapolation von Statistiken. Dass sie für Unfug immer zu haben sind sieht man deutlich an den Inhalten die Sie verbreiten.
Zum Video (und vielleicht konzentrieren Sie sich bei Ihren Bemerkungen auf den Inhalt): die Aussage ist klar dass Polareis schmilzt oder? Ich bin mit den Aussagen von Schellhuber nicht vertraut, aber lineare Interpolation macht vermutlich auch hier keinen Sinn.
Allerdings wird bei linearer Interpolation das Niveau Ihrer Antworten in 2 Antworten den Nullpunkt erreichen.
Bestünde Benzin nur aus Oktan (C818) wären das 6.548 Mol Oktan pro Liter.
Bei einer vollständigen Verbrennung des Oktans brauche ich:
C8H18 + 12 1/2 O2 => 8 CO2 + 9 H2O
Wir erhalten also 8 Mol Kohlendioxid pro Mol Oktan. Ein Mol Kohlendioxid entspricht 44 g, sind wir bei 2,31 kg Kohlendioxid aus dem Liter Oktan.
In Wirklichkeit ist Benzin ein Gemisch aus verschiedenen Kohlenwasserstoffen (35-60% Alkane wie Oktan, 5-15% Olefine, 25-42% Aromaten, in Deutschland ja auch noch 5% oder 10% Ethanol (Alkohol)), trotzdem dürfte das Oktan-Beispiel die Richtung aufzeigen …
Da es nicht möglich ist, den anthropogenen Anteil an der Erwärmung zu extrahieren, haben Lewis & Curry eine Abschätzung von TCR und ECS nach OBEN unternommen. Sämtliche Erwärmung wurde als anthropogen angenommen.
Bei einem signifikanten Anteil natürlicher Erwärmung rutschen die Sensitivitäten auf Werte um oder unter 1 Grad ab.
Dazu passender Artikel von Roy Spencer:
http://www.drroyspencer.com/2018/02/diagnosing-climate-sensitivity-assuming-some-natural-warming/
Orkane, Wirbelstürme werden bei der Klimaerwärmung also nicht zunehmen. Aber warum tischt man uns solche Lügen auf. Damit Klimahysterie bis zur endgültigen Vollendung ihren Höhepunkt erfährt? Aber wenn uns solche Märchen aufgetischt werden, zweifel ich auch an der These, dass der Klimawandel durch Menschen gemachten CO2 Ausstoß verursacht worden ist. Und eines ist auf jeden Fall klar. Eine CO2 Steuer in Deutschland, wird auf das Weltklima überhaupt keinen Einfluss haben. Auf einer so wackeligen wissenschaftlichen Grundlage, die auch vor Lügen nicht zurückschreckt, bin ich nicht bereit, mich als hart arbeitende Mensch, auf Hartz4 Niveau herunter besteuern zu lassen. Und solange es Menschen gibt, die uns die Mobilität verbieten wollen, obwohl sie so gerne vom ungemütlich kalten Deutschland ins warme Florida fliegen, um Eis zu essen, weil ihnen offensichtlich das Klimaerwärmte Deutschland über Sylvester noch zu kalt ist, bin ich nicht bereit dazu, irgendwelche unverschämten Einschränkungen hinzunehmen.
Da der solare Anteil (durch Regressionsanalysen nachgewiesen) bei 57% liegt und damit der Effekt der THG 43% ist, wovon CO2 etwa 60% ausmacht, sollte der CO2-Anteil nicht bei 80%, sondern nur bei etwa 25% liegen.
Man ist immer wieder erstaunt dass einerseits Zweifel am TE gesät werden, IPCC offenbar aber doch geschont werden soll – obwohl die strahlungsphysikalisch korrekt berechneten und sehr viel geringeren Werte längst bekannt sind.
Desweiteren ist ne globale Temperaturanomalie Quatsch, weil ein Blick auf die Temperaturvariabilität der Great Plains in den USA etwas gänzlich anderes zeigt als die paar Messungen auf den Ozeanen, die 2/3 der Erdoberfläche ausmachen aber nicht ohne Zeitverzug auf die Sonnenstrahlungsvariabilität und Wolkendichte der Erdatmosphäre.
Sehr unwahrscheinlich, denn beide sind ja erst Ende Juni bzw. im Juli veröffentlicht worden.
Ihre Zweifel teile ich, Ihre Begründung ist definitiv falsch. Wiederholt wurden in IPCC-Berichten Arbeiten berücksichtigt, die nach Redaktionsschluss veröffentlicht wurden. Der Unterschied liegt nur darin, dass diese Arbeiten die Sicht des IPCC („Der Mensch ist Schuld“) teilen und dem nicht widersprechen.
Würde das IPCC nach wissenschaftlichen Prinzipien arbeiten, müsste der nächste Bericht die Svensmark-Theorie mindestens genauso lang und breit thematisieren wie die Annahme, dass das menschgemachte CO2 das Klima bestimmt – hätte, hätte, Fahrradkette!
MfG
wenn man Ihre Behauptungen genauer betrachtet gibt es noch mehrere solche schwachsinnigkeiten zu entdecken.
Der Kohlenstoffanteil im Kraftstoff bestimmt, wie viel CO2 bei der Verbrennung des Kraftstoffes entsteht.
So werden bei der Verbrennung von einem Liter Benzin 2,37 kg CO2 freigesetzt und bei der Verbrennung der gleichen Menge Diesel 2,65 kg CO2.
Dass ein Liter Kraftstoff dabei mehr als 2 kg CO2 produziert, ist in der Masse des eingebundenen Luftsauerstoffs begründet.
Das ist in der Tat (fast) so, denn das Benzin „holt“ sich bei der Verbrennung den Sauerstoff aus der Luft.
1 Liter Benzin, mal angenommen, er bestünde zu 100 % aus Oktan, wiegt 0,7 kg oder 6,128 mol. Aus jedem Mol Oktan, das verbrennt, entstehen 8 Mol CO2, also ca. 49 mol oder 2,16 kg. Nicht ganz 2,5 kg. Aber tatsächlich ist 1L Benzin etwas schwerer als 0,7 kg und besteht aus einer Vielzahl verschiedener Substanzen. Die genaue Zahl dürfte bei Benzin irgendwo zwischen 2,16 und 2,5 kg liegen, bei Dieses etwas oberhalb von 2,5 kg.
Übrigens: 2,16 kg CO2 sind etwas mehr als 1 Kubikmeter (ca. 1100 Liter).
1 Liter Benzin → ca. 2,3 kg CO2
Verbreiten sie bitte nicht so einen Unfug!