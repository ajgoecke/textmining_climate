Den „größten Stromausfall der deutschen Nachkriegsgeschichte“ hat jedoch die Schneekatastrophe zum Jahreswechsel 1978/79 verursacht – wenn die DDR dabei mit betrachtet wird. Dort waren die Folgen geradezu dramatisch, und so nahm die Katastrophe ihren Lauf:
Das Szenario: In der Nacht vom 28. zum 29. Dezember stürzt im Norden der DDR die Temperatur von zehn Grad über Null auf minus zwanzig Grad. Die nördlichen Bezirke versinken bei gefrierendem Regen binnen weniger Stunden unter einem dicken Eispanzer, dann setzt dort ein dreitägiger Schneesturm ein. Während Erich Honecker zu einem Freundschaftsbesuch nach Afrika aufbricht und seine Minister sich schon zur Silvesterfeier verabschieden, dringt die Kaltfront nach Süden vor und legt dabei den Arbeiter- und Bauernstaat lahm. Bei der Bahn frieren die Weichen ein, Züge mit festgefrorener Braunkohle können nicht mehr entladen werden, und bei minus zwanzig Grad müssen die Braunkohlentagebaue ihre Förderung einstellen. Weil die Energieversorgung auf ständigen Nachschub angewiesen ist, gerät das Stromnetz der DDR immer mehr aus dem Takt. In den Energiekombinaten Thüringens wird schließlich die „Geheime Verschlusssache“ geöffnet; sie enthält den Befehl zur Abschaltung aller Verbraucher – der Süden der DDR versinkt ausgerechnet in der Silvesternacht in völliger Dunkelheit. Die komplette Stromversorgung kann dort erst nach Tagen wiederhergestellt werden.
Dass der „Jahrhundertwinter“ 1978/79 die DDR viel schwerer traf als die damalige Bundesrepublik, war vor allem ihrer fast vollständigen Abhängigkeit von der Braunkohle als Energieträger geschuldet. Zudem gab es keine Vorsorge für den Eintritt eines solchen Ereignisses. Andererseits wurden dessen Folgen sowohl durch eine gewisse, dem Sozialismus systemimmanente Bevorratungsmentalität der Bevölkerung gemildert, als auch durch die im Vergleich zu heute noch sehr geringe Abhängigkeit vom elektrischen Strom.
Der weltweit größte durch ein Extremwetterereignis verursachte Blackout ereignete sich im Januar 1998 in der kanadischen Provinz Quebec. Warme Luftmassen hatten tagelang über kalten Schichten gelegen, bis es am 7. Januar plötzlich zu Niederschlägen kam, die noch gefroren, bevor sie den Boden erreichten. Das ganze Land wurde durch eine Eisschicht praktisch versiegelt. Bäume waren auf einmal von einer mehr als vier Zentimeter starken Glasur bedeckt und knickten wie Streichhölzer. Und die Masten der Hochspannungsleitungen taten es ihnen nach.
Die kleine Auswahl wetterbedingter Gefahrensituationen für das Stromnetz soll durch ein Ereignis abgeschlossen werden, bei dem am 28. März 2012 in Ostdeutschland ein Blackout für das Verbundnetz gerade noch verhindert werden konnte. An diesem Tag herrschte ein außergewöhnlich hohes Angebot an regenerativem Strom, vor allem aus Windenergieanlagen. Die Netzbetreiber waren durch das seit 1991 geltende Stromeinspeisungsgesetz (2000 abgelöst durch das Erneuerbare-Energien-Gesetz) zu seiner Abnahme verpflichtet. Nur die zu gewährleistende Netzstabilität setzte dieser Verpflichtung Grenzen. Am Abend des 28. März fiel die 380 kV-Hochspannungsleitung von Wolmirstedt nach Helmstedt aus; damit standen nur noch zwei Leitungen für den Leistungsausgleich zwischen alten und neuen Bundesländern zur Verfügung. Die im Osten erzeugte Leistung mit einem großen Anteil von Windstrom aus dem Norden konnte nicht mehr ausreichend abgeführt werden, als Folge erhöhte sich die Netzfrequenz. Die daraufhin vorgenommene massive Reduzierung von konventioneller und schließlich auch regenerativer Stromerzeugung von mehreren Tausend Megawatt vermochte diese bedrohliche Entwicklung nicht zu beenden; die Frequenz stieg immer weiter an. Gegen 20.00 Uhr stand das Netz kurz vor der bei 51,5 Hz zu erwartenden Notabschaltung. Rettung brachte schließlich die Schaltung der Pumpspeicherwerke Goldisthal (Thüringen) und Markersbach (Sachsen) auf die Funktion „Pumpen“. Binnen weniger Minuten stieg ihre Leistungsentnahme aus dem Netz auf 2.400 Megawatt – der Blackout mit hoch wahrscheinlich länderübergreifenden Auswirkungen konnte gerade noch vermieden werden.
Heute scheint diese überaus wichtige Fähigkeit der Pumpspeicherwerke zur Netzstabilisierung im Bewusstsein der Politik nicht mehr existent zu sein /30/.
4.4 Menschliches Versagen
Im Stromnetz laufen bestimmte Stabilisierungsmaßnahmen automatisch ab; andere erfordern planvolles menschliches Agieren unter Beachtung von sehr komplexen Bedingungen. Das beginnt mit der auch als „Dispatch“ bezeichneten, unter Punkt 2 beschriebenen Einsatzplanung der Kraftwerke auch für den Folgetag auf der Basis von Prognosen für die benötigte Leistung sowie die Erzeugung von regenerativem Strom. „Redispatch“ sind dann tagesaktuelle Eingriffe in die Erzeugungsleistung von Kraftwerken zur Vermeidung von Überlastungen. Wenn z. B. die Überlastung einer Leitung befürchtet wird, müssen vor dem Engpass befindliche Kraftwerke heruntergefahren werden, während die Leistung der dahinter befindlichen gesteigert wird. Sowohl Dispatch als auch Redispatch erfordert sorgfältige Abstimmungen zwischen mehreren Partnern.
Dass diese anspruchsvolle Tätigkeit nicht immer gut geht, zeigen mehrere Beispiele. So fiel In der Nacht des 28. September 2003 in ganz Italien um 3.27 Uhr der Strom aus, je nach Landesteil für bis zu 18 Stunden. Die Ursache dafür lag nicht in Italien, sondern in der Schweiz. Dort war eine Stromleitung durch eine menschliche Fehlentscheidung überbeansprucht worden und versagte – mit der Folge, dass 57 Millionen Menschen stundenlang ohne elektrische Energieversorgung waren.
Ein besonders markantes und auch lehrreiches Beispiel ist mit dem Kreuzfahrtschiff „Norwegian Pearl“ verbunden, das am 4. November 2006 auf der Ems die Meyer-Werft in Papenburg verließ. Dabei musste aus Sicherheitsgründen die den Fluss querende 380 kV-Hochspannungsleitung abgeschaltet werden, wie es schon etwa 20 Mal zu gleichen Anlässen geschehen war. Doch diesmal saßen nach der Abschaltung plötzlich zehn Millionen Menschen in Westeuropa ohne Strom da. Teile von Deutschland, Belgien, Frankreich, Österreich, Italien und Spanien waren betroffen. In kaskadenartiger Weise pflanzte sich die Störung fort; das Europäische Verbundnetz zerfiel in Teilnetze, welche glücklicherweise relativ rasch stabilisiert und dann wieder miteinander synchronisiert werden konnten, so dass dieser Blackout nur rund zwei Stunden dauerte. Sein Ablauf bestätigte die allgemeine Einschätzung des BBK (in /13/ auf S. 84): „Im Stromnetz entwickeln sich großflächige Ausfälle durchaus kaskadenartig: Ausgehend von der ursprünglich lokalen Störung können Blackouts entstehen, die sich über die Regelzonen in der Fläche fortsetzen. Demgegenüber ist aber auch ein flächendeckender Ausfall denkbar, der durch mehrere Einzelausfälle bedingt ist.“
Die Schuld an dem ziemlich kostenträchtigen, von der 380 kV-Leitung über die Ems ausgehenden Störfall wies der Netzbetreiberverband UCTE nach einer Untersuchung dem Energiekonzern Eon zu, welcher die Abschaltung vorgenommen hatte. Der konnte sich das Ganze nicht erklären und wollte sogar „höhere Gewalt“ nicht ausschließen. Aber der Schuldvorwurf mit seinen juristischen Folgen blieb an dem Konzern haften. Doch sechs Jahre später legte das Max-Planck-Institut für Dynamik und Selbstorganisation in Göttingen eine verblüffende Erklärung vor, die auf umfangreichen Computersimulationen beruhte: Ursächlich für den Blackout vom November 2006 sei das sogenannte Braess-Paradoxon /8/ gewesen. Dieses erst 1968 von dem deutschen Mathematiker Dietrich Braess eigentlich für das Verkehrswesen postulierte Paradoxon besagt, dass in der Verkehrsführung eine zusätzliche Straße unter Umständen eine Verschlechterung des Verkehrsflusses bewirkt. Es lässt sich auch auf Stromflüsse in elektrischen Leitungen anwenden: Die Installation einer neuen Leitung kann zu vorher nicht vorhandenen Engpässen im System führen. Für den zuständigen Eon-Dispatcher war es am 4. November 2006 natürlich nicht möglich, eine umfangreiche Computersimulation der Netzführung vorzunehmen.
Die Erklärung des Max-Planck-Instituts führt schlaglichtartig vor Augen, welchen Grad der Komplexität unser Stromnetz erreicht hat und mit welchem Risiko deshalb menschliche Eingriffe verbunden sein können (s. dazu auch Punkt 6).
In Anbetracht der möglichen Folgen eines Blackouts sollte die Zahl der menschlichen Eingriffe also möglichst verringert werden, doch ist das Gegenteil der Fall, wie Bild 7 zeigt. Damit steigt unbestreitbar die Eintrittswahrscheinlichkeit für einen durch menschliches Fehlverhalten verursachten Blackout. Und noch etwas ist bei der Retrospektive auf das nunmehr fast 14 Jahre zurückliegende Ereignis festzustellen: Heute wären seine Auswirkungen schwerer und die Zeit bis zur Wiederherstellung der Funktionsfähigkeit des Netzes länger. Denn inzwischen ist unsere Abhängigkeit von elektrischem Strom noch vollkommener, das Netz komplexer und die Schwarzstartfähigkeit der Energieerzeuger geringer geworden (s. dazu Punkt 7).
4.5. Cyberangriffe
In seinem Buch „Blackout. Morgen ist es zu spät“ lässt der Autor Marc Elsberg das Europäische Verbundnetz durch einen Hackerangriff zusammenbrechen. Wie realistisch ist ein solches Szenario? Einen Hinweis liefert ein Geschehnis, das sich kurz vor Weihnachten 2015 in der westukrainischen Provinz Iwano-Frankiwsk abspielte. 30 Kraftwerke fallen plötzlich aus, worauf eine Viertelmillion Haushalte keinen Strom mehr haben. Wohnungen, Unternehmen und öffentliche Einrichtungen bleiben tagelang ohne Elektrizität. Was sich erst später herausstellte: Es handelte sich bei dem Vorfall um den weltweit ersten großen Stromausfall, der von Hackern verursacht wurde. Nach Aussagen des US-Heimatschutzministeriums hatten von Russland aus agierende Hacker Spear Phishing E-Mails eingesetzt, um sich über einen Schadcode Zugangsberechtigungen zu den Steuerungseinheiten zu beschaffen. Das Programm war in einem manipulierten Word-Dokument enthalten, das als E-Mail des ukrainischen Parlaments getarnt war /9/. Nach der Implementierung des Schadcodes besaßen sie die völlige Verfügungsgewalt über die Energieversorgung.
Es ist denkbar, dass diese Aktion nur ein Scharmützel aus dem schon längst begonnenen kalten digitalen Krieg zwischen Russland und den USA war, bei dem man der anderen Seite zeigen wollte, wozu man ohne weiteres in der Lage ist. Offenbar versuchen beide Großmächte schon seit einiger Zeit, in den IT-Systemen der Kritischen Versorgungsstrukturen des potentiellen Gegners „logische Bomben“ zu platzieren – inaktive Schadprogramme, die im Fall einer „Zündung“ das öffentliche Leben vollständig lahmlegen /10/. Besonders verheerend ist dabei ihre Fähigkeit, alle Daten und Programme des angegriffenen Systems zu löschen, was einen Neustart unmöglich macht.
Aber auch unterhalb der Ebene globaler Auseinandersetzungen tobt bereits ein Partisanenkrieg der Hacker mit unterschiedlichen Motivationen. Wir zitieren dazu aus einer Wirtschaftsdokumentation von 3sat vom 21.06.2019 /11/:
Das Bundesamt für Sicherheit in der Informationstechnik (BSI) warnt immer wieder vor Cyberangriffen auf Energieversorger. „Jeden Tag gibt es tausendfache Anklopfversuche aus dem Internet“, bestätigt auch Florian Haacke, Leiter der Konzernsicherheit bei Deutschlands größtem Stromnetzbetreiber Innogy. In der Essener Konzernzentrale wehren rund 130 Spezialisten solche Attacken ab. Mit ernsten Bedrohungen haben sie es bis zu 40 Mal im Jahr zu tun.
Haacke mahnt zur Wachsamkeit: „Letztendlich zeigen die Vorfälle in der Ukraine, dass es Angreifer oder Angreifergruppen gibt, die über die logistischen und methodischen Fähigkeiten solcher Angriffe verfügen und diese auch tatsächlich in der Praxis umsetzen. Das war tatsächlich eine neue Dimension für den Energiesektor. Und wir sollten auch in Deutschland nicht annehmen, dass es unmöglich ist – auch unsere Stromnetze sind nicht unverwundbar. Eine hundertprozentige Sicherheit kann es nicht geben.“
Wie sind nun die Perspektiven in dem digitalen Krieg um die Herrschaft im Stromnetz? Die Antwort kann nur lauten: rosig – und zwar für die Angreifer. Denn unserem Netz stehen fundamentale Veränderungen bevor, die seine Verwundbarkeit dramatisch erhöhen werden.
Im Rahmen der Energiewende ist die Umrüstung von einigen Millionen Haushalten auf „Smart Meter“ (intelligente Stromzähler) und deren Integration in „Smart Grids“ (intelligente Netze) vorgesehen. Der Grund dafür ist eine fundamentale Änderung der Versorgungsphilosophie: Wurde bislang die Erzeugung von Elektroenergie an den jeweiligen Bedarf angepasst, hat sich in Zukunft der Verbrauch an die stark schwankende Stromerzeugung aus Wind und Sonne zu adaptieren. Das soll mittels smarter Bauteile wie „Smart Plugs“ (intelligente Steckdosen) oder smarter Lüsterklemmen geschehen. Damit diese kleinen Intelligenzbestien ihre Befehle von zentralen Steuereinheiten erhalten können, bekommt das vorhandene Leitungsnetz eine ganz neue Aufgabe: Es dient nicht mehr nur der Energieversorgung, sondern auch der Übertragung von Informationen – es ist zum Datennetz geworden. Und damit lastet auf ihm plötzlich die ganze Problempalette der Cyber-Sicherheit.
Für technisch versierte Hacker (und das sind leider die meisten), die das Stromnetz mit dem Ziel der Herbeiführung eines Blackout angreifen wollen, eröffnen sich ganz neue Möglichkeiten. Jede dieser smarten Steckdosen oder Lüsterklemmen ist für sie ein potentielles Einfallstor in das Datennetz der Energieversorgung, das ihnen sogar physisch zur Verfügung steht. Natürlich gibt es auf der anderen Seite ernsthafte Bemühungen um Cybersicherheit. Doch bei der Vielzahl der erfolgreichen Angriffe auf Firmen, Kommunen und Behörden gewinnt man den Eindruck, die Angreifer seien den Verteidigern stets einen Schritt voraus. Jüngste beeindruckende Beispiele sind die Hackerangriffe auf das Berliner Kammergericht, welches daraufhin monatelang nicht arbeitsfähig war, /12/ sowie auf die Funke-Mediengruppe.
4.6 Zunahme stochastischer Energien im Netz
Stochastische Größen zeichnen sich durch einen irregulären zeitlichen Verlauf mit großen und raschen Fluktuationen aus. Wind ist eine rein stochastische Energiequelle; der Solarenergie ist ein (weitgehend) deterministischer Anteil der Sonneneinstrahlung auf die Erdatmosphäre überlagert. Die Bruttostromerzeugung in Deutschland wurde 2019 zu 25,2 Prozent aus Windkraft zu 9,5 Prozent aus Photovoltaik gespeist.
Das Erneuerbare-Energien- Gesetz gewährt diesen fluktuierenden Energien Vorrang bei der Einspeisung in das Stromnetz. Doch diese Energien beteiligen sich nicht an der Regelung von Spannung und Frequenz im Netz. Damit ändert sich dessen Steuerung dramatisch. Wurde früher die Energieerzeugung alleine nach dem Bedarf geregelt, muss sie sich jetzt nach dem schwankenden Aufkommen von Wind und Sonne richten und im Extremfall sogar den Stromverbrauch anpassen, indem Verbraucher „abgeworfen“ werden.
Die Lösung der immer größer werdenden Regelaufgabe wird immer weniger Kraftwerken auferlegt.
Folgerichtig können die Autoren der vom Bundesamt für Bevölkerungsschutz und Katastrophenhilfe am 11.09.2019 herausgegebenen Publikation Stromausfall – Grundlagen und Methoden zur Reduzierung des Ausfallrisikos der Stromversorgung /13/ die Freude über die Zunahme von Wind- und Sonnenstrom im Netz nicht so recht teilen. In offenbarer Sorge um dessen Systemstabilität schreiben sie auf Seite 113/114:
Die Betreiber von Übertragungsnetzen, die durch § 13 EnWG verpflichtet sind, in der Bundesrepublik einen sicheren Netzbetrieb zu gewährleisten, können die ‚Stellschrauben‘ Frequenzhaltung, Spannungshaltung, Versorgungswiederaufbau und Betriebsführung nicht mehr so nutzen, wie das vor der Energiewende der Fall war. (Hervorhebungen durch den Autor)
Wie schon in Punkt 2 erwähnt, wurde das Stromnetz für Energieflüsse von den höheren zu den niedrigeren Spannungsebenen konzipiert. Doch mit der bevorrechtigten Einspeisung von Strom aus Wind, Biogas und Sonne auf unteren Spannungsebenen fließt ein erheblicher Teil des Stromes im Netz „rückwärts“. Das hat Konsequenzen, die nur dem fachkundigen Kraftwerkstechniker vollständig bekannt sind; in der Publikation /13/ des BBK heißt es dazu auf Seite 102:
„Die vermehrte Einspeisung in das Niederspannungsnetz über Wechselrichter erschwert die Bereitstellung von Blindleistung als Systemdienstleistung zur Spannungshaltung. Eine erschwerte Spannungshaltung erhöht aber das Risiko von Versorgungsproblemen und stellt deshalb eine Verwundbarkeit für die Netzsteuerung dar.“
Und noch eine Textstelle aus /13/ auf Seite 102 ist beachtenswert:
„Durch die Zunahme von fluktuierenden Erzeugern wird das Engpassmanagement erschwert, da sie einerseits Netzengpässe verursachen, andererseits aber nicht zum Engpassmanagement beitragen können.“
Dass die stochastischen Erzeuger im Gegensatz zu den regelbaren Generatoren grundsätzlich nicht zum Engpassmanagement beitragen können, kann am Beispiel der unter Punkt 2 erwähnten Momentanreserve erläutert werden Die Momentanreserve ist als kinetische Energie in gewaltigen Schwungmassen der Generatoren gespeichert und wird bei Abbremsung des Generators infolge erhöhter Verbraucherlast automatisch im Millisekundenbereich freigesetzt; Photovoltaikanlagen leisten so etwas natürlich nicht. Wie sieht es aber mit der kinetischen Energie der Windräder aus? Die Wechselrichter, mit denen die Windgeneratoren an das Netz angeschlossen sind, eignen sich für eine derartige Regelaufgabe nicht. Dies ließe sich prinzipiell mittels einer geeigneten Leistungselektronik ändern. Ob sich das lohnt, zeigt eine einfache physikalische Betrachtung, die ein Verhältnis der kinetischen Energien von konvetionellem Generator und Windrad von
WGenerator : Wrotor = 90.000 : 1
ergibt. Eine Wiedereinspeisung der vergleichsweise verschwindend geringen Rotationsenergie des Windrotors in das Stromnetz lohnt sich also nicht.
Ohne eine Lösung des Problems der fehlenden Momentanreserve kann aber ein (fast) ausschließlich aus fluktuierenden Energien gespeistes Netz nicht betrieben werden.
Nicht zu unterschätzen ist auch das Gefahrenpotential, das durch den Bedeutungswandel des Wetterberichtes für die Netzsteuerung entstanden ist. Mit dem Wetter ändert sich auch die bevorrechtigte Einspeisung des „grünen“ Stroms – und dies manchmal recht plötzlich entgegen der Voraussage. Windräder beginnen mit der Stromproduktion bei Windgeschwindigkeiten von etwa 10 km/h, bei einem Zehn-Sekunden-Mittel von 70 km/h schalten die ersten Anlagen aus Sicherheitsgründen ab; die letzten gehen bei 108 km/h vom Netz. Wenn ein vorhergesagter starker Wind der Stärke 7 sich auf einmal nicht mehr an die Prognose hält und Sturmstärke entwickelt, entstehen jähe Verminderungen der Einspeisung, weil die sich abschaltenden Windräder ja unmittelbar vor der Abschaltung ihre Maximalleistung entwickelt haben. Dies macht sofortige Redispatchmaßnahmen in einzelnen Bilanzkreisen oder gar Regelzonen erforderlich, wie sie früher nicht nötig waren.
Der Strom aus Sonne und Wind wird in das Netz über Wechselrichter eingespeist. Diese benötigen als „Vorgabe“ für den Betrieb eine externe Wechselspannung von 50 Hz. Ohne eine solche Vorgabe, die derzeit im wesentlichen von den regelbaren konventionellen Großkraftwerken kommt, „wüssten“ sie gar nicht, was für einen Strom sie erzeugen sollen. Der NAEB e. V. Stromverbraucherschutz /14/ vertritt die These, dass für einen stabilen Netzbetrieb mindestens 40% regelbare Energie auf der Erzeugerseite zur Verfügung stehen muss. Es ist zu beachten, dass die weiter oben genannten 37,4 Prozent nur einen Mittelwert darstellen; in Spitzen kamen Wind und Sonne auf mehr als 50 Prozent. Nach der These von NAEB und den obigen Zitaten aus der Veröffentlichung /13/ des BBK dürfte mit Rücksicht auf die unbedingt zu bewahrende Netzstabilität eine weitere Steigerung des Anteils stochastischer Energien im Netz kaum noch zugelassen werden. Doch das Gegenteil ist der Fall! Im Koalitionsvertrag der Bundesregierung ist eine Erhöhung des Anteils der „Erneuerbaren“ an der Bruttostromerzeugung auf 65 Prozent bis 2030 festgeschrieben. Und für den Ausstieg aus gesicherter Erzeugung gibt es auch schon einen Fahrplan, den Bild 8 zeigt.
Nach der Abschaltung von 52 Gigawatt nicht fluktuierender Energie stünden dann im Jahr 2038 als gesicherte Energielieferanten noch Wasserkraft, Biomasse und Erdgas zur Verfügung, die heute etwa 23 Prozent des Bedarfs abdecken können. Um die fehlende Leistung nur theoretisch auszugleichen, müsste die Energieerzeugung aus Wind und Sonne mehr als verdreifacht werden.
<Folge 4 kommt demnächst> Teil 1 steht hier, Teil 2 hier
—————————————–
Hinweis: Das PDF mit dem vollständigen Inhalt ist beigefügt. Es kann aber auch beim Kaleidoscriptum-Verlag berstellt werden (www.kaleidoscriptum-verlag.de)
2 Bemerkungen