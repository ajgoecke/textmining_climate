Das Problem der globalen Mitteltemperatur
Das Problem der Bestimmung einer globalen Mitteltemperatur besteht darin, ein Temperatur-Flächenmittel über die gesamte Erde zu berechnen, welches sich auf Meeresspiegelhöhe bezieht. Damit wird die Bestimmung für hohe Berge und ganze Gebirge nicht gerade leichter. Weiterhin wird die jeweilige mittlere Jahrestemperatur oder der Mittelwert des kältesten und wärmsten Monats der zugehörigen Flächen verwendet. In heutiger Zeit sieht sich für diese Aufgaben das Climate Research Unit (CRU) zuständig. Es gibt Zeitgrafiken der globalen Mitteltemperatur heraus (s. Bild 1). Sie werden dabei aber nur als Anomalien zur Verfügung gestellt, wobei als Bezugswert der HADCRUT4-Anomalie der Temperaturmittelwert von 1961-1990 vom CRU definiert wird. Hier die aktuelle HADCRUT4-Zeitreihe:
Bereits mit dem unbewaffneten Auge ist eine globale Temperaturzunahme von 1850 bis 2019 oder auch von 1910 bis 2019 von etwas mehr als 1 °C ablesbar. Leider führt die Anomalieangabe zu Problemen, wenn man an Absolutwerten der globalen Mitteltemperatur interessiert ist. Die HADCRUT-Internetseite hat diese Probleme unauffällig in „Answers to Frequently-asked Questions“ entsorgt (hier). Dort heißt es, ins Deutsche übersetzt:
„Stationen an Land befinden sich auf unterschiedlichen Höhen und verschiedene Länder messen die durchschnittlichen monatlichen Temperaturen mit unterschiedlichen Methoden und Berechnungsformeln. Um Verzerrungen zu vermeiden, die sich aus diesen Problemen ergeben könnten, werden die monatlichen Durchschnittstemperaturen auf Anomalien bezogen auf den Zeitraum mit der besten Abdeckung (1961-90) reduziert. Für die zu verwendenden Stationen muss eine Schätzung des Basisperiodenmittelwerts berechnet werden. Da viele Stationen für den Zeitraum von 1961 bis 1990 keine vollständigen Aufzeichnungen haben, wurden verschiedene Methoden entwickelt, um die Durchschnittswerte von 1961 bis 1990 aus benachbarten Aufzeichnungen oder unter Verwendung anderer Datenquellen zu schätzen (siehe weitere Diskussion zu diesem und verwandten Punkten in Jones et al., 2012 [1] ). Über die Ozeane, wo Beobachtungen im Allgemeinen von mobilen Plattformen aus gemacht werden, ist es unmöglich, lange Reihen tatsächlicher Temperaturen für feste Flächenpunkte zusammenzustellen. Es ist jedoch möglich, historische Daten zu interpolieren, um räumlich vollständige Referenz-Klimatologien zu erstellen (Durchschnittswerte für 1961-90), sodass einzelne Beobachtungen mit dem lokalen Normal für den jeweiligen Tag des Jahres verglichen werden können (weitere Diskussion in Kennedy et al., 2011 [2]).
Klingt schwierig. Natürlich ist wegen des aktuellen Klimahype der Absolutwert der globalen Mitteltemperatur von 1850 bzw. von 1908 (beide Werte sind in etwa gleich) von besonderem Interesse. Nun waren sich bereits unsere Altvorderen des Problems einer Bestimmung des Absolutwertes der globalen Mitteltemperatur wohl bewusst und haben fachlich hervorragende Arbeit bei seiner Lösung geleistet, die sich vor der modernen Klimatologie mit Computerunterstützung nicht zu verstecken braucht. Hervorzuheben sind hier insbesondere die Arbeiten des Vaters der modernen Klimatologie, Julius von Hann (hier).
Eine neue Fachpublikation zum Thema
Im März dieses Jahres erschien zum Thema „globale Mitteltemperatur“ unvermittelt eine aufschlusreiche und hochinteressante Publikation von G. Kramm et al., 2020 [3] (das pdf der Publikation kann unter dem in [3] angegebenen Link frei im Internet heruntergeladen werden). Diese Arbeit geht detailliert auf die historischen Berechnungen der globalen Mitteltemperatur ein, berücksichtigt die aktuelle Fachliteratur, beschreibt die mathematisch-physikalischen Grundlagen zur Ermittlung der globalen Mitteltemperatur und diskutiert ausführlich die Probleme auf Grund der unvollständigen Flächenabdeckung durch meteorologische Stationen. Die historischen Berechnungen der Vergessenheit entrissen zu haben, ist hier als besonders wichtig hervorzuheben und nach Kenntnis des Autors in der aktuellen Fachliteratur bisher noch nicht erfolgt.
Das Fazit dieser Publikation ist überraschend, es lautet „…the results derived from the historical data suggest no change in the globally averaged near-surface temperature over the past 100 years…“. Also gar kein Anstieg der globalen Mitteltemperatur ab etwa 1910?
Das ist starker Tobak und wohl der Grund, warum solch eine interessante Arbeit vermutlich nicht in einem bekannteren Journal unterzubringen war – verdient hätte sie es. Ohne von dieser Publikation der Autoren Kenntnis zu haben, denn sie wurde erst vor wenigen Wochen im März 2020 veröffentlicht, hatte sich auch der Autor der vorliegenden News des gleichen Themas in seiner demnächst im Buchhandel erhältlichen vierten Auflage des Buchs „Energie und Klima: Chancen, Risiken, Mythen“ angenommen. Die Druckfahnen sind bereits in der Pipeline. Das dort zu lesende Fazit, nämlich die Behauptung des CRU über einen über 1°C hohen Temperaturanstirg seit 1850 bzw. seit 1908 sei mehr als fragwürdig, stimmt mit dem Fazit der hier vorgestellten Fachpublikation [3] überein!
In einem Sachbuch geht es natürlich wesentlich einfacher zu als in einer wissenschaftlichen Publikation. Dennoch seien die entsprechenden Textstellen aus der in Kürze erhältlichen vierten Auflage hier im Originaltext wiedergegeben. Die HADCRUT4-Zeitreihe der globalen Mitteltemperatur wird dort nämlich auch noch aus weiteren Gründen als fragwürdig beurteilt, und schließlich darf etwas Werbung für die 4. Buchauflage erlaubt sein. Ein Vorteil für viele Leser wird zudem darin bestehen, neben der für Laien nicht ganz einfachen Lektüre einer wissenschaftlichen Veröffentlichung auch eine ähnlich aussagende kürzere Version vergleichend zur Hand zu haben. In der 4. Auflage des Buchs lautet der Text (Quellenangaben, Kapitel- und Bildbezüge werden hier nicht weiter verfolgt, sind aber der Vollständigkeit halber mit angegeben):
— Beginn Buchzitat 1:
HADCRUT4 weist die folgenden ernsthaften Widersprüche auf:
- Die fehlende Übereinstimmung von HADCRUT4 und den Satellitendaten ab 1998. Im Jahre 2008 beträgt der Unterschied sogar 0,3 °C. Die Ballonmessungen (s. Bild 19 unter 2.5.4) bestätigen die Satellitendaten. Daher ist HADRUT4 zumindest ab 1979 wahrscheinlich falsch!
- Widerspruch von HADCRUT4 zu den Angaben von Phil Jones und Mitautoren sowie von J. von Hann: Es geht hier um den Zeitraum von 1908 bis 2000 sowie um reale Temperaturen und keine Anomalien. Für die globale bodennahe Temperatur von 1961 bis 1990 geben die Klimaforscher Phil Jones und Mitautoren in einer 1999 von den Reviews of Geophysics der geophysikalischen Union (USA) veröffentlichten Studie den Wert 14 °C an46. Ab hier geht es gemäß den Satellitendaten in Bild 4 nur noch um etwa 0,4 °C herauf bis heute, so dass die aktuelle globale Mitteltemperatur 14 + 0,4 = 14,4 °C beträgt. Prof. Julius von Hann47, Vater der modernen Klimaforschung, gab in seinem 5. Handbuch für Klimatologie für das Jahr 1908 als globales Temperaturmittel eben diesen Temperaturwert von 14,4 °C an. Er verfügte damals über Temperaturdaten, die noch nicht durch industrielle Wärmequellen oder den UHI-Effekt119 verfälscht waren. Gemäß Julius von Hann und der Publikation von P. Jones et al. gab es von 1908 (oder sogar 1850) bis heute, keine globale Erwärmung!
- Widerspruch von HADCRUT4 zu weiteren Quellen: Weiter oben wurde die Temperaturstudie besprochen, in welcher der prominenteste Klimawarner Deutschlands, Hans-Joachim Schellnhuber, Mitautor war. In ihr wurde keine globale Erwärmung im 20. Jahrhundert gefunden40. Zwei davon unabhängige weitere Facharbeiten42,43 geben an, dass von Tausenden weltweiten Temperaturreihen des letzten Jahrhunderts etwa ein Viertel Abkühlung und keine Erwärmung aufweisen. Zweifel, ob von einer maßgebenden globalen Erwärmung im 20. Jahrhundert gesprochen werden darf, äußern auch die Klimaexperten Joseph D’Aleo und Anthony Watts, wobei sie auf die starke Erwärmung in den 1930er Jahren hinweisen48.
— Ende Buchzitat 1:
Dazu wird das aus den numerischen Daten des CRU selbsterstellte Bild der HADCRUT4-Zeitreihe gezeigt
— Beginn Buchzitat 2:
Bild 4: Globale Mitteltemperatur HADCRUT4 von 1850 bis 2018 (blau), globale Mitteltemperatur aus Satellitenmessungen von 1979 bis 2019 (rot) und CO2-Konzentration der Atmosphäre (grün), alle Reihen erstellt aus den numerischen Daten49,50,51. Lineare Regressionsgeraden120 in HADCRUT4 in den Zeitspannen 1850–1911, 1911–1944, 1944–1976, 1976–2001 (schwarz unterbrochen). Wegen unterschiedlicher Anomalie-Nullwerte wurden die Satellitendaten um 0,18 °C angehoben, so dass sie sich mit HADCRUT4-Daten 1979-1980 deckten.
— Ende Buchzitat 2:
Der Grund des Unterschieds im Temperaturanstieg?
An Hand der geschilderten Fakten drängt sich die Frage nach dem Grund der unterschiedlichen Angaben für den Anstieg der globalen Mitteltemperatur seit 1850 bzw. etwa 1910 auf. Wenn HADCRUT4 mehr als 1 °C Temperatursteigerung anzeigt, kann es nur an unterschiedlichen absoluten Basistemperaturen des Jahres 1908 bzw. 1850 liegen. Und so ist es tatsächlich. Die sehr umfangreichen Facharbeiten am Anfang des 20. Jahrhunderts, die in der hier besprochenen Publikation [3] sehr detailliert und ausführlich geschildert sind und stark vereinfacht mit der Angabe von 14,4 °C für 1908 seitens Julius von Hann zusammengefasst werden können, widersprechen extrem den Angaben von HADCRUR4, NASA GISS und Berkeley von 13,7°C, 13,6°C bzw. 13,6°C, wie sie schon im Abstract von [3] zitiert werden.
Also das Rätsel gelöst? Nicht ganz, denn es gibt noch einen weiteren Aspekt! Ein aufmerksamer Leser wird sich nämlich fragen, wie die verantwortlichen Autoren der modernen Werte von HADCRUT4, NASA GISS und Berkeley ihre Werte im Vergleich mit den sehr sorgfältig ermittelten und gut begründeten historischen Werte erklären. Er wird dazu in den betreffenden modernen Facharbeiten – sämtlich über Google Scholar erreichbar – neugierig nachsehen und nichts finden. Zumindest für HADCRUT4 hat der Autor in den zugehörigen Fachpublikationen (hier) nicht das geringste Zitat, geschweige denn ein näheres Eingehen auf die historischen Messungen gefunden. Es sieht tatsächlich so aus, als ob die „moderne Klimaforschung“ diese Arbeiten nicht kennt. Da dies unwahrscheinlich ist, darf wohl von bewusstem Ignorieren ausgegangen werden.
Klimaforscher wie beispielsweise Phil Jones vom CRU, der bereits mit Durchstechereien anlässlich des „Climate Gate“ Skandals auffiel (hier), hätten somit auch noch die Regeln ordentlichen wissenschaftlichen Arbeitens missachtet. Publikationen von Fachkollegen mit anderen Ergebnissen als den eigenen haben sie nicht zitiert, geschweige denn sich mit ihnen wissenschaftlich auseinandergesetzt. Diese perfide Strategie ist verständlich. Bei einer „Null-Erwärmung“ über die letzten 100 Jahre bliebe von einem gefährlichen anthropogenen Klimawandel kaum noch etwas übrig, und den finanziell/politischen Profiteuren wäre die propagandistische Basis des teuren und wohlstandsvernichtenden Unsinns „Klimaschutz“ entzogen.
Quellen
[1] Jones, P.D., Lister, D.H., Osborn, T.J., Harpham, C., Salmon, M. and Morice, C.P., 2012: Hemispheric and large-scale land surface air temperature variations: an extensive revision and an update to 2010. Journal of Geophysical Research 117, D05127.
[2] Kennedy J.J., Rayner, N.A., Smith, R.O., Saunby, M. and Parker, D.E., 2011: Reassessing biases and other uncertainties in sea-surface temperature observations measured in situ since 1850 part 2: biases and homogenisation. Journal of Geophysical Research 116, D14104.
[3] Kramm, G., Berger, M., Dlugi, R., and Mölders, N., 2020: Meridional Distributions of Historical Zonal Averages and Their Use to Quantify the Global and Spheroidal Mean Near-Surface Temperature of the Terrestrial Atmosphere. Natural Science, Vol.12 No. 03, Paper ID 98786, https://www.scirp.org/journal/cta.aspx?paperid=98786.
P.S. Ein Leser dieses Artikels bat mich, die Arbeit von P. Kahlig (Univ. Wien) über Julius von Hann zu erwähnen. Sie kann hier als pdf heruntergeladen werden. Ferner sei auch das Buch von G. A. McBean und M. Mantel: Interactions Between Global Climate Subsystems: The Legacy of Hann für näher interessierte Leser zu empfehlen (hier). Diesem Leserwunsch komme ich hiermit gerne nach.
Man weiß immerhin genau, daß bei dem letzten großen Ausbruch eines Vulkans in Südostasien es etwa drei Jahre lang weltweit deutlich mehr regnete als üblich, was man immerhin als einen deutlichen Einfluß auf das Wetter und einen geringen und nur zeitweiligen Einfluß auf das Globalklima bezeichnen könnte.
Daß Stahlwerke, Heizkraftwerke oder die Menge der Autoabgase einen vergleichbaren Einfluß hätten, das konnte man noch nicht feststellen.
Auch bei Fragen zum täglichen Wärmeaustausch zwischen Ozeanen und Land (Küsten, Tiden) und der vielfach größeren Effizienz (gegenüber Wasser/Luft, Luft/Land) haben die Schwätzperten nur eine Antwort: crickets.
Aber dann könnte man die vulkanisch freigesetzte Energiemenge mit der vom Menschen freigesetzten vergleichen. Und darum geht es mir.
„Meteorologie“ von Prof. Dr. Heinz Fortak aus dem Jahr 1971, Seite 22:
„Die zur Erhaltung einer konstanten Mitteltemperatur der Erdoberfläche (von etwa 13 °C bei Berücksichtigung der Höhenverteilung auf der Erdoberfläche, bzw. von etwa 15 °C bei einer vollkommen flachen Oberfläche der Erde) u. a. erforderliche langwellige Austrahlung ist ebenfalls bilanzmäßig in Abbildung 3 dargestellt. Die Erdoberfläche strahlt entsprechend ihrer Temperatur im langwelligen Bereich des Spektrums 8,21 kWh/m2d nach oben.
„In the early years of the Nobel institution, it was agreed that whereas astrophysics was eligible, pure astronomy was not. Also meteorology and allied sciences, including cosmical physics, were initially seen as unproblematic in the context of Nobel physics. For example, Hann was nominated thrice for the Nobel Prize in physics, in 1906, 1911 and 1913, and in none of the cases were the nominations disallowed with the argument that his work did not belong to physics. Hann did not receive the coveted prize.“
In einer Fussnote dazu heisst es ergaenzend:
„In 1906 Hann was nominated for the physics Nobel Prize by the German meteorologist and physicist Wilhelm von Bezold, in 1911 by the Austrian geologist Eduard Suess, and in 1913 by the Swedish meteorologist and close friend of Arrhenius, Nils Ekholm (Crawford 2002).“
Das Vorgehen von Hansen, Jones und Konsorten, insbesondere die Arbeiten von Julius von Hann zu ignorieren, ist aus wissenschaftlicher Sicht inakzeptabel. Dieses Vorgehen hat sich auch nach dem Erscheinen des Buchs von McBean & Hantel (Edn.),“Interactions Between Global Climate Subsystems: The Legacy of Hann“, im Jahr 1993 nicht geaendert. Man muss also davon ausgehen, dass Hansen, Jones und Konsorten ein Ziel verfolgen, was ausserhalb der Wissenschaft angesiedelt ist.
14. MAI 2020 UM 13:25
Sie haben behauptet:
„„Das Gleichgewicht ist an der Oberfläche mit steigenden CO2 nur mit einer Erhöhung der Wärmeabstrahlung der Oberfläche und entsprechender Gegenstrahlung zu erreichen.“
Darauf habe ich folgendermassen geantwortet:
„Was Sie behaupten, ist hanebuechener Unsinn, denn an der Grenzflaeche Erde-Atmosphaere existiert ueberhaupt kein Strahlungsgleichgewicht, weder lokal noch global.“
Und nun behauptet Sie:
„Habe ich so auch nicht behauptet. Aber das Ergebnis von GCMs ist, dass das Energieflussgleichgewicht sich vor allem durch eine Erwärmung der Oberfläche einstellt, nichtsdestotrotz sind Änderungen der Fluesse von sensibler und latenter Waerme dabei beruecksichtigt.“
Offensichtlich wissen Sie nicht, was Ihre Behaupungen beinhalten.
Was das Ergebnis der GCMs ist, ist voellig belanglos, denn diese Ergebnisse koennen ueberhaupt nicht ueberprueft werden, weil nirgendwo ein globaler Datensatz der Eddy-Kovarianzen fuer sensible Waerme und Wasserdampf existiert, der eine Evaluierung dieser Ergebnisse gestatten wuerde. Offensichtlich leben Sie in einer Computer-Scheinwelt.
Wir wissen von speziellen Feldexperimenten her, dass keine ausgeglichenen Energieflussbilanzen existieren. Im Falle der besten Experimente betraegt die Imbalanz etwa 30 – 40 W/m^2; es gab aber auch Feldexperimente, in denen Imbalanzen von bis zu 200 W/m^2 auftraten.
Die vertikalen Temperaturprofile in der Troposphaere, die von Moeller & Manabe (1961) sowie Manabe & Moeller (1961) an Hand eines Strahlungsgleichgewichtes berechnetet wurden, lieferten Oberflaechentemperaturen von bis zu 350 K und Temperaturgradienten von etwa -14,5 K/km. Dieser Temperaturgradient entspricht einer hochgradig instabilen Schichtung. Und weil diese Ergebnisse nichts mit der Realitaet zu tun hatten, ging dann Manabe dazu ueber, ein sog. Strahlungs-Konvektions-Modell zu etwickeln, in dem der vertikale Temperaturgradient grundsetzlich groesser oder gleich -6,5 K/km sein musste (siehe Manabe & Strickler, 1964). Nur mit dieser als primitiv zu bezeichnenden Limitierung gelang es, Ergebnisse zu erhalten, die in der Naehe von Beobachtungen angesiedelt waren.
Es sind die Fluesse von sensibler und latenter Waerme, die grundsaetzlich ein Strahlungsgleichgewicht an der Grenzflaeche Erde-Atmosphaere verhindern. Und diese sind von der thermischen Stabilitaet abhaengig. Je instabiler die Schichtung wird, desto groesser werden diese Fluesse, wobei der Grenzfall die sog. freie Konvektion darstellt.
Hinzu kommt auch noch der Bodenwaermefluss bzw. das Analogon im Wasser, wobei im Falle des Wassers auch noch die solare Strahlung in tiefere Schichten eindringt.
All‘ diese Energiefluesse, die man in numerischen Modellen nur mit unzureichender Genauigkeit parameterisieren kann, unterliegen einem Tagesgang.
Das trifft auch fuer die Netto-Strahlung im Infrarotbereich zu, also der Differenz zwischen der emittierte Strahlung und der atmosphaerischen Gegenstrahlung. (Der Begriff der Netto-Strahlung wurde schon von Clausius, 1887, verwendet.) Und diese Netto-Strahlung im Infrarotbereich ist im allgemeinen positiv, was bedeutet, dass die Wasser- bzw. Landmassen nahe der Erdoberflaeche durch diesen Strahlungsaustausch Energie verlieren, und nicht gewinnen. Im globalen Mittel sind das etwa 60 – 70 W/m^2, was bei einer Oberflaeche der Erde von 5,1 x 10^14 m^2 etwa 3,1 x 10^16 W – 3,6 x 10^16 W entspricht. Um diese Leistung zu erzielen, waren mindestens 20 Millionen Kernkraftwerke der 1500 MW-Klasse erforderlich.
Ihre Bemerkungen zum Strahlungsgleichgewicht am Oberrand der Atmosphaere belegen, dass Sie nicht wissen, wovon Sie reden. Selbst in dem Falle, dass die Gesamtenergie der Atmosphaere sich zeitlich nicht aendert (stationaerer Zustand), ist eine ausgeglichene Strahlungsbilanz am Oberrand der Atmospahere nicht erforderlich. Und darauf haben der Forist Besso Keks und ich hingewiesen.
Sie versuchen staendig, Behauptungen zu unterstellen, die niemand ausgesprochen hat. Dass Sie versuchen, Prof. Fortak Aussage nach Ihrem Gutduengen umzuformen, belegt, was Sie treiben.
Fazit: Lernen Sie erst einmal die Grundlagen der Physik der Atmosphaere. Die koennen Sie in der Computer-Scheinwelt der GCMs nicht finden.
„Sie haben behauptet:
[A] „„Das Gleichgewicht ist an der Oberfläche mit steigenden CO2 nur mit einer Erhöhung der Wärmeabstrahlung der Oberfläche und entsprechender Gegenstrahlung zu erreichen.“
Darauf habe ich folgendermassen geantwortet:
[B] „Was Sie behaupten, ist hanebuechener Unsinn, denn an der Grenzflaeche Erde-Atmosphaere existiert ueberhaupt kein Strahlungsgleichgewicht, weder lokal noch global.“
Und nun behauptet Sie:
„Habe ich so auch nicht behauptet. Aber das Ergebnis von GCMs ist, dass das Energieflussgleichgewicht sich vor allem durch eine Erwärmung der Oberfläche einstellt, nichtsdestotrotz sind Änderungen der Fluesse von sensibler und latenter Waerme dabei beruecksichtigt.“
Offensichtlich wissen Sie nicht, was Ihre Behaupungen beinhalten.“
Ich werde Sie ja hoffentlich nicht darüber belehren müssen, zwischen Energiegleichgewicht (worauf ich mich in [A] bezog) und Strahlungsgleichgewicht (was Sie in [B] daraus machten) zu unterscheiden. Das wissen Sie ja wohl bestens.
„Was das Ergebnis der GCMs ist, ist voellig belanglos,“
Das ist Ihre Meinung, aber Fakt ist, dass es genügend viele wissenschaftlich akzeptiert Publikationen gibt, die diese Meinung nicht teilen.
„Wir wissen von speziellen Feldexperimenten her, dass keine ausgeglichenen Energieflussbilanzen existieren. Im Falle der besten Experimente betraegt die Imbalanz etwa 30 – 40 W/m^2; es gab aber auch Feldexperimente, in denen Imbalanzen von bis zu 200 W/m^2 auftraten.“
Ja, das stimmt klingt für lokale Werte plausibel. Aber diese hohen Differenzen finden Sie nicht in den langfristigen globalen Mittelwerten.
„Die vertikalen Temperaturprofile in der Troposphaere, die von Moeller & Manabe (1961) …
Es sind die Fluesse von sensibler und latenter Waerme, die grundsaetzlich ein Strahlungsgleichgewicht an der Grenzflaeche Erde-Atmosphaere verhindern. …
Hinzu kommt auch noch der Bodenwaermefluss bzw. das Analogon im Wasser, wobei im Falle des Wassers auch noch die solare Strahlung in tiefere Schichten eindringt.
All‘ diese Energiefluesse, die man in numerischen Modellen nur mit unzureichender Genauigkeit parameterisieren kann, unterliegen einem Tagesgang.
Das trifft auch fuer die Netto-Strahlung im Infrarotbereich zu, …„
Das ist seit Jahrzehnten bekannt. Diese damalige Problematik berücksichtigen die gegenwärtigen GCMs schon längst. Niemand rechnet heute noch Klimaprojektionen mit reinen Strahlungsmodellen ohne Konvektion! Und der Effekt von Tagesgängen von Energieflüssen wird auch berücksichtigt! Nun tun Sie mal nicht so, als würde die Wissenschaft Ihre Kritikpunkte ignorieren. Wenn Ihnen das so erscheint, so liegt das nur daran, dass Sie mit Ihren Einwänden Jahrzehnte zurückliegen und etwas kritisieren, was seit Jahrzehnten bereits berücksichtigt wird.
„Selbst in dem Falle, dass die Gesamtenergie der Atmosphaere sich zeitlich nicht aendert (stationaerer Zustand), ist eine ausgeglichene Strahlungsbilanz am Oberrand der Atmospahere nicht erforderlich. Und darauf haben der Forist Besso Keks und ich hingewiesen.“
Ich nehme mal Ihre Erklärung; sinngemäß: Die Gesamtenergie der Atmosphäre kann sich nur ändern, wenn an den Rändern Energie zu- oder abfließt. Die Ränder sind die zwei konzentrischen Sphären an der Erdoberfläche und durch den quasi luftfreien Weltraum. D.h. wenn die Gesamtenergie der Atmosphaere sich zeitlich nicht aendert (stationaerer Zustand), so muss über beide Sphären die gleiche Leistung gehen. Von mir aus können Sie nun behaupten, dass eine ausgeglichene Strahlungsbilanz am Oberrand der Atmosphäre bei Stationarität der Gesamtenergie der Atmosphäre deswegen nicht erforderlich ist (also eine „Nettoleistung“ ungleich Null durch die „Weltraumsphäre“ geht), wenn gleichzeitig die gleiche Leistung durch die Erdoberfläche fließt.
Jo, das geht. Aber langfristig im Jahrzehnte-Jahrhunderte Zeitbereich ist der Energiefluss durch die Erdoberfläche Null (abgesehen von für die Atmosphäre quantitativ irrelavante Flüsse von Erdwärme). Und damit muss bei konstanter Gesamtenergie der Atmosphäre auch die Strahlungsbilanz am Oberrand der Atmosphäre im gleichen Zeitraum Null sein.
„Dass Sie versuchen, Prof. Fortak Aussage nach Ihrem Gutduengen umzuformen, belegt, was Sie treiben.“
Ich verstehe nicht, was Sie meinen. Fortak zu verstehen, ist nicht schwer, da ist auch kein Interpretationsspielraum. So ist unzweifelhaft anhand des Zitats unten belegt, dass Prof. Fortak kein Problem damit hat, dass man die globale Mitteltemperatur auf die Höhenverteilung bezogen oder auf Meereshöhe reduziert verwenden kann. Er gibt die zwei Werte ja an. Dies unterscheidet ihn von Ihnen, dann Sie scheinen ja nur die letztere als „erlaubt“ anzusehen.
„Meteorologie“ von Prof. Dr. Heinz Fortak aus dem Jahr 1971, Seite 22:
„Die zur Erhaltung einer konstanten Mitteltemperatur der Erdoberfläche (von etwa 13 °C bei Berücksichtigung der Höhenverteilung auf der Erdoberfläche, bzw. von etwa 15 °C bei einer vollkommen flachen Oberfläche der Erde) u. a. erforderliche langwellige Austrahlung ist ebenfalls bilanzmäßig in Abbildung 3 dargestellt. Die Erdoberfläche strahlt entsprechend ihrer Temperatur im langwelligen Bereich des Spektrums 8,21 kWh/m2d nach oben.
Unbedingt kürzer fassen.
14. MAI 2020 UM 4:51
Hallo Herr Schulz,
„Aha, da es eine Erwärmung gibt, musste auch ein Wert dafür im Diagram auftauchen. Und im Gleichgewicht wird es wärmer?“
Natürlich ändern sich die Werte alle von einem Gleichgewicht zum neuen. Wenn wir alles daransetzen und Treibhausgasemissionen augenblicklich stoppen, um so dem Klima die Chance zu geben mit den bestehenden Treibhausgasmengen in ein paar Jahrzehnten ins neue Gleichgewicht (langfristig) zu kommen, werden sich die Energieflußwerte in neuen Gleichgewicht um ein paar W/m2 gegenüber heute ändern und der „net absorbed“ Wert sollte wieder Null werden. Das neue Gleichgewicht für mehr Treibhausgase wird bei höhere Bodentemperatur erreicht.
„Sie können im Diagram die Kreislaufwerte beliebig ändern ohne das sich an der Gesamtbilanz was ändert. Nehmen sie anstatt 333 und 396 w/m2 312 und 375 W/m2. In dem ersten Fall ist die theoretische Temperatur 16 Grad C im zweiten Fall 12 Grad C.
Wie interpretieren sie das?“
Na ganz einfach. Es gibt keine Willkür bei der Wahl der Temperatur am Boden und den Werten der „kreilaufenden“ langwelligen Strahlungsflüsse. Diese Werte der Strahlungsflüsse sind durch die Struktur der Atmosphäre beidingt, insbesondere deren vertiaklen Temperaturverlauf und den Treibhausgaskonzentrationen. Die Werte im Diagram sind die der gegenwärtige Atmsphäre.
„Laut dem Diagramm ist die Frage offen welche mittlere Temperatur es gibt, weil der Wert der Abstrahlung der Atmosphäre ist an die Mitteltemperatur der Oberfläche gebunden. Also der Kreislauf ergibt sich aber regelt nicht die Temperatur.“
Klar, das Diagramm alleine erklärt nicht, warum die Werte so sind wie sie dort sind. Die Werte erklären sich erst aus der Physik der Atmosphäre. Natürlich determiniert die Physik der Atmosphäre die Bodentemperatur und damit den „Kreislauf“!
„Dr. Fortak bestätigt das. Welche mittlere Temperatur das am Ende ist, scheint eine Frage der Definition zu sein und wie wo man was gemessen und dann berechnet hat.“
Fortak bestätigt da nichts, denn er weiß auch, dass die Bodentemperatur kein „Zufall“ ist. Die Abstrahlung des Bodens von je nach Diagramm 390-396 W/m2 im Kiehl Trenberth Diagramm passt durch im Rahmen der Näherung zu 13 °C topographisch wie 15 °C auf Meereshöhe reduziert gleichermaßen.
„Mit Sicherheit sollte man einer Abweichung von mehr als einem Grad in den unterschiedlichen Methoden Vorsicht walten lassen direkte Vergleiche zu machen oder gar „Klimaziele“ auszuweisen, die nahe oder innerhalb dieser Abweichungen liegen.“
Klar ist: mit diesen Strahlungsmessungen, die dem Kiehl Trenberth Diagramm zugrundeliegen, kann man kein „global warming“ nachweisen. Denn die Messungen sind ja erst ein paar Jahrzehnte möglich und die Genauigkeit zu gering, um den „global warming“-Temperaturtrend über den Messzeitraum in entsprechenen Energieflüssen zu sehen. Die erwarteten Änderungen in den Energieflüssen bei einer global warming von vielleicht 3 °C bewegen sich ja bei nur ein paar W/m2 und dies ist unterhalb der Messgenauigkeit. Aber man arbeitet daran, die Genauigkeit zu verbessern. Daher nimmt man heute noch andere Parameter als die Energieflüsse zur Detektion.
Zur Leseempfehlung: Die Kommentare von Prof. Kramm basieren ja nicht auf eigener Forschung zu den Ursachen des global warmings, sondern einer groben persönlichen Einschätzung über die Qualität der Forschung anderer Klimaforscher. Das ist kein wissenschaftlicher Stil und daher ignoriere ich dies solange bis es durch konkrete wissenschaftliche Arbeiten belegt wird.
Unbedingt kürzer fassen.
Und lesen sie noch mal was Dr. Kramm gesagt hat, weil dem ist nichts mehr hinzuzufügen:
„Was das Ergebnis der GCMs ist, ist voellig belanglos, denn diese Ergebnisse koennen ueberhaupt nicht ueberprueft werden, weil nirgendwo ein globaler Datensatz der Eddy-Kovarianzen fuer sensible Waerme und Wasserdampf existiert, der eine Evaluierung dieser Ergebnisse gestatten wuerde. “
Das Diagram benutzt eine Durchschnittstemperatur und ordnet „Strahlungswerte“ oder Waermefluesse so an, das es mit der Treibhaustheorie zusammenpasst. Entsprechend den 396 W/m2 ist die Wohlfühltemperatur der Erde ja sogar 16 Grad C. Und mit 390 W/2 sind es 15 Grad C.
Erzählen sie mal was fuer Erfahrungen oder Kenntnisse sie von den GCM haben. Lassen sie uns teilhaben an ihrem Wissen, wenn sie der Meinung sind, sie müssen die guten Erklärungen von Dr. Kramm nicht folgen.
In Detail würde mich interessieren wie sie denken, das Kiehl und Trennberth in ihrem Diagram die Konvektiven Wärmeflüsse bestimmt, ermittelt, gemessen haben wollen, wie sie das angeben. Vielleicht kennen sie ja eine Datenbank die globale Werte fuer die Eddy-Kovarianzen fuer sensible Wärme und Wasserdampf enthält.
Die Sensiblen Wärmeflüsse sind global gesehen die Unbekannte und haben damit eine Schlüsselrolle Verständnis des Wärmeverlustes der Oberfläche.
Ach so noch was, ich finde Ihren Umgang mit den Ausführungen von Dr. Kramm ignorant.
Das sie nicht selber Fortak sind, sollten sie entweder Ihren Namen hier reinsetzen und entsprechende Leistunen vorzeigen oder solche Äußerungen lassen.
13. MAI 2020 UM 18:55
Sie haben selbstverstaendlich Recht mit Ihrer Aussage:
„Man kann TOA natürlich eine Bilanz aufstellen, es gibt aber kein Naturgesetz wonach diese ausgeglichen sein muß.“
An Hand der integralen Bilanzgleichung fuer die Gesamtenergie in der Atmosphaere, die die zeitlichen Aenderung des Energiegehaltes in der Atmosphaere beschreibt, laesst sich sofort nachweisen, dass im stationaeren Zustand nur dann eine ausgeglichene Strahlungsfluss-Bilanz am Oberrand der Atmosphaere existieren muss, wenn gleichzeitig an der Grenzflaeche Erde-Atmosphaere eine ausgeglichene Energiefluss-Bilanz existiert, denn die Bedingung der Stationaritaet fordert nur, dass das Oberflaechenintegral ueber alle Energieflussdichten identisch gleich null ist. Und die Oberflaeche der Atmosphaere entspricht in erster Naeherung der Oberflaeche einer Kugelschale, deren innere Teil mit der Erdoberflaeche zusammenfaellt.
Dass der aeusserte Teil der Oberflaeche dieser Kugelschale sich auch noch von ihrem inneren Teil unterscheidet, scheint einigen der Klimaesoteriker nicht bekannt zu sein. Nimmt man eine inneren Radius von 6371 km und einem aeusseren Radius von 6500 km an, so betraegt der Unterschied etwa 2,1 x 10^7 km^2. Dieser geometrische Effekt muss bei der Aufstellung der Energiefluss-Bilanzen fuer die Atmosphaere beruecksichtigt werden.
Dass das Prinzip des Kugelkondensators auf einem solchen geometrischen Effekt beruht, wissen die Klimaesoteriker offensichtlich auch nicht.
Es wird häufig die Erhöhung der Tropopausenhöhe als ein Argument für die Erhöhung der Global-Temperatur durch die erhöhte CO2-Konzentration angeführt. Ich habe einmal versucht die Tropopausenhöhe aus den Wetter-Ballondaten deutscher Wetterstationen zu bestimmen. Da dies historische Daten sind stellt sich die Frage wie die Tropopausenhöhe bestimmt wurde. Diese Größe wird ja erst in jüngster Zeit direkt über einen GPS-Sensor gemessen. Glücklicherweise ist die Tropopausenhöhe nicht die entscheidende Größe, sondern die Teilchen-Dichte der relevanten Treibhausgase Wasserdampf, kondensiertes H2O (Wolken), CO2,usw. CO2 ist eine unabhängige Größe, die vom Menschen geändert wird. Warum kann sich die Wolkenbedeckung und die Wasserdampf-Konzentration nicht nach dem Prinzip des kleinsten Zwangs so anpassen, dass die Wirkung durch CO2 kompensiert wird?
dann kann man doch daraus nur schlußfolgern, daß es eben nicht möglich ist die sogenannte mittlere Globaltemperatur“ überhaupt zu bestimmen. Denn gäbe es diese Methode, dann wäre sie längst allgemein aneerkannt und würde sich in unseren Schulphysikbüchern finden lassen. Dort findet man aber nichts.
Daher wird es niemanden überraschen, daß die Vielzahl der unterschiedlichen „Ergebnisse“ nach Belieben interpretiert werden, so wie es jedem in den Kram paßt.
Mit Wissenschaft, die Wissen schafft, hat das nichts zu tun.
Sie haben aber vollkommen recht, daß die benützten Methoden logisch haltbar sein müssen. Also zeitsynchron und flächensynchron und bzgl. der Mittelungsverfahren eindeutig und nachvollziehbar, damit man aufgrund der Rohdaten jederzeit in der Lage ist, ggfs. verloren gegangene Rechnungen zu wiederholen oder auch neue Erkenntnisse einzubringen. Und es wird vorausgesetzt, daß lange Zeiträume und Betrachtung der gesamten Oberfläche die natürliche Wetterdynamik einebenen.
Daß die Ergebnisse aber selbst bei sorgfältiger Vorgehensweise (die in der Wirklichkeit weltweit aber zu bezweifel ist) noch mit einer statistischen Zufallsvariable behaftet sind, ist auch klar.
Was mich aber am meisten wundert, ist, daß man Energiebilanzen aufgrund physikalischer Eigenschaften versucht zu bestimmen, die nicht bilanzierbar sind (Temperaturen versus Wärme).
1) Eine globale Energiebilanz der Atmosphaere hat grundsaetzliche nichts mit einer global gemittelten Oberflaechentemperatur der Erde zu tun.
2) Da die lokale Energiebilanz und die lokale Temperatur einem Tagesgang unterliegt, ist die zeitliche Synchronisation fuer die Bildung von Tages-, Monats- oder Jahresmittel ueberhaupt nicht erforderlich. Ein solches zeitliches Mittel ist kein arithemtisches Mittel. Um zufaellige Schwankungen bestimmen zu koennen, muss der mittlere Tagesgang sogar durch Detrending eliminiert werden.
Fuer Sie zum Mitschreiben:
Selbstverstaendlich gibt es nur eine Methode der globalen Mittelung, die ich hier beschrieben habe. Und wie man die Oberflaeche A einer Kugel bestimmt, A = 4 pi R^2, mit pi = 3,141592… und dem Kugelradius R, sollte ein Ingenieur noch wissen. Zur Herleitung dieser Formel ist die Loesung eines Doppelintegral erforderlich, was ein Ingenieur zumindest wissen sollte, auch wenn er das selbst nicht mehr durchfuehren kann. Da ich das waehrend meines Ingenierustudiums gelernt habe und selbstverstaendlich auch noch so ein Doppelintegral loesen kann, weiss ich, wovon ich schreibe. Und es gibt im Maschinenbau eine Vielzahl von Doppelt- und Dreifachintegrale, die es zu loesen gilt, wobei vielfach numerische Loesungen erforderlich sind.
Die mathematisch-geometrische Vorschrift der globalen Mittelung war auch schon im 19. Jahrhundert bekannt und wurde dementsprechend angewendet. Dass man dabei kein kartesisches Koordinatensystem verwendet, sondern ein sphaerisches Koordinatensystem sollte selbst fuer einen Ingenieur nachvollziehbar sein. Die dabei erforderliche Koordinatentransformation ist relativ einfach; eine Unterscheidung zwischen ko- und kontravarianten Bezugssystemen ist dabei nicht erforderlich. (Was das fuer Koordinatensysteme sind, koennen Sie bei Albert Einstein (1916), „Die Grundlage der allgemeinen Relativitaetstheorie“, Kap. B, „Mathematische Hilfsmittel fuer die Aufstellung allgemein kovarianter Gleichungen“, nachlesen.) Solche Unterscheidungen sind dann unabdingbar, wenn mit krummlinigen Koordinatensystem gearbeitet wird, was in der numerischen Modellierung atmosphaerischer Prozesse durchaus der Fall ist. Allein den Gradienten der Windgeschwindigkeit, einem Tensor der 2. Stufe, in einem krummlinigen Koordinatensystem auszudruecken, erfordert umfassende Kenntnisse in der Vektor- und Tensoranalysis. Ein bekanntes Lehrbuch zu diesem Thema ist:
Gerhard Gerlich (1977), „Vektor- und Tensorrechnung für die Physik“,
was auch im Dubbel, „Taschenbuch fuer den Maschinenbau“, von 1998 zitiert ist.
„Koordinatensysteme und Koordinatentransformationen“ waren immer ein Teil meiner Vorlesungen zur Atmosphaerischen Dynamik, Physik der atmosphaerischen Grenzschicht und Turbulenz, die ich an der University of Alaska Fairbanks gehalten habe.
Die damals von den Altvorderen ermittelte meridionale Verteilung der Normaltemperaturen diente auch dem Zweck der globalen Mittelung. Dabei entspricht die Normaltemperatur dem zonalen Mittel der auf Meeresspiegelniveau zu reduzierendender oberflaechennahen Lufttemperatur.
Das meridionale Mittel und das zonale Mittel, die auf Linienintegrale beruhen, sowie das globale Flaechenmittel sind eindeutig definiert.
Die globale Mittelung ist keine spezielle Mittelwertbildung, sondern eine seit mindestens 140 Jahren bekannte mathematisch-geometrische Vorschrift.
Nein, wenn grundsätzliche Parameter nicht in den Modellen enthalten sind:
The lightness of water vapor helps to stabilize tropical climate“>
Vielleicht hätte man „density“ statt „lightness“ verwenden können.
Um Eines vorweg zu nehmen, ich betrachte mich beim Thema „Klimawandel“ als interessierter Laie, der sich aber so Einiges angelesen hat. Dazu gehören selbstverständlich auch Arbeiten von Herrn Kramm. Wenn Ihnen ein Wissenschaftler im Diskussionsverlauf unbekannt ist, hilft fast immer Google Scholar weiter und reißt Sie spätestens dann aus Ihrer Unkenntnis.
Dass Sie ebenfalls kaum mehr als ein Laie sind ist daran zu erkennen, dass Sie sich fachlich zum Thema nicht äußern, sondern sich nur an Personen auslassen. Dass Sie Rainer Hoffmanns Aussagen zum Vergleich heran ziehen ist zwar anerkennenswert, aber fachlich irrelevant, da er in der Tat alles Andere als eiin Fachmann ist, wie Herr Kramm richtig äußerte und wie es auch jeder, der hier länger zugegen ist, ziemlich genau weiß, was nicht heißen soll, dass Hoffmann falsch liegen muß.
Soweit Dazu.
Ich frage Sie jetzt, warum Sie auf dem Begriff „Leugnen“ beharren. Leugnen kann man nur Fakten, also liegt „Leugnen“ vor, wenn man aus wissenschaftlichen Gründen einen global ermittelten Temperaturanstieg in Zweifel zieht, der, nebenbei bemerkt segensreich wäre, da wir uns sonst noch immer im Zeitalter der „kleinen Eiszeit“ befinden würden ?
Wie antwortete einer der Chefideologen des PIK, Anders Levermann bei einem Klima Hearing im Deutschen Bundestag auf Rückfrage aus dem Plenum, wie hoch denn nun die als Basis 1850 betrachtete absolute globale Temperatur sei, nun „in etwa so ziemlich genau ca 15°C“.
Ist nun die globale Temperatur angestiegen, wie die Frage des Artikels lautet ?
Der selbe Herr Levermann hatte kurz davor, ebenfalls im Hearing den Vortrag des renommierten Wissenschaftlers Nir Shaviv vernehmlich als „kompletten Quatsch“ bezeichnet, und wie ein H2O Molekül im Vergleich zum CO2 Molekül aussieht war ihm absolut fremd, was er im selben Hearing ausgiebigst demonstrierte.
Sie sollten meine Beiträge genauer lesen, da haben Sie einiges missverstanden.
Ich sagte nicht, dass mir der Name Kramm unbekannt ist, ich sagte, dass er nichts Bemerkenswertes hinterlassen hat, was z.B. mal in Lehrbüchern Erwähnung finden wird.
Als Kontrastbeispiele nenne ich mal die Arbeit von Manabe und Wetherald (1975), beide waren wegweisend für die Entwicklung von GCMs. Oder Hansen et al (1984), „climate sensitivity, Analysis of Feedback mechanisms“, was grundlegend ist für das Konzept von Forcings und Feedbacks.
Ja, eines haben Sie richtig verstanden, leugnen kann man nur Fakten. Fakten wie z.B. die globale Erwärmung. Sie mögen doch so sehr Roy Spencers Satellitendatensatz? Jeder sieht dort sofort die Erwärmung in den letzten 40 Jahren. Jeder Temperaturdatensatz zeigt das, jeder sieht die Folgen der globalen Erwärmung in den polaren Regionen und an den Gletschern weltweit. Wer meint, das sein nun alles falsch (und das möge Herr Kramm bitte mal begründet nachweisen) und ein Temperaturvergleich auf einem Äpfel-Birnen-Vergleich stattdessen die Wahrheit, dem ist nicht zu helfen.
Niemand in der Wissenschaft wird darüber diskutieren, kaum jemand wird die Arbeit von Kramm überhaupt nur mal zitieren. Niemand wird sich die Mühe machen, ein rebuttal zu schreiben, das ist so offensichtlich, dass es einfach ignoriert werden wird. Mit „niemand“ ist natürlich die Gemeeinde der Klimaforscher gemeint, Herr Kramm weist zurecht darauf hin, dass es bei Politikern wie Dana Rohrbacher anders aussieht.
PS:
„Chefideologie Anders Levermann“ zeigt doch im Grunde nur, wie ideologisiert Sie selbst sind. Solche Hearings sind politisch vielleicht interessant, wissenschaftlicher Wert hat eine mündliche Aussage nie. Wenn Herr Levermann Zeit gehabt hätte, hätte er sicherlich eine bessere Antwort geben können. Bei Ihnen klingt es so, dass wenn ein Wissenschaftler eine mündliche Behauptung aufstellt ohne Quellenangabe, dann sei das gleichbedeutend mit wissenschaftlicher Exaktheit. Ganz schön naiv, Herr Gans. Was sagt denn ihr Buddy Krüger (Pseudonyme werden ja nicht nur von mir benutzt) dazu? Ich vermute mal, dass er Ihnen die globale Erwärmung bestätigt.
(Zu ihrem anderen Kommentar sage ich nichts, da überhaupt kein Bezug zum Artikelthema erkennbar ist.)
Die Entwicklung der General Circulation Models (GCMs) begann mit der Arbeit von Smagorinsky et al. (1965). Manabe war einer der Mitautoren. Diese GCMs wurden dann zur sog. Klimaprognose herangezogen. Heute spricht man von Klimaprojektionen, weil man das Klima gar nicht prognostizieren kann. Klimamodellierung ist die teuerste und duemmste Form der Spekulation, naemlich die mit numerischen Modellen. Deswegen werden diese Modelle ja auch adjustiert, womit man gegen wissenschaftliche Standards verstoesst. Und da dazu die globale Mitteltemperatur herangezogen wird (siehe Mauritsen et al., 2012), wird diese so genommen, wie von Hansen, Jones und Konmsorten verbreitet wurde und wird.
Hansens „feedback“-Mechanismus ist aus energetischer Sicht barer Unsinn. Ein solcher feedback-Mechanismus existiert ueberhaupt nicht. Und das ist an Hand der Bilanzgleichung fuer die Gesamtenergie nachweisbar, denn es exisieren keine Netto-Quellen bzw. -senken von Gesamtenergie in der Erdatmosphaere. Im uebrigen gehen die Betrachtungen auf das globale Energiebilanzmodell von Schneider & Mass (1975) zurueck. Das Konzept der Klimasensitivitaet berueht naemlich auf dieser Arbeit. Allerdings ist das globale Energiebilanzmodell von Schneider & Mass (1975) aus physikalischen und mathematischen Gruenden zu verwerfen.
Was die Gemeinschaft der Klimaforscher der heutigen Zeit angeht, so sind die meisten dieser Herrschaften mit der Energetik der Atmosphaere ueberhaupt nicht vertraut. Deswegen ist die Zahl der Erbsenzaehler heute so hoch, denn dazu sind die Finger und die vier Grundrechnungsarten erforderlich, aber nicht umfassende Kenntnisse in der Geophysik, Meteorologie und physikalische Ozeanographie.
Was der Rueckgang der Gletscher angeht, so sollten Sie sich erst einmal mit der Massenbilanz von Gletschern beschaeftigen. Und wenn Sie die Arbeit von Oerlemans (2005) studieren.
Was ich als Wissenschaftler geleistet habe, koennen Sie nicht beurteilen, weil Sie meine Arbeiten ueberhaupt nicht kennen. Was die Zahl der Zitate angeht, so betraegt diese nach Google Scholar etwa 1600, und der sog. h-Index 22. Fuer einen Theoretiker sind das gute Werte. Sie uebersehen, dass ich auf dem Gebiet der Theoretischen Meteorologie arbeite, und nicht in einer Pseudowissenschaft, zu der der Klimatismus in den vergangenen 40 Jahren verkommen ist. Im Vergleich zum Klimatismus ist die sog. Deutsche Physik herausragend.
Nur mal ein Beispiel für Überreaktion:
„Prof. Dr. Heinz Fortak fuehrte bereits im Jahr 1971 in seinem Buch „Meteorologie“ folgendes aus:
A Der Strahlungsanteil …, welcher das System Erde – Atmosphaere effektiv erwaermt,…“
Richtig, global warming durch Energie von außerhalb des Klimasystems. Das gehört zum wissenschaftlichen Konsens des mainstreams der Klimatologen und populärer Vertreter wie z. B. Hansen, Schneider.
B “ … besteht aus der kurzwelligen Strahlungsabsorption in der Atmosphaere und am Erdboden (…) abzueglich des Energiebetrages, der zur Verdunstung des Wassers benoetigt wurde.“
Aktuelle Werte der Flüsse siehe z.B. bei Kiehl, Trenberth
C „Der „Kreislauf“ der langwelligen Strahlung zwischen Erdoberflaeche und Atmosphaere traegt nicht zur Erwaermung des Systems bei.“
Auch das gehört zum wissenschaftlichen Konsens des mainstreams der Klimatologen und populärer Vertreter wie z. B. Hansen, Schneider. Denn dieser „Kreislauf“ stellt sich ein.
Herr Kramm glaubt nun, dass dieser „Kreislauf“ zeitlich konstante Flüsse hätte. Aber man übersehe die „…“ nicht, denn dieser Schluß ist falsch. Denn die Flüsse müssen sich so einstellen, dass die Randbedingung an der TOA von langfristiger Gleichheit von kurzwelliger absorbierten und langwellig abgestrahler Strahlung erfüllt wird.
D „Die effektive langwellige Ausstrahlung nach oben von 64 % dient zur Aufrechterhaltung des Strahlungsgleichgewichts an der Obergrenze der Atmosphaere.“
Richtig, Konsens. Der Prozentwert ist aber keine Naturkonstante, sondern ein von Treibhausgaskonzentration u.a. abhängiger Momentanwert. Auch das ist Konsens.
Das Gleichgewicht ist an der Oberfläche mit steigenden CO2 nur mit einer Erhöhung der Wärmeabstrahlung der Oberfläche und entsprechender Gegenstrahlung zu erreichen.
Fortak stimmt also mit mainstream, Hansen, Schneider überein.
„Das Gleichgewicht ist an der Oberfläche mit steigenden CO2 nur mit einer Erhöhung der Wärmeabstrahlung der Oberfläche und entsprechender Gegenstrahlung zu erreichen.“
Was Sie behaupten, ist hanebuechener Unsinn, denn an der Grenzflaeche Erde-Atmosphaere existiert ueberhaupt kein Strahlungsgleichgewicht, weder lokal noch global. Es existiert, wenn ueberhaupt, nur ein Energieflussgleichgewicht, in dem selbstverstaendlich die Fluesse von sensibler und latenter Waerme zu beruecksichtigen sind. Von daher belegt Ihre Behauptung nur, dass Sie nicht wissen, wovon Sie xx. xxxxxx
Die Annahme, dass die atmosphaerische Gegenstrahlung die Temperatur der Wasser- und Landmassen erhoehen soll, beruht nur auf xxxxxxxxx.
Bereits Clausius schrieb in seinem Lehrbuch „Die mechanische Waermetheorie“ von 1887:
„Was ferner die in gewöhnlicher Weise stattfindende Wärmestrahlung anbetrifft, so ist es freilich bekannt, dass nicht nur der warme Körper dem kalten, sondern auch umgekehrt der kalte Körper dem warmen Wärme zustrahlt, aber das Gesammtresultat dieses gleichzeitig stattfindenden doppelten Wärmeaustausches besteht, wie man als erfahrungsmässig feststehend ansehen kann, immer darin, dass der kältere Körper auf Kosten des wärmeren einen Zuwachs an Wärme erfährt.“
Und Planck (1900), „Ueber irreversible Strahlungsvorgaenge“, schrieb:
„Dass auch die strahlende Waerme den Forderungen des zweiten Hauptsatzes Genuege leistet, dass z.B. die gegenseitige Zustrahlung verschieden temperierter immer im Sinne einer Ausgleichung ihrer Temperaturen erfolgt, ist wohl allgemein unbestritten, und schon Kirchhoff hat hierauf seine Theorie des Emissions- und Absorptionsvermoegens der Koerper gegruendet.“
Das bedeutet, dass die Atmosphaere die um allgemeinen waermere Wasser- und Landmassen nahe der Erdoberflaeche nicht noch mehr erwaermen kann. Dabei ist es vollkommen egal, was irgend welche Klimaesoteriker behaupten.
Was Sie zu der Aussage von Prof. Fortak schreiben, ist von der gleichen Guete: xxxxxxxxx Unsinn vom feinsten. Die Aussage von Prof. Fortak beruht darauf, dass keine Netto-Quellen oder -Senken von Gesamtenergie in der Erdatmosphaere existieren, wobei die Gesamtenergie gleich der Summe von innerer Energie plus potentieller Energie plus kinetischer Energie ist.
Hinzu kommt, dass seit den Arbeiten von Moeller & Manabe (1961) sowie Manabe & Moeller (1961) zumindest qualitativ bekannt ist, dass CO2 in der Troposphaere und in der unteren Stratosphaere neutral wirkt. Oberhalb dieser Schichten bewirkt CO2 Abkuehlungsraten. Diese damaligen Modellergebnisse wurden spaeter vielfach bestaetigt (siehe z.B. Liou, 2002, Introduction to Atmospheric Radiation, Abb. 4.14 auf Seite 160).
Ihre Behauptung
„Herr Kramm glaubt nun, dass dieser „Kreislauf“ zeitlich konstante Flüsse hätte. Aber man übersehe die „…“ nicht, denn dieser Schluß ist falsch. Denn die Flüsse müssen sich so einstellen, dass die Randbedingung an der TOA von langfristiger Gleichheit von kurzwelliger absorbierten und langwellig abgestrahler Strahlung erfüllt wird.“
ist an xxxxxxxxxxx kaum zu ueberbieten, denn zu einer zeitlichen Konstant der Fluesse habe ich mich ueberhaupt nicht geaeussert. Und erst recht kann ich daraus keine falschen Schluesse ziehen. Was glauben Sie eigentlich, wer Sie sind, dass Sie sich hier sxxx
xxxxx
Offensichtlich wissen Sie nicht, was eine Bilanzgleichung ist. Diese beschreibt die zeitliche Aenderung einer Groesse wie der Gesamtenergie in einem beliebigen zeitabhaengigen Volumen. Und dazu muessen im Falle der Gesamtenergie die Fluesse der verschiedenen Energieformen an den Grenzflaechen des Volumens betrachtet werden, denn im Innern des Volumens existieren keine Netto-Quellen oder -Senken von Gesamtenergie.
Dass die Fluesse an der Grenzflaeche Erde-Atmosphaere keine zeitlich konstanten Fluesse sind, lernt man schon Im Grundstudium der Meteorologie. Das gilt auch fur den Oberrand der Atmosphaere, denn selbstverstaendlich variiert z.B. die solare Einstrahlung mit dem Tagesgang. Erst durch die globale und langzeitliche Mittelung der Energiefluesse gelangt man am Oberrand der Atmosphaere zu einem Strahlungsgleichgewicht.
Es ist jedoch das absurde Geschwafel von der radiativen Imbalance am Oberrand der Atmosphaere, die einem anthropogenen radiativen Forcing gleichgesetzt wird folglich die global gemittelte Oberflaechentemperatur erhoehen soll. So behaupten Hansen et al. (2011):
„3 Climate sensitivity and climate feedbacks
Climate sensitivity (S) is defined as the equilibrium global
surface temperature change (DTeq) in response to a specified
unit forcing after the planet has come back to energy balance,
S = DTeq/F,
i.e., climate sensitivity is the eventual global temperature
change per unit forcing (F).“
(An Stelle des Deltas wurde hier D verwendet.) Das ist der esoterische Unsinn, der auf die Arbeit von Schneider & Mass (1975) zurueckgeht. Aber nach Ihrer Aussage ist die ja Geschichte.
Ich wiederhole hier die Frage, die der Forist „Besso Keks“ schon einem anderen Foristen stellte:
„In welchem Subventionsxxxxxxxx sind Sie untergekommen?“
Diese erste Aussage ist richtig
„Auch das gehört zum wissenschaftlichen Konsens des mainstreams der Klimatologen und populärer Vertreter wie z. B. Hansen, Schneider. Denn dieser „Kreislauf“ stellt sich ein.“
Die zweite Aussage sollten sie belegen. Wenn sich Hansen und Schneider auf Trenberth berufen, dann stimmt sie nicht.
Trennberth in seinem angeblichen Energiediagramm mit Strahlungsfluessen behautptet naemlich genau das Gegenteil der Aussage in C.
Quatsch!
Lesen Sie G/T zum Thema Wärmekapazität des Erdsystems.
Man kann TOA natürlich eine Bilanz aufstellen, es gibt aber kein Naturgesetz wonach diese ausgeglichen sein muß.
Ich verstehe den Zweck Ihres Geschreibsels sowieso nicht:
G/T haben zu allen Punkten die physikalischen Grundlagen aufgeführt.
Warum lesen Sie das Paper nicht mal anstelle hier gequirrlten Quark zu verbreiten?
Das G/T-Paper ist mit den Grundlagen eines Ingenieurstudiums gut verständlich, wenn Sie es noch etwas detaillierter haben wollen, so besorgen Sie sich die Arbeiten von Kramm und seinen Mitstreitern.
Wenn Sie zu den Ausführungen der genannten Autoren Fragen haben wird Ihnen in diesem Forum sicherlich gerne geholfen.
„Das Gleichgewicht ist an der Oberfläche mit steigenden CO2 nur mit einer Erhöhung der Wärmeabstrahlung der Oberfläche und entsprechender Gegenstrahlung zu erreichen.“
Daß eine Erhöhung der Wärmeabstrahlung aber nur durch ein Mehr an eingesetzter Energie möglich ist, sollte selbst Leuten geläufig sein, die nur ganz rudimentäre Ahnung von Physik haben. Was Sie beschreiben, ist mehr als ein Perpetuum Mobile! Wie sollte sowas funktionieren?
Vermutlich glauben auch Sie an die sog. „energetischen Netto-Quellen“ im Klimasystem, die auf wundersame Weise Energie aus dem Nichts erzeugen? Trenberth/Kiehl sind in dieser Disziplin Meister.
Was Sie behaupten, ist hanebuechener Unsinn, denn an der Grenzflaeche Erde-Atmosphaere existiert ueberhaupt kein Strahlungsgleichgewicht, weder lokal noch global.“
Habe ich so auch nicht behauptet. Aber das Ergebnis von GCMs ist, dass das Energieflussgleichgewicht sich vor allem durch eine Erwärmung der Oberfläche einstellt, nichtsdestotrotz sind Änderungen der Fluesse von sensibler und latenter Waerme dabei beruecksichtigt.
„Die Aussage von Prof. Fortak beruht darauf, dass keine Netto-Quellen oder -Senken von Gesamtenergie in der Erdatmosphaere existieren, wobei die Gesamtenergie gleich der Summe von innerer Energie plus potentieller Energie plus kinetischer Energie ist.“
Dass dies richtig ist, habe ich bereits bestätigt. Also konstruieren Sie keinen virtuellen Dissens. Dies ist nicht der Punkt.
„ist an xxxxxxxxxxx kaum zu ueberbieten, denn zu einer zeitlichen Konstant der Fluesse habe ich mich ueberhaupt nicht geaeussert.“
Na dann äußern Sie sich endlich mal zum entscheidenen Punkt.
„Erst durch die globale und langzeitliche Mittelung der Energiefluesse gelangt man am Oberrand der Atmosphaere zu einem Strahlungsgleichgewicht.“
Korrekt, wir betrachten hier sowieso nur Langzeitmittel.
„Es ist jedoch das absurde Geschwafel von der radiativen Imbalance am Oberrand der Atmosphaere“
Wieso sollte dies Geschwafel sein? Richtig, das ist aber keinesfalls absurd, den Sie
Sie schrieben doch selbst ein paar Zeilen darüber:
„Dass die Fluesse an der Grenzflaeche Erde-Atmosphaere keine zeitlich konstanten Fluesse sind, lernt man schon Im Grundstudium der Meteorologie. Das [= nicht konstante Flüsse] gilt auch fur den Oberrand der Atmosphaere, denn selbstverstaendlich variiert z.B. die solare Einstrahlung mit dem Tagesgang.“
Also ist radiativen Imbalance am Oberrand der Atmosphäre möglich. Punkt.
Die augenblicklich geringere langwellige Abstrahlung und damit eine imbalance am Oberrand der Atmosphäre kommt durch den Anstieg der Treibhausgase zustande: es wird weniger ins Weltall abgestrahlt als von der Sonne absorbiert wird -> global warming. So einfach ist dies.
PS: Im übrigen findet sich in dem Buch „Meteorologie“ von Prof. Dr. Heinz Fortak aus dem Jahr 1971 auf Seite 22 oben die folgende erhellende Textstelle:
„Die zur Erhaltung einer konstanten Mitteltemperatur der Erdoberfläche (von etwa 13 °C bei Berücksichtigung der Höhenverteilung auf der Erdoberfläche, bzw. von etwa 15 °C bei einer vollkommen flachen Oberfläche der Erde) u. a. erforderliche langwellige Austrahlung ist ebenfalls bilanzmäßig in Abbildung 3 dargestellt. Die Erdoberfläche strahlt entsprechend ihrer Temperatur im langwelligen Bereich des Spektrums 8,21 kWh/m2d nach oben.“
Damit sollte sich auch langsam mal die Frage nach der „richtigen“ Mitteltemperatur der Erdoberfläche erübrigt haben. Fortak vertritt zumindest zwei unterschiedliche Definitionen.
Jo!
Und der Zeitbedarf hängt davon ab, wie lange er braucht das zu verstehen was man versucht ihm zu erklären. Eigenes Wissen? Den Kommentar spare ich mir.
„Oder Hansen et al (1984), „climate sensitivity, Analysis of Feedback mechanisms“, was grundlegend ist für das Konzept von Forcings und Feedbacks.“
Oh ja, „forcings und feedbacks“!
Da zählt wohl auch das angebliche „CO2-forcing“ mit zu.
Das einzig „grundlegende“ an der Arbeit war und ist die Beschreibung einer Methode wie man mit Lügen Billionen von €/USD machen kann.
In welchem Subventionsabzockerpalast sind Sie untergekommen?
„In welchem Subventionsabzockerpalast sind Sie untergekommen?“
Die Frage stelle ich mir auch. Und wie berechtigt unsere Fragen sind, belegt eine Aktivitaet von AVAAZ. Auf der Webseite dieser merkwuerdigen Organisation heisst es (https://secure.avaaz.org/page/de/ ):
An die EU-Kommissionspräsidentin Ursula von der Leyen, Bundeskanzlerin Angela Merkel, EZB-Präsidentin Christine Lagarde und alle Staats- und Regierungschefs Europas:
„Es liegt in Ihrer Hand, Europa und die Welt aus den dunklen Tagen dieser Pandemie in eine vielversprechende, grünere und nachhaltige Zukunft zu führen.
Sie können den Green Deal zu unserem Plan für den Wiederaufbau machen: Investieren Sie jährlich Hunderte von Milliarden, um grüne Arbeitsplätze zu schaffen und unsere Volkswirtschaften sauber und fair zu gestalten. Wir zählen darauf, dass Sie eine Klimabank und einen Klimahaushalt ins Zentrum des Wiederaufbaus stellen und dafür sorgen, dass die Gelder im Einklang mit dem Pariser Klimaabkommen ausgegeben werden.
Es ist an der Zeit, von schmutzigen fossilen Brennstoffen wegzukommen. Besteuern Sie große Unternehmensgewinne — anstatt die Einkommen der Menschen — und starten Sie die Revolution für saubere Energien, die wir so dringend brauchen.
Gemeinsam sind wir stark genug, um die Coronakrise durchzustehen und uns davon zu erholen. Wir sind großzügig genug, um sicherzustellen, dass niemand zurückbleibt. Und wir sind weise genug, um mit diesem Wiederaufbau nicht die Grundlage für eine noch schlimmere, zukünftige Klimakrise zu legen.“
Verfasst am: 4 Mai 2020
Hiess es noch im Kommunistischen Manifest:
„Proletarier aller Länder, vereinigt Euch!“
so heisst es heute:
„Subventionsabzocker aller Laender vereinigt Euch!“
Ich fange an dem kalten Krieg nachzutrauern. In diesen Zeiten war weder Platz noch Geld für dieses Abzockergesindel.
Das Beispiel Levermann und Shaviv zeigt doch schön auf, wie unsinnig und nutzlos solche Befragungen sind.
Levermann hat seine Spezialgebiete, wo er sich perfekt auskennt, wir haben gemerkt, wo seine Expertise nicht liegt.
Wäre es nicht viel besser, wenn zu den wissenschaftlichen Themen sich die Spezialisten äußern? Und wenn dann noch alle Aussagen von anderen geprüft werden? Ja, so etwas wäre perfekt. Und nun halten Sie sich fest: Das gibt es schon, dafür sind die IPCC-Berichte da, die Wissenschaft hat längst abgeliefert, irgendwelche Anhörungen sind Zeitverschwendung.
PS:
Wie oft Shaviv den Stand der Wissenschaft ungenügend widergegeben hat, interessiert hier gar nicht? Das, was Levermann 2x passiert ist, dass ist bei Shaviv in Serie passiert. Tja, man muss schon ideologische Scheuklappen ganz feste aufgeschnallt haben, um nur bei einem der Befragten die Unzulänglichkeiten zu erkennen…
Der war gut 😀
Im den IPCC Berichten wurden u.A Arbeiten von NGOs verarbeitet, nennt sich „graue Literatur“, mitnichten nur von Fachleuten sondern von Interessenvertretern irgend welcher Lobby, und das ist jetzt keine VT, sondern amtlich.
Vom IPCC werden Wertungen vergeben, die mit mit de Realität wenig bis nichts zu tun haben, aber als „very likely“ bezeichnet.
Und wenn man sich deren Modell Output ansieht, dann stellt selbst der Laie fest, und Fachleute sprechen es aus, dass der nix mit Realität zu tun hat, sondern eine Erwärmung errechnen, die in jeder Hinsicht unrealistisch ist. Bleiben Sie mir fort mit IPCC und deren „Spezialisten“.
Jo!
Und die sagen, daß es keinen Beweis für eine Beeinflussung von irgendwelchen Temperaturen durch CO2 gibt.
Sagt man de Öffentlichkeit aber nicht.
Die Berichte sind nicht für jedermann zugänglich und die sog. Summaries for Polocymakers sind von vorne bis hinten gelogen
Nutzlos war die Befragung also nur fuer die Seite die Levermann in die Debatte gebracht hat.
Der Nutzen für alle ohne ideologische Scheuklappen war immense.
Danke!
Quelle
😀
„Die zweite Aussage sollten sie belegen. Wenn sich Hansen und Schneider auf Trenberth berufen, dann stimmt sie nicht.
Trennberth in seinem angeblichen Energiediagramm mit Strahlungsfluessen behautptet naemlich genau das Gegenteil der Aussage in C.“
Welches Diagramm von Trenberth meinen Sie? Bis auf die genauen Zahlen (die sind mit dem ERBE Projekt verbessert worden) stimmt das Trenberth-Diagramm grundsätzlich mit Fortak überein. Es gibt auch die Version, die 0,9 W/m2 „net absorbed“ einbezieht.
Empfehle daher die folgende Reihenfolge der Lektüre:
https://www.eike-klima-energie.eu/2020/05/01/ist-die-globale-mitteltemperatur-seit-1850-bis-heute-ueberhaupt-angestiegen/#comment-249080
und Leseempfehlung hier: https://www.eike-klima-energie.eu/2020/05/01/ist-die-globale-mitteltemperatur-seit-1850-bis-heute-ueberhaupt-angestiegen/#comment-249161
Das Diagram von Kiehl und Trenberth und die 0.9 W/m2 ist ein gutes Zeugnis, dass dem ganzen Geschwätz von einem Gleichgewicht widerspricht. Die 0.9 W/m2 geben eine Erwärmung vor. Wo sehen sie da ein Gleichgewicht?
Die Erwärmung ist übrigens laut Diagram eine dauerhafte, da sie die Energieströme zwischen Atmosphäre und Oberfläche beliebig anheben können, ohne das sich an den 0.9 W/m2 was ändert!
Wenn sie das noch mal mit Ihrem Punkt C abgleichen wollen, müssen sie mir recht geben.
Insofern ist das Diagram völlig unfähig den THE zu erklären und keine sinnvolle Grundlage die global gemittelte Temperatur zu erklären.
Das original Kiehl Trenberth Diagramm ist im Gleichgewicht. Da wir momentan aber kein Klima im Gleichgewicht haben, sind die 0,9 W/m2, die für die Erwärmung „verbraucht“ werden, eingefügt. Dieser Betrag wurde natürlich nicht aus ERBE Messungen erhalten. Es geht in „C“ aber nicht um die 0,9 W/m2, sondern um den „„Kreislauf“ (= „Gegenstrahlung“) der langwelligen Strahlung zwischen Erdoberflaeche und Atmosphaere, die nicht zur Erwaermung des Systems beiträgt“. Dieser ist in dem Kiehl Trenberth von 1997 mit 324 W/m2, von 2009 mit 333 W/m2 angegeben, die Unterschiede spiegeln die Genauigkeit der Ermittlung wieder, wobei als Randbedingung Gleichgewicht gefordert wird (ähnlich wie in allen anderen Diagrammen der Energiebilanz der Atmosphäre der letzten knapp 100 Jahre, Fortak gibt z.B. 78% von S/4 an).
Im übrigen findet sich in dem Buch „Meteorologie“ von Prof. Dr. Heinz Fortak aus dem Jahr 1971 auf Seite 22 oben die folgende erhellende Textstelle:
„Die zur Erhaltung einer konstanten Mitteltemperatur der Erdoberfläche (von etwa 13 °C bei Berücksichtigung der Höhenverteilung auf der Erdoberfläche, bzw. von etwa 15 °C bei einer vollkommen flachen Oberfläche der Erde) u. a. erforderliche langwellige Austrahlung ist ebenfalls bilanzmäßig in Abbildung 3 dargestellt. Die Erdoberfläche strahlt entsprechend ihrer Temperatur im langwelligen Bereich des Spektrums 8,21 kWh/m2d nach oben.“
Damit sollte sich auch langsam mal die Frage nach der „richtigen“ Mitteltemperatur der Erdoberfläche erübrigt haben. Fortak vertritt zumindest zwei unterschiedliche Definitionen.
Was für ein Quatsch
Zumindestens sind wir bei C der gleichen Meinung.
Ich wiederhole noch mal was ich oben gesagt habe.
Sie können im Diagram die Kreislaufwerte beliebig ändern ohne das sich an der Gesamtbilanz was ändert. Nehmen sie anstatt 333 und 396 w/m2 312 und 375 W/m2. In dem ersten Fall ist die theoretische Temperatur 16 Grad C im zweiten Fall 12 Grad C.
Wie interpretieren sie das? Laut dem Diagramm ist die Frage offen welche mittlere Temperatur es gibt, weil der Wert der Abstrahlung der Atmosphäre ist an die Mitteltemperatur der Oberfläche gebunden. Also der Kreislauf ergibt sich aber regelt nicht die Temperatur.
Dr. Fortak bestätigt das. Welche mittlere Temperatur das am Ende ist, scheint eine Frage der Definition zu sein und wie wo man was gemessen und dann berechnet hat. Mit Sicherheit sollte man einer Abweichung von mehr als einem Grad in den unterschiedlichen Methoden Vorsicht walten lassen direkte Vergleiche zu machen oder gar „Klimaziele“ auszuweisen, die nahe oder innerhalb dieser Abweichungen liegen.
Hier noch eine Leseempfehlung.
https://www.eike-klima-energie.eu/2010/05/21/klimaforscher-weist-den-brief-zurueck-mit-dem-255-fachfremde-wissenschaftler-die-erwaermungsthese-stuetzen/
Wenn Levermann anderer Wissenschaftler Arbeit ihm gegenüber pauschal öffentlich als Quatsch abtut muß man über seine wissenschaftlichen und moralischen Grundsätze nicht weiter diskutieren.
Und dass er, auch wenn vor Politikern von Politikern gestellte Fragen falsch oder gar doch richtig beantwortet, aber sehr wohl um die Brisanz dieser Frage wissend, dann ist Ihr Hinweis auf mündlich und ohne Zeit irrelevant, denn das Hearing war ja als wissenschaftle Aufklärungsdebatte gedacht. Dann sollten die Antworten korrekt sein.
Ihr „Freund“ Hansen hatte eben einfach mal die globale Basitemperatur von 15° auf 14° runter gesetzt alle Belege zu den Vorgängen finden Sie hier
Eine s.g. vom Menschen verursachte „globale Erwärmung“ hätte sich sonst nicht erklären lassen.
Ebenso grundlegend wie grundlegend falsch, denn zum Einen wird mehr und mehr nachgewisen, das die CO2 Sensitivität weit aus geringer ist als angenommen, nämlich 3 – 5k , sondern tendenziell eher bei max. 1,7k.
Dass dass s.g. „positive Wasserdampf Feedback“ eher ein Märchen ist als in irgend einer Weise belegt kommt erschwerend hinzu, dazu das eben von Ihnen nicht kommentierte Paper in meinem anderen Kommentar belegt außerdem, dass das positive Wasserdampf Feedback nicht existiert, auch Wolken sind in den Feedbacks nicht ausreichend berücksichtigt.
Und was ein Herr Krüger hier in dem Kontext zu suchen hat ist mir schlechterdings nicht ersichtlich.
Den haben Sie ja jetzt selber hergestellt (Feedbacks, CGM) 😀
Dass Sie selbst seinen Namen falsch schreiben, spiegelt Ihre Faehigkeiten wider.
Sie schrieben:
„Chefideologie Anders Levermann“ zeigt doch im Grunde nur, wie ideologisiert Sie selbst sind.
Wo ist in meiner Arbeit als Wissenschaftler die Politik eingeflossen? Da ich als Theoretiker arbeite, sind meiner Ergebnisse von Fachkollegen ueberpruefbar. Sie zaehlen nicht dazu, denn was Sie hier zu der Arbeit von Kramm et al. (2020) behauptet haben, belegt nur, dass Sie die Arbeit nicht kennen.
Offensichtlich versuchen Sie mit Ihren absurden Behauptungen nur Wissenschaftler zu verleumden und zu diffamieren, weil deren Ergebnisse Ihnen nicht passen.
Das globale Energiebilanzmodell von Schneider & Mass (1975) lautet:
R dT_s/dt = (1 – A) S/4 – F_IR (T_s)
Hierin sind R der thermische Inertialkoeefizient, t die Zeit, T_s die globale Oberflaechentemperatur, S die Solarkonstante, A die planetare Albedo im solaren Bereich und F_IR(T_s) die von T_s abhaengige infrarote Strahlung, die in den Weltraum emittiert wird.
Schneider & Mass verwendeten fuer F_IR(T_s) den Parameterisierungsansatz von Budyko (1969):
F_IR(T_s) = a + b (T_s -273)
wobei a = 0,289 cal/(cm^2 min) und b = 0,00208 cal/(cm^2 min K)
Die obige Gleichung lautet dann:
R dT_s/dt = (1 – A) S/4 – a + 273 b – b T_s
bzw.
R dT_s/dt = Q – b T_s
mit
Q = (1 – A) S/4 – a + 273 b
Das ist die sog. „climate feedback equation“. Die Groesse b ist der sog. „feedback“-Parameter, ihr Kehrwert der sog. „climate sensitivity“-Parameter (siehe Manabe & Stouffer, 2007, „Role of ocean in global warming”). Fuer b > 0 tendiert diese Gleichung gegen einen stationaeren Zustand (dT_s/dt = 0). Dafuer ergaebe sich mit T_s = 288 K:
S = 4/(1 – A) (a+ b (T_s-273)) = 1,912 cal/(cm^2 min) = 1333 W/m^2
Budyko erwaehnt 1,92 cal/(cm^2 min) = 1339 W/m^2.
Das bedeutet, dass die Ergebnisse von Schneider & Mass (1975) vollkommen wertlos sind, denn die Solarkonstante betrug damals etwa 1361 W/m^2 (siehe Raschke et al., 1973), was auch heute noch gilt.
Und was dieses globale Energiebilanzmodell sonst noch wert ist, belegt ein simples Vorgehen, naemlich das Ausschalten der Sonne in diesem Modell, was man mit S = 0 erreichen kann. Danach ergibt sich
R dT_s/dt = – a + 273 b – b T_s
Fuer b > 0 erhaelt man im stationaeren Zustand:
T_s = 273 – a/b = 134 K
Dieses Ergebnis ist hanebuechener Unsinn, denn die Oberflaechentemperatur muesste nahe beim absoluten Nullpunkt liegen, falls man den Waermefluss aus dem Innern der Erde von etwa 0,06 W/m^2 nicht beruecksichtigt. Bezieht man diesen mit ein, dann ergibt sich eine Temperatur etwa 32 – 33 K, je nach Annahme des Emissionsvermoegens.
Zum Vergleich: Der Zwergplanet Pluto am aeusseren Rand unseres Sonnensystems (Solarkonstante S = 0,873 W/m^2) hat eine Strahlungstemperatur von etwa 32 K (siehe https://nssdc.gsfc.nasa.gov/planetary/factsheet/plutofact.html). Die in dem NASA Fact Sheet erwaehnte Temperatur von 37,5 K ist fuer eine Bond Albedo von 0,72 etwas zu hoch.
Fazit: Das globale Energiebilanzmodell von Schneider & Mass (1975), worauf der „feedback“-Mechanismus und folglich das Konzept der Klimasensitivitaet beruht, ist vollkommen unphysikalisch. Es gehoert in den Bereich der Esoterik. Aber auf diesen esoterischen Unsinn berufen sich seit mehr als 40 Jahren die Hohen Priester der Kirche der globalen Erwaermung. Sie sind offensichtlich einer der Juenger dieser Kirche.
Heutige GCM’s benutzten solche vereinfachten Ansätze nicht.
Auch wird das feedback nicht explizit ins GCM eingebaut, sondern ergibt sich aus der Komplexität des GCMs selbst.
Die F_IR Gleichung in Form einer simplen linearen Näherung mit den Parametern a und b ist offensichtlich nur ein Fit an die damaligen Klimawerte.
R, a und b können ebenso aus den Modellresultaten von GCMs berechnet werden, analog wie sie aus dem Realklima abgeleitet werden.
Dass diese Fitgleichung F_IR von Budyko für S=0 versagt, ist keine Überraschung. Dieser Fall ist praktisch bedeutungslos, denn dass Klimamodell sollte ja nicht den Fall abdecken, was mit dem Erdklima passiert, wenn die Sonne aus wäre. Im übrigen ist klar, dass a und b vom Klimazustand abhängen, so ist a empfindlich von der Treibhausgasmenge abhängig.
Fakt ist, dass die sog. „climate feedback equation“ auf der Arbeit von Schneider & Mass (1975) beruht. Diese war noch Gegenstand der Arbeit von Manabe & Stouffer (2007). Diese „climate feedback equation“ ist unphysikalisch und hat mit der Realitaet nichts gemein.
Was Sie uber die Konstanten a und b behaupten, belegt, dass Sie nicht den Hintergrund dieser Konstanten kennen. Da der Kehrwert der Konstanten b dem „climate sensitivity parameter“ entspricht, kann man diesen ja bestimmen. Die Konstante b liefert einen „climate sensitivity parameter“ von 0,69 K m^2/W. Zum Vergleich: Hansen et al. (2011) haben einen Wert von 0,75 K m^2/W genannt.
„Was fuer ein wissenschaftlicher Fortschritt.“
Mit dem Wert von Hansen et al. (2011) kann man uebrigens belegen, dass das Pariser Klimaabkommen von 2015 schon 2017 verletzt gewesen waere. Nur orientiert sich die Realitaet nicht an esoterischem Unsinn.
Wenn das Konzept der Klimasensitivitaet auf Geschichte beruht, warum wird dieser esoterische Unsinn denn noch verwendet?
Offensichtlich versuchen Sie die Leser hinters Licht zu fuehren, denn die Auswertungen der Ergebnisse der Klimaprojektionen mit Hilfe der GCMs dienen dazu, die Klimasensitivitaet zu bestimmen. Denn eine Validierung der Klimaprojektionen z.B. fuer das Jahr 2100 an Hand von Beobachtungen laesst sich nicht durchfuehren, es sei denn die Klimatisten verfuegen ueber eine Zeitmaschine.
Die Klimaprojektionen haben aber nichts mit einem Realklima zu tun. Es sind Spekulationen mit numerischen Modellen, die teuerste und die duemmste Form der Spekulation. Mauritsen et al. (2012), „Tuning the climate of a global model“ (https://agupubs.onlinelibrary.wiley.com/doi/full/10.1029/2012MS000154) haben doch dokumentiert, wie man vorgeht. Bereits im Abstract heisst es:
„[1] During a development stage global climate models have their properties adjusted or tuned in various ways to best match the known state of the Earth’s climate system. These desired properties are observables, such as the radiation balance at the top of the atmosphere, the global mean temperature, sea ice, clouds and wind fields. The tuning is typically performed by adjusting uncertain, or even non‐observable, parameters related to processes not explicitly represented at the model grid resolution. The practice of climate model tuning has seen an increasing level of attention because key model properties, such as climate sensitivity, have been shown to depend on frequently used tuning parameters.“
Deswegen wird eine globale Mitteltemperatur benoetigt und die Klimasensitivitaet wird als „key model property“ bezeichnet.
„Tuning“ hat im uebrigen nichts mit Wissenschaft zu tun. Es geht hier nicht um eine Wetterprognose, von der man schon nach kurzer Zeit weiss, ob sie richtig oder falsch war, sondern um grosse Zeitspannen, die zumindest so gross sind, dass die Produzenten dieser absurden Klimaprojektionen nicht mehr zur Rechenschaft gezogen werden koennen, weil sie verstorben sind.
Der Ansatz von Budyko wurde von Schneider & Mass (1975) verwendet, obwohl die Parameter a und b nur fuer eine Solarkonstante von 1,92 cal/(cm^2 min) galten. Gleichzeitig wurde so getan, als habe man eine Solarkonstante von 1,95 cal/(cm^2 min) verwendet. Rechnet man das mit der heutigen Solarkonstanten nach, denn landet man sonstwo, aber nicht in die Naehe voin 288 K.
Ihr Verhalten ist typisch fuer die Klimatisten. Sobald man auf „wichtige“ Arbeiten hinweist und nachweist, dass diese falsch sind, dann heisst es, dass diese Arbeiten Geschichte seien. Was Sie nicht begreifen wollen, ist, dass falsche Modelle im allgemeinen auch falsche Ergebnisse liefern, was fuer das Modell von Schneider und Mass (1975) und fuer diverse Strahlungskonvektionsmodelle zutrifft, die auf Manabe zurueckgehen. Wer dann trotzdem an den darauf beruhenden Ansaetzen festhaelt, der bewegt sich im Bereich der Esoterik. Mit einer exakten Naturwissenschaft hat das nichts zu tun.
Man kann also nur hoffen, dass der Klimatismus bald Geschichte ist und an seiner Stelle wieder die beobachtungsorientierte Klimatologie tritt.
Weil sie die Temperatur am Boden mit der OLR empirisch verknüpft? Die Physik dieser Verknüpfung ist nicht einfach, GCMs sind komplex.
Was bei der Modellierung atmosphaerischer Prozesse zu beruecksichtigen ist, ist spaetestens seit der Arbeit von Vilhelm Bjerknes, „Das Problem der Wettervorhersage, betrachtet von Standpunkt der Mechanik und Physik“ aus dem Jahr 1904 bekannt.
Die Klimamodellierung beruht nach Lorenz (1975) jedoch auf der „prediction of second kind“, was beinhalten, dass die Randbedingungen massgeblich sind und nicht die Anfangsbedingungen („prediction of first kind“). Diese Randbedingungen koennen jedoch nur mit unzureichender Genauigkeit modelliert werden. Das gilt insbesondere fuer die Grenzflaeche „Erde-Atmosphaere“. Die dabei verwendeten Parameterisierungen zur Berechnung der Fluesse von sensibler und latenter Waerme beruhen auf direkten Messungen dieser Fluesse, deren Ergebnisse von relativen Fehlern von 15 – 20 % und mehr behaftet sind. Folglich sind diese Parameterisierungsschemata nicht besser. Das bedeutet, dass eine Genauigkeit in der Klimamodellierung vorgegaukelt wird, die gar nicht zu erreichen ist.
Was das Arbeiten mit dreidimensionalen Modellen der Atmosphaere angeht, gehe ich einmal davon aus, dass ich schon mit solchen Modellen gearbeitet habe, als Sie noch gar nicht geboren waren.
In der so. „climate feedback equation“ nach Schneider & Mass (1975) wird uebrigens der Energiegehalt der Atmosphaere als zeitlich konstant angenommen. Die Konstanten a und b, wie sie von Schneider & Mass verwendet wurden, haben also eine ganz bestimmte Bedeutung, die Sie offenbar nicht kennen.
Obwohl er von dem Chemiker Dr. Kraft (AfD) korrigiert wurde, beharrte Levernmann auf seiner falschen Behauptung, was bedeutet, dass er mit der Materie nicht vertraut ist.
Auf Grund seiner dumpfen Arroganz behauptete Levermann dann auch noch:
„Die Erde erwaermt sich … und wir verstehen auch warum“
Dass er dann auch noch ein Photo von Planck zeigte, obwohl die grundlegende Arbeit zur Absorption und Emission von Lichtquanten durch Molekuele von Einstein im Jahr 1917 publiziert wurde, belegt, was Levermann fuer ein Komiker ist.
Dass auf Einsteins Arbeit von 1917, „Zur Quantentheorie der Strahlung“, eine der wichtigsten Entwicklungen des 20 Jahrhunderts zurueckgeht, hat Levermann wohl auch nicht begriffen, denn Einstein beruecksichtigte in seiner Herleitung des Planckschen Strahlungsgesetzes im Falle von Molekuelen nicht nur die spontane Emission, damals schon bekannt, sondern auch die durch das Strahlungsfeld selbst stimulierte Emission. Und wenn man weiss, was LASER bedeutet, naemlich
„light amplification by stimulated emission of radiation“
dann wird verstaendlich, auf welchem Niveau sich Levermann befindet.
„Eine globale Mitteltemperatur hat mit dem Gesamtenergiegehalt der Atmosphaere nichts zu tun. Zudem sollten Sie lernen, dass die Temperatur eine intensive Groesse ist, wohingegen die Energie zu den extensiven Groessen zaehlt. „
Das ist mir alles bekannt. Ihnen müsste doch klar sein, dass auch Hensen, Schneider, Manabe u.a. diese physikalischen Grundlagen kennen. Auch ist bekannt, dass die lokalen Fehler in Flüssen enorm sind und die Parametrisierungen ebenfalls lokale Fehler im zig % Bereich haben. Dies wird auch nicht verheimlicht. Die Modelle haben den Vorteil, dass man die Auswirkungen von solchen Fehler durch numerische Experimente mit Extremwerten vom Rand des Konfidenzintervalls simulieren kann und damit den Fehler auf größeren Skalen abschätzen kann.
„Was bei der Modellierung atmosphaerischer Prozesse zu beruecksichtigen ist, ist spaetestens seit der Arbeit von Vilhelm Bjerknes, „Das Problem der Wettervorhersage, betrachtet von Standpunkt der Mechanik und Physik“ aus dem Jahr 1904 bekannt.“
Halten Sie mit V. Bjeknes ein eindimensionales Energiebilanzmodell demnach für physikalisch? Läßt sich mit solch einem Modell etwas über das Realklima lernen?
Das ist keine Sinnvolle Aussage! Kann man Fehler simulieren? Numerische Experimente? Fehler auf größeren Skalen abschätzen?
Will man Fehler nicht minimieren, herausrechnen, um ein besseres Bild zu bekommen? Sind die Fehler so gross das man eine größere Skalierung braucht? Wo sind Ihrer Meinung nach die Fehlergrenzen bei der Angabe der Globalen Mitteltemperatur? Wo liegt das Konfidenzintervall?
Kann man mit Konfidenz eine Änderung der Globalen Mitteltemperatur als Katastrophe darstellen, wenn sich diese Änderung innerhalb der Fehlergrenzen befindet?
Es ist also eine Art „normierter Ersatzwert“, der mit der Wirklichkeit nichts zu tun hat, sofern man bei berechneten Mittelwerten überhaupt von einer Wirklichkeit sprechen kann.
Wie hingegen die Integration über Breitengrade funktioniert, ist mir noch nicht klar. Vermutlich mittelt man geometrisch, also zuerst einen Mittelwert je „Sphärischem-Viereck“ und danach über alle Vierecke. Wo Werte fehlen arbeitet man vermutlich mit Kriging. Theoretisch könnte man auch auf den Äquator normieren oder auf einen Pol oder auf den Mittelwert zwischen diesen beiden Extremwerten.
Jedenfalls muß das Problem gelöst werden, wie man vermeidet, daß die unterschiedliche Anzahl von Stationen je Fläche einen verschiebenden Einfluß auf die Mittelung hat.
70% der Oberfläche sind Wasser, wo eine Messung gem. Literatur 1 m unter der Oberfläche stattfindet. Werden also für die Ozeangebiete die Wasserwerte in 1 m Tiefe als Ersatzwerte für Luftwerte 2 m „bodennah“ herangezogen oder gibt es eine „Transformationsformel“?
Habe trotz Google bisher noch keine Literatur finden können, wo beschrieben steht, wie dieses Verfahren genau funktioniert. Eigentlich hätte ich erwartet, solche Dinge in „The Physical Science Basis“ von IPCC zu finden.
Hab mir aber aufgrund des Kommentars von Prof. Kramm das Buch „Grundkurs Klima“ von Hantel & Haimberger bestellt und bin schon gespannt.
Hallo Herr Strasser,
wäre interessant zu erfahren wie die CO2-Idioten das bewerkstelligen – laut denen ist die barometrische Höhengleichung ja Unfug und muß durch irgendeinen Strahlungskram ersetzt werden…
Die Wassertemperatur an der Oberflaeche wird ueblicherweise mit dem Abschoepfen von kleinen Wasserproben bestimmt. Diese unterscheiden sich von der Temperatur des Wassers im Einlauf eines Schiffes. Ich war waehrend des internationalen Projekts JASIN ’78 (Joint Air-Sea Interaction) an Bord des Forschungsschiffes Meteor und habe dort Strahlungsmessungen durchgefuehrt, einschliesslich Messungen der Wasseroberflaechentemperatur mit Hilfe eines Strahlungsthermometers. Es gab auch kleine Unterschiede zwischen den Temperaturen des Strahlungsthermometers und denen der Marinepuetz.
Globale (sphaerische) Mittelung:
Die Oberflaeche A einer Kugel ist gegeben durch A = 4 pi R^2, wobei pi = 3,141592….., und R ist der Radius der Kugel sind, der fuer die Integration eine Konstante ist. Diese Formel wird durch Integration gewonnen. Das Mittel {V} einer Feldgroesse V(t,f) ueber die Oberflaeche einer Kugel ist gegeben durch
{V} = (R^2 INT_(0, 2 pi) INT_(0, pi) V(t,f) sin t dt df)/A
= (INT_(0, 2 pi) INT_(0, pi) V(t,f) sin t dt df)/(4 pi)
wobei der Zenitwinkel t von 0 bis pi und der Azimutwinkel f von 0 bis 2 pi variieren. (In der Arbeit von Kramm et al. (2020) werde an Stelle von t und f die Symbole „theta“ und „phi“ verwendet.) INT kennzeichnet das Integralzeichen. Mit “ _(…, …)“ werden die untere und die obere Integrationsgrenzen bezeichnet.
Das obige Doppelintegral laesst sich auch folgendermassen umformen:
INT_(0, 2 pi) INT_(0, pi) V(t,f) sin t dt df = INT_(0, pi) sin t dt INT_(0, 2 pi) V(t,f) df
Man kann INT_(0, 2 pi) V(t,f) df auch folgendermassen schreiben:
INT_(0,2 pi) V(t,f) df = 2 pi/(2 pi) INT_(0,2 pi) V(t,f) df = 2 pi [V(t)]
mit
[V(t)] = 1/(2 pi) INT_(0,2 pi) V(t,f) df
was dem zonalen Mittel entspricht. Damit ergibt sich
{V} = (1/2) INT_(0, pi) [V(t)] sin t dt
Nimmt man V(t,f) = 1 an, so erhaelt man:
1/(2 pi) INT_(0,2 pi) df = 1
sowie
(1/2) INT_(0, pi) sin t dt = – cos t_(0, pi)/2 = 1
Dieses Ergebnis sagt aus, dass die flaechennormierte Oberflaeche einer Kugel gleich Eins ist, was selbstverstaendlich ist.
Ich kann Ihnen die Herleitung auch als pdf-file liefern.
Ich hoffe dass alle Forscher die gleiche Formel verwenden. Näheres zur Reduktion des Luftdrucks:
old.wetterzentrale.de/cgi-bin/webbbs/wzconfig1.pl?read=134
Was hat das mit der Frage zu tun, ob in Ihrer Arbeit Rohdaten enthalten sind (,oder ob Sie mit Rohdaten gerechnet haben)?
Die von Ihnen zitierte Aussage stammt von Herrn Strasser, wie man leicht an meinem Zitat erkennen kann, wenn man es denn will, da ich das erste Zitat immer mit Name, Datum und Uhrzeit einleite.
Wie man leicht an meiner Frage vom 3. Mai erkennen kann, habe ich in der Hinsicht keine Aussage getroffen. Ich habe die Frage gestellt, „ob man aus einem Vergleich (Datenmenge 1900, Methode A) mit (Datenmenge Heute, Methode B) legitime Schlussfolgerungen ziehen kann“. Sie haben in der letzten Woche viele Kommentare geschrieben, aber auf diese Frage sind Sie immer noch nicht eingegangen. Sie sind dazu auch nicht verpflichtet, es ist nur interessant, dass Sie über alles mögliche andere schreiben, nur nicht darüber.
Ich denke, jeder kann sich selbst ein Bild darüber machen, wer hier über die Sache reden will und wer hier eher mit viel Text, persönlichen Diffamierungen u.a.m. von der Diskussion über das Papier ablenken will.
In der ARbeit von Kramm et al. (2020) heisst es zu den Isothermenkarten:
‚Dove [19] used monthly means, seasonal means and annual means determined from
the longest so far accessible series of observations at 900 stations. As reported by von Hann [25], his isothermal chart is based on all information available to him in January 1884. This information also included Wild’s [24] isothermal charts for the Russian Empire. Buchan’s [27] isothermal chart not only included the observations of the Challenger Expedition, but also the observations performed at 1620 stations during the fifteen-year period 1870-1884, except in the United States, where the observations started in October 1871, when the Signal Service of the War Department took charge of the Meteorological System of the United States.“
Und nun informieren Sie sich, was Hansen, Jones und Konserten aus dieser Zeit verwendet haben. Das ist teilweise erheblich weniger als das, was in die Isothermenkarten eingeflossen ist. Wieviele Stationen Hansen, Jones und Konsorten beruecksichtigt haben, koennen Sie in den Arbeiten dieser Herrschaften finden. Hansen & Lebedeff (1987) gehen von weniger als 100 Stationen im Jahr 1850 und von 200 Stationen im Jahr 1880 aus (siehe deren Abb. 4). Kennen Sie ueberhaupt deren Arbeiten?
Was die Methode angeht, mit die Daten ausgewertet wurde, so hat sich die Methode der globalen Mittelung nicht geaendert, denn das ist eine mathematische Vorschrift, die sich aus dem flaechenbezogenen Mittel ergibt. Das koennen Sie schon bei Spitaler (1885) nachlesen.
Und wieder kein Zitat dessen, was ich wirklich geschrieben habe. Aber das brauchen Sie ja, damit Sie solche Behauptungen aufstellen können. Es gibt keine „legitime Schlussfolgerung“ von mir, ich habe im Gegenteil die Frage gestellt, ob es überhaupt möglich ist, zu einer solchen zu kommen.
Und Sie weichen dieser Frage immer noch aus und reden immer nur über den Vergleich der Daten um 1900. Da das aber vielleicht ein Mißverständnis ist und meine Formulierung diese Interpretation hergibt, frage ich nochmal deutlicher: Kann man einen Wert, der mit Methode A und Datenmenge X für 1900 bestimmt wurde, mit einem Wert vergleichen, der mit Methode B und Datenmenge Y für das Jahr 2020 (bzw. ein Jahr in der Gegenwart) bestimmt wurde und daraus zu einer legitimen Schlussforgerung kommen?
Was mich in dem Zusammenhang auch interessieren würde: Sie erzählen uns die ganze Zeit hier, wie schlecht und teilweise betrügerisch andere vorgegangen seinen. Wenn deren Arbeiten so schlecht sind, wie können Sie dann aus deren Daten noch was schlussfolgern? Wie kann man aus einem Vergleich mit Ergebnissen, denen man nicht traut, den Schluss: „The comparison of the 1991-2018 globally averaged near-surface temperature with those derived from distributions of zonal temperature averages for numerous parallels of latitude suggests no change for the past 100 year.“. Da können doch beliebige Dinge falsch sein. Jones könnte mit seinen 14°C für 1961-1990 falsch liegen – dann verschieben sich alle Werte nach oben oder unten und der Vergleich müßte neu gemacht werden. Oder der Verlauf der Temperaturen (der auf die 14°C drauf gesetzt wurde, um die Zahlen für 1900 und 1991-2018 zu erhalten) könnte falsch sein, … Sie liefern also eigentlich (vielleicht unfreiwillig) nur Argumente, warum man aus dem Vergleich keinen legitimen Schluss ziehen kann.
Worauf die Istothermenkarten von Dove, Hann und Buchan beruhen wurde von Kramm et al. (2020) zitiert.
Ihr Verhalten, diesen Sachverhalt zu ignorieren und staendig Ihre absurde Behauptung zu wiederholen, belegt nur, was Sie beabsichtigen: Die Arbeiten der Altvorderen als unwichtig zu deklarieren und die darauf beruhenden Ergebnisse zu zerreden.
Fuer Sie sind die Opfer die Schuldigen, und nicht die Betrueger, wobei mit Opfer die Buerger gemeint sind, die fuer einen vermeintlichen Klimaschutz zur Kasse gebeten werden.
Ich werde nicht mehr auf Ihre absurden Behauptungen eingehen. Sie koennen ja einen Kommentar zu der Arbeit von Kramm et al. (2020) anfertigen und bei Natural Science einreichen. Und falls er akzeptiert wird, koennen meine Mitautoren auf Ihren Kommentar antworten. So laeuft das in der Wissenschaft ab, nicht so, wie Sie sich das vorstellen.
Wie man sieht, schrieb ich, dass Sie der Frage ausweichen. Und an einer Antwort auf meine Frage wäre ich immer noch interessiert.
Schade, dass Sie diese Frage in der Publikation nicht aufgeworfen haben, wenn es doch allein darum geht. Wie soll denn irgend jemand diese Frage beantworten, wenn Sie sie gar nicht stellen?
Mir ging es um etwas anderes, um etwas, was tatsächlich in der Veröffentlichung steht und hier von Herr Lüdecke hervorgehoben wurde.
Sorry, aber ich habe gar keine Behauptung aufgestellt. Ich bin hier eigentlich nur damit beschäftigt, die von Ihnen unterstellten Behauptungen auszuräumen – also im wesentlichen klarzustellen, was ich alles nicht behauptet habe. Es wäre viel einfacher, wenn Sie einfach mal zitieren würden und dabei auf die korrekte Zuordnung des zitierten achten würden.
Wenn das dazu führt, dass ich nicht mehr ständig Unterstellungen nachrennen muss, gerne. So etwas ähnliches wie eine Antwort auf meine Frage erwarte ich eh nicht mehr.
Das hätte heissen müssen: „… was tatsächlich in der Veröffentlichung steht, die hier von Herr Lüdecke hervorgehoben wurde.“
Prof. Dr. Luedecke verwies nachtraeglich noch auf den Artikel von Prof. Dr. Kahlig hin, der unter
https://www.researchgate.net/publication/260824978_Some_aspects_of_Julius_von_Hann's_contribution_to_modern_climatology
zu finden ist. Auf der Seite 4 dieses Artikels ist ein Auszug aus dem von DeC. Ward im Jahr 1903 ins Englische uebertragenen ersten Band von Hann’s Handbuch der Klimatologie (2.Auflage, 1897) widergegeben. Prof. Kahlig verwies damit auf den Hann-Filter hin, der zur Glaettung von Daten dient, wie das die beigefuegte Tabelle veranschaulicht. Und in dieser Tabelle sind auch die Normaltemperaturen einer Reihe von Breitenkreisen mit Bezug auf Spitaler (1885) und Batchelder (1894) aufgelistet.
Auch nach 1993 wurde dieser Hinweis von Hansen, Jones und Konsorten ignoriert. Man kann dieses Ignorieren auch als einen Versuch des wissenschaftlichen Betruges werten, zumal William Lockyer (1906), „Studies of temperature and pressure observations“(https://www.nature.com/articles/073594a0) schon auf Spitaler’s und Hann’s Arbeiten verwiesen hatte.
William James Lockyer war wie sein beruehmter Vater, Sir Norman Lockyer, Physiker und Astronom. Vater Lockyer war nicht nur einer der Entdecker des Heliums, sondern auch Gruender und Editor-in-Chief des Journals Nature von 1869 bis 1919. Die Beitraege von Vater und Sohn Lockyer zur Meteorologie wurden im Jahr 2012 von Wilkins & Wilson gewuerdigt (siehe https://rmets.onlinelibrary.wiley.com/doi/abs/10.1002/j.1477-8696.1997.tb06324.x). Es ist merkwuerdig, dass insbesondere Jones nichts davon wusste oder wissen wollte.
Hat er auch diese Störgrößen zuverlässig für den betrachteten Zeitraum ausschließen können, erst dann wird er sich in einem dritten Schritt seiner Meßmethode zuwenden und diese hinterfragen.
Wenn aber in den vergangenen zweihundert Jahren schon die Methoden der globalen Temperaturmessung zu solchen Unterschieden führen, dann ist m. E. die Behauptung „99 Prozent aller Wetter-/Klimaforscher seien sich darüber einig, daß es einen Klimawandel gäbe und daß dieser menschengemacht sei“ wissenschaftlicher Unsinn. Auch unter dem Gesichtspunkt, daß die Summe der von der Menschheit „verbrannten“ Energie nur etwa ein Zehnmillionstel der sonneneingestrahlten Energie beträgt.
Und da die Natur sich ständig wandelt und ebenso auch das Wetter, wie wir tagtäglich beim Hochziehen des Rolladens und dem Blick durch’s Fenster bemerken, würde auch eine präzise Globaltemperaturmessung schon im Moment der Veröffentlichung Makulatur sein, denn diese ändert sich täglich, stündlich, sekundlich, und auch weitere Gruppen von Wissenschaftlern würden wiederum andere Globaltmperaturmittelwerte gemessen haben.
Sie sollten davon ausgehen, dass die Meteorologen in aller Welt nicht die Nachhilfe durch irgend welche Fachfremde benoetigen. Lernen Sie erst einmal die Grundlagen, dann koennen Sie sich in 8 – 10 Jahren wieder melden.
Sie schrieben:
„Kramm hat nichts hinterlassen, was erinnerungswürdig ist. Den Namen Kramm habe ich noch nie in Lehrbüchern oder auf Kongeressen vernommen. Der einzige, der von den Arbeiten von Kramm spricht, ist Kramm selbst.
Mir scheint, das könnte der tiefere Grund sein, warum Sie so schlecht über die Größen reden, es ist der Neid des Erfolglosen.“
Offensichtlich sind Sie nicht in der Lage, eine Suche im Internet durchzufuehren. Sie sind auch nicht faehig, hier meinen Namen anzuklicken, denn dann wuerden Sie auf meine Webseite geleitet werden, die selbstverstaendlich auch mein Schriftenverzeichnis enthaelt.
Fuer Sie zum Mitschreiben:
Als Wissenschafler habe ich ueber 80 Publikationen verfasst, das meiste davon fuer begutachtete Fachzeitschriften und Fachbuechern. Zudem habe ich ein Buch, „Zum Austausch von Ozon und reaktiven Stickstoffverbindungen zwischen Atmosphäre und Biosphäre“, veroeffentlicht (https://catalog.loc.gov/vwebv/search?searchCode=LCCN&searchArg=95202046&searchType=1&permalink=y) , was auf meiner Dissertation beruht. Hinzu kommt noch das Lehrbuch „Lectures in Meteorology“ (https://www.springer.com/us/book/9783319021430?utm_medium=affiliate&utm_source=commission_junction&utm_campaign=3_nsn6445_brand_PID100011630&utm_content=de_textlink ), was ich zusammen mit Prof. Dr. Dr. habil. Nicole Moelders (https://en.wikipedia.org/wiki/Carmen_Nicole_Moelders) verfasst habe. (Professor Moelders ist auch einer der Mitautoren von Kramm et al., 2020). Das Lehrbuch wurde u.a. auch in der Note CAUSATION IN ENVIRONMENTAL LAW: LESSONS FROM TOXIC TORTS des Harvard Law Review zitiert (https://harvardlawreview.org/2015/06/causation-in-environmental-law/). Ueber die Bedeutung dieses Journals etwas zu schreiben, eruebrigt sich vor dem Hintergrund, dass im Jahr 2017 der Praesident der Vereinigten Staaten, Dr. Barak Obama, einen Kommentar in diesem Journal zum Thema „The President’s Role in Advancing Criminal Justice Reform“ veroeffentlichte (https://harvardlawreview.org/2017/01/the-presidents-role-in-advancing-criminal-justice-reform/). Barack Obama, der als Staatsrechtler an der Chicago Law School lehrte, war uebrigens in 1990 der „Head of the Harvard Law Review“ fuer das Volume 104 (https://en.wikipedia.org/wiki/Harvard_Law_Review).
Im April 2007 habe ich vor der Joint Alaska Climate Impact Assessment Commission eine gutachterliche Stellungnahme zu „The Climate of Alaska: Facts and Fiction“ abgegeben. Diese Kommission wurde Alaska State House/State Senate gebildet.
Der Congressman Dana Rohrabacher (R-CA) erwaehnte in seiner einstuendigen Rede von dem US House am 9. Juni 2009 folgendes (siehe https://www.govinfo.gov/content/pkg/CREC-2009-06-09/pdf/CREC-2009-06-09-house.pdf ):
„I will now submit the names of 10 prominent scientists, 10 of the thousands of scientists who have signed on to suggest that man-made global warming is far from accepted by all scientists. These are the heads of science departments, the presidents of scientific and academic associations, people with doctorates in the areas of study, and they are coming forward at last, they’re coming out of their shell at last after all of these years of intimidation. This is only a list of 10, but there are thousands more who are stepping forward to voice honest skepticism, if not total rejection, to the claim that human activity is creating a global warming climate catastrophe.
The first one is Dr. Richard Lindzen, top scientist from the Massachusetts Institute of Technology. Dr. William Gray, Colorado State University, former president of the American Meteorological Association. Dr. David Nowell, former chairman and NATO meteorologist from Canada. Dr. Gerhard Kramm, University of Alaska in Fairbanks. Dr. Yury Izrael of the Russian Academy of Sciences, a senior member of the Russian Academy of Sciences whom I met and spoke to, and also a member of the IPCC United Nations report, who now makes it very clear that he does not believe in that report or man-made global warming. Dr. Ian Pilmer of the University of Melbourne. Dr. Diane Douglas, climatologist and paleoclimatologist. Dr. Harry Lins, cochairman of the IPCC Hydrology and Water Resources Working Group. Dr. Antonio Zichichi, president of the World Federation of Scientists. Dr. Ivar Giaever, Nobel Laureate and physicist.“
Darauf beruht also Ihrer Meinung nach meine „Erfolglosigkeit“.
Ihr Verhalten belegt nur, dass es Ihnen um Verleumdung und Diffamierung geht. Zu Ihrem Leidwesen sind Sie an den Falschen geraten, denn solche Typen wie Sie vorzufuehren, ist nur eine kleine Fingeruebung.
Aus diesem Auszug geht hervor, dass es eine Vielzahl von Wissenschaftlern gibt, die nicht die internationale Irrlehre eines von CO2 und anderen sog. Treibhausgasen bewirkten anthropogenen Klimawandel unterstuetzen. Ganz im Gegenteil. Im Februar 2017 formulierte Dr. Richard Lindzen, Professor Emeritus of Atmospheric Sciences, Massachusetts Institute of Technology (MIT) folgende Petition (https://www.eenews.net/assets/2017/03/14/document_daily_03.pdf):
„We urge the United States government, and others, to withdraw from the United Nations Framework Convention on Climate Change (UNFCCC). We support reasonable and cost-effective environmental protection. But carbon dioxide, the target of the UNFCCC is not a pollutant but a major benefit to agriculture and other life on Earth. Observations since the UNFCCC was written 25 years ago show that warming from increased atmospheric CO2 will be benign — much less than initial model predictions.“
Ich gehoere selbstverstaendlich zu den Unterzeichnern dieser Petition.
Im Zusammenhang mit den sonstigen Dingen, die Herr Kramm hier in den Kommentaren schreibt, könnte man sich vielleicht mal ansehen, was Lindzen so zum Thema Greenhouse Effect (Greenhose Effect – A Scientific Analysis, Climate Sensitivity und feedback (On the Observational Determination of Climate Sensitivity and Its Implications oder über seine Iris-These (siehe verlinkten Foliensatz in Observational support for Lindzen’s iris hypothesis) schreibt.
Was Sie seit 10 Jahren hier verbreiten, belegt, dass Sie nicht wissen, wovon Sie schwadronieren. Deswegen ist wohl ein Pseudonym erforderlich.
Korrekt. Das habe ich aber auch nicht behauptet. Ich schrieb: „Im Zusammenhang mit den sonstigen Dingen, die Herr Kramm hier in den Kommentaren schreibt,“ könnte man sich mal ansehen, was ein renommierter Skeptiker zum Thema Treibhauseffekt, Klimasensitivität, Feedbackmechanismen in wissenschaftlichen Veröffentlichungen schreibt. Dann kann man das für sich dem gegenüberstellen, was Sie hier in den Kommentaren schreiben und sich ein Bild machen.
(Kein Lob !!) 😀
Wenn Sie mal skizzieren könnten, wie Sie darauf kommen, könnte ich auf die „Frage“ eingehen. So würde ich das verneinen. Ich mache hier momentan eher insofern den „Willis Eschenbach“, als dass ich ständig darum bitten darf, doch korrekt (oder überhaupt) zitiert zu werden – eine Bitte, die der mittlerweile am Ende jedes Artikel stehen hat:
Gefühlte 95% meiner Kommentare zu diesem Thema hier resultierten daraus, dass einfach Dinge erfunden, projeziert, … wurden …
8. MAI 2020 UM 19:22
Was ich zu Hoffmann gesagt habe, ist korrekt. Und das hat ueberhaupt nichts mit Diffamierung zu tun. Sie solletn sich bei ihm informieren, welchen Beruf er ausgeuebt hat.
Sie tauchen hier aus heiterem Himmel auf, erheben Behauptungen zu der Arbeit von Kramm et al. (2020), die nur dokumentieren, dass Sie die Arbeit nicht kennen, und wundern sich dann, dass ich Ihre Versuche, meine Mitautoren und mich zu verleumden und zu diffamieren nicht hinnehme.
Sollte Ihr Name korrekt sein, dann sind Sie ein Niemand.
Welche Leistungen von Hansen und Jones wollen Sie den anfuegen, die diese Herrschaften vorweisen koennen? Ein irischer Bischof hat im 17. Jahrhundert das genaue Jahr berechnet, in dem Gott die Welt erschuf, naemlich 4000 Jahre vor Christus. Darauf berufen sich auch heute noch die Kreationisten. Aehnliche Bedeutung haben die Aussagen von Hansen und Jones, die Hohepriester der Kirche der globalen Erwaermung.
Das Diffamierende war, dass Sie mich mit diesem Amateur (das ist sehr nett formuliert, ich weiß, aber so bin ich) verglichen haben.
Wir brauchen uns nicht über dessen xxxxxxxxxx Argumentationen unterhalten, wonach seiner Meinung nach keine globale Erwärmung stattgefunden habe. Aber machen Sie hier nicht dasselbe? Sehen Sie, genau deshalb war ich ja so überrascht.
Überrascht bin ich immer noch, warum Sie mir Diffamierung vorwerfen. Ich hatte Sie gefragt, ob Sie die globale Erwärmung leugnen. Sie hatten das bejaht.
Bemerkenswert finde ich auch, wie Sie es ertragen, dass der wirkliche Inhalt ihres Papers im Beitrag oben gar nicht diskutiert und erläutert wird. Die ganze Diskussion kreist um eine Randbemerkung im Schlussteil. Eine Randbemerkung, wo jeder krtische Wissenschaftler im Paper oder spätestens hier in der Diskussion auch die caveats genannt hätte.
Marvin Müller hat hier an anderer Stelle schon aufgezeigt, was untersucht hätte werden müssen, um diese Behauptung zu belegen. Sie haben dazu nichts gesagt (Sie antworten lieber in Überlängen zu Dingen, die nicht zur Diskussion gehören und niemanden interessieren). Ich nehme an, als Wissenschaftler ist Ihnen schon klar, dass das Paper diese Aussage nicht hergibt. Als hochpolitisierter Bürger waren diese Bedenken aber überflüssig?
PS:
Meine Name tut hier nichts zur Sache. Schätzen Sie es einfach, dass es hier noch einen Menschen gibt, der Konversation mit Ihnen erträgt.
„Bemerkenswert finde ich auch, wie Sie es ertragen, dass der wirkliche Inhalt ihres Papers im Beitrag oben gar nicht diskutiert und erläutert wird.“
Was Prof. Luedecke diskutierte und was nicht, ist seine ureigene Angelegenheit. Das geht Sie ueberhaupt nichts an.
Und ich habe das Recht, mich gegen Ihre Versuche der Verleumdung und Diffamierung zu wehren.
Mit Ihrer Behauptung,
„Überrascht bin ich immer noch, warum Sie mir Diffamierung vorwerfen. Ich hatte Sie gefragt, ob Sie die globale Erwärmung leugnen. Sie hatten das bejaht.“
versuchen Sie auch weiterhin mit Falschaussagen mich zu verleumden und zu diffamieren, denn selbstverstaendlich habe ich Ihre Unterstellung zurueckgewiesen. Meine Antwort auf Ihre Unterstellung lautete:
„Offensichtlich haben Sie nicht begriffen, dass meine Mitautoren und ich uns auf Wissenschaftler berufen haben, die zu ihrer Zeit weltbekannt waren und Wesentliches geleistet haben. Deren Arbeiten zu ignorieren, ist unvereinbar mit den wissenschaftlichen Standards. Wie Sie also behaupten, ich wuerde die globale Erwaermung leugnen, dann uebersehen Sie, dass die Ergebnisse dieser Wissenschaftler, die wir praesentiert und bewertet haben, die Schlussfolgerung einer globalen Erwaermung gar nicht zulassen.“
Sie behaupten auch:
„Ich nehme an, als Wissenschaftler ist Ihnen schon klar, dass das Paper diese Aussage nicht hergibt.“
Was Sie annehmen, hat in meiner Wissenschaftsdisziplin keinerlei Bedeutung, denn Sie sind ein Niemand. Meine Mitautoren und ich ueberlassen es den Fachkollegen, die Arbeit von Kramm et al. (2020) zu bewerten. Weder Sie noch der Forist Marvin Mueller zaehlen nicht dazu.
Auf eine Konversation mit Ihnen verzichte ich gerne, denn die Zielsetzung Ihrer Behauptungen ist unmissverstaendlich: Verleumdung und Diffamierung.
„Was Sie annehmen, hat in meiner Wissenschaftsdisziplin keinerlei Bedeutung, denn Sie sind ein Niemand. Meine Mitautoren und ich ueberlassen es den Fachkollegen, die Arbeit von Kramm et al. (2020) zu bewerten. Weder Sie noch der Forist Marvin Mueller zaehlen dazu.“
es ist schwer eine Sache zu leugenen, die die Gegenseite nicht sinnvoll belegen kann.
Sie koennen sie sicherlich nicht belegen, anhand von Arbeiten, die Andere ihrer Meinung nach nicht durchgefuehrt haben.
Sie sind ein Niemand und dort bleiben sie auch! Weil sie nichts in der Hand haben und sich jetzt auch noch darueber beschweren.
Und was ist, wenn die Natur sich nicht an einen von Menschen fehlerhaft ermittelten Temperaturwert hält? Warum sollte sie das auch.
Im übrigen kann man den globalen Temperaturmittelwert bequem erhöhen, indem man mehr Meßstationen in die Wüste stellt. Oder erniedrigen durch mehr Meßstellen in der Antarktis. Alles wäre im Einklang mit der Physik und der Mathematik.
Fällt keinem auf, daß man noch nie die völlig ungleichmäßige Verteilung von Wetterstationen auf der Erde aufgezeigt hat? Warum wohl nicht? Weil dann offenkundig würde, daß der größte Teil der Erdoberfläche vollkommen frei von Meßstationen ist.
Die Frage ist doch eigentlich, was will man überhaupt mit globalen Temperaturmittelwert anfangen? Man kann aus der mittleren kinetischen Energie die Temperatur ausrechnen, oder bei gleicher Temperatur ein thermodynamisches Gleichgewicht. Nur hat das nichts mit dem zu tun, was auf einer Kugel, die nur von einer Strahlungsquelle Energie erhält. Da gibt es weder globale Temperaturen noch Gleichgewicht. Alle Temperaturen, die auf der Erde gemessen werden haben mit der Energie zu tun die gerade nicht an Umiversum durch Strahlung abgegeben wurde. Nach letzten Erkenntnissen liegt die Gleichgewichtstemperatur des Universums bei 2Kelvin. Da wäre die Atmosphäre ein gefrorener Klumpen.
die Antwort ist in Klimatologie-Lehrbüchern zu finden. Klima ist die Statistik des Wetters und Mittelwerte beschreiben neben anderen Kennzahlen die statistische Verteilung von Größen.
Da das Universum expandiert, gibt es keine Gleichgewichtstemperatur desselben.
Der Photonenhintergrund ist in etwa im Gleichgewicht mit momentan 2,7 K, der Neutrinohintergrund ist schon seit kurz nach dem Urknall von Rest der Materie abgekoppelt und hat momentan ca. 2 K.
Meinen Sie!
Dem steht gegenüber, daß heutige Organisationen wie NASA, GISS und CRU die damaligen Temperaturen offenbar aufgrund der identen Rohwerte mit 13,6 bis 13,7°C ermitteln!? Die Vergangenheit wird heute also um ca. 0,8°C kühler gemacht, als sie damals gemessen bzw. integrativ berechnet wurde.
In den meisten heutigen Publikationen wird die Mitteltemperatur der Erde mit ca. 15,0°C angegeben. Bezieht man nun das heutige 1,5°-Ziel auf 14,4°C wäre 15,9°C der angeblich vertretbare Grenzwert (bei 2,0°C sogar 16,4°C). Bezieht man dieses Ziel aber auf 13,6°C, dann wäre 15,1°C der Grenzwert, über dem die Katastrophe „droht“.
15,1°C sind gerade einmal 0,1°C mehr, als allgemein als Idealtemperatur angegeben werden!?
„Grob zusammengefaßt ist die Aussage von Kramm et al.(2020) doch offenbar, daß die damaligen Forscher aufgrund der damals gemessenen Temperaturdaten 14,4°C als jene Mitteltemperatur mit der höchsten Wahrscheinlichkeit ermittelten.
Dem steht gegenüber, daß heutige Organisationen wie NASA, GISS und CRU die damaligen Temperaturen offenbar aufgrund der identen Rohwerte mit 13,6 bis 13,7°C ermitteln!? Die Vergangenheit wird heute also um ca. 0,8°C kühler gemacht, als sie damals gemessen bzw. integrativ berechnet wurde.“
Wenn man als unvoreingenommener Zeitgenosse unterstellt, dass hier kein Betrug vorliegt, so ist die einfache logische Erklärung für diese Diskrepanz, dass sich die Verfahren von heute und damals unterscheiden. Kramms paper gibt dazu einige Hinweise, denn schon damals bekam man eine 1-2 K geringere globale Mitteltemperatur heraus, wenn man die Temperaturdaten vor der Mittelung nicht auf Meereshöhe reduziert.
„15,1°C sind gerade einmal 0,1°C mehr, als allgemein als Idealtemperatur angegeben werden!?“
In der Wissenschaft vertritt niemand, dass 15,0 °C eine anzustrebende Idealtemperatur sei.
Die 1,5 K beziehen sich auf den Zeitraum um 1850. Gegenüber der damaligen globalen Mitteltemperatur haben wir uns also schon um ca. 1 K erwärmt, also bleibt noch ca. 0,5 K als verträgliche Erwärmung übrig. So einfach ist das!
Diese Erwaermung von 1,5 K ist ein Energiezuwachs von weniger als 0.5%.
Und da im Tagesgang die Temperaturen weitaus mehr schwanken, wage ich zu behaupten, das hier keine Vertraeglichkeitsproblem vorliegt.
https://ipa.org.au/publications-ipa/bureau-cooling-the-past-to-declare-record-heat
Oder scheunen sie sich nicht einmal Tony Heller zu gucken:
https://www.youtube.com/watch?v=Gh-DNNIUjKU
Wenn sie ihre Augen aufmachen, koennen sie den Betrug sehen.
Woraus entnehmen Sie, dass die „identen Rohwerte“ benutzt wurden? Herr Kramm schreibt hier in einem Kommentar:
Ich sehe in der Veröffentlichung nur bereits verarbeitete Daten (Mittelwerte für Nord-Süd-Halbkugeln oder die Erde, Mittelwerte für Zonen, …). Haben Sie eine Stelle gefunden, an der die verwendeten Stationen und ihre Daten aufgeführt werden?
Diese meridionale Verteilungen der Normaltemperaturen wurden von Kramm et al. (2020) herangezogen, um die mittleren Werte fuer die beiden Hemisphaeren und das globale Mittel durch Integration zu bestimmen.
Einige Berichte enthalten eine Vielzahl von Stationsdaten. Die Arbeiten in Fachzeitschriften selbstverstaendlich nicht, weil zur Dokumentation der Daten solche Berichte dienen. Auch die Arbeiten von Hansen, Jones und Konsorten enthalten nicht die Stationsdaten.
Ihr Spiel und das des Herrn Krechel, der wie aus heiterem Himmel hier auftauchte, um Werturteile abzugeben (obwohl er keine Qualifikation nachweisen kann), ist leicht zu durchschauen. Es geht um wirtschafliche und politische Interessen, die den Klimatismus erfordern. Warren Meyer zitiert in seinem Beitrag „A Skeptical Layman’s Guide to Anthropogenic Global Warming“ von 2007 den Klimatologen Garth Paltridge:
„A colleague of mine put it rather well. The IPCC, he said, has developed a highly successful immune system. Its climate scientists have become the equivalent of white blood cells which rush in overwhelming numbers to repel infection by ideas and results which do not support the basic thesis that global warming is perhaps the greatest of the modern threats to mankind.“
Von daher war es nicht verwunderlich, dass Lennart Bengtsson, nachdem er der Global Warming Policy Foundation (GWPF) beigetreten war, von einem Vertreter der englischen Windenergie-Industrie als „world criminal“ bezeichnet wurde. Denn ohne das absurde Geschwaetz vom zu schuetzenden Klima, gaebe es diese Windenergie-Industrie nicht und folglich auch nicht den damit verbundenen Umweltfrevel.
Garth Paltridge ist Atmosphärenphysiker
Vielen Dank Herr Kramm, dass Sie bestätigen, dass die Arbeit keine Stationsdaten (spezielle keine „Rohwerte“) enthalten, sondern nur bereits von den jeweiligen Autoren gemittelte Daten.
Warum Sie dann allerdings in eine längliche Kritik ausbrechen und mir irgendwelche Dinge unterstellen, wird mir nicht klar.
Ihr obiger Hinweis,
„Dem steht gegenüber, daß heutige Organisationen wie NASA, GISS und CRU die damaligen Temperaturen offenbar aufgrund der identen Rohwerte mit 13,6 bis 13,7°C ermitteln!?“
belegt, dass Sie glauben, NASA GISS (ohne Komma), HadCRU haetten mehr Daten aus der damaligen Zeit zur Verfuegung als die Altvorderen. Dieses ist absurd, denn erstens wurden von einigen der Altvorderen die Messnetze erst eingerichtet (z.B. in Bayern und Preussen durch von Bezold) und zweitens die Daten untereinander ausgetauscht. Ausserdem uebersehen Sie, dass die HadCRU-Zeitreihe der Temperaturanomalien schon mit 1850 beginnt, aber die von NASA GISS erst mit 1880.
Sie schrieben an anderer Stelle:
Da habe ich gestutzt und da das Papier quergelesen. Verstehe ich das richtig, dass in dem Papier die um 19-hundert veröffentlichte globale Temperaturen mit Temperaturen verglichen werden, die mit heutigen Daten und heutigen Methoden ermittelt wurden? Dass in dem Papier mit Daten aus den damaligen Veröffentlichungen Rechnungen für die Zeit um 19-hundert gemacht werden, aber keine mit der gleichen Methode für die heutige Zeit?“
Und genau das ist Ihr Problem. Sie gehen davon aus, dass die heutigen Realisationen ein und derselben Methode, die global gemittelte oberflaechennahe Luftemperatur zu berechnen, besser sind als die damalige Realisation. Das ist falsch. Die Altvorderen haben die globale Mittelung, naemlich die Integration ueber Breiten- und Laengengrade, mit den damals zur Verfuegung stehenden Mitteln in bester Art und Weise vorgenommen. Das wurde auch detailliert beschrieben. Und weil Kramm et al. (2020) deren Ergebnisse mit den heutigen Moeglichkeiten der numerischen Integration nachgerechnet und die Unterschiede dokumentiert haben, lassen sich die Ergebnisse der Altvorderen bewerten. Deren Qualifikation schaetze ich selbst weit hoeher ein als die von Hansen, Jones und Konsorten. Aber da es um wirtschaftliche und politische Interessen geht, werden aus den Erbsenzaehlern Hansen, Jones und Konsorten „wichtige Wissenschaftler“ gemacht.
Sie wollen auch nicht wahrhaben, dass das Ignorieren von wesentlichen Arbeiten und Lehrbuechern aus der Zeit zwischen 1850 und 1913 unvereinbar ist mit den wissenschaftlichen Standards. Mit dem Ignorieren der Fachliteratur beginnen bekanntlich wissenschaftliche Betruegereien.
Sie sind es, der staendig versucht, Ergebnisse, die Ihnen nicht passen, zu zerreden. Das Vorgehen ist bekannt. Da ich Saul Alinskys „Rules for Radicals“ gelesen habe, weiss ich, nach welchen Regeln gewisse Herrschaften vorgehen. Deswegen ueberrascht mich hier gar nichts mehr.
Ich frage mich ausserdem, warum z.B. die Diskrepanz nicht wahrhaben will, die sich in den Arbeiten von Hansen et al. (1981) sowie Hansen & Lebedeff (1987, 1988) widerspiegelt. Wenn man heute von den HadCRUT4-Daten lamentiert, dann bedeutet das doch, dass fruehere Versionen der HadCRUT-Daten existieren, die sich von HadCRUT4 unterscheiden. Dass ClimateGate Machenschaften aufdeckte, die aus wissenschaftlicher Sicht inakzeptabel sind, will man einfach nicht zur Kenntnis nehmen.
Viele, die Physik studiert haben, kennen den Begriff des Rayleigh-Jeans-Gesetzes. Nur wissen die wenigsten, warum Jeans dabei eine Rolle spielte. Lord Rayleigh, Nobelpreistraeger fuer Physik im Jahre 1904, hatte den Faktor 8 uebersehen, was von Jeans im Jahr 1905 korrigiert wurde. Dass dieses Strahlungsgesetz auch noch in die Katastrophe im Ultravioletten einmuendet (siehe Ehrenfestr, 1911), sei nur am Rande erwaehnt.
Dass es auch Betrueger in der Wissenschaft gibt, belegt der Hendrik-Schoen-Skandal. Eine Vielzahl von Artikeln musste zurueckgezogen werden. Und die Max-Planck-Gesellschaft sah sich gezwungen, das Angebot des Direktors eines Max-Planck-Institutes zurueckzuziehen, was sie Schoen offeriert hatte. Schlimmer war aber, dass die Frauen, die die ersten Hinweise zu Schoens Betruegereien lieferten, zunaechst als unfaehig bezeichnet wurden.
Macht ja nichts, Hansen ist zweifellos ein kompetenter Wissenschaftler, der über die Planetologie zum Klimasystem der Erde kam. Wollen Sie damit andeuten, dass man ohne einen formellen Abschluß in einer Disziplin nie auf diesem Gebiet wissenschaftliche Ergebnisse erzielen kann, egal wieviele wissenschaftliche Publikationen man dort erreicht?
Sie arbeiten sich ja auch in die Quantenmechanik ein und nehmen wohl auch für sich in Anspruch, die Arbeiten zu verstehen, obwohl Sie kein Physiker sind.
Ihr Argument, man könne den Treibhauseffekt erst verstehen, wenn man die historischen Arbeiten ihrer Liste studiert hätte, ist lächerlich. Es gibt inzwischen moderner Lehrbücher, die den Stoff „glatter“ vermitteln und zudem kann man immer behaupten, denn das ist das Wesen der Wissenschaft, ein Effekt sei nicht bis ins Letzte verstanden, wenn man den xyz Aspekt noch nicht berücksichtigt hätte. Ich könnte jetzt auch behaupten, Sie müssten erst die axiomatische Quantenfeldtheorie verstanden haben, um über die Wechselwirkung von IR-Strahlung mit Materie wissenschaftlich reden zu können. Denn erst mit der bekommt man Teilchenwechselwirkungen mathematisch konsistent beschrieben. Tu ich aber nicht, denn es geht ohne Erklärungsverlust auch einfacher.
Zur globalen Mitteltemperatur: Es sollte damit klar sein, dass es grundsätzlich zwei Definitionen gibt: mit Reduktion auf Meereshöhe und ohne auf die wahre Topographie bezogen. Die beiden Temperaturen unterscheiden sich um 1-2K. Da viele Autoren damals reduziert haben, heute aber wohl nicht, könnten sich damit die Unterschiede erklären.
Ihre Behauptung,
„Ihr Argument, man könne den Treibhauseffekt erst verstehen, wenn man die historischen Arbeiten ihrer Liste studiert hätte, ist lächerlich.“
ist eine Unverfrorenheit, weil diese Behauptung gar nicht von mir stammt. Offensichtlichg gehoert xxxxxxxx Aussagen zu Ihren Faehigkeiten. Was von Kramm & Dlugi (2011) stammt, ist die Aussage, dass man einen atmosphaerischen Treibhauseffekt nicht an Hand einer Energiebilanz nachweisen kann.
Prof. Dr. Heinz Fortak fuehrte bereits im Jahr 1971 in seinem Buch „Meteorologie“ folgendes aus:
„Der Strahlungsanteil in Hoehe von 3.52 kWh/(m2 d) (42 %), welcher das System Erde – Atmosphaere effektiv erwaermt, besteht aus der kurzwelligen Strahlungsabsorption in der Atmosphaere und am Erdboden (17 % + 47 % = 64 %) abzueglich des Energiebetrages, der zur Verdunstung des Wassers benoetigt wurde. Der „Kreislauf“ der langwelligen Strahlung zwischen Erdoberflaeche und Atmosphaere traegt nicht zur Erwaermung des Systems bei. Die effektive langwellige Ausstrahlung nach oben von 64 % dient zur Aufrechterhaltung des Strahlungsgleichgewichts an der Obergrenze der Atmosphaere.“
Fortak, mittlerweile im 94. Lebensjahr, war damals Direktor des Instituts fuer Theoretische Meteorologie der FU Berlin. Dieses Institut, was weltweit einmalig war, war fuer Fortak gegruendet worden, der einer der fuehrenden Theoretiker in der Meteorologie weltweit war. Obwohl sich Fortaks Zahlen im Laufe der Zeit leicht geaendert haben, ist seine Aussage immer nocht korrekt, was Kramm & Dlugi (2011) belegt haben.
Und in dem Lehrbuch „Fundamentals of Atmospheric Radiation“ von Bohren & Clothiaux (2006) heisst es:
“In general, energy (or power) is a more relevant physical quantity than temperature. Energies are additive, temperatures are not; energy is conserved, temperature is not.”
Diese Aussage ist ebenfalls korrekt. Der physikalische Hintergrund ist der, dass Energie, Entropie, etc. extensive Groessen und Temperatur, Druck etc. intensive Groessen sind. Und dieser Sachverhalt ist seit mehr als 100 Jahren bekannt (siehe z.B. Planck, 1897; Tolman, 1917).
Quantenmechanik gehoerte zu meiner Studienzeit an der Universitaet zu Koeln zu den Plichtvorlesungen der Meteorologie. Ich habe mir waehrend meiner Zeit als wissenschaftler Mitarbeiter an der Universitaet Frankfurt erlaubt, eine Vorlesung zu diesem Thema von Prof. Greiner zu hoeren. Und das Lehrbuch von John von Neumann zu den Grundlagen der Quantenmechanik gehoert su meiner Privatbiliothek. Offensichtlich ist Ihnen nicht bekannt, dass die Arbeit von Einstein (1917), „Zur Quantentheorie der Strahlung“, aus der Zeit vor der Entwicklung der Quantenmechanik stammt, die Heisenberg mit seinem Artikel von 1925 einleitete. Von daher ist die quantenmechanische Untermauerung, die Dirac im Jahr 1927 lieferte, wichtig. Das koennen Sie bei von Neumann (1932), Unterkapitel 3.6 „Lichttheorie“ nachlesen.
Im uebrigen kann man das Plancksche Strahlungsgesetz auch mit Hilfe der Dimensionsanalyse herleiten, was Kramm & Herbert (2006), „HEURISTIC DERIVATION OF BLACKBODY RADIATION LAWS USING PRINCIPLES OF DIMENSIONAL ANALYSIS“, herleiten. In diesem Artikel haben mein Prof. Dr. Herbert und ich ein verallgemeinertes Wiensches Verschiebungsgesetz hergeleitet (nicht zu verwechseln mit dem Wienschen Verschiebungssatzes), wovon das Plancksche Strahlungsgesetz nur eine der moeglichen Realisationen ist.
Da bereits von Hann und Buchan darauf verwiesen haben, weswegen es erforderlich ist, die Temperatur an einer Station auf Meeresspiegel-Niveau zu reduzieren, will ich das hier nicht wiederholen (ist bei Kramm et al., 2020, erwaehnt). Die Temperatueren nicht zu reduzieren, ist ein Unding. Die Messwerte der Wetterstation auf der Zugspitze werden von dem Wettergeschehen in etwa 3000 m Hoehe ueber NN gepraegt, und nicht von lokalen Bedingungen des Energieumsatzes. Dass der Enthalpiegehalt der Luft in 3000 m Hoehe ueber NN sich voellig von dem im Niveau des Meeresspiegels unterscheidet, sollte auch Ihnen bekannt sein. Da 70 % der Erdoberflaeche mit Wasser bedeckt ist, ist die Meeresoberflaeche die natuerliche Bezugsflaeche.
Wird die Temperatur nicht auf Meeresspiegel-Niveau reduziert, haengt die global gemittelte oberflaechennahe Lufttemperatur von der Auswahl der Stationen ab, was Kramm et al. (2020) belegt haben.
„Offensichtlichg gehoert das Faelschen von Aussagen zu Ihren Faehigkeiten.“
Ich empfehle, den obigen Beitrag von Herrn Kramm zu streichen. Die zitierte Äußerung empfinde ich als ehrverletzend. Wenn dies so stehenbleibt, überlege ich mir, entsprechende Konsequenzen einzuleiten.
Neben einer Korrektur des Beitrags empfehle ich Ihnen, Herrn Kramm gesondert auf die Netiquette hinzuweisen und eine Selbstreflexion seines Umgangs mit anderen zu nahezulegen.
Sie haben recht, das ist eine beleidigende Unterstellung. Ist gelöscht.
danke. Aber ich bin davon ausgegangen, dass Sie davon ausgehen, dass ich diese Mitteilung an Sie nicht als blog-Beitrag verstanden sehe. So, wie Sie es nun umgesetzt haben, ist es unweigerlich kurios. Aber lassen Sie es so. Es amüsiert. I love it!
mit Vergnügen.
6. MAI 2020 UM 20:29
Sie schrieben:
„Im hier beworbenen Buch von Herrn Lüdecke kann man übrigens nachlesen, dass es die globale Erwärmung gibt. Bis vor fünf Minuten war ich mir sicher, dass selbstverständlich auch Sie die globale Erwärmung nicht leugnen. Andere Leser hier sind überzeugt, dass Sie das tun.‘
Offensichtlich haben Sie nicht begriffen, dass meine Mitautoren und ich uns auf Wissenschaftler berufen haben, die zu ihrer Zeit weltbekannt waren und Wesentliches geleistet haben. Deren Arbeiten zu ignorieren, ist unvereinbar mit den wissenschaftlichen Standards. Wie Sie also behaupten, ich wuerde die globale Erwaermung leugnen, dann uebersehen Sie, dass die Ergebnisse dieser Wissenschaftler, die wir praesentiert und bewertet haben, die Schlussfolgerung einer globalen Erwaermung gar nicht zulassen.
Sie schrieben weiterhin:
„Ich hätte gedacht, Sie hätten Interesse daran, diese Verwirrung zu beseitigen. Es geht ja irgendwo auch um ihren Ruf als seriöser Wissenschaftler.“
Sie koennen ueberhaupt nicht denken. Und es gibt auch keine Verwirrung, die beseitigt werden muss, es sei denn die in Ihrem Kopf. Aber dafuer bin ich nicht zustaendig.
Haetten Sie auch nur die Zusammenfassung der Arbeit von Kramm et al. (2020) gelesen, dann haette sich Ihre Frage eruebrigt.
Wenn Sie meine Seriositaet als Wissenschaftler anzweifeln wollen, dann ist das Ihre Angelegenheit. Es gehoert seit etlichen Jahren dazu, dass Leute wie Sie versuchen, die Autoren kritischer Arbeiten zu verleumden und zu diffamieren. Nur zieht das bei meinen Mitautoren und mir nicht, weil wir seit Jahrzehnten gewissenhafte wissenschaftliche Arbeit leisten.
Wo es moglich war, haben wir die Tabellen mit den historischen Daten als Abbildungen dokumentiert. Wo es nicht so ohne weiteres ging, haben wir die historischen Daten in Tabellen zusammengefasst, wobei die Quellen aufgelistet wurden. Fachkollegen koennen diese Daten ueberpruefen.
Als Theoretiker mit einer Berufserfahrung von 40 Jahren weiss ich natuerlich, wie man diese Daten verwenden kann, um globale Mittelwerte zu berechnen. Die Formeln dafuer wurden von Kramm et al. (2020) aufgelistet. Diese sind schon mindestens 145 Jahre bekannt, denn sie wurden von Rudolf Spitaler (1885), „Die Wärmeverteilung auf der Erdoberfläche“, verwendet. Trotzdem ist das Ueberpruefen wichtiger Formeln Teil der wissenschaftlichen Arbeit. Wir haben sowohl die historischen Quellen als auch juengere Lehrbuecher zitiert, z.B. Peixoto & Oort (1992), „Physics of Climate“, sowie Hantel & Haimberger (2016), „Grundkurs Klima“.
Was in der Wissenschaft unserioes ist, das ist das Ignorieren dieser klassischen Arbeiten und Lehrbuecher, die zwischen 1850 und 1913 erschienen sind. Es ist also angebracht, darueber nachzudenken, warum Hansen, Jones und Konsorten diese Fachliteratur ignoriert haben.
Zum Schluss noch ein Hinweis. Im „GUIDE TO CLIMATOLOGICAL PRACTICES – THIRD EDITION“ der WMO von 2018 heisst es:
„Julius von Hann, who published the first of three volumes of the Handbook of Climatology in 1883, wrote the classic work on general and regional climatology that included data and eyewitness descriptions of weather and climate.“
Genau aus diesem Grund habe ich nachgefragt, wie Sie zur Artikelüberschrift stehen. Und jetzt kann ich mich auf ihren Munde berufen und ohne Verleumdung sagen, dass G. Kramm der Ansicht ist, es gäbe keine globale Erwärmung.
Ich bin überrascht.
Was Kramm et al. (2020) in ihrer Arbeit dokumentiert haben, sind die Ergebnisse aus Arbeiten und Lehrbuechern, die zwischen 1852 und 1913 von Dove, Forbes, Ferrel, Spitaler, Batchelder, Arrhenius, von Bezold, Hopfner, von Hann, und Börnstein publiziert wurden. Dieses sind auch nach heutigen Massstaeben international renommierten Wissenschaftler, wovon einer im Jahr 1903 mit dem Nobelpreis fuer Chemie ausgezeichnet wurde. Diese Ergebnisse wurden von Kramm et al. wissenschaftlich bewertet und als korrekt nachgewiesen. An Hand dieser Ergebnisse kann man belegen, dass sich in den vergangenen 100 Jahren die global gemittelte oberflaechennahe Lufttemperatur praktisch nicht geaendert hat.
Ich erlaube mir, aus dem Bericht von Arrhenius (1896), „Ueber den Einfluss des atmosphaerischen Kohlensaeuregehalt auf die Temperatur der Erdoberflaeche“, zu zitieren (der Bericht wurde in Deutsch verfasst):
„Was erst die mittleren Temperaturen betrifft, so kann man dieselben mit den von Spitaler (fuer die Meeresoeberflaeche) berechneten vergleichen. Wir erhalten so die nebenstehende Tabelle (korrigiert zur Meeresoeberflaeche).
Die Abweichung zwischen den beiden Reihen ist nicht gross und im Allgemeinen positiv, nur die erste und die drei letzten Ziffern sind kleiner nach Tab. 10 als nach Spitaler. Die mittlere Abweichung betraegt nicht voellig + 0,1 Grad C.“
Nach Spitaler (1885) betraegt das globale Mittel der oberflaechennahen Lufttemperatur 15,1 Grad C. Arrhenius arbeitete mit 15 Grad C. Dieser Wert wurde auch explizit in Arrhenius‘ Arbeit von 1896, „On the Influence of Carbonic Acid in the Air upon the Temperature of the Ground“, genannt.
Nochmals fuer Sie zum Mitschreiben: Globales Mittel der oberflaechennahen Lufttemperatur: 15 Grad C.
xxxxxxxxxx
Es ist seit geraumer Zeit bekannt, dass sog. Influencer von Firmen und politischen Gruppierungen finanziert werden, um die oeffentliche Meinung zu manipulieren, denn der Klimatismus dient ja dazu, Subventionen in Milliardenhoehe einzufahren.xxxxxxxxxxx xxxxxx
Und wenn andere Anbieter heute niedrigere Temperaturen nennen, sagen wir mal 13,8° für 1885 und 14,8° für heute, dann ist es nciht um 1° wärmer geworden, sondern um 0,3° kälter, das können Ihnen solche Kapazitäten wie Rainer Hoffmann hier bestätigen. Ganz großartig, das wird in der Klimawissenschaft sicherlich für Aufsehen sorgen *lol*.
Eine nette Arbeit über Wissenschaftsgeschichte von Ihnen. Aber fast schon zum Fremdschämen, welchen Spin Sie der Arbeit jetzt geben wollen. xxxxxxxx immerhin haben sie es zu einer Erwähnung durch Herrn Professor Lüdecke gebracht, auch wenn dieser völlig zurecht sich schon in der Überschrift durch das Fragezeichen dezent von Ihnen distanziert. Kaufen Sie sein Buch, dann werden auch Sie erfahren, dass die globale Erwärmung Fakt ist.
Offensichlich sind Sie nicht in der Lage zu begreifen, dass die damals bekannten Beobachtungsdaten sich nicht vermehrt haben. Die damals verwendeten Methoden des globalen Mittelns gelten auch heute noch, was Kramm et al. (2020) ebenfalls dokumentiert haben, und zwar an Hand der aelteren und der juengeren Fachliteratur. Was Sie also als Fortschritt bezeichnen wollen, existiert nur in Ihrer Phantasie.
Was die damaligen Wissenschaftler in ihren Arbeiten und Lehrbuechern detailliert beschrieben haben, wurde von Hansen, Jones und ihren Mitstreitern vollkommen ignoriert, was mit den wissenschaftlichen Standards unvereinbar ist. Folglich ist es egal, was diese Herrschaften heute fuer die Zeitspanne von 1850 bis 1913 anbieten. Sie verfuegen ueber nicht mehr Information als damals vorhanden war.
Was Herr Hoffmann dazu verbreitet, ist vollkommen egal, denn Hoffmann ist wie Sie vollkommen fachfremd.
Sie schrieben:
„Eine nette Arbeit über Wissenschaftsgeschichte von Ihnen. Aber fast schon zum Fremdschämen, welchen Spin Sie der Arbeit jetzt geben wollen. xxxxxxxx immerhin haben sie es zu einer Erwähnung durch Herrn Professor Lüdecke gebracht, auch wenn dieser völlig zurecht sich schon in der Überschrift durch das Fragezeichen dezent von Ihnen distanziert. Kaufen Sie sein Buch, dann werden auch Sie erfahren, dass die globale Erwärmung Fakt ist“
Was glauben Sie eigentlich, wer Sie sind? Sie agieren hier mit Verleumdung udn Diffamierung, um die Ergebnisse von Hansen, Jones und Mitstreitern zu verteidigen, die nicht zu rechtfertigen sind. Dafuer, dass meine Mitauchtoren und ich die damaligen Ergebnisse – im Gegensatz zu Hansen, Jones und Mitstreitern – beruecksichtigt haben, muessen wir uns nicht fremdschaemen.
Wer im uebrigen Wer den ‘warming’-Mechanismus der optisch aktiven Gase physikalisch begruenden will, der muss zuerst die Arbeiten von
– Einstein (1917), “Zur Quantentheorie der Strahlung”,
– Einstein & Ehrenfest (1923), “Zur Quantentheorie des Strahlungsgleichgewichts”,
– Dirac (1927), “The quantum theory of the emission and absorption of radiation”,
– Milne (1928), “The effect of collisions on monochromatic radiative equilibrium”,
– von Neuman (1932), „Mathematische Grundlagen der Quantenmechanik“ (Lehrbuch), und
– Chandrasekhar (1960), “Radiative transfer” (Lehrbuch) und
als falsch nachweisen. Ausserdem muss er die Kommentare von
– Fowler & Milne (1925; http://www.ncbi.nlm.nih.gov/pmc/articles/PMC1086035/)
und
– Tolman (1925; http://www.ncbi.nlm.nih.gov/pmc/articles/PMC1086044/)
zu Einsteins Artikel als unsinnig darlegen. Dirac wurde 1933 fuer seine Arbeiten zur Quantenmechanik zusammen mit Schroedinger mit dem Nobelpreis in Physik ausgezeichnet. Dass Einstein in 1921 und Chandrasekhar in 1983 mit dem Nobelpreis in Physik ausgezeichnet wurden, sollte bekannt sein. Milne starb zu frueh, um als Nobelpreis-Kandidat infragezukommen. Aber er wurde ebenfalls hochrangig fuer seine Arbeiten ausgezeichnet. Ehrenfest, Fowler und Tolman sind ebenfalls in der einschlaegigen Fachliteratur sehr bekannt. John von Neumann wurde von Prof. Dr. Schellhuber sogar als der kluegste Mensch des 20. Jahrhunderts bezeichnet, trotz der Wirkmaechtigkeit von Albert Einstein.
Das sind die Fakten, nicht das, was Sie hier verbreiten.
Nun ja, Sie werden mir bestimmt erklären können weshalb die mittlere Jahrestemperatur des US-Meßnetzes vor und nach 1930 bis 1950 zwischen den beiden Nord-Süd-Gebirgen und nördlich des Golf von Mexiko niedriger ist.
Na, das finde ich jetzt ziemlich beleidigend und diffamierend.
Apropos diffamierend: Sie beklagen sich, von mir diffamiert zu werden, wobei mir nicht ganz klar ist, wo Sie diese sehen, Sie scheinen sehr dünnhäutig zu sein. Und sind zugleich derselbe, der es regelmäßig schafft, die sehr großzügig ausgelegten Regeln gegen Beleidigungen und Respektlosigkeiten hier zu verletzen…
Ja, Sie haben Recht, es gibt genügend Wissenschaftler, die teils sehr bösartig diffamiert werden. Und nun scrollen Sie mal ihre eigenen Kommentare durch, da finden sich einige Beispiele, wo Sie selbst verdiente Wissenschaftler respektlos und diffamierend behandeln.
Wie gesagt, ich finde es schön, dass Sie auf Leistungen verdienter Wissenschaftler aufmerksam machen, die fast schon in Vergessenheit geraten sind. Diese haben Bleibendes hinterlassen. Jones und Hansen ist dies auch gelungen, ihre Namen werden auch noch in 100 Jahren genannt werden.
Kramm hat nichts hinterlassen, was erinnerungswürdig ist. Den Namen Kramm habe ich noch nie in Lehrbüchern oder auf Kongeressen vernommen. Der einzige, der von den Arbeiten von Kramm spricht, ist Kramm selbst.
Mir scheint, das könnte der tiefere Grund sein, warum Sie so schlecht über die Größen reden, es ist der Neid des Erfolglosen.
Machen wir folgendes Gedankenexperiment: Man schicke mehrere Meßtrupps in ein kleines Wäldchen in Hektargröße und lasse diese Trupps die Mitteltmperatur bestimmen. Im Ergebnis wird man ebensoviele unterschiedliche Mittelwerte erhalten wie man Meßtrupps losgeschickt hat. Denn jeder mißt zu einem anderen Zeitpunkt an einer anderen Stelle nach einer anderen Methode. Und welcher dieser „gemessenen“ Mittelwerte wäre der richtige, uind warum wären die anderen falsch?
Sehen Sie, da sich diese Frage nicht und niemals beantworten läßt, sollte man den Unfug vom globalen Mittelwert der Temperatur schleunigst vergessen; es gibt ihn nämlich nicht.
Es ist schon möglich, das Problem ist die Zuverlässigkeit. Ich habe aus veröffentlichten Zeitreihen die mittlere globale Temperatur für 2019 berechnet:
Berkeley Earth TSeaIce = TAir: 15,1 °C
Berkeley Earth TSeaIce = TWater: 15,5 °C
gistemp1200_GHCNv4_ERSSTv5 gridded: 14,9 °C
HadCRUT.4.6.0.0.median.txt: 14,8 °C
CERES_SYN1deg-Month_Terra-Aqua-MODIS_Ed4.1 Initial skin temperature 200003 201911.nc: 15,6 °C
Verwendet man GHCNv4-Daten muss man fehlende Land-Temperaturen durch bekannte Temperaturen von in der Nähe liegenden Stationen schätzen. Dies ist schwierig für Grönland und für die Antarktis. Bei den Ozean-Temperaturen von ersstv5 fehlen die Luft-Temperaturen über Meer-Eis. Deshalb verwende ich nördlich von 60°N und südlich von 60°S die „Skin-Temperaturen“von CERES. Ergebnis: 15,7 °C für 2019.
Die Streuung der verschiedenen Werte ist etwa ein Maß für die Zuverlässigkeit der Daten. Letztlich ist dies eine akademische Übung. Die Ort aufgelösten Datensätze geben das Temperaturprofil der Erdoberfläche wider. Da ist viel wichtiger.
Kurz: Wer behauptet,er kenne den Mittelwert der Globaltemperatur, der ist ein Scharlatan, der es nur deswegen behaupten kann, weil ihn niemand widerlegen kann und er das weiß.
Da habe ich gestutzt und da das Papier quergelesen. Verstehe ich das richtig, dass in dem Papier die um 19-hundert veröffentlichte globale Temperaturen mit Temperaturen verglichen werden, die mit heutigen Daten und heutigen Methoden ermittelt wurden? Dass in dem Papier mit Daten aus den damaligen Veröffentlichungen Rechnungen für die Zeit um 19-hundert gemacht werden, aber keine mit der gleichen Methode für die heutige Zeit?
Werden da nicht Äpfel mit Orangen verglichen? Oder habe ich irgendwie überlesen, dass in dem Papier die gleiche Methode für die Zeit um 1900 und für heute angewendet wurde und die Ergebnisse verglichen wurden?
Es ist nicht verboten verschiedene Methoden anzuwenden, sondern sogar erwünscht. Es werden aber keine Vertrauens-Intervalle für die Ergebnisse angegeben.
Das war nicht meine Frage und ich wollte auch nicht suggereieren, dass die Anwendung verschiedener Methoden verboten oder unerwünscht wäre. Im Gegenteil. In dem papier werden ja sogar drei verschiedene Temperaturreihen referenziert, die mit verschiedenen Methoden und (teilweise verschiedenen) Ausgangsdaten erstellt werden. Alle drei decken den gesamten Zeitraum ab, erlauben also eigentlich eine Aussage, ob es heute wärmer ist als 1900.
Mein Frage war, ob man aus einem Vergleich (Datenmenge 1900, Methode A) mit (Datenmenge Heute, Methode B) legitime Schlussfolgerungen ziehen kann. Warum wurde im Papier die entwickelte Methode nicht auch auf Daten von heute angewendet und dann mit dem Ergebnis von 1900 verglichen?
Ich empfehlen jedem, die Arbeit von Christian Wiener (1879), „Ueber die Stärke der Bestrahlung der Erde durch die Sonne in den verschiedenen Breiten und Jahreszeiten“, zu studieren. Ich habe an Hand seiner Tabelle die normierte solare Einstrahlung fuer die Zeitspanne vom 20. Maerz 1874 bis zum 21. Maerz 1875 graphisch dargestellt und global gemittelt. Die Genauigkeit die Wiener damals erreichte, ist verblueffend. Wiener kannte damals natuerlich nicht den genauen Wert der sog. Solarkonstanten. Deswegen normierte er seiner Ergebnisse. Folglich habe ich meine Ergebnisse ebenfalls mit der Solarkonstanten normiert, so dass die Ergebnisse vergleichbar sind. Die globale Mittelung der Wienerschen Daten ergab 0,2496. Gemaess der heutigen Solarkonstanen ergaebe sich also als globales Mittel der solaren Einstrahlung 339,7 W/m^2.
Diejenigen, die den alten Arbeiten misstrauen, sollten dann auch den Arbeiten von Stefan (1879), Boltzmann (1884), Wien (1896) und Planck (1901) misstrauen, denn diese stammen aus dem gleichen Zeitraum. Von Bezold und Planck waren auch Kollegen an der Universitaet Berlin, der heutigen Humboldt-Universitaet zu Berlin. Nach dem Tode von Hermann von Helmholtz, wurde von Bezold im Jahr 1895 auch Praesident der Deutschen Physikalischen Gesellschaft, ein Amt, was er turnusgemaess im Jahr 1897 aufgab. Im Falle einiger Studenten von von Bezold diente Planck auch als Zweitgutachter.
Es stellt sich nur die Frage, warum diejenigen, die ab 1980 versuchten, an Hand der Zeitreihen des globalen Mittels der oberflaechennahen Lufttemperatur eine anthropogene globale Erwaermung zu belegen, die frueheren Arbeiten ignoriert haben. Das ist unvereinbar mit den wissenschaftlichen Standards, worauf Prof. Dr. Luedecke hier bereits hinwies. Hansen, Jones, etc. haben bis heute nicht eine einzige der frueheren Arbeiten erwaehnt, selbst dann nicht, nachdem das Buch
McBean, G. and Hantel, M., eds., 1993, Interactions Between Global Climate Subsystems: The Legacy of Hann, von der American Geophysical Society publiziert worden war.
Hansen haette zumindest bei seinem „Testimony to the Committee on Energy and Natural Resources of the United States Senate“ (June 23, 1988) auf die alten Arbeiten hinweisen muessen. Dieses geschah nicht.
Der doch recht lange Text wirkt von der Darstellung her wie eine Antwort auf meine Frage. Er enthält jedoch kein Zitat, an dem man erkennen könnte, worauf sich der Text bezieht, noch geht er jedoch überhaupt auf meine Frage ein. Ist der Text versehentlich als Reaktion auf meine Frage eingeordnet worden?
Könnten Sie, Herr Kramm, vielleicht meine Frage(n) beantworten?
„Mein Frage war, ob man aus einem Vergleich (Datenmenge 1900, Methode A) mit (Datenmenge Heute, Methode B) legitime Schlussfolgerungen ziehen kann. Warum wurde im Papier die entwickelte Methode nicht auch auf Daten von heute angewendet und dann mit dem Ergebnis von 1900 verglichen?“
Die von Dove, Forbes, Ferrel, Spitaler, Batchelder, Arrhenius, von Bezold, Hopfner, von Hann, und Börnstein angewandten Methoden sind auch noch heute gueltig. Ob sie seit 1980 korrekt angewendet wurden, ist zweifelhaft, denn Hansen, Jones und Konsorten haben alle Arbeiten aus dem von uns betrachteten Zeitraum voellig ignoriert, und damit gegen alle wissenschaftliche Standards verstossen. Folglich muessen Hansen, Jones und Konsorten nachweisen, dass ihre Auswertungen der Beobachtungsdaten mit dem damaligen Standard uebereinstimmen, nicht umgekehrt.
Hansen, Jones und Konsorten verfuegten ueber keine besseren Daten aus dem von uns betrachteten Zeitraum als die Altvorderen, unter deren Leitung die meteorologischen Beobachtungen vielfach durchgefuehrt wurden. Es fand damals ein reger Austausch zwischen den einzelnen Forschergruppen statt, was die Fachliteratur belegt.
Ich frage mich auch, ob Hansen und seine Mitarbeiter ueberhaupt begriffen haben, dass damals in Europa noch vielfach mit der Reaumur-Skala gearbeitet wurde. Fuer einen Fachfremden wie Hansen, der mit der Fahrenheit-Skala aufgewachsen ist, ist der Unterschied zwischen der Celsius-Skala und der Fahrenheit-Skala vielleicht noch auf Anhieb erkennbar. Aber kannte und kennt er den Unterschied zwischen der Reaumur-Skala und der Celsius-Skala?
Was die Altvorderen getan haben, ist detailliert dokumentiert. Was Hansen, Jones und Konsorten getan haben, laesst sich bestenfalls erraten. Eine exakte Beschreibung ist nicht zu finden. Und ClimateGate ist noch nicht allzu lange her.
Ich empfehle Ihnen doch die Diagramme der Temperaturanomalie von Hansen et al. (1981) sowie Hansen & Lebedeff (1987) zu vergleichen, und das Diagramm hinzuzuziehen, was er 1988 dem US Senate Committee on Energy and Natural Recources praesentierte. Offensichtlich sind die Unterschiede nicht wichtig, obwohl sie augenscheinlich sind. Hauptsache: „Es wurde waermer“!
Zum Schluss zitiere ich aus der Arbeit von Feulner et al. (2013), „On the Origin of the Surface Air Temperature Difference between the Hemispheres in Earth’s Present-Day Climate“ (https://journals.ametsoc.org/doi/10.1175/JCLI-D-12-00636.1). Darin heisst es:
„By the beginning of the twentieth century, a small temperature difference of 1°–2°C between the Northern and Southern Hemispheres was well established in meteorology (Lockyer 1906). It should be noted that this value of the hemispheric temperature difference is already remarkably close to the one derived from modern measurements discussed later in this paper.“
Dieses Ergebnis wurde mehr als 100 Jahre spaeter bestaetigt.
Lockyer’s Artikel, „Studies of temperature and pressure observations“, erschien 1906 in Nature (https://www.nature.com/articles/073594a0). Darin heisst es:
«Prof. Mohn has just completed a study of the meteorological observations made during Nansen’s memorable North Polar expedition in 1893-6, and has been able to make a new determination of the mean temperatures of the air for the parallels of latitude 60° to 90° north. These new values have enabled Prof. Hann to re-calculate afresh the mean temperature of the whole northern hemisphere, using the results obtained in the investigation of Spitaler for the parallels from 0° to 55° N. The value obtained for the mean of the northern hemisphere was finally 15.1 °C. For the southern hemisphere Prof. Hann had previously determined the value to be 13.6 °C., so that the mean value for the whole earth comes out as 14.35 °C. It is interesting to remark that the northern hemisphere appears to be 1.5 °C warmer than the southern. Spitaler in 1886 came to a similar conclusion, his figures being :-
Northern hemisphere …..15.4 °C,
Southern hemisphere….. 14.8 °C,
Whole earth…………..15.1 °C,
Excess of N. over S. …..0.6 °C.
Prof. Hann points out that the meteorological observations made during the recent Antarctic expeditions will be of special interest in relation to this question, since a new and better determination of the value for the southern hemisphere is rendered possible.»
Rahmstorf und Levermann, Mitautoren der Arbeit von Feulner, sollten also die Arbeit von Lockyer kennen und folglich auch die darin erwaehnten Temperaturen. Wieso behauptete Levermann vor dem Umweltausschuss des Deutschen Bundestages im Jahre 2018:
„Stabilisierung der Temperature geht physikalisch nur mit Null Emissionen“
Dazu sollten Sie Ihre Fragen stellen.
Vielen Dank für Ihre Antwort. Sie antworten zwar nicht direkt auf meine Frage, aber haben (denke ich) klargestellt, dass
* in dem Papier keine Berechnungen für die heutige Zeit durchgeführt wurden
* GISSTEMP/HadCrut/BEST 2020 mit von anderen ermittelten Werten für 1900 verglichen werden
Wir haben also auf der einen Seite drei Temperaturreihen, die den ganzen Zeitraum abdecken und in denen man einen Temperaturanstieg sieht und auf der anderen Seite eine Aussage zu Temperaturen um 1900 ohne eine IMHO adäquate Vergleichsmöglichekeit mit heute. Wir wissen nicht, was herauskommt, wenn man die Methoden auf heutige Temperaturdaten anwendet. Die Zuständigkeit für diese Aufgabe sehen Sie bei jemand anderem.
So wie schon ausgeführt, warum stellen Hansen, Jones und andere derzeitige Klimafolgenwissenschaftler keinen Bezug in ihren Arbeiten zu den historisch verfügbaren Daten her?
Wenn ich mir die Zahlen so anschaue ist meine Vermutung, das sich anhand der Zahlen keine Erwärmung darstellen ließe.
Das Weglassen von Information ist genauso eine Lüge wie die Manipulation.
Wie kritisch gehen sie mit den Arbeiten von Hansen, Jones und den anderen um?
Als Leser würde mich Ihre Antwort auf die Artikelüberschrift interessieren:
„Ist die globale Mitteltemperatur seit 1850 bis heute überhaupt angestiegen?“
Mir scheint, dass diese Fragestellung in ihrer Arbeit gar nicht untersucht wurde.
Wenn Sie wirklich der Meinung sind, Sie hätten nachgewiesen, dass es keine globale Erwärmung gibt, dann überrascht es, dass dieses über alle Maßen sensationelle Ergebnis im abstract nicht einmal erwähnt wird.
Im hier beworbenen Buch von Herrn Lüdecke kann man übrigens nachlesen, dass es die globale Erwärmung gibt. Bis vor fünf Minuten war ich mir sicher, dass selbstverständlich auch Sie die globale Erwärmung nicht leugnen. Andere Leser hier sind überzeugt, dass Sie das tun.
Ich hätte gedacht, Sie hätten Interesse daran, diese Verwirrung zu beseitigen. Es geht ja irgendwo auch um ihren Ruf als seriöser Wissenschaftler.
Damit ist die bleibt die Frage der Überschrift unbeantwortet und die Spekulationen im Artikel bleiben mehr als gewagt.
Historisch interessant ist Kramms Arbeit schon. Schön, die alten Karten und Daten mal zusammengetragen zu haben. Auch sieht man gut, dass das globale Mittel mit den alten Daten gar nicht genauer als ca. 0,5 K genau berechnet werden kann – was zu erwarten ist.
http://temperature.global/
Diese darf man sogar mit den Arbeiten von Jones und Hansen vergleichen.
Aufgepasst:
The Earth’s Temperature
Currently: 57.17°F/13.98°C
Deviation: -0.03°F/-0.02°C
Stations processed last hour: 58331
Last station processed: Shenyang, China
Update time: 2020-05-07 15:20:30 UTC
Wenn ich jetzt mal so adhock die Frage beantworten darf dann ist die Antwort mit einer Genauigkeit von 0.5K: Nein es hat sich eher noch abgekuehlt
Und mit einer Genauigkeit von 1K ist es so ungefaehr gleich geblieben.
Welche Genauigkeiten geben Hansen und Jones eigentlich an?
„Diese darf man sogar mit den Arbeiten von Jones und Hansen vergleichen.“
Mir scheint, wenn das Ergebnis „keine Erwärmung“ lautet, dann ist plötzlich alles erlaubt, dann existieren keine wissenschaftlichen Prinzipien und Mindeststandards mehr.
So etwas hätten Sie oder Herr Kramm keinem Klimaforscher durchgehen lassen, mir scheint, die Ansprüche an echter Wissenschaft gelten nur für „Alarmisten“. Herr Kramm scheint das auch zu wissen, ansonsten hätte er sein „Ergebnis“ im abstract untergebracht und nicht nach über 40 sehr ermüdenden Seiten im Schlussteil in zwei Sätzen versteckt. Da musste man schon etwas tricksen…
In der Arbeit
Peixoto, J.P. and Oort, A.H. (1984) Physics of Climate. Reviews of Modern Physics , 56, 365-429.
wurden diese Methoden nochmals beschrieben, wie sie in juengster Zeit auch von Hantel & Haimberger (2016) in dem Lehrbuch „Grundkurs Klima“ praesentiert wurden.
Es stellt sich also nur die Frage, ob die NASA GISS-Temperaturen von Hansen und Mitarbeitern sowie die HadCRU-Temperaturen von Jones und Mitarbeitern sowie die Berkeley-Temperaturen entsprechend dieser Methoden ausgewertet wurden. In den beiden Arbeiten von Hansen & Lebedeff (1987, 1989) wird die Arbeit von Peixoto & Oort (1984) nicht zitiert; die frueheren Arbeiten aus der 2. Haelfte des 19. Jahrhunderts und zu Beginn des 20. Jahrhunderts sowieso nicht. Das gleiche gilt auch fuer Hansens beruechtigtes „Testimony“ von 1988. Dass ein gravierender Fehler in der Arbeit von Hansen & Lebedeff (1987) enthalten ist, sollte bekannt sein. Deswegen wurde 1988 das „Update“ nachgeschoben, mit dem dieser Fehler korrigiert wurde, ohne ihn allerdings zu nennen.
Dass die HadCRUt-Daten mehrfach geaendert wurden, belegt schon die Zahl der Versionen. Weder bei Jones et al. (1999), „SURFACE AIR TEMPERATURE AND ITS CHANGES OVER THE PAST 150 YEARS“, noch bei Morice et al. (2012), „Quantifying uncertainties in global and regional temperature change using an ensemble of observational estimates: The HadCRUT4 data set“, findet man irgend einen Hinweis auf die frueheren Arbeiten; auch Peixoto & Oort (1984) wird nicht erwaehnt. Im Rahmen von ClimateGate, was Ende 2009 hochkochte, wurde aufgedeckt, wie diese Herrschaften agiert haben. Mit einer exakten
Naturwissenschaft hat das nun wirklich nichts zu tun.
Dass sich die Zeitreihen dieser drei Institutionen auch noch merklich unterscheiden, haben Kramm et al. (2020) in ihrer Abbildung 1 veranschaulicht. Erst ab 1980 liegen die Temperaturanomalien nahe beieinander. Kramm et al. haben deswegen die Zeitspanne von 1991 bis 2018 zum Vergleich mit den frueheren Ergebnissen herangezogen.
Die Zahl der Stationen und die jeweilige Zeitspannen, auf denen die Isothermenkarten von Hann und Buchan beruhen, wurden angegeben. Wer glaubt, dass graphische Methoden zu ungenau seien, der weiss nicht, wovon er schwadroniert. In einer der alten Arbeiten fand ich einen interessanten Hinweis, die fast einer Entschuldungung gleichkam. Der Autor wies darauf hin, dass die zweite Stelle hinter dem Komma bei der Temperatur sich rechnerisch ergab, aber sonst keine Bedeutung hat.
Kramm et al. (2020) haben auch die Daten von Hann & Suering (1939) sowie Sellers (1965) herangezogen. Das zweibaendige Lehrbuch von Hann-Suering ist ein Klassiker, an dem eine Reihe von Suerings Fachkollegen mitgearbeitet haben, so u.a. Julius Bartels, Fritz Moeller, Ratje Muegge, Gerhard Mueller, Max Robitzsch und Ludwig Weickmann. Es ist schade, dass dieses Werk nicht ins Englische uebertragen wurde.
Dass Sie wenig bis gar nichts von der Materie verstehen, belegt Ihr Hinweis:
„Auch sieht man gut, dass das globale Mittel mit den alten Daten gar nicht genauer als ca. 0,5 K genau berechnet werden kann – was zu erwarten ist.“
Selbstverstaendlich weisen die von Kramm et al. (2020) betrachteten Zeitreihen der Temperaturanomalien nach NASA GISS, HadCRU und Berkeley Fehler auf. Da die historischen Datensaetze der Normaltemperaturen keine Fehlerangaben enthielten, haben Kramm et al. (2020) zu jedem historischen Datensatz Ensembles von jeweils 50 Realisationen gebildet. Dabei wurden den urspruenglichen Datensaetzen mit Hilfe eines Zufallsgenerators normalverteilte „Fehler“ aufgepraegt und dann das Ensemblemittel gebildet. Diese Technik wird auch bei den Anfangswerten der numerischen Wetterprognose verwendet, so dass das Ergebnis der Prognose ein Ensemblemittel +/- einer Abweichung ist. Die Realisation der Pronose eines Ensemblemittels (https://www.ecmwf.int/file/262080/download?token=Aqpmf0CI) geht auf das erste prominente Opfer des Klimatismus zurueck: Henk Tennekes.
Ich habe 1978 Henk Tennekes auf einem 14-taegigen Workshop der NATO-Science School zu „Air-Sea Interactions“ kennengelernt. Im Vergleich zu ihm haben gewisse Herren aus der Naehe von Berlin die Intelligenz eines Kieselsteins.
danke das sie meine persönliche Meinung als wissenschaftliche Aussage auffassen.
Keine ihrer Annahmen ist aber dem Gesagten zu entnehmen, sondern nur ein Produkt ihrer eigenen Vorurteile.
Sie beklagen sich nun, dass die neueren paper die alten Arbeiten nicht mehr zitieren. Aber ist dies nicht normal? Ich habe nachgeschaut: auch die von Ihnen zitierten Klimatologen Oort und Peixoto führen in dem Lehrbuch ‚Physics of Climate‘, 1991 v. Hann oder Süring etc. nicht mehr auf. Was die Berechnung von zonalen oder globalen Mitteltemperaturen angeht, so scheint mir, dass heute einfach nach Sellers gerechnet wird und die Temperaturen nicht auf Meeresniveau reduziert werden, sondern über die Topographie integriert werden und deswegen rund 1 K niedriger liegen als nach den reduzierten Daten im damaligen Verfahren. Durchs global warming haben sich nun in den letzten 100 Jahren die Temperaturen so erhöht, dass es in etwa einer globalen topographischen Absenkung von 1-200 m entspricht, also etwa dem Reduktionsbeitrag und damit scheinbar keine Erwärmung der absoluten Temperatur stattfindet, wenn man die Werte nach unterschiedlichen Verfahren miteinander vergleicht.
Currently: 57.13°F/13.96°C
Deviation: -0.07°F/-0.04°C
Stations processed last hour: 66241
Last station processed: Saltillo, Mexico
Update time: 2020-05-13 02:51:04 UTC
ja was macht er denn der Jakobshavn Isbræ?!?
Eine aktuelle Antwort können Sie hier finden:
https://science.sciencemag.org/content/sci/early/2020/04/29/science.aaz5845/F2.large.jpg
Hier ist die jährliche Eismassenbilanz 2003-2019 auf Grönland dargestellt.
Entnommen aus dieser gerade veröffentlichten Arbeit:
https://science.sciencemag.org/content/early/2020/04/29/science.aaz5845
Wie schon an anderer Stelle diskutiert, allein die Längenänderung ist nicht dier beste Indikator für eine Gletschermassenbilanz.
MfG
Ketterer
http://polarportal.dk/fileadmin/polarportal/surface/SMB_curves_LA_EN_20200501.png
SMB (Surface Mass Balance) ist nicht gleich MB (Massenbilanz).
Mein link war Höhenänderung und entspricht so eher der MB.
https://link.springer.com/article/10.1007/s40641-016-0040-z/figures/1
Ihren ‚Einwurf‘ verwerfe ich somit erst einmal, Herr Schulz. Wennn Sie Belege für Ihre Annahme bringen, können wir gerne weiterdiskutieren.
MfG
Ketterer
damit bestaetigen sie ja nun, dass die Höhenmessung vom Eis nicht ausreichend ist die Eismassenbalanz zu ermitteln.
Oder meinten sie GRACE und die gravitative Auswertung?
Mit ein wenig Grundwissen würde einem auch auffallen, dass die Höhenänderung der Gletscher-Oberfläche 2 bis 3 Größenordnungen über der isostatischen Bewegung liegen. Aus diesen beiden Punkten folgere ich, dass man auch ihren zweiten Einwand getrost bei Seite legen kann.
Nein ich hatte Grace nicht erwähnt. Folgen sie doch einfach dem Link, den ich am 1.Mai um 22:25h gepostet habe.
sie haben recht, GRACE ist nur als Referenz in der Arbeit ausgegeben.
Ich hatte gestern noch ein paar andere Arbeiten offen, eine davon machte den Vergleich mit GRACE Daten.
wenn mein etwas angestaubtes Englisch mich nicht täuscht, basiert das verlinkte Modell auf Satellitenmessungen der Eishöhe, während das dänische Polarportal Messstationen vor Ort betreibt. Hier ergibt sich eine Analogie zu dem durch Satellitenmessungen festgestellten „immer schneller steigenden“ Meeresspiegel, der sich aber an keinem Küstenpegel finden lässt. Eine zentimetergenaue Höhenmessung vom Satelliten aus scheint nicht so einfach zu sein.
Der Jakobshaven-Gletscher hat im unteren Zungenbereich an Dicke zugenommen, nicht insgesamt.
„The bottom line for Jakobshavn is that it is still a major contributor to sea level rise and it continues to lose more ice mass than it’s gaining.“
ist hier zu lesen:
https://climate.nasa.gov/blog/2925/why-a-growing-greenland-glacier-doesnt-mean-good-news-for-global-warming/
Und so schreibt es nature geosciense online; Jakobshavn Isbrae, die größte Quelle für den Verlust von Eismassen aus dem grönländischen Eisschild, ist seit 2016 nach einem jahrzehntelangen Rückzug wieder auf dem Vormarsch und enthüllt eine Analyse der Höhenaltimetrie und Satellitendaten in der Luft. Der Fortschritt fällt mit der regionalen Ozeankühlung zusammen.
Die Frage ist einzig was eine anscheinend anthropogene Erwärmung seit den 1970ern verursacht haben mag. Wie in Abbildung 4 kann man das schon irgendwie mit CO2 zu korrelieren versuchen, doch der Versuch wirkt sehr bemüht. Man stellt einen Aufwärtstrend einem Aufwärtstrend gegenüber, der aber nur in diesem Zeitraum so ungefähr passen könnte. Bis 1970 reicht hingegen die Sonnenaktivität alleine aus, gänzlich ohne zutun von CO2, um den Verlauf zu erklären. Dabei hätte CO2 bei ca. 330ppm bereits die Hälfte des heutigen (zusätzlichen) Strahlungsantriebs leisten müssen.
Während die autonome Erwärmung der Erde ab den 1970ern für CO2 viel zu spät kommt, stimmt sie perfekt mit der Entwicklung des Flugverkehrs überein. Darüber hinaus gibt es diesbezüglich auch eine geographische Übereinstimmung, wie schon bekannt sein dürfte.
Wenn man dann noch weiß, dass CO2 gar keine relevante Erwärmung verursachen kann, Kondensstreifen das aber sehr wohl müssen, dann ist die Geschichte, wie man so schön sagt, „gegessen“.
Sowohl HADCRUT4 als auch Satellitenmessungen (REMSS) zeigen seit etwa 1980 deutlich steilere Temperaturanstiege (Faktor 2) auf der Nordhalbkugel als auf der Südhalbkugel. Dieser deutliche Trend setzt sich gemäß REMSS zu den Polarregionen hin fort: Praktisch Null Anstieg in der Südpolarregion, maximaler Anstieg in der Nordpolarregion. Wohingegen sich das CO2 über den Globus hinweg nur wenig ändert! M.E. steht dies eklatant im Widerspruch zur offiziellen Klimaforschung, wonach das anthropogene CO2 der maßgebliche Temperaturtreiber sei. Es sei denn, es gäbe einen mir bisher unbekannten, globalen Mechanismus, der (im Widerspruch zum 2. Hauptsatz) die Wärme fortlaufend von Süd (kalt) nach Nord (warm) transportiert?? In Frage kommen da wohl eher Wärmeinseleffekte, die es vor allem auf der Nordhalbkugel gibt, sowie ein möglicher Einfluss des Luftverkehrs, ebenfalls schwerpunktmäßig im Norden. Dessen Rückgang infolge Corona müsste dann einen deutlichen Temperaturrückgang in März und vor allem April bewirken – in Kürze werden wir es wissen.
Herr Prof. Lüdecke, was meinen Sie dazu?
Interessant Herr Dr. Ullrich.
Jones resumiert in seiner Arbeit das Folgende:
„average global temperature of 14.0øC (14.6øC in the NH and 13.4øC in the SH)“
Bisher ging ich davon aus, das die Landmassenverteilung die Ursache ist. Jones spezifiziert das nicht weiter.
Er resumiert aber noch was anderes:
“ Annual global surface temperatures warmed by 0.57øC over the period 1861-1997 and by 0.62øC over 1901-1997. Over both periods the warming was slightly greater in the SH than in the NH. “
Demnach waere die SH favourisiert. Eventuell ein Zeichen dafuer, das die Methodik von Jones ueber grossen Wassermassen unbrauchbar ist?!
http://www.remss.com/measurements/upper-air-temperature/
ca. Höhe/m 2.000 3.000 4.000 10.000 17.000 25.000 35.000
N Polar (60,82.5) 0,468 0,280 0,242 0,130 -0,139 -0,676 -0,890
Continental US 0,291 0,236 0,192 0,066 -0246 -0,009 -0,720
N mid-lat (25,60) 0,275 0,232 0,187 0,046 -0,263 -0,121 -0,685
N Hemi (0,82.5) 0,254 0,217 0,176 0,057 -0,235 -0,266 -0,568
Global (-70,82.5) 0,208 0,174 0,137 0,033 -0,225 -0,362 -0,503
Tropics (-25,25) 0,172 0,183 0,145 0,040 -0,236 -0,385 -0,360
S mid-lat (-60,-25) 0,166 0,113 0,083 -0,025 -0,219 -0,485 -0,514
S Hemi (-82.5,0) 0,160 0,130 0,099 0,008 -0,214 -0,458 -0,438
S Polar (-82.5,-60) 0,043 0,016 0,003 0,042 -0,122 -0,317 -0,398
Die Eingabe sieht noch ganz gut aus. Mal schau’n, was das System draus macht…
Was in der Tabelle auch deutlich wird, ist die ausgeprägte Temperaturabnahme mit zunehmender Höhe. Offenbar aufgrund gestiegener IR-Abstrahlung in den Weltraum (und somit mehr Kühlung) aufgrund des vermehrten CO2.
Davon muss man ausgehen!
Trotzdem hat sich bei Roy Spencer seit 1980 der mittlere Temperaturanstieg pro Dekade von 0,13 auf 0,14 Grad C erhöht, was ohne den letzten Rückgang vmtl. um 0,1 Grad höher ausgefallen wäre.
Sehr geehrter Herr Dr. Ullrich,
der Temperaturunterschied zwischen Nord- und Südhalbkugel ist als seesaw (Meeresschaukel) bekannt. Er schankt mit einer Periode von etwa 60 Jahren Länge. Siehe hierzu z.B. Chylek, P., Folland, C. K., Lesins, G., Dubey, M. K., 2010. Twentieth century bipolar seesaw of the Arctic and Antarctic surface air temperatures. Geophysical Research Letters, 37(8), L08703 (Goggle Scholar, dort können Sie den Artikel herunterladen).
Ursache sind vermutlich große Meeres-Oszillationen wie AMO, NAO, PDO, ENSO. Letzte Ursache scheint die Sonnenaktivität zu sein (Sonnenmagnetfeld). Sicheres ist aber bislang unbekannt.
MfG
Lüdecke
Die Autoren begründen zwar ihre Wahl für 11 year averages und 17 year averages, geben aber keine Vergleichsmöglichkeit der levels für z.B. 13 oder 19 year averages. Hat Jemand die Daten aus dem Paper und kann was dazu sagen? bin an Muster anstatt dem statistischen Plattklopfen durch Statistik, von gegenläufigen (z.B. Sonne/Mond bei 48 Jahren) Anomalien interessiert. TIA
https://judithcurry.com/2020/05/02/week-in-review-climate-science-edition-2/#more-26073
Kang 2020 Why Does Ocean Warming Pattern Matter?
https://agupubs.onlinelibrary.wiley.com/doi/pdf/10.1029/2019AV000130
Rathore 2020 Recent hemispheric asymmetry in global ocean warming induced by climate change and internal variability
https://www.nature.com/articles/s41467-020-15754-3.pdf
Wahrscheinlich hängt mit dieser Meeresschaukel auch der periodische Rückgang des arktischen Meereises zusammen, der in größeren Zeitabständen immer wieder aufzutreten scheint – früher noch ohne anthropogenem CO2.
Wenn es sich allerdings um periodische Vorgänge handelt, was letztlich auch für den Einfluss der Sonne gilt, dann bleibt vor allem die interessante Frage, wie und ob sich der längerfristige globale Temperaturmittelwert verändert! Und welchen Anteil daran hat dann das anthropogene CO2… Aber erstmal die empfohlene Literatur – vielen Dank dafür!
Dazu zwei Bemerkungen: erstens, wo kann man diese Definition in ihrem vollständigen Wortlaut nachlesen?
Und zweitens, wenn man so eine Umrechnung macht, hängt der Korrekturwert einmal von der geographischen Breite ab und weiters von der Luftfeuchtigkeit bei gegebener Seehöhe.
Die Breitengradabhängigkeit geht von ca. -23°C am Nordpol bis zu +26°C am Äquator, wobei hier auch noch der Kalender eine Rolle spielen dürfte. Bei sehr trockener Luft rechnet man gem. Literatur bis zu -0,9°C pro 100 m Seehöhe, bei normal feuchter aber nur ca. -0,6°C pro 100 m. Bei Inversionslagen kann es aber auch umgekehrt sein. Alleine diese Varianz der Basiswerte verhindert eine exakte Angabe von Anomalien auf 2 Nachkommastellen, wie es häufig gemacht wird.
Dazu kommt natürlich die minimale Flächenabdeckung der frühen Erfassungen. Und dann kommt noch die Frage, was bedeutet ein globaler Mittelwert für eine Region?
Momentan wird berichtet, daß sich die globale Erhöhung von ca. 1°C z. B. im Alpenraum mit bis zu +4°C bemerkbar macht. Eine Globalangabe ist daher für lokale Klimata offenbar wenig aussagekräftig.
Man muß sich mit dem Klimablödsinn aufgrund obiger Aussage nicht weiter beschäftigen. Selbst in Deutschland gab es erst ab dem Deutschen Reich ab 1880 beginnend vereinheitlichte Meßreihen.
Und auf den Ozeanen wurde ohnehin selbst bis in die 70er Jahre des letzten Jahrhunderts nicht einheitlich gemessen. Unsereiner hat das Mitte der 70er für ein paar Wochen von Äquatornähe bis zum Nordkap selbst gemacht. Damals mußten alle Meßschiffe von GATE zur Meteor und ihre Meßeinrichtungen vergleichen, damit die dann keine technisch bedingten Abweichungen voneinander hatten.
Und damit dürfte klar sein, daß es keine soliden Messungen vor Beginn der Satellitenära gibt.
Kaum bin ich mal neugierig, habe Zeit und will mir was ansehen.
https://www.scirp.org/journal/cta.aspx?paperid=98786.
This page is being maintained. Please try again later.
Scientific Research Publishing Inc
Goto HomePage>>
https://www.researchgate.net/publication/339819293_Meridional_Distributions_of_Historical_Zonal_Averages_and_Their_Use_to_Quantify_the_Global_and_Spheroidal_Mean_Near-Surface_Temperature_of_the_Terrestrial_Atmosphere/link/5e6788774585153fb3d1ffae/download
Es freut mich, dass Ihnen das aufgefallen ist. Der Kommenar war nicht von mir, es scheint jetzt einen zweiten Kommentator mit meinem Namen zu geben (oder jemand wollte sich für mich ausgeben, was ich nicht hoffe).
Da der angegebene Link prima funktioniert, wenn man das Satzzeichen beachtet und weglässt, ist eigentlich kein recherchieren nötig.
So wie sie sich in der Diskussion geben, hatten sie ein Interesse die Arbeit von Herrn Dr. Kramm anzubringen.
Umso erstaunlicher, dass sie nicht mal zugeben können, dass sie einen Punkt übersehen haben.
Wie einfach wäre das gewesen! Und nun kommen sie mit dieser Ausrede! Das lässt tief blicken.
Das „nun“ war vor 12 Tagen und es war mein allererster Kommentar zu diesem Artikel. Ob der von mir oder jemand anderem war, kann nur jemand klären, der Zugriff auf die angegebenen eMail-Adressen hat. Da es keinen weiteren Kommentar des Nutzers gegeben hat, würde ich das inzwischen sogar begrüssen, wenn der Admin feststellen könnte, dass der Kommentar nicht mir war.
sie sagen doch gerade das es ihr erster Kommentar war.
Ist doch nicht schlimm einen Punkt zu übersehen? Schwamm drüber! Der Einzige den es jetzt noch interessiert sind sie!
Nett formuliert, so dass man denke könnte, ich hätte eingeräumt, der von Ihnen referenzierte Kommentar vom sei von „Marvin Müller 1. Mai 2020 um 10:52“ sei von mir gewesen. Aber auch etwas billig und nur zum rumtrollen geeignet.
Und weil ich der einzige bin, den das interessiert, kramen Sie den Kommentar nach 12 Tagen nochmal raus? Es ist gut geeignet zum trollen und Sie hatten Erfolg. Gönne ich ihnen …
Lieber Gruss!
Faulheit ist wohl auch eine Art besonderer Recherchequalität.
Nicht umsonst wird so viel Titel angegeben, dass google problemlos einen Link (so einer noch vorhanden ist) findet. Dass Links öfters schon nach Tagen „verschwinden“, kennen Sie wohl nicht.
Und welche Ansprüche stellen Sie an die Artikel, welche mit viel Aufwand kostenlos von Engagierten eingestellt werden. Perfektion, die nicht einmal mehr der zu bezahlende Mainstream bietet? Reicht Ihnen der Inhalt nicht.
Ich bin Martin Müller und habe lediglich versucht, Herrn Marvin Müller zu helfen. (Zufällige Namensähnlichkeit.)
Kurz Uebersetzt, keine Aenderung in den letzten 100 Jahren.
Kann man auch hier gucken:
http://temperature.global/
Heute:
The Earth’s Temperature
Currently: 57.15°F/13.97°C
Deviation: -0.05°F/-0.03°C
Stations processed last hour: 68622
Last station processed: Rajasansi, India
Update time: 2020-05-01 12:52:46 UTC
Ja, aber muss man nicht auch beachten, was sich nicht geändert hat?
Nicht die globalen Temperaturen, sondern der Vergleich der mit den beiden verschiedenen Verfahren ermittelten Temperaturen.
Ich lese da also, dass seit 100 Jahren beide Verfahren dieselben Mittelwerte liefern, also gleichwertig sind.
Dass sich die absoluten Temperaturwerte nicht verändert haben in 100 Jahren, steht da nicht. Wäre auch ein überraschendes Ergebnis, weil auf den 40 Seiten des Papers nirgends Temperaturtrends von Zeitreihen berechnet worden sind.
„Kann man auch hier gucken:“
Ich habe hier geguckt, da stehen aber nur die Temperaturmittel der letzten 5 Jahre. Und daraus können Sie auf die Temperaturänderung der letzten 100 Jahre schließen?
Mir scheint, Sie denken überaus oberflächlich.
dann habe ich fuer sie nicht mitgedacht!
Sie finden die Absoluttemperaturen in der Arbeit. Ich habe oberflaechlich behauptet, das es keine Aenderung gibt. Natuerlich ist das so nicht haltbar, da es ueber ein Grad Differenz gibt, die man nicht einfach unter den Tisch wischen sollte.
Ich vertraue den heute gemessenene,gemittelten und unter http://temperature.global/ pubilzierten Temperaturen und insofern ist es also ein Grad zu kalt! Ich schaetze mal das die Homogenisierung der Daten das bereinigen koennte!
Heute sind es uebrigens:
The Earth’s Temperature
Currently: 57.17°F/13.98°C
Deviation: -0.03°F/-0.02°C
Stations processed last hour: 59105
Last station processed: Watsonville, United States
Update time: 2020-05-03 16:25:39 UTC
Ich sehe, dass Sie sehr misstrauisch sind, was Homogenisierung angeht. Ok, dann nehmen Sie halt den BEST-Datensatz, dort werden die Rohdaten ohne Homogenisierung verarbeitet.
Können Sie mir erklären warum die Global-Temperatur seit einem Monat konstant 13,98 °C ist? Es ist doch bekannt, dass die Global-Temperatur sich saisonal ändert. Am niedrigsten ist sie im Januar (ca. 14 °C) und am höchsten im Juli (ca.17 °C). Ursache ist der unterschiedliche Oberflächen-Anteil der Ozeane auf den beiden Halbkugeln Nord bzw. Süd.
Man sollte immer den Besten Datensatz nehmen!
So weit mir bekannt ist setzt das BEST-Team auf ein anderes Verfahren, das Kriging genannt wird!
Die angegebene Webseite verwendet, seit dem Beginn die gleichen Datenquellen und eine wichtige Methode, Rohdaten! Also sind die Werte in sich recht aussagefaehig. Schauen sie mal auf die Varianz seit 2016.
Die vielgepriesene Globale Erwaermung kann man hier nicht unbedingt rauslesen.
Herr Berberich,
„Können Sie mir erklären warum die Global-Temperatur seit einem Monat konstant 13,98 °C ist? Es ist doch bekannt, dass die Global-Temperatur sich saisonal ändert. Am niedrigsten ist sie im Januar (ca. 14 °C) und am höchsten im Juli (ca.17 °C). Ursache ist der unterschiedliche Oberflächen-Anteil der Ozeane auf den beiden Halbkugeln Nord bzw. Süd.“
Offensichtlich halten sich die Temperaturen nicht an diese Regeln. Unter Umstaenden ueberlagern andere klimatische Faktoren diese Fluktuationen.
Wir sehen ja nur ungefaehr 5 Jahre und wir sehen unadjustierte Daten.
„Ich vertraue den heute gemessenene,gemittelten und unter http://temperature.global/ pubilzierten Temperaturen und insofern ist es also ein Grad zu kalt! Ich schaetze mal das die Homogenisierung der Daten das bereinigen koennte!“
belegt also nur Ihre abgrundtiefe Inkompetenz.
Unter der Leitung von Wilhelm von Bezold wurden die meteorologischen Messnetze in Bayern und Preussen aufgebaut. Wollen Sie von Bezold unterstellen, er haette nicht gewusst, was er treibt? Die Arbeiten, die von Bezold zur Thermodynamik der Atmosphaere publiziert hat, belegen seine Kompetenz. Von ihm stammt auch der Begriff der potentiellen Temperatur, die sowohl in der Meteorologie als auch in der Ozeanographie verwendet wird.
kann es sein das ihr Fachwissen die Hoefflichkeit verdraengt hat?
Sie sollten nur einmal versuchen zu verstehen, was die andere Seite sagt. Auch die hat Argumente!
An keiner Stelle habe ich etwas Gegenteiliges zu den Altvorderen gesagt. Ehrlich gesagt kenne ich Herr Bezold nicht, aber ich werde es mir anlesen.
Ich habe lediglich Temperature.global erwaehnt und gesagt, das man jedwede Differnz von dem gewuenschten Ergebnis durch Homogenisierung der Daten erhalten kann.
Diese Anspielung auf die Verfahren der Klimafolgenforscher duerfen sie mir verzeihen, weil ich sie in mit diesem Wissenstum nicht in Verbindung bringe.
Jetzt muss ich erst mal Bezold lesen.
mfg Werner
… Die medienwirksamsten Opfer des Klimawandels sind angeblich die Gletscher, immer wieder ist das Abschmelzen der Gletscher Gegenstand umfassender Berichte in den Medien über den Klimawandel. Gletscher; diese Eisriesen, haben für mich das gleiche mystische Potential wie Eisbären. Wenn man ihr dauerhaftes Verschwinden – und historisches verschweigt; androht, kann man Aufmerksamkeit erregen. Die Schwankungen der Gletscher in den vergangenen Jahrhunderten konnten in den letzten Jahrzehnten gut erforscht werden. Ja, es werden sich immer Gletscher auf der Erde auf dem Rückzug befinden, schmelzen Jahr für Jahr immer weiter zurück. Aber; und das ist wichtig hervorzuheben, denn Fakt ist – dass schon vor 1820 der weltweite Rückzug der Gletscher begann. Die Eis- und Gletscherschmelze sind und bleiben Bestandteil der Erdgeschichte …
Noch größere Kopfschmerzen bereitet jedoch der Blick zurück in die Klimageschichte der letzten Jahrtausende. Bereits in früheren Beiträgen, die von den „Klimafolgenforschern“ nicht ernst genommen werden, wurde von seriösen Forschern darauf hingewiesen, dass die Alpengletscher auch in den früheren Wärmeperioden signifikant abschmolzen. Die Schmelzphasen während der „Mittelalterlichen Warmzeit vor 1000 Jahren sowie der römischen Wärmeperiode vor 2000 Jahren sind mittlerweile gut dokumentiert.
Bereits 2014 erschien in den Quarternary Science die Studie der Forscher um Anaëlle Simonneau von der französischen Universite Orleans, in der die Gletscherbewegungen der letzten Jahrtausende rekonstruiert wurden. Der Blick zurück in die reale Klimageschichte entlarvt die Alpenalarmgeschichten schnell als Sturm im Wasserglas. Es ist „Alles schon einmal dagewesen“. Ganz offensichtlich haben die Klima – Kreationisten ( IPCC und PIK-Asse ) als Betreiber der Panikmache den ungetrübten Blick in die vorindustrielle klimatische Vergangenheit ( vor 1820 ) versäumt … Satire; auch die Erde hat ihr „Klimakterium“ … ist nicht von der Realität zu verdrängen.
Wie lange kommen die Panikmacher noch damit durch, ohne dass sich aus der seriösen Wissenschaft ernsthafter Widerstand regt? Ich weise daraufhin, dass ich kein Wissenschaftler bin, und meine Meinung aufgrund 3 jähriger Recherchen bekannt gebe. Sehr hilfreich waren alte Physikarbeiten befreundeter Menschen, scheinbar haben sich die physikalischen Naturgesetze in den letzten Jahrzehnten einer neuen Wissenschaft, Klimawissenschaft – was immer das auch sein soll, unterworfen. Das ist für viele normal denkende „Skeptiker“ inakzeptabel, ja; verwerflich …!
116
Wie klingt diese Horrornachricht? „In den Regionen um den Polarkreis hat ein bemerkenswerter Klimawandel stattgefunden“ heißt es in einem für jeden zugänglichen Schreiben, der britischen Akademie der Wissenschaften – The Royal Society – … Mehr als 2000 Quadratmeilen Eisfläche zwischen 74° und 80° nördlicher Breite, die bislang die Grönlandsee bedeckten, sind in den letzten 2 Jahren vollkommen verschwunden. Die Kälte, die das Gebiet für Jahrhunderte in einen undurchdringlichen Eispanzer verwandelt habe, sei offenbar in kürzester Zeit höheren Temperaturen gewichen. Auch in Zentraleuropa registriert der Bericht alarmierende Zeichen für eine rasche, unerklärbare Klimaerwärmung. Alle Flüsse, die im Alpenmassiv entspringen, haben aufgrund der abgetauten Schnee- und Gletscher – Wasser weite Regionen überschwemmt. Interessant und aussagekräftig ist in diesem Zusammenhang auch die Forschung von Professor Schlüchter von der Universität Zürich von 2019 … googeln sie.
Dieses von mir zitierte Schreiben wurde am 20. November 1817 verfasst. der Präsident der Royal Society schickte es der britischen Admiralität, mit der Bitte um Entsendung eines Schiffes. Die Wissenschaft sollte den dramatischen Klimaumschwung im Nordmeer erforschen. Auch in der Schweiz war das Klima in jenen Jahren nicht so, wie es sein sollte. Die Bauern litten unter schlechten Sommern. Nach Ansicht vieler Eidgenossen war daran die technische Zivilisation schuld; Aufgebrachte Bürger rissen Blitzableiter von den Häusern herunter. AM 9.Juli 1818 berichtete die Neue Zürcher Zeitung über zahlreiche Fälle von Vandalismus an den als Unheilsbringer verdächtigten Wetterablenker …
117
Wirklich überproportional erhitzt haben sich die Gemüter. Der Klimawandel ist der Dreh- und Angelpunkt der gesamten Klimatologie. Vielen Klimaaktivisten gilt der Treibhauseffekt als teuflischste Gefahr seit der Atombombe – Kohlenstoffdioxid wird nun als der neue verdächtige Wetterablenker zum Unheilsbringer der modernen Wissenschaften.
Bleibt anzumerken, dass sich in der Oberfläche des Meeres schneller neueres Eis bildet, als erwartet. Das als Eisbrecher gebaute norwegische Forschungsschiff „Kronprins Haakon“ war daher im Juli 2019 gezwungen, nördlich von Spitzbergen umzukehren, nachdem es trotz gewaltiger Eisschmelze auf wesentlich dickeres Eis – als erwartet; gestoßen war.
Wie war es im Jahr 2013? Glauben sie, dass die 22 Boote, die im Arktiseis gefangen waren, einen Anspruch gegen die „Klimawissenschaft“ hatten, die diesen Sommer in Panik eine offene Arktis vorhergesagt hatten?
Die grüne Idiotologie lässt sich doch von der Realität nicht die Ideologie überhitzen. Das dicke Eis ist daher die Folge und ein Beweis für den Klimawandel. Nicht dass diese Meldungen „Klimalügenforscherschiff“ bleibt im dicken Eis von Arktis stecken, fast jedes Jahr kommen … das wäre ja fürchterlich! Da brauchen wir dann eine polare Eis-Steuer, am besten als planetarer Notfall auf die Rohform Wasser.
Wie man sieht, die echte Welt ist doch offensichtlich anders, als die simulierte. Also muss die Simulation irgendwie falsch sein. Liegt mit Sicherheit am ideologischen Kern der Wissenschaft.
Falsch; die Klimawissenschaft des IPCC und der PIK-Asse sagt: Die Realität muss sich an die Modelle anpassen, das Modell ist der Plan und an den muss man sich halten. Hat bis heute zwar in keiner Planwirtschaft funktioniert, aber das ist den Klimaforschern egal.
Welche Szenarien bleiben denn den Klima-Kreationisten für den Fall einer neuen Klimaabkühlung? Werden dann die Wälder angezündet damit es schnuckelig warm bleibt?
… das ist ein Auszug aus meinen Recherchen (…)
Einen Spruch habe ich irgendwo gelesen: „Die Theorie bildet die Realität nicht ab, Pech für die Realität“
Dank aber auch vor allem an Herrn Prof. Lüdecke, der sich viel Mühe (in der Freizeit ) gemacht hat.
Ich habe den Spruch etwas anders gelesen; „die Theorie erweitert nicht nur die Wahrheit, sondern auch die Realität … Und Paul claudel: Die Wahrheit hat nichts zu tun mit der Zahl der Menschen, die von ihr überzeugt sind.
Mir gefallen ihre Kommentare auf EIKE .. weiter so.
Es reicht die Wälder abzuholzen und neue Windquirle aufzustellen
Auch in der Arktis, in den Rockies und der West Küste der USA,…
MfG
Ketterer
Sie haben den den Jakobshaven-Gletscher auf Grönland vergessen….., oh wait.
Auch wenn es bei unveränderter Temperatur gleichbleibend warm bleibt, kann es viele Jahre dauern, bis die Gletscher wieder im Gleichgewicht sind.