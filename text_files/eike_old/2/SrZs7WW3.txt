Die Autorin der Studie, die bedeutende amerikanische Klimatologin Prof. Judith Curry erklärt, dass der Klimaalarm auf hoch komplexen Computer-Simulationen des Klimas der Erde beruht.
Aber obwohl Wissenschaftler sich seit Jahrzehnten mit der Entwicklung derselben befasst haben, müssen diese Simulationen immer noch „frisiert“ werden, um sie dem realen Klima anzupassen. Dies macht sie im Wesentlichen unbrauchbar für den Versuch herauszufinden, was Änderungen des Klimas verursacht, und es macht sie unzuverlässig für Prophezeiungen, was in der Zukunft passieren wird.
Prof. Curry: „Es ist nicht nur die Tatsache, dass Klimasimulationen frisiert werden müssen, die problematisch ist. Es kann gut sein, dass es unmöglich ist, langfristige Prophezeiungen über das Klima zu erstellen – es ist schließlich ein chaotisches System. Falls das der Fall ist, dann versuchen wir möglicherweise, die globale Ökonomie für nichts und wieder nichts umzukrempeln“.
Prof. Curry kündigte kürzlich an, dass sie ihre akademische Laufbahn aufgegeben habe infolge von Angriffen auf ihre Forschungen und dem „Idiotismus“ [craziness] der Klimadebatte.
Einschub des Übersetzers: Das gesamte PDF steht hier . Die ,Executive Summary‘ lautet [Ende Einschub]:
Executive Summary
Es gibt eine große Debatte über Genauigkeit und Brauchbarkeit von globalen Klimamodellen (GCMs). Diese Debatte findet innerhalb der Gemeinschaft der Klimawissenschaftler statt, die sich über das Gewicht uneinig sind, welches man Computermodellen relativ zu Beobachtungen beimessen sollte. GCM-Outputs werden auch von Ökonomen, Gesetzgebern und Politikern herangezogen, weshalb die Modelle Gegenstand sehr genauer Überprüfungen seitens einer größeren Gemeinschaft von Wissenschaftlern, Ingenieuren, Software-Experten und Wissenschaftsphilosophen waren und sind. Dieser Report versucht, die Debatte um die GCMs zu beschreiben für eine gebildete, aber nicht technisch bewanderte Zuhörerschaft.
Schlüsselpunkte der Summary:
● GCMs wurden niemals einer rigorosen Verifikation und Validierung unterzogen, welche jedoch die Norm sind im Ingenieurswesen und in der behördlichen Wissenschaft.
● Es gibt wohlbegründete Bedenken hinsichtlich eines fundamentalen Fehlens von Vorhersagbarkeit im komplexen, nicht linearen Klimasystem.
● Es gibt zahlreiche Argumente, die die Schlussfolgerung stützen, der zufolge Klimamodelle nicht geeignet sind für das Ziel, den Anteil der Erwärmung des 20. Jahrhunderts mit hoher Sicherheit zu identifizieren, der im Gegensatz zu natürlichen Kräften anthropogenen Ursachen zuzuschreiben ist.
● Es gibt immer mehr Beweise dafür, dass Klimamodelle viel zu viel Erwärmung prophezeien infolge des steigenden atmosphärischen CO2-Gehaltes.
● Die Ergebnisse der Klimamodell-Simulationen für das 21. Jahrhundert, wie sie vom IPCC bekannt gegeben werden, enthalten nicht entscheidende Elemente der Klimavariabilität und sind daher wenig nützlich für Projektionen, wie sich das Klima im 21. Jahrhundert tatsächlich entwickeln wird.
Klimamodelle sind nützliche Utensilien für die Durchführung wissenschaftlicher Forschungen, um das Klimasystem besser zu verstehen. Allerdings führen die oben genannten Punkte zu der Schlussfolgerung, dass die gegenwärtigen GCMs nicht geeignet sind, um die Gründe der Erwärmung des 20. Jahrhunderts anzugeben oder die Vorhersage globaler oder regionaler Klimaänderungen im Zeitmaßstab von Jahrzehnten bis Jahrhunderten vorzunehmen, mit welch hohem Niveau von Vertrauen auch immer. Übertragen bedeutet dies, dass sie keineswegs herangezogen werden sollten für politische Entscheidungen, die die Sozial-, Ökonomie- oder Energiesysteme der Erde fundamental verändern. Es ist diese Anwendung der Ergebnisse von Klimamodellen, welche die Lautstärke der Debatte um Klimamodelle befeuern.
Hier folgt jetzt noch die Zusammenfassung am Schluss der Studie:
Summary
Es gibt immer mehr Beweise, dass Klimamodelle viel zu warm ausfallen und dass die Klimasensitivität bzgl. Kohlendioxid am untersten Rand der vom IPCC angegebenen Bandbreite liegt. Nichtsdestotrotz wird diesen niedrigeren Werten der Klimasensitivität in den IPCC-Klimamodell-Projektionen bis zum Ende des 21. Jahrhunderts oder bei Schätzungen der Reduktion von CO2-Emissionen auf die Temperatur in keiner Weise Rechnung getragen. Die IPCC-Klimamodell-Simulationen konzentrieren sich auf die Reaktionen des Klimas bei verschiedenen Emissions-Szenarien. In den Klimamodell-Projektionen für das 21. Jahrhundert sind nicht enthalten:
● Eine Bandbreite von Szenarien bzgl. vulkanischer Eruptionen (die Modelle nehmen an, dass die vulkanische Aktivität im 21. Jahrhundert mit derjenigen im 20. Jahrhundert vergleichbar ist, obwohl die Aktivität in Letzterem deutlich geringer war als im 19. Jahrhundert).
● Ein mögliches Szenario solarer Abkühlung analog dem solaren Minimum, welches von russischen Wissenschaftlern vorhergesagt wird.
● Die Möglichkeit, dass die Klimasensitivität um einen Faktor zwei niedriger ist als von den meisten Klimamodellen simuliert.
● Realistische Simulationen von Phase und Amplitude der natürlichen internen Klimavariabilität im Zeitmaßstab von Jahrzehnten und Jahrhunderten.
Die Gemeinschaft der Klima-Modellierer konzentrierte sich auf die Reaktion des Klimas auf vom Menschen verursachte Emissionen, und die politische Gemeinschaft akzeptiert (entweder explizit oder implizit) die Ergebnisse der Simulationen für das 21. Jahrhundert als tatsächliche Prophezeiungen. Folglich fehlt uns bislang ein gutes Verständnis der relativen Klimaauswirkungen auf die oben genannten Parameter oder dessen potentielle Auswirkungen auf die Entwicklung des Klimas im 21. Jahrhunderts.
Übersetzt von Chris Frey EIKE
1. Wenn das Wasser und Eis der Atmosphäre nicht Wärmestrahlung emittieren „würde“, „würden“ es das Wasser der Ozeane, das Eis der Polarzonen und Berge (und sonstige Materie) an der Erdoberfläche ganz sicher auch nicht tun.
2. Sind 5800K nicht „etwa“ 6000K?
3. Physik studiert habe ich an den Universitäten in Jena und Frankfurt am Main.
Sie haben richtig erkannt, dass die Temperatur der Erde auf etwa 6000K ansteigen würde, wenn Eis und Wasser der Atmosphäre den gewandelten solaren Energiefluss nur sammeln und nicht als Wärmestrahlung in den Weltraum emittieren würden.
Erde strahlt im atmosphärischen Fenster [Strahlung aus der Atmosphäre hatten Sie ja ausgeschlossen] und kommt dennoch auf 6000K ?!?!?!?
Wo haben Sie denn Physik studiert? Egal wie mehr als ca. 5800K geht nicht.
Trotzdem sollen angeblich mathematische Modelle Prognosen von Klimaveränderungen liefern. – Auch das gelingt bekanntlich nicht. –
Das hat u. a. folgende Ursache:
Grundlage für den jeweiligen Zustand der Materie im menschlichen Lebensraum ist primär Größe und räumliche Verteilung ihrer Enthalpie. (Sie folgt der variablen Intensität des absorbierten Anteils solaren Energieflusses und der Zeitdauer seines Durchlaufs bis zur Emission als Wärmestrahlung in den Weltraum. Überwiegend emittieren Wasser und Eis diese Wärmestrahlung aus der Atmosphäre. Ihre Intensität folgt lokal der 4. Potenz ihrer Temperatur. Es resultiert eine entsprechend schwankenden Energiebilanz der Erde.)
Die Temperatur korreliert über unterschiedlichen Zustandsgleichungen mit der Enthalpie der Materie. Als Folge ist der Zusammenhang zwischen der Enthalpie der Materie in einem Raumelement und ihrer mittleren Temperatur gewöhnlich vieldeutig!!!! – Jeder Versuch einer deterministischen Beschreibung mit Hilfe mathematischer Modelle geht daher – wie auch empirisch bewiesen – ins Leere!
Ihr Kommentar enthielt jede Menge Steuerzeichen. Bitte anderen Texteditor verwenden.
was Sie immer mit den „Wärmestrahlen“ von Wasser und Eis argumentieren???
Bitte vergessen Sie nicht, dass die Erde nur ein passiver (Rück-)Strahler ist, die Energiequelle dafür ist doch die Sonne
und die Wolken sind nun mal dazwischen,
deshalb KÜHLT das Wasser die Erdoberfläche!
Kann man messen: http://tinyurl.com/ns3jeha
Warum einfach, wenn es kompliziert geht?
Das System hat schlichtweg zu viele Freiheitsgrade.
Gleich nach Erscheinen dieses Pamphlets ’study‘ habe ich Prof. Judith A. Curry in einer E-Mail gefragt welche Ursache sie veranlasst hat herauszufinden dass Modellrechnung und Realität verschiedener nicht sein können. Das ging im CC auch gleich an GWPF, und deren Direktor Dr. Benny Peiser hat mir bereits eine E-Mail Lesebestätigung zukommen lassen.
In meiner Anfrage habe ich Prof. Judith A. Curry deutlich gemacht dass jeder Doktorand der Computer Sciences dasselbe herausfindet (sonst wäre er/sie kein Doktorand) und auf die Errungenschaften der Computer Sciences, von der Umsetzung von ersten, vorgeprüften Spezifikationen bis hin zur Verifikation und Validierung der errechneten Resultate hingewiesen, auch darauf dass die Computer Sciences Community nicht davor zurückschreckt ihre bisher unlösbaren Problemklassen zu veröffentlichen und zu lehren.
Zu meiner Überraschung (nicht wirklich) besteht die Antwort von Prof. Judith A. Curry bis zum jetzigen Zeitpunkt aus dem Geräusch von crickets.
P.S. liebe Chaos Amateure, kommt mir jetzt bloss nicht mit dem Abtippen von akademisierten Verabredungen: ein Chaos ist deshalb chaotisch weil es sich chaotisch von jedem anderen Chaos unterscheidet, das kann kein Computer simulieren oder approximieren — sonst wäre er kein Computer sondern ein Universum.
Es kommt darauf an, welches Ergebnis man mit welcher Fehlermarge benötigt. Der Pilot, der mit einem A340 von Miami nach Hamburg fliegt, möchte nur wissen, ob da zur voraussichtlichen Landezeit kein Crosswind mit Orkanstärke für die 23 herrschen wird. Der Pilot mit Flug nach VFR will wissen, ob unterwegs und am Zielort bestimmte Grenzen nicht unterschritten werden, also Wolkenuntergrenze wegen der vielen Windmühlen nicht unter 1000 Fuß und die Sichtweite über 5 km. Regen und Vereisungsbedingungen sollen auch nicht herrschen.
Was will der „Klimaforscher“ wissen, der die Kosten eines Klimawandels (natürlich oder menschengemacht) berechnen will? Der will wissen ob die Statistik stimmt. Klima ist ja ein statistischer Begriff wie die Kennzahlen eines Unternehmens, welche die Aktienkäufer und -inhaber gerne wissen wollen.
Deshalb ist ein GCM dann validiert, wenn es für die Vergangenheit lokale Kennzahlen statistisch korrekt wiedergegeben hat.
Das allerdings können die GCM derzeit noch nicht.
Das Klima ist reel! Die Simulation virtuell!
Es ist schlicht und einfach Irssin zu glauben, dass alles, was seitdem Urknall passiert ist und mehr oder weniger das schwankende Klima beeinflusst, zwar ohne das exakte Wissen dazu in der ganzen Komplexität letztendlich haargenau in einem im Vergleich zu Natur sehr simplen Computerprogramm wiedergegeben wird.
Simulationen funktionieren letztendlich IMMER nur befriedigend im ständigen Vergleich mit der Wirklichkeit. Beim wetter täglich sichtbar: Die Simulatione, die das Wetter 2 Wochen im Voraus berechnet, hat wenig mit der Wirklichkeit zu tun und eine übliche 90% Trefferquote wird nicht erwartet. Innerhlab der 2 Wochen werden ständig berechnete Werte durch reel gemessene ersetzt und somit kommt man ständig der Wirklichkeit näher.
Klimasimulationen bleiben ohne Vergleich mit der Wirklichkeit eben reine Spekulation. Die abbildung der Verghangenheit ändert daran nichts. Die Programmierer hatten die Aufgabe, einen bekannten Verlauf nachzubilden. Eine simple Nachbildung bedeutet nicht, dass in der Simulation die gleichen naturkräfte wirken, sondern dass der Programmierer das gemacht hat, was von ihm erwartet wird.
Mit dem gesunden Menschenverstand muss man soweit beurteilen können, dass die reele Natur und Simulationen nicht gleichgesetzt werden können. Wenn dabei nicht exakt wissenschaftlich bewiesene Zusammenhänge und zum teil Vermutungen einprogrammiert werden und keine Möglichkeit der Kontrolle besteht (Klima ist der Wetterdurchschnitt von min 30 Jahre), dann ist es eigentlich lächerlich, das Ganze als wissenschaftliche Grundlage zu betrachten.