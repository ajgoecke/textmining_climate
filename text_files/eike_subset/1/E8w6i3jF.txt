Abstract
In dieser Studie geht es um die Beziehungen zwischen der Temperatur an der Erdoberfläche von 1850 bis heute und den langfristigen Temperatur-Prophezeiungen globaler Erwärmung. Eine entscheidende Komponente dieser Analyse ist die Berechnung des Verlaufs der Erwärmung. Die Berechnung entfernt aus den aufgezeichneten Daten Fehler bei den Temperaturmessungen und -fluktuationen infolge kurzfristiger Wetterereignisse. Die Ergebnisse zeigen, dass die mittlere Erwärmungsrate an der Erdoberfläche über die letzten 170 Jahre weniger als 0,07°C pro Dekade beträgt. Die Erwärmungsrate an der Erdoberfläche korreliert nicht mit der Rate der Zunahme von CO2 durch Emissionen fossiler Treibstoffe. Die eingebildete Bedrohung exzessiver zukünftiger Temperaturen könnte aus der Falschinterpretation von 40 Jahren zunehmender Intensität des Klimatreibers ENSO im östlichen Pazifik resultieren. Die ENSO-Aktivität erreichte im Jahre 2016 mit der höchsten jemals aufgezeichneten Temperatur-Anomalie. Die Erwärmungsrate der Erdoberfläche ist seit dem Jahr 2006 um 41 Prozent gesunken.
Abschnitt 1 – Introduction
Die Ergebnisse dieser Studie zeigen, dass die gegenwärtige Bewegung zur Abschwächung der globalen Erwärmung voreilig sein kann. Sowohl die höchsten Wärmeströmungen, die jemals im östlichen Pazifik aufgezeichnet worden waren, als auch technologisch fortgeschrittene Verfahren zur Messung der Ozean-Temperaturen begannen zufällig beide Ende der 1970er Jahre. Diese Studie beschreibt, wie beides zusammen gespielt haben könnte, um zu langfristigen Temperatur-Prophezeiungen zu führen, die zu hoch sind.
Monatliche Temperatur-Anomalien von HadCRUT4
Für diese Analyse wurden sowohl die Version HadCRUT4.6.0.0 monatlicher globaler Zeitreihen von Temperatur-Anomalien herangezogen als auch der NASA-Datensatz des Goddard Institute for Space Studies der globalen mittleren jährliche Land- und Wassertemperatur-Anomalien von 1880 bis 2018. Die Ergebnisse gleichen sich im Wesentlichen. Danach wurde mit den HadCRUT4-Daten gearbeitet, weil die Zeitreihe länger ist und weil die monatlichen globalen Temperatur-Anomalien leichter nach Excel transferiert werden können.
Erst während der letzten Jahre haben hoch auflösende Satelliten gleichzeitig gemessene Daten vom Festland, dem Ozean und der Atmosphäre erfasst (Palmer, P.I. 2018). Die Satelliten NOAA-6 und NOAA-7 wurden im Dezember 1979 bzw. im Jahre 1981 gestartet. Beide waren mit speziellen Mikrowellen-Sensoren ausgestattet, um präzise Anomalien der Wassertemperatur im Gebiet des Ostpazifik und in den ENSO-Regionen zu messen (Spencer et al. 1990).
Die ersten Analysen der hoch aufgelösten Satellitendaten zeigten ein bemerkenswertes Ergebnis. Spencer et al. (1990) folgerten daraus: „Der Zeitraum der Analyse (1979 bis 1984) zeigt, dass die nord- und südhemisphärischen troposphärischen Temperatur-Anomalien (aus dem sechs-Jahre-Mittel) in längerzeitlichen Maßstäben positiv und über kürzere Zeiträume negativ korrelieren. Die ENSO von 1983 dominiert die Aufzeichnung, wobei die Anfang 1983 zonal gemittelten Temperaturen in den Tropen bis zu 0,6°C über dem Mittelwert der verbleibenden Jahre lagen. Diese natürlichen Variationen sind viel größer als man sie von verstärkten Treibhausgas-Anteilen erwartet, und daher ist es wahrscheinlich, dass eine deutlich längere Periode mit Satellitenmessungen sich akkumulieren muss, um Aufschluss über längerfristige Trends zu geben“.
Karl et al. (2015) behaupteten, dass die vergangenen 18 Jahre mit stabilen globalen Temperaturen dem Gebrauch von verzerrten Bojen-Daten in den Ozeanen geschuldet ist. Die Autoren schreiben, dass eine „Bias-Korrektur die Berechnung der mittleren Differenz zwischen gesammelten Bojen- und Schiffsmessungen involvierte. Die mittlere Differenz betrug global -0,12°C. Diese Korrektur wurde an die Bojen-Messwerte der Wassertemperatur in jedem Gitterquadrat in der ERSST-Version 4 angebracht“. Diese Analyse ist nicht konsistent mit der Interpretation des nunmehr 18-jährigen Stillstandes bzgl. globaler Erwärmung. Die hier folgende Diskussion des ersten Derivativs einer Trendlinie der Temperatur-Anomalie zeigt die Rate der Erwärmung relativ stabil und nahezu frei von Rauschen, die im Jahre 2006 ihren Höhepunkt erreichte und seitdem eine Abnahme des Anstiegs bis heute.
[Es folgen zwei Absätze mit längeren Ausführungen zu den einzelnen Temperatur-Auswertungen, die hier übersprungen werden.]
…
Analyse von Temperatur-Anomalien
Alle in dieser Studie herangezogenen Temperaturmessungen sind berechnete Temperatur-Anomalien und keine absoluten Temperaturen. Eine Temperatur-Anomalie ist hier die Differenz der gemessenen absoluten Temperatur zu einer zugrunde liegenden Mitteltemperatur – in diesem Falle die mittlere jährliche Temperatur von 1961 bis 1990. Mit diesem Konversionsverfahren sollen die Auswirkungen auf Temperaturen relativ zur Umgebung der Messstation minimiert werden (d. h. Tallagen oder Bergspitzen). Damit sollen regionale Temperaturtrends besser erkannt werden.
In Abbildung 1 stellt die schwarze Kurve die monatliche mittlere Temperatur-Anomalie an der Erdoberfläche dar. Der gezackte Verlauf der schwarzen Temperatur-Anomalie-Kurve ist dem Rauschen in den Daten geschuldet (Ungenauigkeiten der Messungen und zufällige kurzzeitige Wetterereignisse). Die rote Kurve repräsentiert eine Excel sixth-degree polynomial best fit-Trendlinie der Temperatur-Anomalien. Bei diesem Verfahren wird das hochfrequente Rauschen entfernt. Die grüne Kurve, aus der Trendlinie abgeleitet, ist die wichtigste Kurve, die aus den globalen mittleren Temperatur-Anomalien abgeleitet worden ist. Die Kurve ist eine Zeitreihe der Differenzen von Monat zu Monat der mittleren Temperatur mit der Einheit Änderung in Grad Celsius pro Monat. Diese sehr kleinen Zahlen sind mit 120 multipliziert worden, um die Einheiten in Grad pro Dekade umzurechnen (linke vertikale Achse der Graphik). Grad pro Dekade ist eine Maßzahl der Rate, mit welcher die Temperatur auf der Erde steigt oder sinkt. Manchmal wird das auch als die Kurve der Erwärmung (oder Abkühlung) der Erdoberfläche angesehen. Die Temperaturwerte der grünen Kurve sind hinsichtlich der Größenordnung ähnlich der Größenordnung der rauschbefreiten Temperaturschätzungen seitens der University of Alabama in Huntsville UAH (Christy, J. R., 8. Mai 2019). Die grüne Kurve wurde zuvor nicht bekannt gemacht und ist entscheidend für die Analyse langzeitlicher Temperaturtrends.
Eine Erwärmung um 0,038°C pro Dekade müsste signifikant zu- oder abnehmen, um für eine Prognose einer langfristigen Änderung der Erdtemperatur zu taugen. Falls die Temperatur an der Erdoberfläche kontinuierlich von heute an mit einer Rate von 0,038°C pro Dekade steigen würde, gäbe es in 100 Jahren einen Anstieg von nur 0,4°C, was nicht gerade eine Bedrohung für die Menschheit darstellt.
Die Schätzung der 0,038°C pro Dekade liegt wahrscheinlich jenseits der Genauigkeit von Temperaturmessungen von 1850 bis 1979. Jüngsten statistischen Analysen zufolge bewegt sich die 95%-Bandbreite der Unsicherheit der globalen mittleren Temperatur während der letzten 140 Jahre zwischen 0,05°C bis 0,15°C. Das heißt, dass 95 von 100 Messungen innerhalb der Bandbreite der Unsicherheits-Schätzungen liegen (Lenssen, N. J. L., et al. 2019). Von 1850 bis 1979 war es nur zu einer sehr geringen Erwärmung gekommen.
In Abbildung 2 zeigt die grüne Kurve die Erwärmungskurve, das heißt eine Zeitreihe der Änderungsrate der Temperatur auf der Erde in Grad Celsius pro Dekade. Die blaue Kurve ist eine Zeitreihe der CO2-Konzentration in ppm in der Atmosphäre. Die grüne Kurve verläuft von 1900 bis 1979 in etwa glatt und steigt dann leicht infolge des niederfrequenteren Rauschens, welches in den Temperatur-Anomalien von 40 Jahren El Nino-Aktivität verbleibt. Die Erwärmungskurve ist seit dem Jahr 2000 bis heute leicht rückläufig. Die CO2-Konzentration nahm von 1943 bis 2019 stetig zu. Es gibt keine Korrelation zwischen einer steigenden CO2-Konzentration in der Atmosphäre und einer relativ stabilen, geringen Erwärmungsrate an der Erdoberfläche von 1943 bis 2019:
In Abbildung 3 ist die Temperaturspitze vom Dezember 1979 (Punkt A) verbunden mit einem schwachen El Nino-Ereignis. Während der folgenden 39 Jahre war es zu fünf sehr starken derartigen Ereignissen gekommen, wobei das letzte davon 2015-16 die höchste, jemals aufgezeichnete El Nino-Intensität aufwies. Die höchste monatliche globale Temperatur-Anomalie jemals war mit 1,111°C im Februar 2016 aufgetreten. Seitdem zeigten die monatlichen globalen Temperatur-Anomalien einen Rückgang um 35 Prozent auf 0,724°C im August 2019, nachdem der El Nino sich in seiner Intensität abgeschwächt hatte.
Die Punkte A, B und C markieren sehr signifikante Änderungen des Verlaufs der grünen Erwärmungskurve (Werte auf der linken vertikalen Achse).
1. Die Werte der grünen Kurve nahmen in jedem Monat von 0,085°C pro Dekade im Dezember 1979 (Punkt A) auf 0,136°C im Juli 1988 zu (Punkt B). Das ist eine Zunahme der Erwärmungsrate um 60% innerhalb von fast 9 Jahren. Die Erwärmungkurve ist aufwärts konkav. Punkt A markiert einen schwachen El Nino und den Beginn zunehmender ENSO-Intensität.
2. Von Juli 1988 bis September 2006 nahm die Erwärmungsrate zu von 0,136°C pro Dekade auf 0,211°C pro Dekade (Punkt C). Das ist eine Zunahme um 55% innerhalb von 18 Jahren, aber nur etwa die Hälfte der Rate insgesamt der 9 Jahre zuvor infolge einer Abnahme der Zunahme-Rate jeden Monat. Der Punkt Juli 1988 auf der X-Achse ist ein Wendepunkt, an welchem die Erwärmungkurve abwärts konkav verläuft.
3. Punkt C (September 2006) markiert ein sehr starkes El Nino-Ereignis und den Spitzenwert des fast 40 Jahre langen vorübergehenden ENSO-Erwärmungstrends, was der grünen Kurve das Aussehen eines stilisierten S verleiht. Die Erwärmungsrate hat jeden Monat abgenommen seit dem Spitzenwert von 0,211°C im September 2006 auf 0,125°C im August 2019, das ist eine Abnahme um 41 Prozent innerhalb von 13 Jahren.
Abschnitt 2: Wahrheit und Konsequenzen
Die „Hockeyschläger-Graphik“, welche von den Medien häufig als Beleg für eine außer Kontrolle geratene globale Erwärmung während der letzten 20 Jahre herangezogen worden ist, wird durch die gegenwärtigen Temperaturaufzeichnungen nicht gestützt. Die Graphik taucht in den Printmedien auch nicht mehr auf.
Keines der 102 Klimamodelle der Mitteltemperatur der mittleren Troposphäre zeigt in ausreichender Art und Weise eine Prognose zukünftiger Temperaturen, welche zu Änderungen der Umweltpolitik Anlass geben. Die Modelle beginnen in den 1970er Jahren, also zu Beginn eines Zeitraumes, in welchem die stärkste ENSO jemals kulminierten, und bis zum Jahr 2015 liegt die mittlere prognostizierte Temperatur aller Modelle fast 2,4 mal höher als die gemessene troposphärische Temperatur-Anomalie im Jahre 2015 (Christy, J. R. May 8, 2019). Die wahre Geschichte der globalen Klimaänderung muss erst noch geschrieben werden.
Die höchste Erwärmung während der ENSO war im September 2006 mit 0,211°C pro Dekade aufgetreten. Die höchste jemals gemessene mittlere globale Temperatur betrug 1,111°C im Februar 2016. Diese Fälle sind möglicherweise verbunden mit einer Zunahme von Qualität und Messdichte von Ozean-Temperaturen der beiden zuvor erwähnten erdumlaufenden MSU-Satelliten. Frühere ENSO-Ereignisse hoher Intensität könnten wegen des Fehlens fortschrittlicher Satellitenbeobachtungen über den Ozeanen nicht erfasst worden sein.
Der Gebauch einer Temperatur-Trendlinie zur Entfernung hochfrequenten Rauschens eliminiert nicht die vorübergehenden Auswirkungen von Komponenten der ENSO-Erwärmung mit längeren Wellenlängen während der letzten 40 Jahre. Daher wird bei den Schätzungen der Ewärmungsrate jenes Zeitraumes in dieser Studie immer noch Hintergrund-Rauschen des ENSO vorhanden sein. A noise-free signal for the past 40 years probably lies closer to 0.038 degrees C per decade, the average rate of warming from 1850 to the beginning of the ENSO in 1979 than the average rate from 1979 to the present, 0.168 C degrees per decade.* Die höhere Zahl enthält unkorrigierte Residual-ENSO-Effekte.
[*Für diesen Ausschnitt aus dem Original habe ich keine vernünftige Übersetzung zustande bekommen. Anm. d. Übers.]
Foster und Rahmstorf (2011) zogen mittlere jährliche Temperaturen aus fünf Datensätzen heran, um die mittlere Erderwärmung von 1979 bis 2010 abzuschätzen. Das aus dem Rohmaterial entfernte Rauschen wird ENSO-Aktivitäten, Vulkanausbrüchen und solaren Variationen zugeordnet. Vom Ergebnis heißt es, dass es ein Rauschen-adjustierter Verlauf der Temperatur-Anomalie ist. Die mittlere Erwärmung der fünf Datensätze über 32 Jahre beläuft sich auf 0,16°C pro Dekade im Vergleich zu den 0,17°C pro Dekade in dieser Studie aus 384 monatlichen Punkten, abgeleitet aus dem Derivativ der Temperatur-Trendlinie. Foster und Rahmstorf (2011) nehmen an, dass der Erwärmungstrend linear ist auf der Grundlage nur einer mittleren Schätzung, und ihre Daten überdecken auch nur 32 Jahre. Dreißig Jahre wird allgemein als der minimale Zeitraum angesehen, um einen Punkt in einem Trend zu definieren. Dieser Zeitraum von 32 Jahren enthält die höchste beobachtete ENSO-Aktivität jemals und ist nicht lang genug, um einen Trend zu definieren. Die Erwärmungskurve in dieser Studie über fast 170 Jahre ist gekrümmt (grüne Kurven in den Abbildungen 1 und 3). Sie wird definiert durch 2032 monatliche Punkte, abgeleitet aus dem Derivativ der Temperatur-Trendlinie. Von 1979 bis 2010 variiert die Erwärmung zwischen 0,08°C und 0,20°C pro Dekade. Der Erwärmungstrend ist nicht linear.
Die vermeintliche Bedrohung durch exzessive zukünftige Temperaturen kann einer Unterschätzung der ungewöhnlich großen Auswirkungen der jüngsten ENSO auf natürliche globale Temperaturanstiege geschuldet sein. Fast 40 Jahre einer natürlichen, vorübergehenden Erwärmung durch den höchsten jemals beobachteten ENSO könnte fehlinterpretiert worden sein dahingehend, dass eine Erwärmung aufgrund anthropogener Aktivitäten angenommen wurde. Es gibt keinerlei Beweise für einen signifikanten anthropogenen Beitrag zu den gemessenen Temperaturen während der letzten 40 Jahre.
Caltech verkündete jüngst den Beginn eines 5-Jahre-Projektes zusammen mit vielen anderen Forschungszentren zur Entwicklung eines neuen Klimamodells „von der Grundlinie an“ (Perkins 2018). Während dieser fünf Jahre sollte sich das Verständnis der Welt bzgl. der Ursachen von Klimawandel erheblich verbessern.
Das wissenschaftliche Zielt muss es sein, die Bandbreite der Unsicherheit von Prognosen mittels besserer Daten und besseren Modellen immer mehr einzuengen, bis eine menschliche Intervention sinnvoll erscheint. Wir haben Zeit, das hinzubekommen. Ein rationales Umweltschutz-Programm und eine dynamische Ökonomie können koexistieren. Die Herausforderung besteht darin, den Wissenschaftlern die Zeit und die Freiheit zu gewähren, ohne Einmischung von Interessengruppen zu arbeiten.
[Hervorhebung vom Übersetzer]
Acknowledgments and Data
All the raw data used in this study can be downloaded from the HadCRUT4 and NOAA websites. http://www.metoffice.gov.uk/hadobs/hadcrut4/data/current/series_format.html
https://research.noaa.gov/article/ArtMID/587/ArticleID/2461/Carbon-dioxide-levels-hit-record-peak-in-May
References
1. Boden, T.A., Marland, G., and Andres, R.J. (2017). National CO2 Emissions from Fossil-Fuel Burning, Cement Manufacture, and Gas Flaring: 1751-2014, Carbon Dioxide Information Analysis Center, Oak Ridge National Laboratory, U.S. Department of Energy, doi:10.3334/CDIAC/00001_V2017.
2. Christy, J. R., May 8, 2019. The Tropical Skies Falsifying Climate Alarm. Press Release, Global Warming Policy Foundation. https://www.thegwpf.org/content/uploads/2019/05/JohnChristy-Parliament.pdf
3. Foster, G. and Rahmstorf, S., 2011. Environ. Res. Lett. 6 044022
4. Golden Gate Weather Services, Apr-May-Jun 2019. El Niño and La Niña Years and Intensities. https://ggweather.com/enso/oni.htm
5. HadCrut4 dataset. http://www.metoffice.gov.uk/hadobs/hadcrut4/data/current/series_format.html
6. Karl, T. R., Arguez, A., Huang, B., Lawrimore, J. H., McMahon, J. R., Menne, M. J., et al.
Science 26 June 2015. Vol. 348 no. 6242 pp. 1469-1472. http://www.sciencemag.org/content/348/6242/1469.full
7. Mann, M., Bradley, R. and Hughes, M. (1998). Global-scale temperature patterns and climate forcing over the past six centuries. Nature, Volume 392, Issue 6678, pp. 779-787.
8. Mckitrick, R. Department of Economics, University of Guelph. http://www.rossmckitrick.com/uploads/4/8/0/8/4808045/mckitrick_comms_on_karl2015_r1.pdf, A First Look at ‘Possible artifacts of data biases in the recent global surface warming hiatus’ by Karl et al., Science 4 June 2015
9. Mears, C. and Wentz, F. (2016). Sensitivity of satellite-derived tropospheric
temperature trends to the diurnal cycle adjustment. J. Climate. doi:10.1175/JCLID-
15-0744.1. http://journals.ametsoc.org/doi/abs/10.1175/JCLI-D-15-0744.1?af=R
10. Morice, C. P., Kennedy, J. J., Rayner, N. A., Jones, P. D., (2012). Quantifying uncertainties in global and regional temperature change using an ensemble of observational estimates: The HadCRUT4 dataset. Journal of Geophysical Research, 117, D08101, doi:10.1029/2011JD017187.
11. Lenssen, N. J. L., Schmidt, G. A., Hansen, J. E., Menne, M. J., Persin, A., Ruedy, R, et al. (2019). Improvements in the GISTEMP Uncertainty Model. Journal of Geophysical Research: Atmospheres, 124, 6307–6326. https://doi.org/10. 1029/2018JD029522
12. NOAA Research News: https://research.noaa.gov/article/ArtMID/587/ArticleID/2461/Carbon-dioxide-levels-hit-record-peak-in-May June 4, 2019.
13. Palmer, P. I. (2018). The role of satellite observations in understanding the impact of El Nino on the carbon cycle: current capabilities and future opportunities. Phil. Trans. R. Soc. B 373: 20170407. https://royalsocietypublishing.org/doi/10.1098/rstb.2017.0407.
14. Perkins, R. (2018). https://www.caltech.edu/about/news/new-climate-model-be-built-ground-84636
15. Spencer, R. W., Christy, J. R. and Grody, N. C. (1990). Global Atmospheric Temperature Monitoring with Satellite Microwave Measurements: Method and Results 1979–84. Journal of Climate, Vol. 3, No. 10 (October) pp. 1111-1128. Published by American Meteorological Society.
——————
Link: https://wattsupwiththat.com/2019/11/14/170-years-of-earth-surface-temperature-data-show-no-evidence-of-significant-warming/
Übersetzt von Chris Frey EIKE
28. November 2019 um 11:47
… jetzt überfordern Sie den Herrn Schrage aber total ….
27. November 2019 um 9:24
Zitat:
„Wenn dies richtig wäre, dann könnte ich in meiner Analyse vom 24.11.2019 13:30 nicht diese ausgeprägte saisonale Systematik finden. Dies wäre doch ein großer Zufall.“
Wir müssen hier keinen Dauerstreit vom Zaun brechen, aber Ihre Betrachtung entspricht eben nicht der üblichen Verfahrensweise nach DAkkS. Ein kleines Beispiel zum Verständnis: Ein typisches Quecksilber-Fieberthermometer hat eine Eichfehlergrenze von ± 0,25 K. Wenn Sie während einer Fieberphase immer das gleiche Thermometer benutzen, könnnen Sie zwar nicht die „absolute“, aber eine recht genaue Tendenz ihrer Körpertemperatur über die Tage ableiten. Haben Sie zu jeder Messung ein anderes Thermometer, ist dieser Verlauf durch die u.U. unterschiedlichen systematischen Fehler der beteiligten Thermometer (alle innerhalb der Fehlergrenzen!) nicht mehr so eindeutig ableitbar (Wir hatten früher einen schwedischen Kunden, der Fieberthermometer mit farblichen Kennzeichnungen bekam, jeder Patient eines Krankenzimmers im Krankenhaus hatte „seine“ Farbe, bekam also immer „sein“ Thermometer, damit Trends eindeutiger feststellbar waren). Deshalb kann Ihre Aussage zu einer saisonalen Systematik durchaus richtig sein, aber genaugenommen gehört zu jedem Messwert die Angabe der Messunsicherheit (was Sie schuldig bleiben), sonst ist aus wissenschaftlicher Sicht die Messung wertlos. Der Herr Limburg hat dazu ja in seiner Arbeit im Wesentlichen die gleichen Erkenntnisse gewonnen, die aber in der Meteorologie anscheinend noch nicht so richtig angekommen sind. Ich hoffe für Sie, dass Sie nicht dem „digitalen Glauben“ verfallen sind und Stellenzahl (Auflösung) für Genauigkeit halten. Deshalb sind die oft zwei Stellen nach dem Komma bei den el. Fieberthermometern für mich z.B. absoluter Quatsch, weil Genauigkeiten vorgegaukelt werden, die praktisch nicht vorhanden sind.
Ich habe zum Glück in den vergangenen 30 Jahren kein Fieber-Thermometer trotz Klima-Erwärmung benötigt. Meine Thermometer zu Hause kalibriere ich mit einem Pt-Widerstands-Thermometer, das ich mit einer Eis-Wasser-Mischung checke. Deshalb bin ich nicht dem „digitalen Glauben“ verfallen. Angaben zur Mess-Unsicherheit meiner Analyse vom 24.11.2019 um 13:31 habe ich unterlassen. Sie können sie aber gerne anhand des links zu den Originaldaten von HADCRUT 4 nachholen:
https://www.metoffice.gov.uk/hadobs/hadcrut4/data/current/download.html
Übrigens: Gemäß kaltesonne.de ist Ihr zitierter Datensatz „kreativ behandelt“ worden, um den von den Klimawahnsinnigen gewünschten Trend der Temperaturen zu bestätigen. Was ist der dann außerhalb von unseren Unsicherheitsbetrachtungen noch wert?
Noch mal eine private Frage? Wo und haben Sie Ihr Pt100 angeschlossen? („angeschlossen“ ist doppeldeutig, ich meine zwar an welche Normale, aber ein Pt100 allein zeigt ja auch noch keine Temperatur an …., also: Angeschlossen an welche Normale und an welche Geräte… und wie und wo sind die „angeschlossen“?)
die Sonnenaktivität hat doch in den vergangenen Jahren abgenommen und ist nun so ziemlich auf dem Minimum, die Temperaturen sind aber angestiegen.
Sonnenaktivität sowie ihr monatlicher und jährlicher Mittelwert.
http://chaac.meteo.plus/de/klima/sonne-aktuell.png
Sind die Temperaturen gestiegen?
http://www.woodfortrees.org/plot/hadcrut4gl/from:2015/to:2020/plot/hadcrut4gl/from:2015/to:2020/trend
den von Ihnen nicht übersetzten Abschnitt würde ich so in deutsch ausdrücken:
„Ein vom Rauschen befreites Signal für die letzten 40 Jahre liegt wahrscheinlich näher am Wert von 0,038°C Erwärmung pro Jahrzehnt (entsprechend der durchschnittlichen Erwärmungsrate von 1850 bis zur ENSO 1979) als am Wert von 0,168°C pro Jahrzehnt.“
MfG
Jetzt übersetzen Sie das noch in Baecksprech, und verSchulzen Sie das ganze.
Wahrscheinlich hilft das auch nix, weil ja 108% der Wissenschaftler…
Uff.
Sie mögen zwar ein Temperaturmesstechniker sein, aber ich bezweifele dass Sie langjährige Erfahrung in der Bewertung von Messreihen der Außen-Temperatur haben. Dazu gehört eine solide Abschätzung des systematischen und des zufälligen Fehlers. Die Messreihen, auf die sich der Autor bezieht, sind die von HADCRUT 4. Die Fehlerabschätzungen zur Messreihe können Sie sich jederzeit herunterladen unter:
https://www.metoffice.gov.uk/hadobs/hadcrut4/data/current/download.html
Wenn dies richtig wäre, dann könnte ich in meiner Analyse vom 24.11.2019 13:30 nicht diese ausgeprägte saisonale Systematik finden. Dies wäre doch ein großer Zufall.
Da die Ozean-Temperaturen kaum vom Wärme-Insel-Effekt beeinflusst sind, sollte eine Zeitreihe der Differenz zwischen Land- und Ozean-Temperatur darüber Aufschluss geben. Ich betrachte hierzu die Jahres-Mittelwerte dieser Größe für die Zeitreihe HadCRUT.4.6.0.0.median 185001 201909.dat. Sie war zwischen 1850 und 1960 konstant etwa -7,6 °C und verringerte sich bis 2018 auf etwa -7,0 °C. In anderen Worten: Land erwärmte sich relativ zu den Ozeanen um ca. 0,4 °C. Die Analyse der Jahres-Mittelwerte allein lässt es leider nicht zu, die einzelnen Beiträge Wärme-Insel-Effekt,Landnutzung und Tiefen-Erwärmung der Ozeane zu quantifizieren.
+1 für den Wissenschaftler.
Und die Landtemperatur? 1850 gab es ein Thermometer auf der Südhalbkugel u. das stand in Indonesien. 1900 gab es auf der Südhalbkugel etwa 50% der Thermometer der Nordhalbkugel an Land. Nur… auf der Südhalbkugel gibt es wesentlich mehr Ozean. Während an Land noch halbwegs vernünftige Messanlagen standen, hat man auf den Schifffahrtsrouten u. die waren ebenfalls „da unten“ nicht besonders üppig, einen Eimer über Bord geworfen. Da wäre ich doch sehr vorsichtig, was diese Temp.reihen betrifft.
12-02;-16,0; 1,0
03-05; -5,1; 1,2
06-08; +1,2; 0,5
09-11; -8,2; 0,2
01-12; -7,0; 0,7
Man erkennt, dass die Änderung in den vergangenen 60 Jahren im Winter und Frühjahr am größten und im Herbst am geringsten ist. Die Ursache ist wohl hauptsächlich in der geringeren Bedeckung von Schnee und Eis zusuchen.
Sieht aus wie ein Interglazial (mit erwartbar trägen Ozeanen). Bin gespannt in welche Richtung sich das entwickelt wird (Basis sind ja „offizielle“ Zahlen).
Sie übersehen da was, Herr Berberich. Die Ozeantemperaturen unterliegen einer jahrzehntelangen Variabilität bzw. Periodizität. Die AMO des Atlantiks hat eine Periodizität von etwa 70 Jahren und die des Pazifik bei ca. 40 Jahren.
Was auf der Südhalbkugel abgeht müssen Sie selbst herausfinden.
Die Messstation Temnpelhof hat 2,8°C um 1:00Uhr
Die Messstation Bestensee hat 3,0°C um 1:00Uhr
Die Messstation Eberswalde hat 3,0°C um 1:00Uhr
Die Messstation Buckow/Märkische Schweiz hat 2,5°C um 1:00Uhr
Die Messstation Templin hat 3,0°C um 1:00Uhr
Die Messstation Luckenwalde hat 3,1°C um 1:00Uhr
Hab mal zufällige Stationsmesswerte um Berlin (auf ca. 40m Höhe) so wir Temnpelhof angeschaut und da kann man nicht sagen das Berlin Temnpelhof eine erhöhte Temperatur hat im Vergleich zu den umliegenden Messstationen.
Wenn es doch nur ein „Wärmeinseleffekt ist, wie erklärt man:
1. Zunahme der Meerestemperatur, auch in tieferen Schichten
2. globales Schmelzen von Gletschern und Eisfeldern
3. Verlängerung der Vegetationsphasen
4. Verbreitung von invasiven Arten
5. Auftauen von Permafrostböden
Selbst wenn der Wärmeinseleffekt den größten Teil der gemessenen Erwärmung ausmachen „würde“….. All diese Auswirkungen würden dann schon bei wesentlich kleineren Temperaturunterschieden eintreten und dennoch von uns verlangen, die Erwärmung so klein wie möglich zu halten.
Wie oft hat man Ihnen das alles schon erklärt? Den Wi-effekt von Tempelhof können sie nur quantifizieren, wenn sie 2 Erden hätten, die ein von 1850 und die jetzige. Sie können aber den UHI-Effekt quantifizieren, der derzeitige Stadt-Landunterschied z.B. Uni Bamberg, die Ergebnisse liegen bei 2 bis 4 Grad.
1) Zunahme der Meerestemperaturen: Es gibt überhaupt keinen Beweis der Zunahme, weil es kein Ozean-Messnetz seit 1850 gibt. Schon gar nicht in Tiefen. Wie könenn sie überhaupt eine solche Frage stellen. Außerdem würde eine Temperatur-Zunahme noch längst kein Beweis des CO2-Treibhauseffektes sein, auf das ihre Frage abzielt.
2)Gletscher und Eisfelder sind kleine Reste der letzten Eiszeit, diese ging vor 12000 Jahren zu Ende. Der Schneefernergletscher reichte einst bis zur Donau. Auch momentan kalte Jahre sind immer noch wärmer als die Temperaturen der Eiszeit.
3) Vegetationsphasen, die werden nur in den Wärmeinseln länger. Seit 1850 sind diese Wärmeinseln zu wärmeregionen angewachsen, überall auf der Welt. Bei uns in BaWü inzwischen sechs große Regionen. Weit außerhalb der bebauten Fläche in der freien Natur, wo ich mich als aktiver Naturschützer täglich aufhalte, blüht das Märzenveilchen bei uns im Ostalbkreis Ende März/Anfang April, die Forsythie Anfang April. Auch in Hamburg verspätet sich der DWD-Vorzeigeforsythienstrauch seit 33 Jahren, weil die Wärmeinsel Innenstadt Hamburg seitdem ausgereizt ist. Die Fragen 4 und 5 können Sie jetzt vielleicht selbst beantworten, das hat alles nichts mit dem Ansteig von CO2 von einst 280 ppm auf momentan 400 ppm zu tun. Wollen Sie die weitere Erwärmung in den ca 15 bis 20% Wärmeinselflächen Deutschlands zurückfahren, dann müssen sie die Wetterstationen einfach wieder an ähnliche Plätze wie früher stellen, siehe Freiburg, Wolfach, Nürnberg-Netzstall, deutsche Antarktiswetterstation, Dale Enterprise in Virginia…
Für den weiteren Erkenntnisgewinn empfehle ich Ihnen die Artikel von Kämpfe/Kowatsch bei EIKE. Leider werden diese von der Qualitätspresse nicht veröffentlicht. Außerdem mein persönlicher Rat an Sie: Werden Sie aktiver Naturschützer mit dem täglichen regelmäßigen Aufenthalt draußen vor den Wärmeinseln, dann wäre ihre sinnliche Naturerfassung realistisch. Ihre Fragen würden sich erübrigen. Als Fazit ergibt sich für mich nach vielen Jahrzehnten. Wir sind weit entfernt von einer gefährlichen Erwärmung. Das zeigt mir die Natur in der freien Fläche jeden TAg. Wo sich trotz CO2-Zunahme nichts erwärmt, brauche ich auch die CO2-Erwärmungsfrage nicht zu stellen. Ein Märchen für mich, für Sie Religion. Die CO2-Steuern sind für die Katz, ein Geschäftsmodell wie die Erfindung der Erbsünde im Mittelalter mit dem Ablaßhandel. Das schreibe ich seit 10 Jahren.
Zu Ihren 5 Fragen füge ich eine dazu:
Wie erklären Sie sich die Abkühlungstrendlinie Freiburgs im Breisgau seit 30 Jahren?, in Freiburg haben doch die CO2-Konzentrationen genauso zugenommen wie im übrigen Deutschland.
Noch etwas zu Ihrer Wärmeinseltheorie….
Zwischen 2002 und 2015 hat in Deutschland der Energieverbrauch für Raumwärme und Warmwasser um 21% abgenommen. Es müsste also im gleichen Zeitraum auch der Wärmeinseleffekt geschrumpft sein, da ja nun weniger Wärme der Wohnungen an die Umgebung abgegeben wird.
Die Temperaturen sind jedoch weiter gestiegen.
https://www.dena.de/fileadmin/user_upload/8162_dena-Gebaeudereport.pdf
da es ja waermer geworden ist, wird weniger geheizt. Also stellt sich die Frage ob sie wissen wovon sie reden.
Im Uebrigen ist der Wärmeinseleffekt ausdruecklich nicht mit dem Energieverbrauch des Menschen erklaert, sondern mit der Versiegelung von Flaechen und Betonierung und Veraenderung der Oberflaechen.
Ich beantworte meine oben gestellte Frage: Sie haben keine Ahnung wovon sie reden!
Noch etwas zu Ihrer Wärmeinseltheorie….“
Komiker
“ Es müsste also im gleichen Zeitraum auch der Wärmeinseleffekt geschrumpft sein, da ja nun weniger Wärme der Wohnungen an die Umgebung abgegeben wird.“
Der Wärmeinseleffekt entsteht nicht allein aus der Heizung der Wohnbebauung, sondern andere Faktoren müssten n. m. M. sogar überwiegen. Im Sommer (keine Gebäudeheizung) ist nämlich der Effekt durchaus größer als im Winter, Berlin Innenstadt z. B. bis zu 9° gegenüber Grunewald…
1. Zunahme der Meerestemperatur, auch in tieferen Schichten“
Herr Schrage,
wo ist der Beweis der Zunahme der Meerestemperatur? Wobei Sie erst mal erklären müssen, was denn das Meer ist.
Auf der Nordhalbkugel gibt es vier „Meere“: Den Nordpazifik, den Nordatlantik, den Indischen Ozean und das Nordpolarmeer.
Desweiteren dürfen Sie mir erklären was denn die Temperatur in den „tieferen Schichten“ ändert, also die von Ihnen behauptete Zunahme verursacht? Wobei Sie natürlich erst mal beweisen müssen, daß da eine Änderung (Zunahme) statfindet.
Und wenn Sie das gemacht haben, werde ich ihnen wissenschaftlich fundierte Antworten geben.
Ozeantemperaturen von 1850 bis 2019. Sieht für mich nach einem eindeutigen Anstieg seit den 1920er Jahren aus.
Ähnliches Bild ergibt sich beim „Heat Content“ der Ozeane. Die gespeicherte Wärme der Ozeane hat seit 1990 stark zugenommen, und ist auch eine Erklärung dafür, warum es einen scheinbaren „Stillstand“ der Erwärmung in den 2000er Jahren gab. Der größte Teil er Erwärmung ist in die Ozeane gewandert.
https://wiki.bildungsserver.de/klimawandel/index.php/Erw%C3%A4rmung_des_Ozeans
Zur *versteckten Wärme im Ozean*, *Heat Content*, ist mir noch folgendes in Erinnerung:
Um 2012 wurde erbittert um den *Hiatus* in der Erderwärmung gestritten. Man nahm, 2013 glaube ich, deshalb geradezu begierig eine Arbeit von Trenberth auf, in der er nachzuweisen versucht, dass die Wärme im Ozean nur „zwischengespeichert“ wäre. Da die Oberflächen- Temp. Messungen das allerdings wohl nicht so recht hergaben, verortete er die Wärme in größeren Tiefen, 200-700m so ist mir in Erinnerung. Er hatte scheinbar ein paar ausgewählte recht lokale Datensätze aus dem pazifischen Raum.
Im wesentlichen hat er dann damit die Wärmemenge, die in der Athmosphäre fehlte im Vergleich zu den Modellprojektionen, rückgerechnet. Es war wohl mehr eine Theorie als ein Beweis, jedenfalls nimmt heute kaum einer mehr in dieser Sache Trenberth als Kronzeuge.
auch wenn diese Grafiken ab 1850 kompletter Blödsinn sind, erfolgen sie doch wenigstens auf ein Zehntel Grad genau – Chapeau!
Die Gletscher nehmen ab, weil die höheren Sommertemperaturen eine Firnbildung verhindern. In den Alpen: höhere Sonnenscheindauer (weniger Wolken), höhere Temp., kein Schneeproblem. Werden die Sommer wieder kälter, wachsen sie wieder.
Gleichzeitig dringen die Wälder wieder in größere Höhen vor resp. in die Tundra.
Wo ist das Problem?
Zu dem Meerestemp. hat meine Vorredner(schreiber) schon alles gesagt.
Die genannten, sichtbaren Veränderungen, die wir wahrnehmen, sind also das Resultat dieser 1K Temperaturänderung.
Wenn wir annehmen würden, z.B. 80% der gemessenen/behaupteten Temperaturerhöhung käme nur vom Wärmeinseleffekt, dann hätte sich die Erde ja dieser These nach nur um 0,2K erwärmt.
Die sichtbaren Veränderungen bleiben jedoch, was bedeutet, 0,2K Temperaturänderung hätten ausgereicht, bereits solch sichtbaren Effekte zu haben. Wir hätten sogar einen noch größeren Anreiz, eine Temperaturänderung zu verhindern, da ja scheinbar schon 0,2K ausgereicht hätten, solch sichtbaren Resultate zu haben.
Die Temperaturerhöhung seit vorindustrieller Zeit beträgt global etwa 1K.
Bitte benennen Sie doch mal auf welche Temperatur und welche Zeit sich diese Änderung bezieht. Samt Fehlerbalken!
Was sehen sie denn da so?
Somit ist das eine Erwärmung von 1850 bis 2019 von ca. +1,2°C.
Das deckt sich auch ca . mit den Messungen vom DWD.
Ab 1970 ging das erst so richtig los mit der Temperaturerhöhung.
https://www.bilder-upload.eu/bild-d41f07-1574843755.png.html
Korreliert hervorragend mit der Zunahme des BIP (pro Kopf) besonders ab 1980
Es gibt kein „forcing“ !