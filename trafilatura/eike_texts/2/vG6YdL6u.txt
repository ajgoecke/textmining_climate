Abbildung 1 (rechts): Der lineare Regressionstrend kleinster Quadrate im Datensatz der mittleren globalen Temperaturanomalie des RSS zeigt keine globale Erwärmung seit Oktober 1996, also seit 18 Jahren und drei Monaten.
Angesichts dessen, dass sich der Papst unklugerweise darauf vorbereitet, für immer die politische Neutralität aufzugeben, die ihm seine Stellung auferlegt und seine Unterschrift unter eine klima-kommunistische Enzyklika zu setzen, entworfen vom radikalen Präfekten der Academy of Sciences im Vatikan, Monsignore Marcelo Sanchez Sorondo, zeigt der Allmächtige weiterhin einen Sinn für Humor.
Die Welt-Konferenz in Paris ist zeitlich nicht einmal mehr ein Jahr entfernt. Und dennoch hat die globale Erwärmung, die das IPCC so vertrauensvoll aber irreführend vor 25 Jahren vorhergesagt hatte, vollständig aufgehört.
Abbildung 2: Kurzzeit-Projektionen von Erwärmung mit einer Rate äquivalent zu 2,8 (1,9; 4,2) K pro Jahrhundert, ausgegeben mit „substantiellem Vertrauen“ vom IPCC (1990) von Januar 1990 bis November 2014 (orangefarbene Region und rote Trendlinie) im Vergleich zu den beobachteten Anomalien (dunkelblau) und Trend (hellblau) mit einem Äquivalent von weniger als 1,4 K pro Jahrhundert als Mittelwert der monatlichen mittleren Temperaturanomalien der unteren Troposphäre von RSS- und UAH-Satellitenmessungen.
Ein Vierteljahrhundert nach 1990 ist das Ergebnis der globalen Erwärmung bis heute – ausgedrückt als der lineare Regressionstrend kleinster Quadrate im Mittel der RSS- (1) und UAH (2)-Daten – 0,34°C, äquivalent zu lediglich 1,4°C pro Jahrhundert oder mehr als halb so gering wie die zentrale Schätzung des IPCC (1990) und noch deutlich unter der geringsten Schätzung (Abbildung 2).
Der Große Stillstand ist ein wachsendes Ärgernis für all jene, die uns mit „substantiellem Vertrauen“ weisgemacht haben, dass die Wissenschaft ,settled‘ und die Debatte vorüber sei. Die Natur hatte Anderes im Sinn. Trotz inzwischen fast 70 Entschuldigungs-Gründen, die untereinander nicht kompatibel und mehr oder weniger implausibel sind und die in nervös gewordenen begutachteten Journalen und unter missionierenden Wissenschaftlern erscheinen, kann die Möglichkeit nicht länger ausgeschlossen werden, dass der Stillstand stattfindet, weil die Computermodelle schlicht und ergreifend falsch sind hinsichtlich der Sensitivität der Temperatur in Bezug auf menschliche Treibhausgase. Dies wird in einer großen begutachteten Studie deutlich, die im Dezember 2014 im führenden Wissenschaftsjournal des Orients veröffentlicht worden ist.
Bemerkenswerterweise liegen sogar noch die jüngsten und deutlich reduzierten Projektionen des IPCC bzgl. der globalen Erwärmung ebenfalls viel zu hoch (Abbildung 3):
Abbildung 3: Vorhergesagte Temperaturänderung von Januar 2005 bis November 2014 mit einer Rate von 1,7 (1,0; 2,3)°C pro Jahrhundert (orangefarbene Region mit dicker roter Best-Estimate-Trendlinie) im Vergleich zu beobachteten Anomalien (dunkelblau) und Nulltrend in der realen Welt (hellblau) als Mittelwert der monatlichen mittleren Temperaturanomalien der unteren Troposphäre von RSS- und UAH-Satellitenmessungen.
Im Jahre 1990 lag die zentrale Schätzung des IPCC der Erwärmung im Kurzfristzeitraum um zwei Drittel über der heutigen Schätzung. Damals war es ein Äquivalent von 2,8°C pro Jahrhundert. Jetzt ist es ein Äquivalent von 1,7°C – und wie Abbildung 3 zeigt, erweist sich selbst das noch als substantielle Übertreibung.
In den RSS-Satellitendaten gab es seit über 26 Jahren keine statistisch von Null unterscheidbare globale Erwärmung. Keines der Modelle hat vorhergesagt, dass im Endeffekt ein Vierteljahrhundert lang keine globale Erwärmung auftreten würde.
Schlüsselfakten zur globalen Temperatur:
● Der RSS-Satelliten-Datensatz zeigt keinerlei globale Erwärmung seit 219 Monaten von Oktober 1996 bis Dezember 2014 – ein Zeitraum, der mehr als die Hälfte der 432-monatigen Satellitenaufzeichnung umfasst.
● Der Trend der globalen Erwärmung seit 1990 ist äquivalent zu 0,8°C pro Jahrhundert. Dies liegt deutlich innerhalb der natürlichen Variabilität und hat vermutlich nicht viel mit uns zu tun.
● Seit 1950, als ein menschlicher Einfluss auf die globale Temperatur erstmals theoretisch möglich war, lag der Trend der globalen Erwärmung unter einem Äquivalent zu 1,2°C pro Jahrhundert.
● Die größte Erwärmungsrate über 10 Jahre oder mehr seit 1950 war in den 33 Jahren von 1974 bis 2006 aufgetreten. Der Wert war äquivalent zu 2,0°C pro Jahrhundert.
● Im Jahre 1990 lag die mittlere Vorhersage des IPCC im Kurzfristzeitraum bei einem Äquivalent zu 2,8°C pro Jahrhundert, also um zwei Drittel höher als dessen gegenwärtige Vorhersage von 1,7°C pro Jahrhundert.
●Der Trend der globalen Erwärmung seit 1990, als das IPCC seinen ersten Bericht geschrieben hat, ist äquivalent zu weniger als 1,4°C pro Jahrhundert – also die Hälfte dessen, was das IPCC damals vorhergesagt hatte.
● Obwohl das IPCC seine Erwärmungsvorhersage im Kurzfristzeitraum reduziert hat, hat es seine Erwärmungsvorhersage für dieses Jahrhundert bei ,Business as Usual‘ um 4,8°C bis zum Jahre 2100 nicht reduziert.
● Die vom IPCC vorhergesagte Erwärmung um 4,8°C bis zum Jahr 2100 ist deutlich mehr als doppelt so hoch wie die höchste Erwärmungsrate über mehr als zehn Jahre, die seit 1950 gemessen worden ist.
● Die vom IPCC vorhergesagte Erwärmung um 4,8°C bis zum Jahr 2100 ist fast vier mal so hoch wie der in der realen Welt gemessene Erwärmungstrend, seit wir theoretisch in der Lage waren, das Klima zu beeinflussen (1950).
● Von September 2001 bis November 2014 ist der Erwärmungstrend im Mittel der 5 globalen Temperaturdatensätze Null. Keine Erwärmung seit 13 Jahren und drei Monaten.
● Jüngste Extremwetterereignisse können nicht der globalen Erwärmung geschuldet sein, weil es keinerlei globale Erwärmung gegeben hat. So einfach ist das.
Technische Anmerkung
Unsere letzte thematische Graphik zeigt den linearen Regressionstrend kleinster Quadrate im Datensatz der monatlichen globalen mittleren Verhältnisse in der unteren Troposphäre, indem man so weit wie möglich zurückgehen kann und immer noch einen Null-Trend findet. Der Startzeitpunkt ist keine „Rosinenpickerei“ dergestalt, dass der Beginn mit der Temperaturspitze des Super-El Nino 1998 zusammenfällt. Stattdessen ist der so berechnet, dass man den längsten Zeitraum mit einem Null-Trend findet.
Aber ist der RSS-Satelliten-Datensatz „Rosinenpickerei“? Nein. Es gibt gute Gründe, diesen als den besten der fünf primären globalen Temperatur-Datensätze anzusehen. Der unermüdliche „Steven Goddard“ zeigte im Herbst 2014, dass der RSS-Datensatz – zumindest soweit er das Historical Climate Network HCN betrifft – eine geringere Warmverzerrung zeigt als die Aufzeichnungen von GISS (3) oder UAH (2). Der UAH-Datensatz soll demnächst überarbeitet werden, um dessen Warmverzerrung zu reduzieren und ihn konformer mit dem RSS-Datensatz zu machen.
Abbildung 4: Warmverzerrungen der Temperatur. RSS zeigt einen geringeren Bias als die UAH- und GISS-Aufzeichnungen. UAH wird in seiner demnächst erscheinenden Version 6.0 Schritte unternehmen, um den Warm-Bias in seiner Erfassung der globalen Temperatur zu reduzieren.
Steven Goddard schreibt:
„Die Graphik vergleicht die US-Temperaturen nach UAH, RSS und GISS mit den tatsächlichen Messungen der HCN-Stationen in den USA. UAH und GISS zeigen beide eine große Warmverzerrung, während RSS nahe bei den gemessenen täglichen Temperaturdaten liegt. Der geringe Unterschied zwischen RSS und HCN ist möglicherweise dem Umstand geschuldet, dass meine HCN-Berechnungen nicht flächengemittelt [gridded] sind. Meine Schlussfolgerung lautet, dass RSS der einzige glaubwürdige Datensatz ist und alle anderen einen falschen Warm-Bias aufweisen“.
Auch zeigt sich in den RSS-Daten der Große El Nino von 1998 deutlicher als in allen anderen Datensätzen. Der Große El Nino verursachte wie seine beiden Vorgänger während der letzten 300 Jahre eine verbreitete Korallenbleiche. Dies ist eine unabhängige Verifikation, dass RSS viel besser in der Lage ist, derartige Fluktuationen abzudecken ohne künstliches Herausfiltern derselben wie in anderen Datensätzen.
Terrestrische Temperaturen werden mit Thermometern gemessen. Korrekt in ländlichen Gebieten aufgestellte Thermometer, ausreichend weit entfernt von menschlichen Wärmequellen zeigen Erwärmungsraten, die merklich unter denen liegen, die veröffentlicht werden. Die Satelliten-Datensätze basieren auf Messungen der genauesten derzeit verfügbaren Thermometer – Platin-Widerstandsthermometer, die eine unabhängige Verifikation der Temperaturmessungen erlauben, indem man mittels Richtung Weltraum ausgerichteter Spiegel die bekannte Temperatur der kosmischen Hintergrundstrahlung misst, welche 1% des Gefrierpunktes von Wasser ausmacht bzw. um 2,73 Grad über dem Absoluten Nullpunkt liegt. Es war die Messung infinitesimaler Variationen der kosmischen Hintergrundstrahlung, die es der NASA erlaubte, das Alter des Universums zu berechnen: 13,82 Milliarden Jahre.
Die RSS-Graphik ist genau (Abbildung 1 oben rechts). Die monatlichen Daten stammen direkt von der RSS-Website. Ein Computer-Algorithmus liest sie aus dem Textfile heraus, mittelt sie und plottet sie automatisch mittels einer fortschrittlichen Routine, die automatisch das richtige Format des Datenfensters auf beiden Achsen adjustiert, um die Daten der Klarheit halber im maximalen Maßstab zu zeigen.
Der letzte monatliche Datenpunkt wird visuell untersucht um sicherzustellen, dass er korrekt positioniert worden ist. Die hellblaue, über die die tatsächlichen Daten zeigende dunkelblaue Profilkurve gelegte Trendlinie wird errechnet durch die Methode der linearen Regression kleinster Quadrate, welche den Schnittpunkt mit der y-Achse berechnet sowie die Neigung der Linie mittels zweier etablierter und funktional identischer Gleichungen, die miteinander verglichen werden, um sicherzustellen, dass es zwischen ihnen keine Diskrepanzen gibt. Das IPCC und die meisten anderen Agenturen verwenden lineare Regression, um globale Temperaturtrends zu berechnen. Prof. Phil Jones von der University of East Anglia verlangt dies in einer der Klimagate-E-Mails. Die Methode ist geeignet, weil globale Temperaturaufzeichnungen nur wenig Autoregression zeigen.
Dr. Stephen Farish, Professor für epidemiologische Statistik an der University of Melbourne hat freundlicherweise die Zuverlässigkeit des Algorithmus‘ verifiziert, mit dem der Trend in der Graphik und der Korrelations-Koeffizient berechnet werden, der sehr niedrig ist, weil der Trend trotz der hoch variablen Daten flach verläuft.
RSS selbst ist inzwischen ernsthaft an der Länge des Großen Stillstands interessiert. Dr. Carl Mears, der leitende Forschungswissenschaftler beim RSS, diskutiert dies hier.
Seine Ergebnisse werden in Abbildung 5 zusammengefasst:
Abbildung 5: Output der 33 IPCC-Modelle (türkis) verglichen mit der gemessenen globalen Temperaturänderung nach RSS (schwarz), 1979 bis 2014. Die vorübergehenden Abkühlungsphasen durch die Ausbrüche des Chichon (1983) und des Pinatubo (1991) werden gezeigt, ebenso wie die Wärmespitze durch den Großen El Nino von 1998.
Dr. Mears schreibt:
„Die Leugner mögen die Hypothese, dass die Ursache für die Diskrepanz zwischen Modellen und Beobachtungen irgendeinem Problem mit der fundamentalen Modellphysik geschuldet ist, und sie gehen mit Geringschätzung über jede andere Art der Erklärung hinweg. Dies führt sie zu der sehr wahrscheinlich irrigen Schlussfolgerung, dass die langfristige Sensitivität des Klimas viel geringer ist als ursprünglich gedacht“.
Dr. Mears räumt die zunehmende Diskrepanz zwischen den RSS-Daten und den Modellen ein, aber er vermutet „Rosinenpickerei“ hinsichtlich des Startdatums des Graphen der globalen Temperatur:
„Vor Kurzem hat eine Anzahl von Artikeln in den Main-Stream-Medien darauf hingewiesen, dass es so aussieht, als ob es während der letzten zwei Dekaden kaum oder gar keine Änderungen der Temperatur gegeben habe. Deswegen stellt man uns eine Menge Fragen nach dem Motto ,ich habe diesen Plot auf einer Leugner-Website gesehen. Sind das wirklich Ihre Daten?‘ Während in einigen dieser Berichte die Endpunkte tatsächlich ,cherry-picked‘ sind, um deren Beweise stärker erscheinen zu lassen, gibt es kaum Zweifel daran, dass die Erwärmungsrate seit Ende der neunziger Jahre geringer ist als vom IPCC im AR 5 vorhergesagt. Die Leugner mögen es wirklich, Trends im Jahre 1997 beginnen zu lassen, so dass das gewaltige El Nino-Ereignis von 1997/1998 am Beginn ihrer Zeitreihe liegt, was zu einer linearen Anpassung mit der kleinstmöglichen Neigung führt“.
In Wirklichkeit wird die Temperaturspitze des Großen El Nino von 1998 großenteils durch zwei Faktoren in der linearen Trendberechnung kompensiert: die nicht unähnliche Spitze des El Nino 2010 und die schiere Länge des Großen Stillstands selbst.
Ersetzt man alle monatlichen RSS-Anomalien für das Jahr 1998 mit dem mittleren Anomaliewert von 0,55 K, erhalten während des El Nino 2010 und berechnet dann erneut den Trend seit September 1996 (nicht Dr. Mears‘ „1997“) bis September 2014 zeigt sich, dass die Trendwerte „-0,00°C (-0,00°C pro Jahrhundert)“ in den unveränderten Daten (Abbildung 1) zu „+0,00°C (+0,00°C pro Jahrhundert)“ geworden sind. Fazit:
keine Rosinenpickerei.
Die Länge des Großen Stillstands bzgl. der globalen Erwärmung, so signifikant sie auch ist, ist indessen von geringerer Bedeutung als die immer größer werdende Diskrepanz zwischen den von den Modellen vorhergesagten Temperaturtrends und den weit weniger aufregenden Temperaturänderungen in der realen Welt, die gemessen worden sind.
Im Ersten Zustandsbericht hat das IPCC vorhergesagt, dass die globale Temperatur um 1,0°C (0,7; 1,5) bis zum Jahre 2025 steigen würde, äquivalent zu 2,8 (1,9; 4,2)°C pro Jahrhundert. In der ,executive Summary‘ wird gefragt: „wie viel Vertrauen haben wir in unsere Vorhersagen?“ Das IPCC verwies zwar auf einige Unsicherheiten (Wolken, Ozeane usw.), kam aber zu der Schlussfolgerung:
„Nichtsdestotrotz haben wir substantielles Vertrauen, dass die Modelle zumindest die groben Umrisse des Klimawandels vorhersagen können … Es gibt Ähnlichkeiten zwischen den Ergebnissen der gekoppelten Modelle unter Verwendung simpler Repräsentationen der Ozeane und jenen, die kompliziertere Verfahren verwenden, und unser Verständnis solcher Unterschiede, wie sie auftreten, verleiht uns einiges Vertrauen in unsere Ergebnisse“.
Jenes „substantielle Vertrauen“ war substantielles Über-Vertrauen. Weil die Rate der globalen Erwärmung seit 1990 nur etwa halb so groß ist wie vom IPCC damals vorhergesagt.
Erwärmt sich der Ozean?
Eine oft diskutierte Erklärung für den Großen Stillstand lautet, dass das gekoppelte Ozean-Atmosphäre-System weiterhin Wärme akkumuliert hat mit etwa der von den Modellen vorhergesagten Rate, dass aber während der letzten Jahrzehnte die Wärme aus der Atmosphäre durch die Ozeane entfernt worden ist, und – da global die oberflächennahen Schichten weit weniger Erwärmung zeigen als von den Modellen vorhergesagt – es wird hypothetisch angenommen, dass das, was man die „fehlende Wärme“ nennt, in die Tiefsee unter 2000 m abgesunken ist, wo man praktisch nichts messen kann. Von dort wird die Wärme irgendwann in der Zukunft wieder auftauchen.
Die „Fehlende-Wärme-Theorie bzgl. der Ozeane“ wird federführend von einer einzigen Gruppe in den USA befürwortet. Meehl, Arblaster, Fasullo, Hu und Trenberth (7) sagen:
„Acht Jahrzehnte mit einem leicht negativen globalen Oberflächen-Temperaturtrend zeigen, dass die Ozeane oberhalb 300 m signifikant weniger Wärme aufnehmen, während die Ozeane tiefer als 300 m signifikant mehr Wärme aufnehmen, verglichen mit den Dekaden ohne Stillstand. Das Modell bietet eine plausible Beschreibung der Prozesse im Klimasystem, die die Stillstands-Perioden verursachen, und sie zeigen, dass eine Stillstands-Periode ein relativ normales Klimaphänomen ist und mit La Nina-Bedingungen zusammenhängen kann“. Balmaseda, Trenberth und Källen (8) sagen dagegen: „Im vergangenen Jahrzehnt ereignete sich etwa 30% der Erwärmung unter 700 m, was signifikant zu einer Beschleunigung des Erwärmungstrends beitrug. Die Erwärmung unterhalb 700 m bleibt bestehen, selbst wenn das ARGO-Beobachtungssystem zurückgezogen wird, obwohl die Trends reduziert sind“. Und Trenberth & Fasullo (2013), wiederholt in Trenberth, Fasullo & Balmaseda (9) sagen: „Eine Inventur der Änderungen der Energiespeicherung zeigt, dass sich über 90% des Ungleichgewichtes als ein Anstieg des ozeanischen Wärmegehaltes OHC manifestieren. … Die globale Erwärmung ist nicht zum Stillstand gekommen: sie hat sich lediglich auf unterschiedliche Weise manifestiert“.
Diese US-Gruppe wird unterstützt durch eine Gruppe an der Chinese Academy of Sciences (10):
„eine schwankende globale Wärmesenke in mittleren Ozeantiefen geht einher mit unterschiedlichen Klimaregimes der Erwärmung an der Oberfläche infolge anthropogenen Antriebs. Während der zweiten Hälfte des 20. Jahrhunderts zeigte sich eine rapide globale Erwärmung, da mehr Wärme an der Oberfläche verblieben war. Im 21. Jahrhundert hat sich die Erwärmung verlangsamt, da mehr Wärme in tiefere Ozeanschichten abgesunken ist … Abkühlungsperioden im Zusammenhang mit der späteren Wärmeabscheidung in größeren Tiefen dauerten historisch gesehen 20 bis 35 Jahre“.
In (11) spekulieren die Akademiker, dass zu irgendeinem Zeitpunkt in der Zukunft der Stillstand sein Vorzeichen ändern könnte, was zu einer weiteren Episode einer möglicherweise beschleunigten globalen Erwärmung führt.
Und doch gibt es bis auf den heutigen Tag kein empirisches, theoretisches oder numerisches Verfahren, das erfolgreich mechanistisch spezifiziert hat, wie einmal die durch anthropogene Treibhausgase erzeugte Wärme aus der Atmosphäre kommend die tiefen Ozeanschichten erreicht haben könnte ohne den Wärmegehalt der durchlaufenen oberflächennahen Schichten wesentlich zu verändern, oder wie zum Anderen die Wärme vom Grund der Ozeane eventuell zurück an die Oberfläche kommen kann, um die oberflächennahen Klimabedingungen zu verändern, die für das landbasierte Leben auf der Erde relevant sind.
Die meisten Ozeanmodelle, die für Sensitivitäts-Läufe gekoppelter allgemeiner Zirkulationsmodelle verwendet werden, können einfach nicht den größten Teil der physikalischen Prozesse auflösen, die für das Einfangen der Wärme durch die Tiefsee relevant sind. Ultimativ verlangt der Zweite Hauptsatz der Thermodynamik, dass jedwede Wärme, die sich in der Tiefsee akkumuliert haben könnte, mittels verschiedener Diffusionsprozesse aufgelöst wird. Es ist nicht plausibel, dass irgendwelche von der Tiefsee aufgenommene Wärme plötzlich die oberen Ozeanschichten erwärmen wird und über diesen Zwischenschritt die Atmosphäre.
Selbst falls Wärme die benthischen Schichten erreicht, ohne die oberflächennahen Schichten auf ihrem Weg zu erwärmen, ist die kurzfristige oberflächennahe Reaktion ziemlich unempfindlich gegenüber einem steigenden atmosphärischen CO2-Gehalt. Aus diesem Grunde ist die Lösung der ozeanischen Thermodynamik keine Vorbedingung für das empirische Studium der Klimasensitivität mittels unseres einfachen Modells. Falls die „Tiefsee“-Erklärung für den Stillstand der globalen Erwärmung korrekt ist (und das ist lediglich eine unter Dutzenden anderen), dann sind die komplexen Modelle daran gescheitert, dies korrekt in Betracht zu ziehen: anderenfalls wäre die wachsende Diskrepanz zwischen den vorhergesagten und den beobachteten atmosphärischen Erwärmungsraten nicht so signifikant geworden, wie es der Fall gewesen ist.
Da die komplexen Modelle in dieser Hinsicht versagt haben, es ungenügende Beobachtungen aus der Tiefsee gibt, um zuverlässige quantitative Beweise einer vermeintlichen Wärmeakkumulation unter 2000 m zu erbringen, es noch weniger möglich ist, den Mechanismus des imaginären Wärmetransfers zu berechnen, es wiederum weniger möglich ist, die rechtzeitige Dosierung der jeweiligen Verteilung anthropogener, solarer oder untermeerischer Vulkanaktivitäten zu bestimmen, ist es sicher unvernünftig, von unserem einfachen Modell das zu erwarten, woran die komplexen Modelle aus sich selbst heraus gescheitert sind – und was kann man mit einem Modell nicht alles machen, einfach oder komplex, solange und bis Messungen mit weit höherer Auflösung als jetzt zur Verfügung stehen an allen Punkten der ozeanischen Säule.
Beispiel:
die 3500 automatisierten ARGO-Bathythermograph-Bojen haben eine Auflösung äquivalent zur Messung eines einzigen Temperatur- und Salzgehaltes im Oberen See weniger als einmal pro Jahr: und bevor ARGO Mitte Mitte des vorigen Jahrzehnts in Berieb ging wurde, war die Auflösung ozeanischer Temperaturmessungen sogar noch deutlich schlechter als das, vor allem in Tiefsee-Schichten.
Die mittlere Tiefe des globalen Ozeans beträgt 3700 m. Wie jüngst in (11) beobachtet, was implizit die Infragestellung der Behauptungen der USA-Gruppe (7 – 9) enthält, sind sowohl die Auflösung von Stichproben in verschiedenen Tiefen als auch die Länge der Aufzeichnung beide unzureichend, um entweder verlässliche Messungen des ozeanischen Wärmegehaltes oder das Monitoring der ozeanischen Strahlungsflüsse zu erlauben:
Einige grundlegende Elemente des Stichprobe-Problems sind in Tabelle 2 gelistet. Etwa 52% des Ozeans ist tiefer als 2000 m und etwa 18% tiefer als 3600 m. Definiert man eine bestimmte Wassermenge als „getestet“, falls mindestens eine CTD-Station innerhalb eines Gitterquadrats von 60 X 60 km² im Zeitintervall 1992 bis 2011 existiert, wurde etwa ein Drittel (11% der Gesamtmenge) Wasser unter 2000 m betrachtet … In Tiefen unter 3600 m waren etwa 17% vermessen … Viele Studien gehen davon aus, dass es in der Tiefsee während des historischen Zeitraumes keine signifikanten Änderungen gegeben hat … Die Historie der Erforschung zeigt jedoch, dass weiße Flächen auf der Karte entweder als uninteressant angesehen und damit aus der weiteren Diskussion ausgeklammert worden sind, oder das andere Extrem war der Fall, die Flächen seien gefüllt mit ,Drachen‘, die herbeigefleht werden, um seltsame Berichte von dort zu erklären (in G. De Jode 1578, Speculum Orbis Terrarum, Antwerpen). …
Jüngst wurden in (60) Schätzungen von Änderungen in der Tiefsee mit einer behaupteten Genauigkeit in der Größenordnung von 0,01 W/m² in den Raum gestellt (äquivalent zu einer Temperaturänderung von 0,0004°C innerhalb von 20 Jahren) unter 700 m. Falls diese Genauigkeit wirklich erreicht worden wäre, wäre die geringe Abdeckung ausreichend, vielleicht erweitert auf die WOCE hydrographische Überwachung und alle paar Jahrzehnte wiederholt“.
Außerdem mangelt es in fast allen Analysen des ozeanischen Wärmegehaltes und -haushaltes an genauer Berücksichtigung der räumlichen, zeitlichen und anderer systematischer Fehler und Unsicherheiten, wie z. B. jene, die in einer Arbeit durch eine Gruppe an der chinesischen Academy of Sciences (12) identifiziert worden sind:
„In dieser Studie wurde eine neue Quelle von Unsicherheiten bei der Berechnung des OHC diagnostiziert, und zwar infolge der ungenügenden vertikalen Auflösung der historischen Ozeantemperaturprofile unter der Oberfläche. Dieser Fehler wurde untersucht mittels einer Stichprobe einer hohen vertikalen Auflösung in einem klimatologischen Ozeanmodell, dem Messungen in Tiefenintervallen von der Oberfläche aus gegenüber gestellt wurden. Dann wurde der Fehler definiert als der Unterschied zwischen dem OHC berechnet aus Stichproben-Profilen und dem OHC des klimatologischen Ozeans. Der so erhaltene auflösungsbezogene Fehler scheint in den oberen 100 m kalt zu sein (mit einem Spitzenwert von etwa -0,1°C), warm in Tiefen zwischen 100 und 700 m (mit einem Spitzenwert um 0,1°C bei 180 m) und warm bei einer Mittelung zwischen 0 und 700 m (mit einem globalen Mittel von ~0,01°C bis -0,025°C sowie ~1 bis 2,5 X 10²² J). Geographisch zeigte sich eine Warmverzerrung innerhalb von 30°S bis 30°N und eine Kaltverzerrung in höheren Breiten beider Hemisphären. Das Vorzeichen hing von der konkaven oder konvexen Krümmung des vertikalen Temperaturprofils ab. Schließlich fordern die Autoren, ein biasfreies Beobachtungssystem in Zukunft zu installieren: Eine minimale vertikale Tiefe von 5% wird gebraucht, um die der vertikalen Auflösung geschuldete Verzerrung auf weniger als 0,005°C des globalen Mittels zu bringen (gleiche Genauigkeit wie bei ARGO).
Und weiter (13):
„…ein neues Korrekturschema für historische XBT-Daten wird vorgestellt für neun verschiedene Stichproben-Typen. Das Schema enthält auch Korrekturen sowohl für die Temperatur als auch für Aufzeichnungen in der Tiefe, die alle mit dem Kalenderjahr variabel sind, außerdem für die Wassertemperatur und den Typ der Stichprobe. Die Ergebnisse bestätigen die in vorhergehenden Studien gefundenen: eine Verlangsamung der Fallrate während der siebziger Jahre und des ersten Jahrzehnts dieses Jahrhunderts sowie der große, rein thermische Bias von 1970 bis 1985. Das Verhalten von neun unterschiedlichen Korrekturschemata wird verglichen. Nachdem die vorgestellten Korrekturen an die XBT-Daten im WOD09-Datensatz angebracht worden waren, wird der globale ozeanische Wärmegehalt von 1967 bis 2010 neu abgeschätzt“.
Eine demnächst erscheinende Studie (14) beschreibt ein vertikales Profil der Temperaturänderung im Ozean von 2004 bis 2013 mit einem Erwärmungs-Stillstand über 100 m und in Tiefen zwischen 300 und 700 m, nachdem einige der Stichproben-Verzerrungen und Instrumentenfehler und Unsicherheiten in den Daten des ozeanischen Wärmegehaltes berücksichtigt worden waren (d. h. der neue globale Ozean-Temperatur-Datensatz vom Institute for Atmospheric Physics wurde angebracht). Die beiden Erwärmung zeigenden Schichten liegen zwischen 100 und 300 sowie 700 und 1500 Metern. Diese Schichten mit Erwärmung zeigen ihre eigenen charakteristischen horizontalen räumlichen Verteilungen, wenn man sie mit den sich nicht erwärmenden Schichten zwischen 300 und 700 Metern vergleicht. Diese beobachtete Tatsache führt zu folgender Schlussfolgerung:
Es ist immer noch unklar, wie die Wärme in die Tiefsee transferiert worden sein soll“.
Außerdem ist der Vorschlag, dass die Wärmeakkumulation in der Tiefsee erklärt, warum es seit 18 Jahren keinerlei globale Erwärmung mehr gegeben hat, in der wissenschaftlichen Literatur alles andere als allgemein akzeptiert. Eine bemerkenswerte Vielfalt von miteinander konkurrierenden und mit oftmals sich widersprechenden Erklärungen für den Stillstand der globalen Erwärmung, hauptsächlich unter Betrachtung der Phänomene nahe der Oberfläche, werden in Studien aus jüngerer Zeit in den begutachteten Journalen der Klimawissenschaft vorgestellt.
[Die folgende Auflistung steht im Original ohne jeden Absatz in einem langen, unübersichtlichen Abschnitt, zum Glück aber mit Ordnungszahlen. Zum besseren Verständnis auch für mich selbst habe ich diesen Abschnitt den Ordnungszahlen folgend unterteilt. Anm. d. Übers.]
In der Literatur wird der Grund für den Stillstand der globalen Erwärmung auf sehr vielfältige Weise erklärt:
1. eine eingeführte Kaltverzerrung durch mangelnde Abdeckung während der letzten Jahre (15), widerlegt von (16) und hinsichtlich der Abdeckung der Arktis von (17);
2. anthropogene Aerosole aus der Kohleverbrennung (18), widerlegt von (19, 20);
3. Abnahme der Erwärmung infolge Absorption durch Ruß (20);
4. Emission von Aerosol-Partikeln durch Vulkanausbrüche (21), widerlegt von (22);
5. reduzierte Sonnenaktivität (23);
6. Effektivität des Montreal-Protokolls bei der Kontrolle der Emissionen von Chlor-Fluor-Kohlenwasserstoffen (24);
7. eine geringere Zunahme der Methan-Konzetration als erwartet (24);
8. eine Abnahme der stratosphärischen Wasserdampf-Konzentration (25);
9. verstärkte Passatwinde im Pazifik (26), (zuvor waren in (27) schwächere Passatwinde im Pazifik der anthropogenen globalen Erwärmung zugeordnet worden);
10. Stadium Waves [?] in der Zirkulation im tropischen Pazifik (28);
11. Zufall (29):
12. Aerosolpartikel von Kiefern (30),
13. Natürliche Variabilität (31, 32);
14. kältere Nachttemperaturen in der Nordhemisphäre (33);
15. Vorhersagen von jenen Modellen, die die Möglichkeit eines Stillstands der globalen Erwärmung zulassen;
16. die negative Phase der Pazifischen Dekadischen Oszillation (36 – 38);
17. die Atlantische meridionale overturning [?] Zirkulation (39);
18. Globale Verdunkelung (dimming), die globalen Aufhellung (brightening) von 1983 bis 2001 folgte (40);
19. relative Häufigkeit bestimmter Arten von El Nino (41);
20. oberflächennahe Abkühlung im äquatorialen Pazifik (42);
21. Abkühlung im Pazifik, verstärkt durch Erwärmung im Atlantik (43);
22. eine Kombination von Faktoren einschließlich der ENSO-Variabilität, Abnahme der Sonnenaktivität und stratosphärische Aerosole (44);
23. unterschätzer Antrieb anthropogener Aerosole (45);
24. eine neue Form multidekadischer Variabilität, die sich von den Ozeanoszillationen unterscheidet, aber mit diesen in Beziehung steht (46) und
25. Scheitern bei der Initialisierung der meisten Modelle, um sie mit Beobachtungen konform zu machen, besonders bei ozeanischen Bedingungen (47).
Und schließlich, obwohl die ARGO-Bojen die Änderung der Ozeantemperatur direkt messen, wird die Temperaturänderung vor der Veröffentlichung in Zetajoule der Änderung des ozeanischen Wärmegehaltes konvertiert, was die Änderung größer aussehen lässt. Die Konversion der OHC-Änderung zurück zu Temperaturänderungen ist sehr erhellend. Sie zeigt, wie gering die tatsächlich gemessene Änderung ist. Die Zunahme des ozeanischen Wärmegehaltes während der 94 ARGO-Monate September 2005 bis Juni 2013 betrug 10 X 10²² J = 100 ZJ (Abbildung 6).
Abbildung 6: Änderung des ozeanischen Wärmegehaltes 1957 bis 2013 aus dem NODC Ocean Climate Laboratory: http://www.nodc.noaa.gov/OC5/3M_HEAT_CONTENT.
Konversion: 650 million km³ x 4 MJ per tonne per Kelvin: each cubic meter is 1,033 tonnes. Then:
100 ZJ increase in ohc 100.000.000.000.000.000.000.000 J
To raise 650.000.000.000.000.000 m³
x 1,033 te m–3 671.450.000.000.000.000 te
x 4,000,000 J te 2.685.800.000.000.000.000.000.000 J per Kelvin
Dann 100.000 / 2.685.800 = 0,037233 K über 94 Monate ist äquivalent zu 0,0457 K pro Jahrzehnt. Dem zufolge beträgt die Änderung der mittleren Ozeantemperatur in den oberen 2000 m während der letzten Jahrzehnte weniger als 0,5 K pro Jahrhundert, selbst nach den ziemlich extremen NODC-Aufzeichnungen des OHC.
References
1. RSS (2014) Satellite-derived monthly global mean lower-troposphere temperature anomaly dataset: http://www.remss.com/data/msu/monthly_time_series/RSS_Monthly_MSU_AMSU_Channel_TLT_Anomalies_Land_and_Ocean_v03_3.txt. Accessed 1 July 2014
2. UAH (University of Alabama at Huntsville) (2014) Satellite MSU monthly global mean lower-troposphere temperature anomalies. http://vortex.nsstc.uah.edu/data/msu/t2lt/uahncdc_lt_5.6.txt. Accessed 1 July 2014
3. NCDC, 2014, National Climatic Data Center monthly global mean land and ocean surface temperature anomalies, 1880-2013, ftp://ftp.ncdc.noaa.gov/pub/data/anomalies/monthly.land_ocean.90S.90N.df_1901-2000mean.dat. Accessed 1 July 2014
4. Morice, CP, Kennedy JJ, Rayner N, Jones PD (2012) Quantifying uncertainties in global and regional temperature change using an ensemble of observational estimates: The HadCRUT4 data set. J. Geophys Res 117:D08101. doi:10.1029/2011JD017187
5. GISS, 2014, Goddard Institute for Space Studies monthly global mean land and sea surface temperature anomalies, 1880-2014, http://data.giss.nasa.gov/gistemp/tabledata_v3/GLB.Ts+dSST.txt. Accessed 1 July 2014
6. McKitrick RR (2014) HAC-robust measurement of the duration of a trendless subsample in a global climate time series. Open J Stat 4:527-535
7. Meehl GA, Arblaster JM, Fasullo JT et al (2011) Model-based evidence of deep-ocean heat uptake during surface-temperature hiatus periods. Nat Clim Change 1: 360–364
8. Balmaseda MA, Trenberth KE, Källen E (2013) Distinctive climate signals in reanalysis of global ocean heat content. Geophys Res Lett 40:175401759
9. Trenberth KE, Fasullo JT, Balmaseda MA (2014) Earth’s energy imbalance. J Clim 27:3129-3144
10. Chen X, Tung KK (2014) Varying planetary heat sink led to global-warming slowdown and acceleration. Science 345: 897–903
11. Wunsch C, Heimbach P (2014) Bidecadal thermal changes in the abyssal ocean. J Phys Oceanol 44: 2013–2030
12. Cheng L, Zhu J (2014) Uncertainties of the ocean heat content estimation induced by insufficient vertical resolution of historical ocean subsurface observations. J Atm Oceanic Tech 31: 1383–1396
13. Cheng L, Zhu J, Cowley R et al (2014a) Time, probe type, and temperature variable bias corrections to historical expendable bathythermograph observations. J Atm Oceanic Tech 31: 1793–1825
14. Cheng L, Zheng F, Zhu J (2014b) Distinctive ocean interior changes during the recent climate hiatus. Geophys Res Lett submitted
15. Cowtan K, Way RG (2014) Coverage bias in the HadCRUT4 temperature series and its impact on recent temperature trends. Quart J R Meteot Soc 140: 1934-1944
16. Fyfe JC, Gillet NP, Zwiers FW (2013) Overestimated global warming over the past 20 years. Nat Clim Change 3: 767-769
17. Chung CE, Cha H, Vilma T et al (2013) On the possibilities to use atmospheric reanalyses to evaluate the warming structure of the Arctic. Atmos Chem Phys 13: 11209-11219
18. Kaufmann RK, Kauppi H, Stock JH (2011) Reconciling anthropogenic climate change with observed temperature 1998-2008. Proc Natl Acad Sci USA 108: 11790-11793
19. Kühn T, Partanen A-I, Laakso A et al(2014) Climate impacts of changing aerosol emissions since 1996. Geophys ResLett 41: 4711-4718
20. Neely RR, Toon OB, Solomon S et al (2013) Recent anthropogenic increases in SO2 from Asia have minimal impact on stratospheric aerosol. Geophys Res Lett 40. doi: 10.1002/grl.50263
21. Santer BD, Bonfils C, Painter JF et al (2014) Volcanic contribution to decadal changes in tropospheric temperature. Nat Geosci 7:185-189
22. Haywood J, Jones A, Jones GS (2014) The impact of volcanic eruptions in the period 2000-2013 on global mean temperature trends evaluated in the HadGEM2-ES climate model. Atmos Sci Lett 15: 92-96
23. Stauning P (2014) Reduced solar activity disguises global temperature rise, Atmos Clim Sci 4: 60-63
24. Estrada F, Perron P, Martinez-Lopez B (2013) Statistically derived contributions of diverse human influences to twentieth-century temperature changes. Nat Geosci 6: 1050–1055
25. Solomon S, Rosenlof KH, Portmann RW et al(2010) Contributions of stratospheric water vapor to decadal changes of global warming. Science 327: 1219-1223
26. England MH, McGregor S, Spence P et al (2014) Recent intensification of wind-driven circulation in the Pacific and the ongoing warming hiatus. Nat Clim Change 4: 222-227
27. Vecchi ga, Soden BJ, Wittenberg AT, et al (2006) Weakening of tropical Pacific atmospheric circulation due to anthropogenic forcing. Nature 441: 73-76.
28. Glaze Wyatt M, Curry JA (2013) Role for Eurasian Arctic shelf sea ice in a secularly varying hemispheric climate signal during the 20th century. Clim Dyn 42: 2763-2782
29. Schmidt GA, Shindell DT, Tsigaridis K (2014) Reconciling warming trends. Nat Geosci 7(158-160). doi: 10.1038/ngeo2105
30. Ehn M, Thornton JA, Kleist E, et al (2014) A large source of low-volatility secondary organic aerosol. Nature 506:476-479
31. Watanabe M, Shiogama H, Tatebe H et al (2014) Contribution of natural decadal variability to global warming acceleration and hiatus. Nat Clim Change 4: 893–897
32. Lovejoy S (2014) Return periods of global climate fluctuations and the pause. Geophys Res Lett 41:4704-47
33. Sillmann, J, Donat MG, Fyfe JC et al (2014) Observed and simulated temperature extremes during the recent warming. Environ Res Lett 9. doi: 10.1088/1748-9326/9/6/064023
34. Risbey J, Lewandowsky S, Langlais C,et al (2014) Nat Clim Change 4:835-840
35. Guemas V, Doblas-Reyes FJ, Andreu-Burillo I et al (2013) Retrospective prediction of the global warming slowdown in the past decade. Nat Clim Change 3:649-653
36. Maher N, Sen Gupta A, England MH (2014) Drivers of decadal hiatus periods in the 20th and 21st centuries. Geophys Res Lett 41:5978-5986
37. Trenberth KE, Fasullo JT, Branstator G et al (2014) Seasonal aspects of the recent pause in surface warming. Nat Clim Change 4: 911–916
38. Dong L, Zhou T (2014) The formation of the recent cooling in the eastern tropical Pacific Ocean and the associated climate impacts: a competition of global warming, IPO and AMO. J Geophys Res doi: 10.1002/2013JD021395
39. Schleussner CF, Runge J, Lehmann J, et al (2014) The role of the North Atlantic overturning and deep ocean for multi-decadal global-mean-temperature variability. Earth Sys Dyn 5:103-115
40. Rahimzadeh F, Sanchez-Lorenzo A, Hamedi M, et al (2014) New evidence on the dimming/brightening phenomenon and decreasing diurnal temperature range in Iran (1961-2009). Int J Climatol doi: 10.1002/joc.4107
41. Banholzer S, Donner S (2014) The influence of different El Nino types on global average temperature. Geophys Res Lett 41:2093–2099
42. Kosaka Y, Xie SP (2013) Recent global-warming hiatus tied to equatorial Pacific surface cooling. Nature 501: 403–407
43. McGregor S, Timmermann A, Stuecker MF, England MH, Merrifield M, Jin FF, Chikamoto Y (2014) Recent Walker circulation strengthening and Pacific cooling amplified by Atlantic warming. Nature Clim. Change 4:888-892. doi: 10.1039/nclimate2330
44. Huber M, Knutti R (2014) Natural variability, radiative forcing and climate response in the recent hiatus reconciled. Nat Geosci 7: 651–656
45. Hansen J, Sato M, Kharecha PK, et al(2011) Earth’s energy imbalance and implications. Atmos. Chem Phys 11:13421-13449.
46. Maclas D, Stips A, Garcia-Gorriz E (2014) Application of the Singular Spectrum Analysis Technique to Study the Hiatus on the Global Surface Temperature Record. Plos One. doi: 10.1371/journal.pone.0107222
47. Meehl, GA, Teng H (2014) CMIP5 multi-model hindcasts for the mid-1970s shift and early 200s hiatus and predictions for 2016-2035. Geophys. Res. Lett. 41(5):17y11-1716
Link: http://wattsupwiththat.com/2015/01/03/the-great-pause-lengthens-again/
Übersetzt von Chris Frey EIKE
Satelliten messen also Strahlung, lieber Herr Müller.
Zeigen diese Strahlen, mit der dann offensichtlich die Temperatur ERRECHNET wird, woher sie kommen?
Antwort: NEIN
Das bessere Gerät ist also die aufsteigende Ballonsonde.
mfG
„Mal eine vielleicht blöde Frage, weil ich es nicht weiß: in welcher Höhe messen diese Satelliten eigentlich die Temperatur der Troposphäre?“
In verschiedenen Höhen, der wiki Artikel „MSU temperature measurements“ beschreibt das als Einstieg ganz gut. Meist werden die Daten der Lower Troposphere gezeigt.
„Rahmstorf und Co argumentieren ja immer, dass sich die Troposphäre abkühlen muss …“
Es ist die Stratosphäre, die sich abkühlen soll und auch die wird von den Satelliten vermessen. Kann man sich z.B. bei RSS ansehen: „Upper Air Temperature“ – http://goo.gl/ATyJgM
Die Satelliten messen mit Mikrowellen die Sauerstoffmolekülemissionen und können dementsprechend keine Vertikalprofile erstellen. Satellitenmessung ist zwar ne feine Sache, aber mit einem Radiosondenaufstieg kriegt man eine sehr hohe vertikale Auflösung hin. Ist allerdings ziemlich teuer. Und was sind schon 30 Jahre Satellitenmessungen mit einer horizontalen Auflösung von 100 km ohene Vertkalprofil gegenüber 70 mit Radiosonden, die auch noch gleich Windgeschwindigkeit, -richtung und Luftfeuchte liefern.
Eine Antwort von EIKE oder Herrn Heinzow wäre mir lieb, denn was die Forentrolle schreiben werden, ist eh klar, ansonsten ist das Netz sowieso grün verseucht, schlimmer als eine Landplage.
“ ein Abwehrsystem gegen Asteroiden wäre das eine sinnvollere Geldvernichtung!“
Hallo Herr Seilkopf,
eine gute Idee, aber ich hab da was wirkungsvolleres:
64 Raumforts im Orbit, bewaffnet mit den neuesten Laserwaffen von den Amis und viel Atomraketen und dem ganzen Drumherumgedöhns.
Ist viel teurer als die Asteroidenabwehr je sein kann und damit viel effizienter.
Warum brauchen wir das?
Von der Weltökoidiotenpresse völlig unbemerkt sammeln Aliens grade eine Invasionsflotte hinter der Bahn des Pluto.
Mutti weiß davon nix, weil die Umfragen, nach denen sie ihren Mantel in den Wind hängt, dazu nix sagen. Bild (ihre zweite Bildungsbroschüre) weiß darüber auch nix, da die ganze Redaktion auf dem Bayerngelände versammelt ist, um zu sehen wann Uli Hoeneß zum Pinkeln geht.
Damit bin ich in meiner verzweifelten Lage ganz alleine mit meinem Wissen um diese Gefahr.
Und falls ich mich irren sollte:
Müssen wir nicht Vorsorge betreiben für den Fall, daß die Aliens doch kommen?
Wer kann verantworten für diesen Fall nicht vorbereitet zu sein?
Insbesondere auch weil Aliens am liebsten mit Latzhose und Jesusreifen bewaffnete Gutmenschen fressen?
Nein, es bestätigt scheinbar die andernorts zwar als falsch nachgewiesenen Argumente der IPCC/PIK/CO2-Fans und ist damit absolut unangreifbar. Die Wirkung vom klimawärmenden anthropogen erzeugten CO2 mittels Schwefeltropfen reduzieren: Ja geht’s noch besser!
Ich bin lediglich volkswirtschaftlich ausgebildet und kann über chemische … Prozesse nichts begründet aussagen. Aber so viel weiß ich: nach schweren vulkanischen Ereignissen regnete u.a. es Schwefel mit fatalen Folgen auf die Erde. Steht schon in der Bibel.
Nein, es bleibt dabei: Derzeit ist die Kaste der Prediger von Physikern besetzt. Sie verheißen uns glorreiche Jahre, wenn wir uns nur an ihre begutachteten Studien halten, was heißt: viel Geld spenden! Nicht wie in den Klingelbeutel, es bissle mee sollte es scho sei!
Waren es vorher über etwa 20 Jahre die Ökonomen (incl. der Zukunftsforscher und versuchsweise der Soziologen), die mit allerlei Prognosen auf das Verhalten von Staaten eingewirkt haben, davor hin und wieder Chemiker (u.a. 1. Weltkrieg – chemische Waffen), bis in die 60er Jahre des letzten Jahrhunderts aber vor allem die „normalen“ Prediger (Pfarrer und Priester der hier noch üblichen Religionen, die jahrhundertelang den (Zeit-)Geist und damit die Politiken in den betr. Ländern beherrscht haben oder zu beherrschen versuchten, zwischenzeitig abgelöst mit übelsten Folgen durch die NS-Prediger, so schafften es seit 20 Jahren etwa Physiker spezifischer Provenienz, sich mit diesen apokalyptischen Thesen Raum/Geld zu verschaffen. Willige Gehilfe des immerwährenden Kapitalismus, denn hinter allem steht doch die Gier nach „money, money, money … makes the world go round“ oder wie ein sehr erfolgreicher Prediger in Harlem mal sagte: I don’t like cash, I like money“.
Wer hat denn das IPCC tatsächlich gegründet?
Dennoch: Superbeitrag und xxl-faches Lob an Herrn Frey.
Ganz ehrlich, wenn man solchen Schwachsinn sogar in Harvard lehrt (!), dann sollte man doch bitte schön auch damit anfangen, ein Abwehrsystem gegen Asteroiden wäre das eine sinnvollere Geldvernichtung!