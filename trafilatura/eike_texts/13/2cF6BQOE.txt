Wurde sie gerade noch einmal abgewendet, diese schreckliche Klimakatastrophe? Zumindest in Lingen? Das war – zur Erinnerung – bei jener Hitzewelle vor kurzem bekanntlich Deutschlands heißester Ort. Eine Station des Deutschen Wetterdienstes registrierte am 25. Juli der Wert von 42,6 °C, der von Medien und Potsdamer Klimakatastrophisten als Vorstufe zur Wetterhölle erklärt wurde.
Doch jetzt hat der private Wetterdienst »Wetter online« diesen Wert zurückgezogen: Rekord unbrauchbar. »Bezüglich des Standorts gibt es aber so viel berechtigte Kritik, dass Wetter online diesen Rekordwert nicht anerkennt.«
Historisch sei die Hitze im letzten Julidrittel ohne Zweifel gewesen, bekundet Wetter online. In Geilenkirchen wurde der alte Rekord von 40,3° am 24. Juli mit 40,5° knapp überboten. Danach hatten verschiedene Stationen mehr als 40° gemeldet. »So etwas hat es in Deutschland seit Beginn der regelmäßigen Wetteraufzeichnungen nicht gegeben.«
In Duisburg und Tönisvorst zeigte das Thermometer 41,2° an. Lingen kam dann in die Schlagzeilen mit 42,6°. Doch diese Messstelle in Lingen erfüllt jetzt nicht mehr den Standard der Weltorganisation für Meteorologie WMO. Denn es ist nicht egal, wo und wie das Thermometer steht und die Umgebung beschaffen sein soll. Der Messfühler muss abgeschattet sein, so dass er nicht von der Sonnenstrahlung oder der Wärmeabstrahlung eines Mauerwerkes beeinflusst wird. Er muss zudem ausreichend belüftet werden.Doch gerade im Umfeld der Station in Lingen wuchsen die Büsche in den vergangenen Jahren so, dass rund um die Wetterstation eine Wärmeinsel entstand, in der Wärme gestaut wurde. Höhere Temperaturen sind also nicht weiter verwunderlich. Die Station in Lingen geriet schon in den vergangenen Jahren in die Kritik, weil der Unterschied der Messwerte zu den umliegenden Stationen von Jahr zu Jahr größer wurde. Wetterunternehmer Jörg Kachelmann kritisierte den Standort der Station schon seit längerem; er wusste um den Effekt der Wärmeinseln.
Auch der Deutsche Wetterdienst DWD plante seit einigen Jahren, die Station zu verlegen. Allerdings fürchtet der Dienst die politischen Folgen einer solchen Verlegung. Wetter online: »Erkennt man den Wert nicht an, rücken »Klimawandelleugner« auf den Plan und erklären, dass es nach dem Medienhype gar nicht so heiß gewesen sei. Wird er für ungültig erklärt, wären wohl schnell unangenehme Fragen zur Standardqualität im Allgemeinen aufgetaucht.«
Denn Temperaturmessungen sind nach einem alten Spruch von Meteorologen das größte Problem dieser Zunft. Wo wird gemessen? Jeder kennt das: Steht in einem Zimmer das Thermometer nah an einem Ofen, ist es wärmer als in der Ecke gegenüber. Wo also ist die wahre Zimmertemperatur?
Die Vorschriften für offizielle Temperaturmessungen sehen einen Standort der Wetterhäuschen zwei Meter über dem Boden auf einer freien Fläche vor. Der Messfühler muss abgeschattet sein, ein Ventilator die Luft durchwedeln. Das Thermometer soll nicht die eigene Wärme messen, sondern die der Luft.
Besonders delikat sind Vergleiche der Temperaturentwicklung über vergangenen Jahrzehnte oder gar Jahrhunderte hinweg. Messtechnik ändert sich, ebenso wandeln sich die Gegebenheiten rund um die Messstationen. Häuser werden gebaut oder Wände hochgezogen, die die Temperaturen in der Umgebung verändern. Häufig muss der Wetterdienst auch den Standort seiner Station verändern. Messstationen mussten umgestellt werden, weil die Ableser laut Protokoll des Wetterdienstes unfähig waren, regelmäßig die Werte abzulesen und weiterzugeben.So wurde die Station in Bad Dürkheim, in der Rheinebene nahe dem Pfälzer Wald gelegen, mehrfach verlegt. »Am 13.9.1977 wurden die Beobachtungen an der jetzigen Station wegen Unfähigkeit des Beobachters eingestellt.« Zwei Monate später wurde ein neuer Beobachter gefunden und die Station wieder entsprechend verlegt. Da auch dieser Beobachter ausschied, ruhte die Station vom vom 21.10.1987 bis 14.4.1988. Die Station meldete rückgängige Temperaturen. Es ist also ein sehr schwieriges Unterfangen, Temperaturmesswerte über viele Jahre zu vergleichen. Meteorologen versuchen daher, stark schwankende Daten durch statistische Verfahren zu »homogenisieren«, etwas böse ausgedrückt: passend zu machen.
Wie schwierig, ja unmöglich es ist, die Entwicklung von Temperaturen über die letzten 100, 200 Jahre sogar auf die Nachkommastelle genau anzugeben, zeigte einst die wichtige Arbeit von Michael Limburg, der als Ingenieur im Bereich der Messtechnik und Fehlerstatistik gearbeitet und die entsprechenden Erfahrungen gesammelt hat: »Analyse zur Bewertung und Fehlerabschätzung der globalen Daten für Temperatur und Meeresspiegel und deren Bestimmungsprobleme« lautete der etwas sperrige Titel.
Limburg ging in seiner Dissertation der Frage nach, ob die meteorologischen Daten der vergangenen 150 Jahre genau genug sind, um den Verlauf der »Globalen Mitteltemperatur« auf 1/10 Grad Celsius genau zu berechnen. Dieser Verlauf spielt in der aktuellen Klimadebatte eine wichtige Rolle; belegen die einen damit doch, dass es wärmer, die anderen, dass es kälter wird.
Doch die wichtige Frage ist: Lässt sich eine solche Aussage überhaupt treffen? Satelliten vermögen heute sehr genau alle möglichen Wetterdaten wie Temperaturen der verschiedenen Oberflächen zu messen. Sie gibt es allerdings erst seit etwa knapp 40 Jahren. Davor beruhen die Temperaturangaben auf Messungen unterschiedlicher Messstationen. Bei denen hängt es sehr davon ab, wo und wie die Thermometer angebracht sind. Über einer Wiesenfläche ergeben sich andere Temperaturen als über Asphaltflächen. Ziemlich schwierig, wenn man sehr unterschiedlich zustande gekommene Temperaturaufzeichnungen mit vielen dubiosen Angaben miteinander vergleichen und Trends herauslesen will.Das Ergebnis der Dissertation von Limburg:
»Dabei kam ich zu dem eindeutigen Ergebnis, dass die verwendeten historischen Wetter-Messdaten dies nicht erlauben. Ich fand heraus, dass die bei der Berechnung der globalen Mitteltemperatur unvermeidliche verbleibende Unsicherheit mindestens genau so groß ist wie die ganze offiziell angegebenen Änderung über 150 Jahre, wahrscheinlich aber sogar ein Vielfaches beträgt. Dies ergibt sich zwangsläufig bei Anwendung aller gängigen und vielfach erprobten Regeln der Messtechnik und der statistischen Fehlerrechnung.«
Dieses Ergebnis schreckte die prüfenden Professoren erheblich auf. Limburg weiter: »Die Arbeit stellte ja indirekt wesentliche Aussagen zur angeblichen ›menschengemachten Klimaerwärmung‹ und damit einen der Hauptgründe für die Förderung der sogenannten ›Erneuerbaren Energien‹ infrage. Für beide Themenkomplexe gibt es jedoch höchst umfangreiche Fördergelder. Vermutlich befürchteten die Verantwortlichen diesbezügliche Nachteile, falls sie einer Arbeit Platz und dem Autor einen akademischen Grad zugestanden, der dem bisherigem Dogma – und sei es auch nur indirekt – widersprach.«
Man kann sich vorstellen, wie der Blutdruck der Herren Prüfprofessoren hochschnellte. Die erste Kommission, die die Promotionsarbeit prüfen sollte, trat tatsächlich geschlossen zurück. Begründung: »Weitgehende politische Motivationder Arbeit«.
Um es kurz zu machen: Die Arbeit wurde nach einer hanebüchenen Odyssee schließlich abgelehnt. Es darf nicht belegbar sein, was nicht ins politische Konzept passt.
Nur die Entwicklung der Temperaturen über Jahrhunderte hinweg wird nach wie vor so genau angegeben, wie dies messtechnisch überhaupt nicht möglich ist. Doch ist sie ist Grundlage jener wilden These der Klimakatastrophe, auf der moderne Ablasshändler ihre Geschäfte aufbauen.
Der Beitrag erschien zuerst bei TE hier
So hot that we can see those Urban Heat Islands from space
Dieser Beitrag ist in der Übersetzung und wird demnächst hiert auf Deutsch erscheinen.
Chris Frey
Das ist die Art von Kommentar, die ich darauf erwarte, denn ich lese hier mit und registriere das automatisch.
Seit Jahren schreibe ich, die werden noch ne Kohle drauflegen. Ich muß mich berichtigen: mehrere Schüppen Kohle hamse grad wieder drauf gelegt!
Was helfen kann (Vorbehalt: es wird kälter, weil es wärmer wird … das Paradoxon lebt): die u.a. von Prof. Abdusamatov bereits 2006 angekündigte Abkühlung (die ich gar nicht haben will!) ab 2014 plus 5 Jahre findet tatsächlich statt. Und zwar so, wie prognostiziert: Richtig munter. Das Wasser im Eimer vom Herrn Schellnhuber zum Abkühlen friert ein.
Eine andere Sache ist die Ungenauigkeit von Temperaturmessungen über Jahrzehnte. Auch da liegen Sie und Herr Limburg richtig, aber Sien unterliegen auch einem Denkfehler: Warum sollte die Toleranz von Thermometern nur nach einer Richtung ausschlagen, sprich eine Erwärmung heute vorgaukeln, indem sie früher durchweg zu niedrige Werte anzeigen? Dann müsste man ja schon Ende des 19. Jahrhunderts begonnen haben, Messgeräte zu manipulieren, um 2019 eine Klimakatastrophe erfinden zu können. Das ist nicht überzeugend – insofern könnte Messungenauigkeit mit ebenso großer Wahrscheinlichkeit bedeuten, dass die Erwärmung noch stärker ist als amtlich festgestellt.
Ein weiteres: Wenn schon Messgeräte große Toleranzen zeigen, wie steht es dann erst um die Proxys? Können dann die „mittelalterliche Warmzeit“ und das „römische Klimaoptimum“ als Indiz dafür herangezogen werden, dass die aktuell beobachtete Klimaveränderung eine ausschließlich natürliche ist?
Die früheren Glasthermometer für meteorologische Messungen als auch die heute üblichen elektrischen Fühler wurden / werden in Flüssigkeits-Umwälz-Bädern kalibriert. „Wärmeübertragung“ vom Bad zum Fühler also nur durch Wärmeleitung von der bewegten Flüssigkeit durch die Wandung des Fühlers zum Sensor / zur thermometrischen Flüssigkeit. Strahlung darf bei der Klaibrierung nicht vorkommen.
Strahlung sollte aber auch in der Anwendung nicht vorkommen (weshalb die „Englische Hütte“ entwickelt wurde), ist aber erst recht bei den heutigen automatischen Stationen (für mich temperaturseitig „Messkrücken“ …) nicht zu vermeiden. Dazu kommt, dass Quecksilberthermometer durch die konvexe und durchsichtige Glasoberfläche mit der als Hochglanzspiegel wirkenden Quecksilberfüllung als Strahlungsspiegel gewirkt haben und nicht ganz so „affin“ waren bezüglich Wärmestrahlung wie die heutigen Fühlerkonstrukte. Die Holzhütten hatten zudem eine wesentlich schlechtere Wärmeleitung nach innen, sodaß doch eher die durchströmende Luft gemessen wurde.
Die Sonne mit ihrer Oberflächentemperatur von über 5500 °C bestrahlt nun die Erde und erzeugt je nach Oberflächenbeschaffenheit und Konvektion Temperaturen, die nur eine Richtung kennen. Das ist die einzige Ursache dafür, dass die Messfehler bei der meteorologischen Temperaturmessung in der Praxis nur eine Richtung haben. Konnten Sie folgen?
Laut Patzelt und Nicolussi war die höchste holozäne Baumgrenzeim Kaunertal weit weniger als 400m über der heutigen Baumgrenze (und das war ca. 8000 Jahre BP) .
https://www.dwd.de/DE/leistungen/besondereereignisse/temperatur/20190801_hitzerekord_juli2019.pdf?__blob=publicationFile&v=3
Ein kurzer Blick auf das ESA-Bild zeigt, dass Lingen tatsächlich ein Hotspot war (UHI möglicherweise):
https://www.esa.int/spaceinimages/Images/2019/07/Extreme_heatwave
(eine hochauflösende Version kann heruntergeladen werden). Lingen ist der Hot-Spot unterhalb des Wolkenfeldes südlich der Ems-Mündungsbucht.
Das Argument, die Messung war möglicherweise nicht korrekt, da die Umlandstationen niedrigere Werte ermittelt hatten, lässt sich mit dem ESA-Bild entkräften. Man sieht auch deutlich, dass die Stadtkerne der großen Städte sogar noch deutlich über dem Lingen-Wert waren. Ein schönes UHI-Beispiel selbst auf einer so kleinmassstäbigen Darstellung.
MfG
Ketterer
Aber das muß man den ganzen „Experten“ erstmal erklären.
Carsten
https://www.pik-potsdam.de/services/klima-wetter-potsdam/klimazeitreihen/bodentemperatur/index_html