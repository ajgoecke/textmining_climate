Sie liefern auch einen wahrscheinlichen Wert von 2,4°C auf Seite 9, obwohl sie auf Seite 2 einen Wert „nahe 3,0“ angeben. Der Wert auf Seite 9 ist nicht weit entfernt von der empirischen Schätzung von 2°C von Guy Callendar aus dem Jahr 1938, aber deutlich höher als der von Nic Lewis und Judith Curry (Lewis & Curry, 2018) angegebene Wert von 1,2°C bis 1,95°C (Bereich von 17% bis 83%, best estmate 1,5°C).
Das IPCC schätzt in seinem AR5-Bericht (Bindoff & Stott, 2013) die ECS auf einen Temperaturbereich zwischen 1,5°C und 4,5°C und liefert kein best estimate. Diese Spanne entspricht genau der des Charney-Berichts vor 34 Jahren. Während sich die empirischen, auf Beobachtungen basierenden Schätzungen deutlich verringert haben, hat sich die theoretische Bandbreite nicht verändert, obwohl Tausende von staatlich finanzierten Wissenschaftlern Milliarden von Dollar dafür ausgegeben haben. Die Daten sind heute sehr ähnlich, und es scheint keine Rolle zu spielen, dass sie mit leistungsfähigeren Computern und Milliarden von Dollar schneller ausgegeben werden. Mit Dung funktioniert es auf dieselbe Weise.
[Hervorhebung vom Übersetzer]
Wenn wir den AR5 genau unter die Lupe nehmen, wie es Monckton et al. in MSLB15 taten, einem Aufsatz mit dem Titel „Why Models run hot: results from a irreducially simple climate model“ (Monckton, Soon, Legates, & Briggs, 2015), sehen wir, dass die Elemente der theoretischen AR5-Berechnungen darauf hindeuten, dass sich der Bereich nach unten verengt. Angesichts des politischen Umfelds beim IPCC kann man leicht vermuten, dass die Politiker nicht zugeben wollen, dass die theoretischen Risiken des CO2-bedingten Klimawandels abnehmen. Je mehr empirische Schätzungen des CO2-Effekts erscheinen und je mehr theoretische Arbeit geleistet wird, desto mehr fragt man sich, wie lange die Politiker die deutlich überhöhte Spanne von 1,5°C bis 4,5°C noch unterstützen können.
Die Schätzungen der ECS sind seit langem rückläufig, wie Nicola Scafetta und Kollegen 2017 gezeigt haben. Abbildung 1 stammt aus ihrer Studie:
In den 1980er Jahren wurde die Idee der katastrophalen, vom Menschen verursachten (oder anthropogenen) globalen Erwärmung (CAGW) entwickelt. Seitdem schlagen die Alarmisten Jahr für Jahr die Trommel. In den Vereinigten Staaten fand am 23. Juni 1988 im Dirksen-Senatsbürogebäude in Washington, DC eine Senatsausschusssitzung zum Thema CAGW statt, die von Senator Tim Wirth ausgerichtet wurde. Es war ein heißer und feuchter Tag im sumpfigen Washington, DC. Das Treffen war ein Wendepunkt, was nicht zuletzt Dr. James Hansen von der NASA zu verdanken war. In seiner Präsentation vor dem Kongressausschuss sagte er:
„1988 ist es wärmer als jemals zuvor in der Geschichte der instrumentellen Messungen.
Alles in allem sind die Beweise dafür, dass sich die Erde um einen Betrag erwärmt, der zu groß ist, um eine zufällige Fluktuation zu sein, und die Ähnlichkeit der Erwärmung mit der durch den Treibhauseffekt zu erwartenden, ein sehr starker Fall. Meiner Meinung nach … ist der Treibhauseffekt entdeckt worden, und er verändert jetzt unser Klima.
Die gegenwärtig beobachtete globale Erwärmung liegt nahe 0,4 Grad C, relativ zur ‚Klimatologie‘, die als Mittelwert der dreißig Jahre (1951 – 1980) definiert ist. … können wir mit etwa 99-prozentiger Sicherheit feststellen, dass die gegenwärtigen Temperaturen eher einen echten Erwärmungstrend als eine zufällige Schwankung über den Zeitraum von 30 Jahren darstellen“. (Hansen, 1988)
ExxonMobil glaubte, dass die natürliche Variabilität ±0,5°C betrug. Man war der Meinung, dass eine Veränderung größer als diese sein musste, um signifikant zu sein. Offensichtlich schränkte Hansen diesen natürlichen Bereich irgendwie ein. Die Welt kühlte sich von 1944 bis 1977 global ab und begann sich dann 1978 zu erwärmen. Ein Anstieg von 0,4°C ist nicht viel, so dass die Verwendung dieses Wertes, um festzustellen, dass der „Treibhauseffekt“ nach einer langen Abkühlungsperiode festgestellt wurde, hätte Stirnrunzeln und Fragen hervorrufen müssen. Man beachte, dass Hansen „Treibhauseffekt“ sagt, wenn er den „vom Menschen verursachten Treibhauseffekt“ oder „verstärkter Treibhauseffekt“ meint. Es gibt einen natürlichen Treibhauseffekt, der durch natürliches CO2 und andere Treibhausgase, insbesondere Wasserdampf, verursacht wird. Dies ist der Beginn einer Täuschungstaktik, die von den Alarmisten häufig angewendet wird. Um die natürlichen Ursachen des Klimawandels zu ignorieren, setzen sie den „Treibhauseffekt“ mit dem „vom Menschen verursachten Treibhauseffekt“ gleich. Außerdem verwenden sie „globale Erwärmung“ als Synonym für „vom Menschen verursachte globale Erwärmung“, und „Klimawandel“ ist gleichbedeutend mit „vom Menschen verursachter Klimaänderung“. Diese Art von trügerischer und manipulativer Sprache wird auch heute noch verwendet.
Die IPCC-Berichte
Der erste IPCC-Bericht (FAR) unter dem Vorsitz von Bert Bolin stellte fest, dass die globale Erwärmung bis 1992, als der Bericht veröffentlicht wurde, in den Bereich der „natürlichen Klimavariabilität“ fiel und nicht unbedingt auf menschliche Aktivitäten zurückzuführen war (IPCC, 1990, S. XII). Sie hielten den eindeutigen Nachweis eines menschlichen Einflusses „für ein Jahrzehnt oder länger für unwahrscheinlich“. Bert Bolin war der Meinung, dass James Hansens Aussage im Kongress 1988 die Bedeutung der jüngsten globalen Erwärmung übertrieben habe.
Der zweite, 1996 veröffentlichte Bericht SAR kam zu dem Ergebnis, dass „die Abwägung der Beweise auf einen erkennbaren menschlichen Einfluss auf das globale Klima hindeutet“. (IPCC, 1996, S. 4). Dies basierte jedoch auf unveröffentlichten und nicht überprüften Arbeiten von Benjamin Santer und Kollegen. Seine Studie legte nahe, dass die Vorhersagen der Klimamodelle über die Erwärmung in der Troposphäre und die Abkühlung in der Stratosphäre dem entsprachen, was sich abspielte. Er nannte dies einen „Fingerabdruck“ des menschlichen Einflusses auf das Klima (Santer, et al., 1996a). Nach der Veröffentlichung der Studie stellte sich heraus, dass Santer bzgl. dieses Fingerabdrucks „Rosinenpickerei“ betrieben hatte (Michaels & Knappenberger, 1996). Die Studie wurde zurückgewiesen, und der IPCC wurde gedemütigt. Diese Demütigung wurde noch dadurch verstärkt, dass die für den IPCC verantwortlichen Politiker dabei erwischt wurden, wie sie die wissenschaftlichen Berichte innerhalb der SAR veränderten, um sie ihrer Summary for Policymakers anzupassen (Seitz, 1996).
Der 2001 veröffentlichte dritte Bericht TAR stellte fest, dass „der Großteil der in den letzten 50 Jahren beobachteten Erwärmung wahrscheinlich auf den Anstieg der Treibhausgaskonzentrationen zurückzuführen ist“. (IPCC, 2001, S. 10). Sie stützten diese Entscheidung auf den „Hockeyschläger“, der sich später als fehlerhaft erwies. Bis zur Veröffentlichung des vierten Berichts (AR4) im Jahr 2007 zeigten zahlreiche Untersuchungen des Hockeyschlägers, dass er fehlerhaft war und zu wenig Variabilität aufwies. Dies wurde im vierten Bericht, AR4, von Keith Briffa eingeräumt, der, etwas beschönigend, schrieb, dass der Hockeyschläger zu empfindlich auf bestimmte Proxies (Baumringe) und die statistischen Verfahren (Hauptkomponenten) reagierte, welche zu seiner Konstruktion verwendet worden waren (IPCC, 2007b, S. 436). Willie Soon und Sallie Baliunas zeigten, dass der Hockeyschläger nicht die Daten widerspiegelte, die zu seiner Konstruktion verwendet wurden (Soon & Baliunas, 2003). Der Hockeyschläger entpuppte sich als eine ausgeklügelte Fiktion, die einzig und allein aus einem fehlerhaften statistischen Verfahren und einem schlecht ausgewählten Satz von Temperaturproxies entstand (National Research Council, 2006, S. 112-116) und (Wegman, Scott, & Said, 2010, S. 4-5, 48-50).
Als AR4 im Jahr 2007 veröffentlicht wurde, hatte die Führung des IPCC aufgegeben, direkte Beweise dafür zu finden, dass der Mensch den Klimawandel beherrscht. Sie hatten es mit dem „Fingerabdruck“ von Santer und dem „Hockeyschläger“ von Michael Mann versucht und konnten die Öffentlichkeit mit beidem nicht überzeugen. So versuchten sie im AR4, die Öffentlichkeit mit Klimamodellen zu überzeugen, dass „der größte Teil des beobachteten Anstiegs der globalen Durchschnittstemperaturen seit Mitte des 20. (IPCC, 2007b, S. 10) sehr wahrscheinlich der beobachteten Zunahme von Treibhausgasen in der Atmosphäre geschuldet ist“. Sie präsentieren keine Beobachtungen, sondern lediglich Modellergebnisse. Der fünfte Bericht, AR5, war lediglich eine Wiederholung von AR4. Dieselben zwei Modelle, dasselbe Ergebnis. Wie bereits erwähnt, zeigte MSLB15 (Monckton, Soon, Legates, & Briggs, 2015), dass die neueren Ergebnisse des AR5-Modells darauf hindeuteten, dass die Schlagzeilen des IPCC die Empfindlichkeit des Klimas gegenüber CO2 überbewerten, aber dieses Ergebnis wurde im Bericht weder erklärt noch eingeräumt.
Während also die empirischen Berechnungen der Klimasensitivität gegenüber CO2 nun eine ECS zwischen 1,1°C und 2,45°C zeigen (siehe Tabelle 1), blieben die theoretischen Schätzungen bei 1,5 bis 4,5 – mit Ausnahme von AR4, als diese auf 2,0 bis 4,5 geändert wurde. Die Bereiche in Tabelle 1 sind allesamt 5% bis 95% Bereiche, soweit ich das beurteilen kann.
Tabelle 1. Verschiedene Schätzungen der ECS. Alle sind theoretische Berechnungen mit Ausnahme von Lewis und Curry, deren Schätzung auf Beobachtungen beruht:
Tausende von Wissenschaftlern und Milliarden von Dollar später haben wir also immer noch die gleiche theoretische Unsicherheit über die Auswirkungen von CO2 auf das Klima. Die einzige empirische Schätzung der ECS, die gezeigt wird, liegt bei etwa 1,5°C. Die meisten dieser empirischen Schätzungen liegen unter 2°C und gruppieren sich um 1,5°C bis 1,6°C (Lewis & Curry, 2018). Die empirische Schätzung von Guy Callendar lag bei 2°C (Callendar, 1938) und die theoretische Schätzung von Arrhenius (Arrhenius, 1908) bei 4°C. Man kann also sagen, dass die gesamte Arbeit und das Geld, das seit 1938 aufgewendet wurde, um den Klimawandel dem Menschen zuzuschreiben, verschwendet wurde.
[Hervorhebung vom Übersetzer]
Wird es nun besser? Wie steht es mit der neuesten Generation theoretischer Modelle, CMIP6? Erste Anzeichen deuten darauf hin, dass die Ergebnisse nicht besser, sondern schlechter werden, wie Ron Clutz und John Christy berichten. Während die meisten der neuen Modelle absurd überhöhte Werte für die ECS zeigen, ist es interessant, dass die neueste Version des russischen Modells, INM-CM4, auf das ich in meinem vorherigen Beitrag Bezug genommen habe, jetzt eine ECS von 1,83 vorhersagt. Mit Ausnahme des INM-CM4 haben wir also seit 1938 keine Fortschritte gesehen. Wie meine verstorbene Großmutter Marie McCartney sagen würde, „ist das jetzt nicht einfach großartig?“.
This is a condensed excerpt, with minor modifications, from my new book, Politics and Climate Change: A History.
To download the bibliography, click here.
Link: https://wattsupwiththat.com/2020/11/12/modern-climate-change-science/
Übersetzt von Chris Frey EIKE
1,5 – 4,5 Grad sagen also die meisten Prognosen, da kann sich ja fast jeder irgendwo wieder finden! Aber wenn das wirklich so ist, mit welchem Recht greift denn die politische Klasse so tief in unser Leben ein? Und weshalb ist bei jenen Unsicherheiten der Prognosen von „Leugnern“ und „Verschwörungstheoretikern“ die Rede? Und warum bekommen diejenigen, welche am lautesten schreien, „recht“?
https://wattsupwiththat.com/2020/11/15/uncertain-certainty-germanys-potsdam-climate-institute-humiliated-after-one-year-el-nino-forecast-model-flops/
Wie wahr! Aber zur Verdummung der Grünwähler samt Luisa reicht es allemal – die Potsdämlichen helfen nach Kräften mit. Und schon laufen unsere gewählten Klimairren um die Wette, um Blödland zu ruinieren.
Wie aber kann diese Basisannahme eigentlich belegt werden? Ich kenne keine durchgängig auf Basis der Physik beweisbare Argumentation, die eine solche Annahme zwingend belegt. Kennt jemand eine? Die faktische Ergebnislosigkeit der millionenteuren ECS-Forschung der letzten Jahrzehnte legt doch nahe, daß hier ein Irrweg erforscht wird. Man will etwas finden, was offensichtlich nicht existiert, oder?
Mir kommt das so vor, wie die überall verbreitete Behauptung, die Temperaturen auf der Venus beruhen auf Treibhauseffekt. Dabei ist die Venusatmosphäre hochgradig trüb für sichtbares Licht, damit scheidet aber jene Argumentation, die den Treibhauseffekt auf der Erde erklären will, von vorne herein aus. Das scheint aber niemand zu merken …
Wie logisch klingt es, anzunehmen, daß ca. 300 ppm eine Temperaturzunahme durch THE um 33 K bewirken (-18°C auf +15°C) und weitere 300 ppm dann zwischen 1,5 und 4,5 K? Wie sieht die zugehörige Gesamtkennlinie diese „Effektes“ aus? Und welche Kennlinienpunkte daraus kann man auch physikalisch berechnen?
Herr Strasser, Sie beachten leider nicht das logarithmische (!) Gesetz sowie die Tatsache dass der „best guess“ des IPCC von 3±1,5 Grad ein Fake ist, der auf solar-ozeanischen Ausgasungsdaten von Eisbohrkernen beruht und NICHTS mit der CO2-Verdoppelungssensitivität zu tun hat. Dasselbe gilt für den Feedback-Faktor 2,7 welcher aus dem „Strahlungsantrieb“ für CO2-Verdoppelung von 3,7 W/m² aus den 1,11 Grad am Boden dann 3 Grad macht.
Die wahre Verdoppelungssensitivität (im Gleichgewicht, mit Wolken, Wasserdampf, Feedback) ist nur etwa 0,6 Grad, was sich ja auch durch Berechnungen mit MODTRAN ergibt. Die Formel, mit der die Temperaturerhöhungen berechnet werden, lautet deltaT=0,6*ln(C/Co)/ln(2). Damit ergibt sich z.B. für den CO2-Anstieg von vorindustriell bis heute, also von 280 auf 410 ppm, nur 0,33 Grad sowie auch die Tatsache dass die völlige Dekarbonisierung von D bei einem globalen Anteil von 2,3% längerfristig nur 0,01 Grad bewirken würde.
Schade dass EIKE es versäumt hat, dieses Thema in dem EIKE-Beitrag von Andy May zu behandeln. Andererseits wird doch behauptet (z.B. beim so oft präsentierten solaren Hemisphärenansatz von Uli Weber ohne Gegenstrahlung) dass es gar keinen Treibhauseffekt gibt. Informationen über verschiedene Auffassungen sind zwar nützlich – aber was wir dringend benötigen, sind klare Aussagen darüber, was denn nun richtig ist. Mit dem Hinweis, der korrekte Wert sei heute (nach über 40jähriger Forschung seit Charney) immer noch nicht „bekannt“, hat man eigentlich keine belastbaren Argumente gegen Klimaschutz und Dekarbonisierung.
Das würde bedeuten, 0,6 Moleküle CO2 auf eine Million, oder 1 Molekül CO2 auf 1,67 Millionen Moleküle Luft würden bereits eine Temperaturerhöhung von 6 K bewirken!?
Noch absurder wird das Ergebnis, wenn man nicht mit Mittelwert 3,0 sondern mit 1,5 K rechnet. Dann ergibt sich, ein Molekül CO2 auf 1,67 Millionen Moleküle Luft würde eine Temperaturerhöhung von bereits 19,5 K bewirken!?
Mit welcher Physik erklären das die Klima-Alarmisten eigentlich?
Mit „Treibhausphysik“
Mfg
Werner Holtz
Wenn unsereiner sich die Meßdaten in den USA anschaut, wurde es da von ca. 1880 bis 1930 wärmer und von 1950 bis jetzt kälter.
Von Erwärmung durch Sonneneinstrahlung ist da nix feststellbar. Woran das wohl liegt?
Also:
Wir beobachten, daß eine Gegenstrahlung nicht existiert (Gegenstrahlungsgrill, Glasplatte)
Aufgabe für die Physik:
Beantwortung der Frage warum das so ist.
Die ganze blöde Rumrechnerei mit angeblicher „Sensivität“ kann man den Hasen geben:
Falsch verstandene Vorgänge in mathematische Formeln gepreßt, welche nicht in der Lage sind die Realität abzubilden.
Keine „Physik“, sondern Propaganda!
Man sollte einfach lernen mit den klimatischen Schwankungen, die es seit Milliarden von Jahren schon immer gegeben hat, zu leben, ebenso mit dem Corona Virus. Die Mitglieder der Merkel Regierung & Co. unterscheiden sich manchmal kaum von den Schildbürgern.