Wir wollen deshalb hier einmal versuchen, möglichst klar und prägnant die Kernthesen der Treibhaus-Klimawandel-Hypothese herauszuarbeiten – und warum sie falsch sind. Was also sind die konkreten Behauptungen der Klimawandel-Industrie? Prinzipiell kann man den von ihr postulierten Prozess des vermeintlichen menschlich verursachten “Klimawandels” in zwei Stufen einteilen:
Erstens, das was man als “primären” oder “physikalischen” Treibhauseffekt bezeichnen kann; konkret wird behauptet, dass eine Verdoppelung der atmosphärischen Kohlendioxidkonzentration vom vorindustriellen Wert von 0,028 auf 0,056 Prozent – die derzeitige Konzentration beträgt 0,041 Prozent – in eine Erhöhung der Einstrahlung an der Erdoberfläche um etwas mehr als 1 Prozent (3,7 Watt pro Quadratmeter) resultiert, was weiterhin zu einer Temperaturerhöhung um 1 Grad Celsius führt (Dies wird in der Literatur auch als Planck-Wert bezeichnet).
Nicht einmal die Klimawandel-Industrie wagt aber zu behaupten, dass eine solch geringe Temperaturerhöhung zu wesentlichen Problemen führen würde (Ab 1,5 Grad Celsius soll es aber angeblich ganz fürchterlich werdeni). Deshalb wird in den Klimamodellen als zweite Stufe eine Verstärkung der initialen Erwärmung durch Rückkopplungseffekte postuliert: Durch die Erwärmung verdampft mehr Wasser; Wasserdampf ist aber auch ein Treibhausgas, was dazu führt das es noch wärmer wird und noch mehr Wasser verdampft und so weiter und so fort. Über die Höhe der dadurch erreichten Verstärkung ist man sich in den verschiedenen Modellen durchaus nicht so ganz einig; als “Konsenswert” wurde vom IPCC, der UNO-”Klimabehörde” ein Faktor 3 festgelegt. Das würde also heißen, dass eine Verdoppelung der Kohlendioxidkonzentration zu einer Temperaturerhöhung um 3 Grad Celsius führen würde.
Eventuell könnte man dann noch als dritte Stufe die Auswirkungen dieser postulierten Erwärmung auf spezifische klimatische Ereignisse einführen, welche bekanntlich in den grellsten Farben ausgemalt werden – massiver Anstieg des Meeresspiegels, mehr Stürme und so weiter.
Alle diese Behauptungen basieren jedoch einzig und allein auf den berühmt-berüchtigten Klima-Modellen. Dafür, dass diese “Modelle” in der Lage sind, das real existierende Klima auf der Erde vorherzusagen gibt es jedoch keinerlei Beleg. Ganz im Gegenteil: Sie versagen bereits bei der Aufgabe, auch nur vergangene Klimaentwicklungen zu reproduzieren.
Man ist deshalb dazu gezwungen, die Abweichungen von der Realität irgendwie auszubügeln. Zunächst bediente man sich hierzu vorwiegend der “Flusskorrekturen”: dabei werden Werte im Modell – etwa Temperatur oder Wassergehalt – so korrigiert, dass sie mit den beobachteten Werten übereinstimmen. Wenn beispielsweise in einem globalen Klima-Modell das für die Atmosphäre zuständige Teilmodell eine Temperatur liefert, welche um 2 Grad Celsius höher ist als tatsächlich gemessen, so wird auf diese Temperatur einfach eine “Flusskorrektur” von minus 2 Grad Celsius angewandt, bevor man den Wert ausgibt oder an ein anderes Teilmodell (etwa für den Ozean) weiterleitet. Bei dieser grobschlächtigen Methode tritt natürlich die Unzulänglichkeit der Modelle klar zutage; in neuerer Zeit setzt man deshalb, in einem Versuch die Schummelei nicht gar so offensichtlich zu machen, stattdessen auf das sogenannte ”Tuning”. In einer der – bezeichnenderweise raren – wissenschaftlichen Veröffentlichungen (Mauritsen et al., “Tuning the climate of a global model”) zu diesem heiklen Thema wird die Vorgehensweise bei dieser Methode so beschrieben:
“Während der Entwicklungsphase werden die Eigenschaften globaler Klimamodelle auf vielfältige Art und Weise so eingestellt oder getunt, dass sie möglichst gut dem bekannten Zustand des klimatischen Systems der Erde entsprechen. Diese gewünschten Eigenschaften sind beobachtbare Größen wie das Strahlungsgleichgewicht an der Grenze zum Weltall, die weltweite Durchschnittstemperatur, Meereis, Wolken und Windfelder. Das Tunen erfolgt üblicherweise durch die Anpassung nicht genau bekannter, oder sogar nicht beobachtbarer, Parameter von Prozessen, welche nicht explizit im Modell repräsentiert werden.”
Im Klartext: Wir haben zwar keine Ahnung, was diese klimatischen Prozesse eigentlich tun, aber wir stellen sie einfach einmal so ein, dass die Abweichungen (oder zumindest ein Teil der Abweichungen) in unserem Modell zum tatsächlich beobachteten Klima ausgeglichen werden. Das ist natürlich keine wirkliche Verbesserung gegenüber den Flusskorrekturen, weshalb es nicht verwundert, dass man es auch hier vermeidet, das Vorgehen an die große Glocke zu hängen. In einer anderen Veröffentlichung (Hourdin et al., “The art and science of climate model tuning”)ii wird der nicht gerade offene Umgang mit der Tuning Problematik vorsichtig thematisiert:
“Obwohl die Notwendigkeit des Parametertunens in bahnbrechenden Arbeiten anerkannt (z.B. Manabe und Wetherald 1975) und als wichtiger Aspekt in erkenntnistheoretischen Studien der Klimamodellierung behandelt wurde (Edwards 2001), wird die Bedeutung des Tunens vermutlich nicht so deutlich kommuniziert wie es sollte. Es wird oftmals ignoriert, wenn die Leistungen von Klimamodellen in Multi-Modell Analysen verglichen werden. Die Tuning-Strategien waren nicht einmal Teil der erforderlichen Dokumentation der CMIP5 Simulationen. [Ein Vergleich von Klimamodellen, welcher die Basis für einen wesentlichen Teil der Berichte des IPCC bildet] … Warum ein solcher Mangel an Transparenz? … Es mag auch Bedenken geben, dass eine Erklärung der Tatsache, dass die Modelle getunt sind, die Argumente derer stützen würde, welche die Korrektheit der Prognosen des Klimawandels in Zweifel ziehen. Das Tunen kann durchaus als verstohlene Methode gesehen werden, Fehler in den Modellen zu kompensieren.”
Etwas weiter wird dann eingestanden, dass diese Funktion des Tunings als Fehlervertuschung nicht nur so gesehen werden kann, sondern schlichtweg eine Tatsache ist:
“Sobald eine Modellkonfiguration festgelegt ist, besteht das Tunen darin, Parameterwerte so zu wählen, dass die Abweichung der Modellausgaben von Beobachtung oder Theorie minimiert oder auf ein akzeptables Maß reduziert wird. Wenn man es so definiert, wird Tuning in anderen Anwendungsbereichen komplexer numerischer Modelle gewöhnlich als Kalibrierung bezeichnet (Kennedy und O’Hagan 2001). Einigen Klimamodellierern widerstrebt es jedoch, diesen Begriff zu verwenden, da sie wissen, dass sie durch die Parameteranpassungen, absichtlich oder nicht, auch (oft unbekannte) Defekte in der Modellformulierung selbst kompensieren.”
Dieselbe Veröffentlichung enthält auch eine Umfrage unter Klima-Modellierungsgruppen, welche die Notwendigkeit des Tunings eindringlich unterstreicht – von den 23 Befragten geben 22 an, dass sie ihre Modelle tunen. Die einsame Ausnahme lässt sich wohl mit der Tatsache erklären, dass unter die ganzen Klimamodelle auch eines für die Wettervorhersage geraten war – dort hat man im Gegensatz zur Klimagemeinde nicht den Luxus, nachträglich noch Schummelkorrekturen anwenden zu können, hier werden korrekte Vorhersagen erwartet.
Als Stellschrauben zur Klima-”Korrektur” werden insbesondere Parameter im Zusammenhang mit Wolken und Konvektion, der Interaktion beim Auftreffen von Wind auf Bergen, der ozeanischen Wassermischungsverhältnisse und der Reflektivität von Schnee und Meereis verwendet. So führt beispielsweise eine Erhöhung der Rate, mit der beim konvektiven Aufsteigen von Wolken deren Feuchtigkeit als Niederschlag ausfällt, zu weniger Wolken, was weniger Rückreflektion der Sonneneinstrahlung ins Weltall bedeutet und damit zu einer höheren Temperatur. Hier Mauritsen et al. mit einem konkreten Beispiel:
“An diesem Punkt war klar, dass das neue gekoppelte Modell im Vergleich zu der von uns angepeilten vorindustriellen Temperatur zu warm war. Verschiedene Maßnahmen zur Senkung der globalen Durchschnittstemperatur durch Änderung der konvektiven Entrainment Raten, des Anteils überschießender Konvektion und der Wolkenhomogenitätsfaktoren wurden getestet. Letztendlich wurde entschieden, vorwiegend einen von 0,70 auf 0,77 erhöhten Homogenitätsfaktor für flüssige Wolken kombiniert mit einer leichten Reduzierung des Anteils der überschießenden Konvektion von 0,22 auf 0,21 zu verwenden, was eine Erhöhung der Wolkenreflektivität in niedrigeren Höhen und damit eine Reduzierung der Abweichung der Oberflächentemperatur-bewirkte. Jetzt war die weltweite Durchschnittstemperatur genügend nahe an unserem Zielwert und das Abdriften nur mehr sehr schwach ausgeprägt.”
Angesichts der Tatsache, dass sich in der Klima-”Wissenschaft” seit Jahrzehnten fast ausschließlich alles darum dreht, einen menschlichen Einfluss auf das Klima zu demonstrieren, ist es nicht verwunderlich, dass beim Modell-“Tunen” neben natürlichen klimatischen Prozessen auch vermeintliche menschliche Einflüsse bemüht werden. Hierbei geht es insbesondere um die durch Emissionen von Industrie, Kraftwerken und Verkehr in die Atmosphäre gelangenden sogenannten Aerosole. Ihre angebliche Klimawirksamkeit wurde bereits unter anderen Vorzeichen in den 70er Jahren propagiert – damals wurden sie beschuldigt, durch Blockade der Sonneneinstrahlung für das Kommen einer neuen Eiszeit verantwortlich zu sein.iii Ihre heutige Bedeutung ergibt sich dadurch, dass sie verwendet werden, um das offensichtliche Versagen der Treibhausmodelle bei der Beschreibung des Klimas des 20sten Jahrhunderts zu kaschieren; wie bereits erwähnt, soll eine Verdoppelung der Kohlendioxidkonzentration seit dem Beginn der Industrialisierung eine Temperaturerhöhung von etwa 3 Grad Celsius bewirken. Von dieser Verdoppelung ist knapp die Hälfte bereits eingetreten; da die Auswirkung nicht linear, sondern (annähernd) logarithmisch ist und andere Treibhausgase wie Methan ebenfalls zugenommen haben, sollte der größte Teil dieser 3 Grad Celsius Erwärmung bereits jetzt geschehen sein. Aber selbst mit allen Tricks und intensivster Massage von historischen Temperaturdaten kommt man gerade einmal auf eine Erhöhung von 0,85 Grad Celsius.iv Als Retter in der Not kommen nunmehr die Aerosole zum heldenhaften Tuningeinsatz – ihre vermeintlich kühlende Wirkung auf das Klima soll die fehlende Erwärmung erklären:
“Einer der wenigen Tests, welchen wir Klimamodelle unterziehen können, ist ob sie in der Lage sind den beobachteten Temperaturverlauf seit dem Beginn der Industrialisierung bis hin zur Gegenwart zu reproduzierten. Die Modelle schneiden hierbei überraschend gut ab (Räisänen, 2007), wenn man die breite Spanne an Klimasensitivitäten bedenkt – ein Verhalten welches auf eine Kompensation durch anthropogenen Einfluss im zwanzigsten Jahrhundert zurückgeführt wird (Kiehl, 2007): Modelle mit einer hohen Klimasensitivität tendieren dazu, einen schwachen anthropogenen Einfluss zu haben und umgekehrt. Weiterhin wurde als Ursache für einen Großteil der Abweichungen zwischen den Modellen unterschiedliche Aerosoleinflüsse bestimmt.”
Die vermeintliche Temperaturwirkung der Aerosole wird also einfach dreist so angenommen, wie es gerade eben passt – und das auch noch für jedes Modell anders. Dass menschlich verursachte Aerosole überhaupt irgendeinen nennenswerten Einfluss auf das globale Klima ausüben, erscheint aufgrund der Tatsache, dass diese lediglich im unteren Bereich der Atmosphäre verbreitet werden, mit daher kurzer Verweildauer in der Atmosphäre und einer räumlich begrenzten Verbreitung rein prinzipiell als unplausibel. Messungen der Durchlässigkeit der Atmosphäre für Sonneneinstrahlung für das letzte Jahrhundert zeigen denn auch mit Ausnahme von größeren Vulkanausbrüchen, bei welchen Material hoch in die Stratosphäre geschleudert wird – was zu jeweils kurzzeitigen Einstrahlungssenkungen mit entsprechender weltweiter Abkühlung führte – keine nennenswerten Veränderungen an.v Es ist nicht einmal sicher, dass insofern die Aerosole überhaupt einen Einfluss ausüben, dieser tatsächlich, wie behauptet, abkühlend ist – es gibt auch Aerosole die die Sonneneinstrahlung nicht reflektieren, sondern absorbieren und damit erwärmend wirken.
Hier wird auch ein weiteres massives Problem der Klimamodelle deutlich, nämlich die großen Abweichungen der verschiedenen Modelle voneinander. Es geht also nicht nur darum, ob man den Modellen Glauben schenken will – sondern welchem denn nun. Oben haben wir festgehalten, dass bei einer Verdoppelung des Kohlendioxidgehalts in der Atmosphäre eine Einstrahlungserhöhung um 3,7 Watt pro Quadratmeter behauptet wird, was laut IPCC-Konsenswert zu einer Temperaturerhöhung um 3 Grad Celsius führen soll. Was sich hinter der Nennung solcher Modell-“Durchschnitte” verbirgt, sehen wir etwa hier bei Hourdin et al.:
“Dieses Tunen des Energiegleichgewichts ist von entscheidender Bedeutung, da eine Änderung um 1 W/m2 des Energiegleichgewichts in globalen Klimamodellen, je nach Sensitivität des jeweiligen Modells, typischerweise zu einer Änderung um 0,5 bis zu 1,5 K in der weltweiten Durchschnittstemperatur führt.”
Also mal ganz locker Unterschiede um den Faktor 3. Und das auch nur, wenn wir im “typischen” Bereich bleiben – die Bandbreite ist also eher noch größer. Bei Mauritsen et al. wird aufgezeigt, was das für Auswirkungen hat:
“Jedoch beträgt die Spanne zwischen dem kältesten und dem wärmsten Modell fast 3 Grad Kelvin, mit gleichem Abstand nach Oben und Unten zu den tatsächlichen Werten, wobei die Mehrheit der Modelle nach Unten tendieren. Obwohl die Spanne nur ein Prozent relativ zum absoluten Nullpunkt beträgt, ist dies kaum ein Grund zur Beruhigung. Relativ zu der Erwärmung im 20igsten Jahrhundert ist die Spanne um den Faktor vier größer, während sie in etwa unserer besten Abschätzung der klimatischen Auswirkung einer Verdoppelung der Kohlendioxidkonzentration und etwa der Hälfte des Unterschieds zwischen dem letzten eiszeitlichen Maximum und der Gegenwart entspricht.”
Dem ist wohl nichts hinzuzufügen. Dennoch regen sich nur vereinzelt Stimmen in der Modellierungsgemeinde, welche die Konsequenzen ziehen und es wagen, wie hier, prinzipielle Kritik an der Praxis des Tunings zu üben (Dommenget und Rezny, “A Caveat Note on Tuning in the Development of Coupled Climate Models”)vi:
“Aktuelle globale Klimamodelle weisen wesentliche Fehler in ihren Simulationen des Klimas auf. Insbesondere können diese Fehler zu großen Unsicherheiten in den simulierten Auswirkungen (sowohl global als auch regional) einer CO2-Verdoppelung führen. Zurzeit werden globale Klimamodelle durch umfangreiches Tunen der Modellphysik im Rahmen von Parametrisierungen entwickelt. Es ist nicht klar, ob solches Tunen die Modelle tatsächlich verbessert. Der Prozess des Tunens ist (im Allgemeinen) weder dokumentiert noch reproduzierbar. … Das Tunen mag die Modellergebnisse verbessern (wie etwa die Reproduktion beobachteten vergangenen Klimas), erzielt jedoch keine Annäherung an die “wahre” Physik; ebenso wenig werden dadurch Prognosen des zukünftigen Klimawandels nennenswert verbessert.”
Tatsächlich macht das Tunen das Modell nur noch schlechter, da beim Tunen eines Teilbereichs des Modells auch andere Teilmodelle von den dadurch verfälschten Werten beeinflusst werden:
“Innerhalb der globalen Klimasimulation verursachen die Fehler in den jeweiligen Teilmodellen – zum einen Fehler in der Parametrierung des Teilmodells selbst, zum anderen falsche Eingabewerte, die es von anderen Teilmodellen erhält – Folgefehler. Beim Tunen des globalen Klimamodells werden die Parameter in allen Teilmodellen so eingestellt, dass Beides kompensiert wird. Wenn sich zum Beispiel in einer globale Simulation Abweichungen in der Wolkenbedeckung in einer bestimmten Region zeigen, so kann dies sowohl von einem Fehler im Wolkenmodell oder von einem falschen Eingabewert herrühren (Abweichender Durchschnittszustand in anderen klimatischen Variablen). Das Entwicklungsteam des Modells könnte zu dem Entschluss kommen, die Parameter des Wolkenmodells zu tunen, obwohl eigentlich falsche Eingabewerte in das Wolkenmodell aufgrund von Problemen in anderen Teilmodellen verantwortlich sind. … Tatsächlich erschwert das Tunen die Modellentwicklung (und Verbesserung): Das Tunen von Klimamodellen führt zu Kompensationsfehlern, welche effektiv alle Teilmodelle des globalen Modells voneinander abhängig machen. Deshalb ist es so gut wie sicher, dass das Ersetzen oder Austauschen von Teilmodellen die Simulation des Gesamtklimas verschlechtern wird und weitere Optimierung notwendig ist. Die Optimierung wird dann (ein weiteres Mal) die Modellphysik von der “Wahrheit” entfernen.”
Durch Tunen mag man es zwar so hintricksen, dass das die von einem Modell gelieferten Resultate für ein ganz bestimmtes Szenario zumindest halbwegs mit dem real beobachteten Klima übereinstimmt. Die Wahrheit kommt aber spätestens dann ans Licht, wenn man versucht, das Modell für eine andere Situation einzusetzen als für die, für welche es “optimiert” wurde:
“Damit hat der Optimierungsansatz es zwar geschafft den indirekten Fehler zu reduzieren, hat aber gleichzeitig die direkten Fehler für die Reaktion zu einer CO2 Verdopplung erhöht. Er hat Kompensationsfehler erzeugt, die nur sichtbar werden, wenn er auf ein Problem angewandt wird, das sich wesentlich von dem unterscheidet für das er getunt wurde. … Der Tuning Prozess wird die Verlustfunktion reduzieren, aber die Physik die wir dadurch erhalten, ist nicht näher an der “wahren” Physik. Danach scheint es zwar so, als ob die Modelle das Klima besser reproduzieren können, aber wenn eine detaillierte Analyse auf Basis der physikalischen Prozesse oder unter anderen klimatischen Szenarios (z.B. erdgeschichtlich weiter zurückliegend oder zukünftige Klimawandelszenarien), so werden gravierende Modellierungsfehler auftreten.”
Die Autoren kommen deshalb zu dem Schluss, man solle doch besser wieder mit offenem Visier schummeln und zu den heute verpönten Flusskorrekturen zurückkehren:
“Flusskorrekturen sind eine nützliche Alternative: Sie bewirken keine Veränderung der Modellphysik, weshalb keine Optimierung notwendig ist. Weiterhin tritt keine Fehlerkompensation aufgrund des Tuning Prozesses auf. Ein weiterer Vorteil ist, dass Flusskorrekturen leicht zu dokumentieren und zu quantifizieren sind – die Korrektur ist einfach ein Eingabewert für das Modell (und kann abgeschaltet werden).”
Flusskorrekturen sind insofern das kleinere Übel, weil sie zumindest deutlich signalisieren, wo die Fehler im Modell liegen, während Tuning diese nur vertuscht aber nicht nur nicht löst, sondern sogar noch vermehrt. Natürlich setzt dies voraus, dass man wirklich an der “wahren” Physik des Klimas interessiert ist – etwas, was bei der heutigen Treibhaus-Klimaindustrie in der Regel mit Fug und Recht bezweifelt werden darf.
Es muss betont werden, dass selbst nach dem “Tunen” immer noch genügend Abweichungen zwischen den Modellen und der Realität übrigbleiben (Schmidt et al., “Practice and philosophy of climate model tuning across six U.S. modeling centers”)vii:
“Die Grenzen des Tunens sind wohlbekannt (Mauritsen et al., 2012; Schmidt und Sherwood, 2014; Hourdin et al., 2016). Zunächst einmal ist es bemerkenswert wenig hilfreich, wenn es um die Verbesserung der allgemeinen Modellfähigkeiten geht, sobald ein ausreichender Teil des Parameterraums identifiziert wurde – zum Beispiel war Tuning nicht in der Lage, das hartnäckige Problem der sogenannten “Doppelten Innertropischen Konvergenzzone” zu lösen (Lin, 2007; Oueslati and Bellon, 2015). Zweitens sind Verbesserungen in einem Bereich oftmals von Verschlechterungen in einem anderen begleitet, weshalb die letztendliche Parameterwahl subjektive Bewertungen über die relative Wichtigkeit verschiedener Aspekte der Simulationen beinhaltet. Zum Beispiel benutzt der australische Beitrag zu CMIP5 (ACCESS v.1) eine Variante des britischen Met Office Atmosphärenmodells mit kleineren Modifikationen um Problemen in den Tropen und der südlichen Hemisphäre, welche die Vorhersagen für Australien betreffen, entgegenzuwirken, auf Kosten der Leistung anderswo (Bi et al., 2013). Es gibt viele weitere offensichtliche Abweichungen von der Realität in Modellsimulationen, die über Modellgenerationen erhalten bleiben, was darauf schließen lässt, dass diese Aspekte resistent gegen Änderungen im Rahmen der Modellentwicklung sind (das schließt das Tunen ein) (Masson and Knutti, 2011).”
Die Unzulänglichkeiten der Klima-Modelle bieten schier endlosen Diskussionsstoff, aber wir wollen es bei den bisherigen Punkten belassen, welche ganz bewusst zu einem Großteil in Form von Zitaten der Worte der Klimamodellierer selbst dargelegt wurden; sie sind mehr als ausreichend, um die völlige Ungeeignetheit der sogenannten Klima-Modelle einen vermeintlichen Treibhausgas-induzierten Klimawandel – oder sonst irgendetwas – zu belegen: Sie sind nicht nur nicht dazu imstande, das tatsächlich beobachtete Klima zu reproduzieren (geschweige denn vorherzusagen) sie zeigen auch noch massive Abweichungen untereinander; und selbst das “Tunen” schafft es nur, die allergröbsten Abweichungen von der Realität zu kaschieren.
Auch gibt es keine Anzeichen dafür, dass sich die von den Modellen gelieferten Ergebnisse trotz der massiven Fortschritte in der verfügbaren Computerleistung über die letzten Jahrzehnte in irgendeiner Weise verbessert haben. Eine interessante Frage ist, ob die oftmals stark nichtlinearen Prozesse im irdischen klimatischen System eine prinzipielle Barriere für den Einsatz von Klimamodellen darstellen, oder ob diese bei einem Wegfall der ihnen aufgezwungenen politischen “Zielorientierung” doch noch eine nützliche Rolle spielen könnten. Das hängt natürlich auch davon ab, ob man sich der “offiziellen” Position in der Klimaforschung anschließt, dass klimatische Variabilität im Wesentlichen intern im irdischen Klimasystem bestimmt wird oder ob man externe Einflüsse – etwa Sonnenaktivität – als wichtige Faktoren in Betracht zieht.
Für die Beantwortung der Frage der Korrektheit der Treibhaus-Klimawandelhypothese spielt das aber keine Rolle. Um diese zu widerlegen benötigen wir keine Modelle, sondern lediglich die empirischen Beobachtungen des irdischen Klimas. Das soll das Thema des nächsten Artikels sein.
Mauritsen et al. 2012, „Tuning the climate of a global model“
Hourdin et al. 2017, „The Art and Science of Climate Model Tuning“
Dommenget und Rezny 2017, „A Caveat Note on Tuning in the Development of Coupled Climate Models“
Schmidt et al. 2017, „Practice and philosophy of climate model tuning across six U.S. modeling centers“
Anmerkung: Dieser Beitrag erschien auch hier.
„Erstens, das was man als “primären” oder “physikalischen” Treibhauseffekt bezeichnen kann; konkret wird behauptet, dass eine Verdoppelung der atmosphärischen Kohlendioxidkonzentration vom vorindustriellen Wert von 0,028 auf 0,056 Prozent – die derzeitige Konzentration beträgt 0,041 Prozent – in eine Erhöhung der Einstrahlung an der Erdoberfläche um etwas mehr als 1 Prozent (3,7 Watt pro Quadratmeter) resultiert, was weiterhin zu einer Temperaturerhöhung um 1 Grad Celsius führt (Dies wird in der Literatur auch als Planck-Wert bezeichnet).“
Wer so einen hanebuechenen Unsinn verbreitet, der sollte nun wirklich nicht ueber Klimaprojektionen schwadronieren.
Ich frage mich zudem, was dieser esoterische Quatsch von der Klimasensitivitaet mit Planck zu tun hat.
Wenn ich aber hier von der „Wissenshoheit“ immer wieder höre, dass CO₂ ein hochaktives Klimagas wäre, was aber nicht schlimm ist, weil eine „Sättigung“ eingetreten wäre, die bei einer Verdopplung des Gases nur zu einer unbedeutenden Temperaturerhöhung führen könne (Klimasensitivität), frage ich mich, wohin der Weg noch gehen soll.
Sie und nur eine handvoll von Lesern wehren sich gegen diese Auffassung, das ist zu wenig.
Wenn ich die nicht‑wissenden, mit wissend aufgelegten und Überheblichkeit versehen Gesichter unserer Politiker sehe, denke ich, dass alle Arbeit keinen Nutzen hat und wir die schrecklichen Konsequenzen dieser Politik ertragen müssen.
Auch wenn es keiner hören will, dieses ist das Resultat einer Desinformation, die über Generationen betrieben wurde und jetzt ihre schäbigen Früchte trägt.
Die dümmsten Weltverbesserer werden die Regierung übernehmen, gewählt von einer Wählerschaft, die zu 90 % verblendet ist, um so, zum eigenen Schaden, einem kleinen Anteil von kriminellen die Unterstützung zuzusagen.
Waren wir die letzten 70 Jahre zu faul oder nicht sensibel genug, um diesem Treiben, von Anfang an, kein Fundament geboten zu haben?
Setzt man die Gesamtanzahl der Kugeln und die Anzahl von Trefferkugeln als bekannte Basis an (z. B. 6 aus 49), erhält man viele Millionen Möglichkeiten als Ergebnisbandbreite.
Ergänzt man das Modell aber nachträglich je Ziehungstag um ein individuelles „Tuning“, kann man jede erfolgte Ziehung mit 100% Wahrscheinlichkeit „nachprognostizieren“.
Das Einzige, was so ein Modell aber nicht leistet, ist eine erhöhte Trefferwahrscheinlichkeit für zukünftige Ziehungen. Genau so arbeiten aber die Klimamodelle.
Bitte beachten Sie, dass die Trommel keine Kugeln „Wasserdampf und CO2“ enthält.
Wer an dieser Stelle anfängt, kindliche Modelle zu kritisieren, klebt bereits fest auf der Leimrute der Schwindler. Fakt ist – eigentlich leicht zu erkennen -, dass weder Wasserdampf noch CO2 die Wirkung des atmosphärischen Treibhauseffektes beeinflussen können:
Die Atmosphäre nimmt bekanntlich als sog. Luftfeuchte (das ist immer nur der gasförmige Anteil!) bei Wassertemperaturen zwischen +30 Grad C und -2 Grad C (und rel. Feuchte zwischen 60% – 100%) pro Kubikmeter zwischen 30 -3 Gramm Wasser auf. Bereits beim Unterschreiten von -30 Grad C ist dieser „Dampfgehalt“ als Folge von Kondensation und Eisbildung auf 1 g/m^3 abgesunken, in der Tropopause kommen nur noch 0,05 g/m^3 an. Was tun wohl die Wasser und Eis Schwebeteichen, bis die Schwerkraft ihre Flugreise beendet?
Bereits bei 1 g/m^3 schweben über jedem Quadratkilometer der Erdoberfläche in jedem Kubikkilometer Luft 1000 Tonnen solcher Aerosole, die bei einem Radius von z. B. 0,01 mm über eine Oberfläche von 30.000 km^3 verfügen. Bei Teilchen mit einem Radius von 1 mm sind es immer noch 30 km^3, die ein erträumtes Fenster für Wärmestrahlung zweifellos schließen.
In der Tropopause senkt ihre Emission von Wärmestrahlung mit etwa 140 W/m^2 den Erdball umspannend die Temperatur unter -50 Grad C ab. 10 Grad C stellen sich ein, wenn Wassertropfen mit 360 W/m^2 zum atmosphärischen Treibhauseffekt beitragen.
Fazit: Wasserdampf und CO2 können nur deshalb etwas verändern, weil die unter der Modllitis leidenden Wichtigtuer den vorgenannten Sachverhalt ignorieren (müssen!).
https://de.scribd.com/document/372778420/Klimasensitivita-t-des-CO2-eine- Seifenblase
Zitat: Eigentlich ein Fall für die Psychiatrie, aber freiwillig werden die Klimahütchenschieber wohl nicht gehen! Zitat Ende.
Wenn man bedenkt das der IPCC eine von der Politik erschaffendes etwas ist das den Menschen gemachten Klimawandel nachweisen soll, sagt das schon alles.
Daten die von diesem Verein Zusammen getragene werden, die man nach gut dünken einsetzt oder andere gar weg lässt.
Diese Politiker hatten damals schon etwas im Sinn mit dem IPCC was man nutzen kann, CO2 Steuer und eine Steuerung des Individual Verkehr, Fahrverbote uvm.
Diese Leute werden nie einen natürlichen Klimawandel zustimmen, ansonsten wäre dieser Verein so etwas von überflüssig das er dicht gemacht werden müsste.
Damit wären aber die Steuer-finanzierten und gut dotierten Arbeitsplätze weg, das sollte jedem bewusst sein.
Den Verein kann man mit Greta vergleichen, die kann auch das CO2 sehen!
Habe mich schon wund geschrieben über die grundsätzliche Unmöglichkeit, die Zukunft über Modelle zu sehen, so ausgeschlossen wie mit der berühmten Glaskugel. Nur ist man überall geneigt, auch hier bei EIKE, dem überdimensionierten Taschenrechner irgendwie doch ein wenig zu glauben.
1. Man sollte sich klar machen, dass in Modellen nicht im Geringsten richtig oder weniger richtig die Naturgesetze einprogrammiert werden, sondern die bekannte Wirkung der Naturgesetze mit völlig anderen Mitteln nachgeahmt wird.
2. Das erkennt man schon daran, dass alle Wetter- und Klimasimulationen letztendlich andere Ergebnisse liefern, weil jeder Modellierer eben mit andere Algorithmen das Bekannte „nachmalen“ will. Ginge eine exakte Naturabbildung, hätten alle Modelle die gleichen Formeln und die gleichen Ergebnisse.
3. Alle Modelle wie alle Softwareprodukte werden auf gleicher Weise vor Freigabe überprüft: Die Ergebnisse müssen passen, also die errechneten Zahlen und Größen müssen mit real existierenden Werten übereinstimmen. Sonst wird weitergetrimmt. Bei Wettersimulationen ist der Vergleichswert klar, Bei Klimasimulationen gibt es erst in 50 Jahren ein echten Vergleichswert. Die kleinen Temperaturschwankungen über ein-zwei Jahrzehnte, wobei es regional auch kälter wird, hat keine Aussagekraft über eine Klimaentwicklung.
4. Die Klimamodelle bilden einigermaßen die Vergangenheit ab, kein Wunder, dass ist die Hauptaufgabe der Programmierer, und man hat schon Geld für gute. Das bedeutet aber nicht im Geringsten, dass damit eine Aussage für die Zukunft möglich ist. Die Zukunftsaussage liegt im Code und entspricht den Wunschvorstellungen des Auftragsgebers.
Zusammenfassung: Alle Simulationen, die nicht in jedem Schritt regelmäßig mit reellen Werten abgeglichen werden, sind reine 100% Spekulationen, damit ALLE Klimamodelle. Gebt mir genügend Geld und 20 Jahre Zeit und ich stelle ein Klimamodell zu Verfügung, dass die Vergangenheit befriedigend abbildet und für 2100 keine Temperaturänderung oder auf Wunsch moderate Abkühlung anzeigt.
Sie zeigen mit Ihrem Kommentar eigentlich nur, dass Sie von Klimamodellen keinerlei Ahnung haben. Bereits Ende der 1980iger Jahre hat sich in der Wissenschaft die Erkenntnis durchgesetzt, dass nichtlineare, chaotische Prozesse (wie das Klima) nicht mittels Computermodellen vorhersagbar sind. In der Mathematik hat sich daran bis heute nichts geändert. D.h. immer, wenn Jemand behauptet, für das zukünftige Klima Vorhersagen / Prognosen abgeben zu können ohne gleichzeitig zu beweisen, dass er nun nichtlineare, chaotische System modellieren kann, handelt es sich nicht um einen Wissenschaftler sondern um ein Scharlatan. Solche „Vorhersagen“ sind auch keine Theorien (wie beim Pluto oder bei Einstein), wie der Artikel und auch der Kommentar von Herrn Georgiev verdeutlichen – beides haben Sie aber offensichtlich nicht verstanden. Macht aber nichts – nehmen wir mal an, dass das, was die Klimamodelle vorhersagen, doch irgendwie Wissenschaft sei. Dann müssten die Vorhersagen mit der späteren Realität übereinstimmen sonst sind sie Müll. Untersuchungen der Klimamodelle des IPCC-Berichts 2007 zeigen nun, dass alle (!) diese „Vorhersagen“ bereits heute mit der Realität (CO2-Konzentration oder/und Temperaturentwicklung) nicht übereinstimmen – aus die Maus!
Wer heute noch von Klimavorhersagen redet, hat entweder keine Ahnung vom Thema oder er/sie will betrügen (oder er/sie ist einfach nur krank, wie wir in jüngster Zeit gelernt haben)!
MfG
Christian-Dietrich Schönwiese (HR Statdtgespräche 2.2.2010) wir machen keine Vorhersagen, sondern bedingte, Szenarien gestützte Projektionen… Und Projektion heißt ..wenn – dann Aussage!
Wenn ich in das Modell hinein stecke der Mensch macht das und das und die Natur macht quasi nichts, sie wird also weitgehend vergessen, bei diesem Blick in die Zukunft , dann wird die Temperatur so und so ansteigen
… das trifft praktisch auf die Gesamtheit der natürlichen Klimaprozesse zu (Lehrbuch Christian-Dietrich Schönwiese Klimatologie 4. Auflage Seite 362)
Schellnhuber, Rahmstorf, Levermann, Latif, Trenberth, M. Mann, ehemals J. Hansen, Al Gore, Pachaurie …(bitte die zwei streichen, hab mich vertan, sind Senator und Eisenbahningenieur), überhaupt 97% der *Klimawissenschaftler* sind sich doch einig, das wir einer Heißzeit entgegengehen, einer Selbstverbrennung, dass das Klima Erdregionen unbewohnbar machen wird, immer stärkere Hitzewellen, Kältewellen, Dürren und Starkregen, Flauten und Stürme, Schneefälle und keinen Wnter mehr, geben wird: wegen dem phösen Co2.
Kommen die aus der Zukunft oder tätigen diese ihre Aussagen an Hand von rechnerbasierten Modellen?
Die wissen das doch! Die sagen das doch so! Die kennen also das Klima der Zukunft! Sie bleuen das den Kindern ein, die rennen freitags von der Schule weg, oder nicht? Prof. Lesch, Dr. Hirschhausen, Dr. Kanzlerin Merkel, Bearbock, Habeck, Hofreiter, Roth und Özdemir (ich kennen deren akademische Grade leider nicht), alle stimmen doch mit ein.
Sind die o.g. Protagonisten des Klimawandels (sic!) nun seriöse Wissenschaftler, oder nicht? Nun kommen Sie schon… seien Sie weiterhin so ehrlich wie bisher… Danke für die Antwort im Voraus!
Sie sollten bei ihren Betrachtungen nicht Berechnungen mit realen Werten und bekannten Zusammenhänge einerseits, und Simulationen von Prozessen, deren Verläufe grundsätzlich nicht berechenbar sind und in weiten Teilen noch nicht erforscht sind andererseits, durcheinander bringen.
Wenn man die Bahnen von Planeten nicht so präzise berechnen könnte, dass dabei die Abweichung durch den Pluto festgestellt wird, könnte man keine Satelliten ins All bringen. Das hat man auch lange vor der Erfindung moderner Computer und Simulationen gemacht, die sind dazu nicht mal nötig.
Andererseits, wenn ich eine Temperaturprognose über eine Wettersimulation für Berlin am 30 Juni von z.B. 25 Grad heute lesen würde, könnte ich auch selbst ohne jegliches Wissen und Technik selbst eine ähnlich fundierte Prognose aufstellen. Ich würde unterstellen, dass die 20 Grad nicht unterschritten werden und die gewürfelte Zahl zwischen 1 und 6 dazu addieren. Die Chancen ob mein Würfel oder die Simulation näher dran ist, kann man als gleichgroß betrachten. Am 28/29.6. dagegen sind in der (gleichen) Simulation aber zig simulierte Werte durch real gemessenen Werten ersetzt worden und somit kann mein Würfel nicht mehr mithalten.
Bei Klima kennt man nicht einmal alle Einflußfaktoren im Gegensatz zum nicht voraussagbaren Wetter, daher sind alle Klima-Simulationen wertlos.
Der wichtigste Grund dafür ist, dass man simulierte Werte nicht mit echten Werten abgleichen kann…
Also Herr Heinecke, die erlebten Klimaschwankungen der Menschheit im Mittelalter seien mitnichten bewiesen, aber die Klima-Computermodelle seien Naturwissenschaft pur.
Mit dieser Einstellung brauchen Sie wirklich Ihr Hirn nicht mit Zahlen und Argumenten belasten, glauben Sie einfach an was Sie wollen.
Jetzt nehmen Sie einen Würfel aus Holz, auf den die Punkte nicht aufgemalt sind, sondern mit einem Bohrer gefräst. Was passiert? Die Seite mit der 1 ist schwerer als die mit der 6, weil für die 6 mehr Holz weggefräst wurde. Der Würfel fällt also mit etwas höherer Wahrscheinlichkeit öfter mit der 1 nach unten und der 6 nach oben als ein nicht manipulierter Würfel, in der langen Reihe feststellbar. Die Analogie zum Klima: Wenn die Temperaturen so offenkundig steigen, ist das System aus dem Gleichgewicht.
Wenn die Temperaturen offenkundig sinken, ist das System auch aus dem Gleichgewicht?
Was soll das denn?
Sie gehören offenkundig zu den Menschen, die zwei 4 mm Bohrer kaufen, wenn sie ein 8 mm Loch bohren wollen.
bezüglich Softwareentwicklung habe ich nur Allgemeinwissen, bin aber seit Jahrzehnten für den wirtschaftlichen Erfolg einer ziemlich komplexen Software verantwortlich. Meine Hauptaufgabe ist es, die komplexen Ergebnis-Anforderungen der Kunden zu verstehen und das Entwicklerteam dazu zu bringen, die Erwartungen der Kunden zu erfüllen. Dabei lernt man, dass eine jede Software keine neue Erkenntnisse bringen kann, sondern nur exakt die Ziele der Auftraggeber erfüllt.
Noch mal zu Wetter und Klima-Simulationen: Beim Wetter ist natürlich das Ziel der Auftraggeber an die Entwickler, dass das Wetter so präzise wie möglich vorausgesagt wird, daher kann man immer weiter verbessern und trimmen, indem man die Differenz zwischen Simulation und Wirklichkeit intensiv durchleuchtet. Beim Klima dagegen gibt es keine Vergleichstabelle, die berechnete Temperatur von 2100 ist vom Talent und Willen des Entwicklers und den Auftrag abhängig. Ich erneuere mein Angebot für eine Klimasimulation nach Wunschwerten.
In der Forschung kommt es immer zu Fehleinschätzungen, das ist ganz normal und kein Zeichen von Dummheit.
Sie schreiben hier, die vielen falschen Wege und Ergebnisse nicht beachtet, von Errungenschaften die den Weg zur Anerkennung gefunden haben.
Wie kommen Sie nur zu Ihrer Ehrfurcht, Ihrem blinden Glauben, Ihrer Hörigkeit (von Ihnen Respekt genannt), vor der Wissenschaft?
Das alles hat doch nichts mit dem Thema, dass der Mensch, durch seine Machenschaften, mit dem lebensnotwendigen Gas (CO₂) das Klima beeinflussen könnte, zu tun.
Alle Wissenschaftler sind nur Menschen, die Betrüger sein können, geldgierig sein können und machtbesessen sein können. Das alles wird von Ihnen nicht infrage gestellt, das ist nicht in Ordnung, das ist krank.
Es ist nun einmal so, dass die Konzentration von CO₂, in unserer Atmosphäre, keinen Einfluss auf das Klima und auch noch zum Schaden der Menschheit hat.
Sie haben sich die Lügner und Fernseh-Clowns unter Wissenschaftlern ausgesucht, um diese zu bewundern.
Sie gehen offenbar mit der Mehrheit und fühlen sich auf dem richtigen Wege, während mithilfe der CO₂‑Lüge unsere Zivilisation beendet werden soll.
Dieser Lüge entsprechend verhält sich unsere Politik, die eine Welle Reitet, die ins Ungewisse führt.
Es ist vollkommen egal, welche Partei Sie benennen wollen, alle reiten die falsche Welle, alle Altparteien.
Es gibt nur eine neue Partei auf dem Markt und mit dem Kreuzchen an der richtigen Stelle können Sie das Ende des derzeitigen Wahnsinns sofort beginnen.
Weil es nur zwei Parteien gibt, die alten sind eine und die neue ist eine, kann die Entscheidung nicht schwer sein.
Die Mehrheit geht den falschen Weg, deshalb muss man dem Mut haben das richtige zu tun – die neue Partei wählen.
Weg mit den Altparteien und weg mit den Endzeit‑Lügen!
Interessant dass hier inzwischen fast jeder Post mit einer mehr oder weniger versteckten Werbung für EINE bestimmte Partei endet und kein Admin da regulierend eingreift, um die Unabhängigkeit von Eike zu schützen. Gibt es hier neben der schwarz-weißen am Ende auch noch eine blaue Brille?
CO₂ ist für das Klima und dessen Entwicklung nicht relevant.
Respekt vor der Wahrheit wäre angebracht.
Genau dieses hat nur EINE Partei erkannt und weil es nur eine Partei ist, können weder zwei noch mehrere genannt werden.
Wie heißt diese eine Partei noch einmal, die sagt, dass CO₂ unschädlich ist?
Wie kann man nur so blöde sein?
Erst mal müßte bewiesen werden, daß CO2 bodennah überhaupt strahlt.
Dann müßte bewiesen werden, daß diese Strahlung den Boden erwärmt.
Erst dann macht es Sinn, sich mit dem nachfolgend Geschilderten zu beschäftigen.
wenn „jede Materie strahlt.“, dann müsste in der Atmosphäre ja auch der Sauerstoff und der Stickstoff strahlen und da diese Hauptbestandteile der Atmosphäre (99%) in der These von der menschgemachten Erwärmung nicht beachtet werden, haben Sie dann gerade diese These widerlegt! Glückwunsch!
MfG
Wie wäre es mit einem Blick auf Creation of the satellite temperature record? Die Satelliten benutzen die von Sauerstoff abgegebene Mikrowellenstrahlung um die Temperaturen in Troposphäre und Stratosphäre zu bestimmen …
Jo!
Aus dem Grund ist die heutige Klima“wissenschaft“ keine Naturwissenschaft, sondern lediglich eine „Budgetbeschaffungswissenschaft“.
Machen Sie sich doch einfach mal mit dem Geltungsbereich der Planck’schen Gesetze vertraut…
Die (zusätzlichen) Wolken selbst stecken in der Bilanz noch gar nicht drin. Vermutlich kommt man bei Bilanzen insgesamt eher auf eine Dämpfung als auf eine positive Rückkopplung. Das ist jetzt zwar geraten, aber vermutlich seriöser geraten als der Unfug, der vom IPCC kommt.