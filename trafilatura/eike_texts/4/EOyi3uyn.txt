Er stellt fest: Die digitalisierte Methode in der neuen Wetterhütte brachte bei seiner Station über achteinhalb Jahre eine Erhöhung um 0,9K gegenüber der herkömmlichen Messung, siehe hier seine aktuellen Veröffentlichungen
http://www.augsburger-allgemeine.de/bayern/Meteorologe-findet-Diskussion-um-Klimaschutz-laecherlich-id32569342.html
und bei Hagers Seite: http://www.hager-meteo.de/aktuelle%20berichte.htm und http://www.hager-meteo.de/
Auch bei EIKE wurde am 13. Jan. ein Artikel darüber veröffentlicht.
http://www.eike-klima-energie.eu/news-cache/augsburger-meteorologe-findet-diskussion-um-klimaschutz-laecherlich/
In der Berliner Wetterkarte wurden die Ergebnisse ausführlich diskutiert: http://wkserv.met.fu-berlin.de/Beilagen/2013/Autom%20WSt_Hager.pdf
Damit stellt sich die Frage, ob dieses Ergebnis der 0,93K Erwärmung durch die Messmethodenänderung nur ein Einzelfall in Augsburg war oder ob das Ergebnis verallgemeinert werden kann. Hat die Umstellung der Messmethoden in den Jahren zwischen 1985 und 2000 generell zu einer gemessenen Klimaerwärmung geführt, die in der freien Natur so gar nicht stattgefunden hat?
Um diese Frage zu beantworten, unterteilen wir im Folgenden die DWD-Zeitreihen in drei Zeitabschnitte.
1) Temperaturmessung mit der alten Methode von 1900 bis 1985. 2) Die Zeit der Umstellung auf neue elektronische sowie automatische Temperaturmessungen von 1985 bis 2000 und 3) Die Zeit ab dem Jahre 2000 bis heute, alle 2000 Messstationen sind umgestellt.
Die folgenden Diagramme sind alle nach den Originaldaten des Deutschen Wetterdienstes in Offenbach erstellt. Aufgetragen sind immer die vom DWD aus vielen deutschen Stationen ermittelten Jahresdurchschnittswerte. Die Frage wäre also, können wir aus den Trends der DWD-Messungen irgendwelche Ungereimtheiten oder gar Parallelen zu den Angaben von Herrn Hager aus Augsburg erkennen?
Fakt ist, in Deutschland wurde um die Mitte der 80er Jahre mit der Digitalisierung und der Umstellung der alten Wetterhütten begonnen, sie dauerte etwa bis zur Jahrtausendwende.
Schauen wir uns als erstes die die deutschen Jahrestemperaturen von 1900 bis 1985 an, also die Zeit vor dem Digitalisierungsbeginn und der Messmethodenänderung.
Abb1.die Trendlinie ist nahezu ausgeglichen. Es gab somit in den ersten 85 Jahren des letzten Jahrhunderts, von 1900 bis 1985 fast keine Erwärmung.
Ergebnis 1: Von 1900 bis 1985 waren die Temperaturen in Deutschland sehr ausgeglichen, es gab zwar wärmere und kältere Jahre und Jahrzehnte. Doch genau diese Feststellung ist die Beschreibung für normales Temperaturverhalten. Auf 85 Jahre betrachtet, kaum Erwärmung trotz Industrialisierung und der damit verbundenen CO2- Zunahme. Die Trendlinie, zugleich fast der Mittelwert, liegt bei etwa 8,2C. Die Werte wurden alle mit der alten Messmethode und mit Glasthermometern ermittelt. Wir stellen aber auch fest: Der Anstieg des Treibhausgases Kohlendioxid zeigte 85 Jahre lang keinerlei Wirkung.
Wir sehen außerdem: Bei der Witterung ist nichts ist konstanter als der Wandel. Es gab wie 1934 sehr warme Jahre, aber schon kurz darauf mit 1940 das kälteste Jahr seit 1900. Über einen längeren Zeitraum gesehen, hat sich die Temperatur nicht verändert, obwohl der C02- Gehalt in diesen 85 Jahren selbstverständlich weiter gestiegen ist.
Betrachten wir nun den kurzen Zeitraum nach 1985 bis 2000, die Zeit der Umstellung der deutschen Wetterstationen auf automatisierte und elektronische Messverfahren. Wegen seiner geringen Dauer ist dieser freilich nur sehr eingeschränkt hinsichtlich des allgemeinen Temperaturtrends aussagefähig, trotzdem ist unstrittig, dass es in diesem Zeitraum in Mittel- und Westeuropa, beginnend mit dem Winter 1987/88, eine rasche Erwärmung („Klimasprung“) gab.
In diesem Zeitraum gegen Ende des letzten Jahrhunderts hat von 1985 bis 2000 die Hauptmasse der Digitalisierung der 2000 deutschen Messstationen stattgefunden. In der folgenden Abbildung wollen wir den Temperaturverlauf nur in diesen 15 Jahren vor der Jahrtausendwende näher erläutern. Das Ergebnis ist überraschend: Denn tatsächlich beginnt in Abb.2 die Trendlinie zu steigen. Laut der Trendlinie wird es in diesen 15 Jahren während der Umstellung der Stationen wärmer, genauso wie es Herr Hager in Augsburg aufgrund der Messmethodenumstellung als Ursache festgestellt hat. Ist es ein Zufall? Besteht ein Zusammenhang? Man könnte es meinen.
Abbildung 2: Die Jahrestemperaturen zeigen einen deutlichen Temperatursprung
Ergebnis 2: die Trendlinie der deutschen Werte steigt in diesen 15 Jahren der Digitalisierung und der Messmethodenänderung ebenfalls um gut 0,9 Grad wie in Augsburg. Ein Zufall?
Die Frage ist erlaubt. Wurde es in diesen 15 Jahren tatsächlich wärmer oder stimmt das Ergebnis mit Herrn Hagers Veröffentlichungen überein? Bestätigt es seine Aussagen? Die dritte Möglichkeit wäre natürlich nicht ein Entweder Oder, sondern beides könnte zutreffend sein. Dann wäre nur bei manchen Stationen schlampig gearbeitet worden und es hätte nur bei manchen Stationen keinen Abgleich gegeben, eine fehlerhafte Homogenisierung stattgefunden. Die Naturbeobachtungen aus dieser Zeit sprechen allerdings eindeutig für eine markante, reelle Erwärmung im betreffenden Zeitraum, denn nahezu alle phänologischen Phasen (Entwicklungsstadien der Pflanzen) haben sich besonders zwischen 1987 und 1990 enorm verfrüht. Ein weiterer, ernster Hinweis für einen tatsächlichen Temperaturanstieg ist die Anzahl der Schneedeckentage, welche in jenem Zeitraum deutlich abnahm (Datenquelle: PIK Potsdam):
Abb. 3: Ein ernster Hinweis auf einen reellen Temperaturanstieg in den letzten 15 Jahren des 20. Jahrhunderts ist beispielsweise die abnehmende Zahl der Tage mit einer Schneedecke von mindestens 1cm Höhe in diesem Zeitraum. Besonders die Winter 1987/88 bis 1989/90 waren extrem schneearm, weil ihre Niederschläge bei den hohen Temperaturen meist als Regen fielen. Nach dem Jahr 2000 wurden die Winter wieder schneereicher, und bei langzeitlicher Betrachtung (in Potsdam 1893 bis heute) ist fast kein Trend erkennbar.
Gegen eine Dominanz von Messfehlern beim Zustandekommen der Erwärmung des „Klimasprungs“ sprechen auch die vom DWD durchgeführten aktuellen Referenzmessungen. In der Arbeit Augter, Gisela (Hrsg.: Deutscher Wetterdienst): Vergleich der Referenzmessungen des Deutschen Wetterdienstes mit automatisch gewonnenen Messwerten. – 2., korr. Aufl. -Offenbach am Main: Selbstverlag des Deutschen Wetterdienstes, 2013.(Berichte des Deutschen Wetterdienstes ; 238), ISBN 978-3-88148-455-8, kommt der DWD zu folgendem Ergebnis: „Der Vergleich manuell gewonnener Referenzmesswerte mit den Werten, die automatisch ermittelt werden, hat ergeben, dass die Differenzen der Terminwerte in den meisten Fällen so gering sind, dass die Homogenität einer Messreihe beim Wechsel des Messverfahrens nicht gestört wird.“ Freilich räumt der DWD in dieser Veröffentlichung auch ein, dass es bei einzelnen Parallelmessungen Abweichungen (mittlere Differenzen) bis zu 0,35K gegeben hat, beispielsweise an der Station Lindenberg südöstlich von Berlin. Diese wenigen Einzelfälle beeinflussen freilich das Gesamtergebnis kaum.
Wir fragen aber auch ironisch, warum hat in diesen 15 Jahren der „C02-Treibhauseffekt“ plötzlich seine volle Wirkung entfalten dürfen, nachdem er zuvor 85 Jahre ohne jede Wirkung blieb? Wer hat dem „C02-Treibhauseffekt“ in diesen 15 Jahren den Turbo gezündet?
Und wie ging es nach 2000 weiter?
Nach 2000 waren alle Klimastationen des DWD digitalisiert, es kamen also keine mehr dazu, die quasi von heute auf morgen höhere Werte anzeigen konnten. Zunächst stellt man fest: Die Temperaturergebnisse sind auf dem erreichten höheren Niveau fortgeführt worden. Das zeigt die Abb. 4:
Abb. 4: Die Temperaturen nach 2000 steigen nicht weiter, sie fallen sogar ganz leicht. Die Trendlinie im neuen Jahrtausend liegt etwa um 1 Grad höher wie die Trendlinie von 1900 bis 1985, zwischen 9,4°C und 9,2°C.
Ergebnis 3: Nach dem Umstellungsende der etwa 2000 deutschen Stationen ist auch der Trendlinienanstieg beendet. Die Temperaturen sinken seit 2000 sogar wieder leicht. Und wo bleibt der „Treibhauseffekt“: Irgendjemand hat den „CO2-Treibhauseffekt“ wieder ausgeschaltet. Oder wirkt der ab dem Jahre 2000 abkühlend auf das Klima?
Wären die in Augsburg festgestellten 0,9 Grad Messfehlererwärmung auf ganz Deutschland übertragbar, dann würde der 2000er Jahres-Wert von 9,9 C nur 9 Grad betragen, also ähnlich wie die Jahrestemperaturen reihenweise vor 1985 schon waren.
Weiter ergäbe sich: Auch die 10,3°C von 2014 wären dann nur 9,4°C. Das Jahr 1934 wäre demnach mit 9,6°C das wärmste Jahr der Neuzeit gewesen. Mehrere Fragen seien an die Klimawissenschaft gestellt: Ist die weltweite, aber vor allem in Deutschland laut verkündete Klimaerwärmung tatsächlich menschengemacht? Hat diese menschengemachte Klimaerwärmung ausschließlich zwischen 1985 und dem Jahr 2000 stattgefunden? Brachte die Messmethodenänderung die Klimaerwärmung?
Die jetzigen, also nach dem Jahre 2000 mit der neuen Methode ermittelten Temperatur-Werte liegen alle um etwa ein Grad höher als vor 1985.
Aus den drei Diagrammen lässt sich aber nur ein Faktum gesichert ablesen. Das angebliche „Treibhausgas CO2“ ist nirgendwo beteiligt an diesem gemessenen Temperaturverhalten. Im ganzen Zeitraum sind CO2-Konzentrationen der Atmosphäre gestiegen, während die Jahrestemperaturen immer wieder Sprünge aufweisen.
Zusammenfassung: Von 1900 bis 2014 wurde es nach den Temperaturstatistiken des Deutschen Wetterdienstes um etwa 1 Grad wärmer. Erwärmungsgläubige sehen das als Beweis einer menschengemachten C02-Klimaerwärmung an.
Die Erwärmung erfolgte allerdings in drei Schüben
Von 1900 bis 1985, also 85 Jahre lang fast gar keine Erwärmung
Innerhalb von 15 Jahren von 1985 bis 2000 erfolgt die Erwärmung schlagartig von etwa einem Grad.
Seit 2000, also seit 15 Jahren, stagniert die Erwärmung, die Trendlinie ist sogar leicht fallend.
Diese drei Schübe kommen besser zur Geltung, wenn man nur die drei Trendlinien der drei Zeitabschnitte aneinanderreiht.
Abb. 5: Die drei geglätteten Trendlinien der drei Zeitabschnitte von Abb. 1 bis Abb. 3 ergeben überhaupt keine homogene Erwärmung. Auffallend ist der starke Anstieg von 1985 bis zum Jahr 2000. In diesem recht kurzen Zeitraum fand fast die gesamte „Klimaerwärmung“ statt.
Zwischen Kohlendioxid und gemessener Temperaturerwärmung gibt es keinerlei Zusammenhang. Der Anstieg von knapp 0,03% auf jetzt 0,04% CO2 in den letzten 120 Jahren erfolgte leicht beschleunigt, während die Temperaturerhöhung nur sprunghaft zwischen 1985 bis 2000 stattfand.
Da alle vier Grafiken auf den Originaldaten des DWD in Offenbach basieren, ist ein Irrtum ausgeschlossen.
Während für die sprunghafte Erwärmung um 1990 mit hoher Wahrscheinlichkeit eine erhöhte Einstrahlung (Globalstrahlung) infolge der Luftreinhaltemaßnahmen und des Zusammenbruchs der Industrien der Mittel- und osteuropäischen Staaten sowie Zirkulationsänderungen in Betracht kommen (zeitweise mehr Westlagen im Winter, insgesamt mehr südliche Lagen im gesamten Jahr), wirkten langfristig außerdem auch folgende Ursachen erwärmend:
Änderungen der Landnutzung (Entwässerung, Intensivierung der Landwirtschaft) sowie ein zunehmender Bebauungs- und Versiegelungsgrad, einhergehend mit mehr Abwärme (Heizungen, Verkehr, Industrie); neuerdings auch Solar- und Windparks, die den kühlenden Wind bremsen und/oder die Albedo (das Rückstrahlungsvermögen) verringern. Es handelt sich um Wärmeinsel- Effekte im weitesten Sinne.
Zunehmende Sonnenaktivität im 20. Jahrhundert.
Stationsverlagerungen, geänderte Messtechnik und Beobachtungszeiten.
Ergebniszusammenfassung: Die in der Überschrift gestellte Frage, ob allein die Messmethode zu diesem Temperatursprung zwischen 1985 und 2000 geführt hat, beantworten wir mit Nein. Die Änderung der Messmethoden und die neuen Wetterhütten haben jedoch sicherlich einen Anteil an diesem Erwärmungssprung. Wie groß dieser Anteil ist, das können wir mit diesem Artikel und dem uns vorliegendem Datenmaterial nicht beantworten. Der Augsburger Stationsleiter schreibt selbst, die von ihm ermittelten 0,93K würden nur für Augsburg gelten und jede Station würde sich anders verhalten.
Josef Kowatsch, unabhängiger Natur- und Klimaforscher
Stefan Kämpfe, unabhängiger Natur- und Klimaforscher
„1) (hatte ich schon zweimal dazu aufgefordert): Sie malen in Ihre Diagramme das Temperatursignal ein, welches laut CO2-Theorie nach Ihrer (!) Meinung für die Deutschlandtemperatur erwarten ist. Man sieht damit dann Ihre Vorstellung von der Wirkung CO2-Theorie auf die Deutschlandtemperatur im Vergleich zu den DWD-Messdaten der Deutschlandtemperatur im gleichen Diagramm.
2) Sie untersuchen, ob der Unterschied dieser beiden Kurven statistisch signifikant ist, die Nullhypothese also abzulehnen ist.
3) Wenn die Nullhypothese (= kein signifikanter Unterschied) mit einem Vertrauensbereich von mehr als 90% abzulehnen ist, haben Sie zumindest erst mal einen objektiven Hinweis (basierend auf Stochastik), daß an der Theorie was faul ist. Ohne dem ist alles Wunschdenken, was Sie von sich geben.“
Wann haben Sie die Punkte 1) bis 3) beantwortet? Zumindest zu 1) sollten Sie eine Meinung haben. Wenn nicht, weiß man nicht, auf was Sie sich eigentlich bislang berufen wollen.
MfG
P.S.: Ich kenne einen Maschinenbau-Ingenieur, der fiel auch auf das Gärtner-Treibhaus herein. Er nahm eine Glasglocke. Und der hat sein Ingenieur-Studium dann auch noch gepackt. Den muss ich mal wieder anrufen. Um zu sehen, ob er etwas dazu gelernt hat. Manche Leutchen versagen sich dem Fortschritt. :))
Das Gärtner-Treibhaus kann also wesentliche Wärme-Transportvorgänge, die in der Troposphäre dominieren, nicht beschreiben.
..Da nach Abgabe der fühlbaren und latenten Wärme nur noch 65 W·m-2 zur Verfügung stehen, muss die Gegenstrahlung 325 W·m-2 betragen. Das ist mehr als der solare Input abzüglich 30 % Albedo, nämlich ca. 240 W·m-2, und somit auf Dauer nicht möglich, weil es ein Verstoß gegen den Energieerhaltungssatz wäre.
Was CO2 betrifft, ist die Abb.1 besonders schön, die zeigt, wie viel höher der CO2-Anteil früher war und dass unsere heutige Kohle aus einer Zeit viel höherer CO2-Konzentration entstanden ist.
Das kann also nicht schlecht sondern im Gegenteil förderlich für das Leben gewesen sein.
Ich will noch mal darauf hinweisen,
dass das „Nachlaufen“ von CO2 keine Theorie ist, schon gar nicht meine, sondern ein unbestrittener Messbefund.
Theorie ist dagegen, dass CO2 selbst eine Temperaturwirkung entfalten soll.
Und diese Theorie, genannt Treibhauseffekt wird durch die Realität dieses Messbefundes widerlegt.
Das hat ja nun selbst Baecker einsehen müssen.
mfG
wichtig ist eigentlich nur, dass Sie kappieren, dass CO2 NICHT die Temperatur steuert,
aber lebenswichtig für die Pflanzen ist.
Wissen Sie denn wieviel CO2 die Insekten produzieren?
mfG
mir ist nicht bekannt ob sie das folgend verlinkte Schreiben bei der TU-Freiberg kennen, aber es ist hinsichtlich ihrer Argumentation sehr Interessant und widerlegt auch ihren Diskussionsgegner Hr. (?) Baecker.
Textauszug:
„Die aus Sauerstoff-18-Bestimmungen am Eis abgeleiteten Temperaturen schwanken mit einer Perio-
dendauer von ca. 100000 Jahren um etwa 10 K.
• Der an der extrahierten Luft bestimmbare CO 2 -Gehalt schwankt mit etwa gleicher Periodendauer,
wobei der voreiszeitliche CO 2 -Gehalt meist nicht wieder erreicht wird. (CO 2 -Verluste?).
• Der Anstieg des CO 2 -Gehaltes (der Luft?) folgt der Erwärmung mit einer Verzögerung von 600 … 1000 Jahren“
Quelle: http://tinyurl.com/nbgd9hn
Sie kapieren wohl immer noch nicht, daß das anthropogen freigesetzte CO2 kaum durch die Temperatur gesteuert wird. Die CO2 Konzentration in der Atmosphäre wird in den letzen Jahrzehnten dominant durch den Menschen gesteuert, die Temperatur macht da nur Nuancen in der Kurve.
Für die Gesamtmenge an CO2 im Ozean ist selbstverständlich nicht die Temperatur verantwortlich, sondern schlicht die übrig gebliebene Menge aus der Erdgeschichte und die heutigen materiellen CO2-Quellen und Senken!
Das ist daher kein Widerspruch zu der temperaturabhängigen Verteilung zwischen Wasser und Luft darüber, eine Frage der Löslichkeit, beschrieben im Henry´Gesetz.
Hierzu MUSS es daher auch eine Korrelation geben, die dazu führt, dass die Oberflächentemperatur ABFÄLLT, während das CO2 noch ANSTEIGT.
Also im kurzfristig höchsten CO2-Gipfel fällt die Oberflächentemperatur, was einen „Erwärmungseffekt von CO2 eindrucksvoll widerlegt.
Einfach gesagt, löst kaltes Wasser deutlich mehr CO2 als warmes Wasser, CO2 als Lebensquelle, also ein Wachtumsvorteil für Bioplankton in kaltem Wasser, weshalb Fische sowohl im Nord- wie im Südpoolbereich bis unters Eis schwimmen, weil es hier so viel Nahrung gibt, dank CO2.
http://tinyurl.com/oybzywl
Offensichtlich besteht aber keinerlei Zusammenhang (Korrelation) zwischen absoluter CO2-Konzentration und Erdtemperatur, was EBENFALLS einen CO2-Treibhauseffekt ausschließt.
Prof.Hans-Günter Appel hat das durch fossile Brennstoffe entstandene CO2 beträgt im Jahr 0,014 % des CO2 errechnet, das in der Atmosphäre und in den Meeren gelöst ist. Das wäre also 0,00056 % mehr „anthropogen“.
wörtlich:
„Mir sind keine Untersuchungen bekannt, woher der große, durch Messungen nachgewiesene Anstieg von CO2 im letzten Jahrhundert in der Atmosphäre stammt. Möglicherweise ist dafür die Vulkantätigkeit im Meer verantwortlich. Mehr als 2/3 aller tätigen Vulkane liegen unter dem Meeresspiegel.“
siehe auch hier
http://tinyurl.com/pep4cxo
mfG
Das geht auch nicht mit blöden Witzen:
im Paleozoikum gab es noch keine Dinosaurier,
arbeiten Sie etwas an Ihrer Allgemeinbildung.
http://tinyurl.com/oybzywl
Und auch Salby hat in Hamburg sehr deutlich ausgeführt, dass CO2 bei ausreichender Zeitauflösung der Temperatur FOLGT, nicht nur heute sondern auch in der Erdgeschichte bei ausreichender „Zeitauflösung“.
Nichtmal normale vernünftige Sätze können Sie formulieren:
daß die Response-Funktion zwischen mittlerer globaler Temperatur und CO2-Konzentration vom Zeitintervall abhängt.
Eine Responsfunktion hängt also von einem „Intervall“ ab?
Wieviel Zeit darf sich denn das CO2 nehmen, damit es die Ursache für die VORAUSGEHENDE Temperatur sein könnte???
Selbst Einstein hat ein Rückwärtslaufen der Zeit doch verboten.
Vielleicht fehlte es Ihnen ja nur an Englischkenntnissen, den schönen letzten Vortrag von Salby in Hamburg 2013 zu verstehen:
http://tinyurl.com/l5uzrah
Oder versuchen Sie die Ebeltaktik mit seinen Angström, der aus einer Widerlegung eines Treibhauseffektes einen Nachweis machen möchte,
egal wie dumm das auch klingt?
Mit freundlichen Grüßen
in #38 Punkt 3) statt
„daß an der Theorie was faul ist.“
präziser:
„an Ihrer Vorstellung über die Wirkung der CO2-Theorie auf die Deutschlandtemperatur was faul ist.“
an Paul:
übrigens hat Prof. Salby ja schon gezeigt, daß die Response-Funktion zwischen mittlerer globaler Temperatur und CO2-Konzentration vom Zeitintervall abhängt. Ihr Vergleich ist schon unter diesem Aspekt falsch. Aber ich kann Sie auch mit Ihrem eigenen Schwachsinn ad absurdum führen: Sie behaupten doch immer, es gäbe keine Korrelation zwischen Temperatur und CO2. Wie erklären Sie sich dann Ihre eigene dazu widersprechende Interpretation Ihres links http://tinyurl.com/oybzywl ?
“ nämlich das von Ursache und Wirkung,
CO2 FOLGT Temperaturververänderungen.“
Sicher, den Saurier wurde es zu warm und sie haben ihre Kohlekraftwerke abgeschaltet.
Paul, zeigen Sie mir mal, wie die fossile Energieerzeugung mit der Temperatur korreliert.
„Sie haben unseren Artikel schon gelesen, oder? Unsere in der Überschrift gestellte Frage haben wir mit NEIN beantwortet.“
Aber ohne Beweise können Sie Ihre Aussage in den Eimer werfen. Sie stellen ja weder da, wonach Sie quantitativ suchen, noch geben Sie an, welche Genauigkeit Ihr Verfahren hat.
„Frage: Nach ihrem Kommentar in K35 ist mir unklar, wie Sie die Frage beantwortet haben wollen“
Ganz einfach:
1) (hatte ich schon zweimal dazu aufgefordert): Sie malen in Ihre Diagramme das Temperatursignal ein, welches laut CO2-Theorie nach Ihrer (!) Meinung für die Deutschlandtemperatur erwarten ist. Man sieht damit dann Ihre Vorstellung von der Wirkung CO2-Theorie auf die Deutschlandtemperatur im Vergleich zu den DWD-Messdaten der Deutschlandtemperatur im gleichen Diagramm.
2) Sie untersuchen, ob der Unterschied dieser beiden Kurven statistisch signifikant ist, die Nullhypothese also abzulehnen ist.
3) Wenn die Nullhypothese (= kein signifikanter Unterschied) mit einem Vertrauensbereich von mehr als 90% abzulehnen ist, haben Sie zumindest erst mal einen objektiven Hinweis (basierend auf Stochastik), daß an der Theorie was faul ist. Ohne dem ist alles Wunschdenken, was Sie von sich geben.
Sie haben unseren Artikel schon gelesen, oder? Unsere in der Überschrift gestellte Frage haben wir mit NEIN beantwortet. Frage: Nach ihrem Kommentar in K35 ist mir unklar, wie Sie die Frage beantwortet haben wollen. Oder nehmen Sie mal wieder die Gelegenheit wahr, einfach eine Diskussion im leeren Raum zu starten, über Gott und die Welt und über Baecker.?
http://tinyurl.com/oybzywl
Je länger die Zeitreihe desto besser ist ein auch noch so winziger Zusammenhang (Wirkung) erkennbar!
Das kann ihnen jeder Statistiker erklären.
Wenn Sie nun unbedingt zeitlich ganz ganz fein tunen wollen,
ergibt sich ein ganz neues Problem für die Hypothese eines CO2-Treibhauseffektes,
nämlich das von Ursache und Wirkung,
CO2 FOLGT Temperaturververänderungen.
mfG
„Was sagt uns das „Leibniz-Institut für Astrophysik Potsdam (AIP)“ dazu?
Bewiesen wird mit Logik, nicht mit Statistik:
Wir sehen uns die Voraussetzungen an und schließen dann. Die Hauptfehlerquellen sind das Übersehen von Voraussetzungen und die Verletzung der Schlussregeln, und wenn beides gezielt angewandt wird, kann dann von allem Möglichen behauptet werden, dass es bewiesen ist. Das geht mit statistischen Argumenten besonders eindrucksvoll, weil der geneigte Hörer glaubt, er könne ebenfalls richtig zählen. Wir wollen uns ansehen, wie das funktioniert, und die Ehre des Statistik retten. „
Meine Rede, sage ich ja: Herr Kowatsch beherrscht weder die richtigen Voraussetzungen zu nehmen (Wahl der Zeitreihe und Zeitspanne, die überhaupt einen Nachweis statistisch signifikant anhand des SNR ermöglichen kann) noch korrekt (also Theorie im Vergleich zum Ergebnis) zu schließen. Denn ohne den Nachweis der statistischen Signifikanz sind seine Schlüsse für den Eimer.
„Und im Rahmen diese Unsicherheit wird die Beobachtung mit der Theorie verglichen.“
Das geht aber nur mit Theorien, nicht mit nicht quantifizierten Hypothesen.
„Sie scheinen in Ermangelung einer technisch-naturwissenschaftlichen Ausbildung damit Probleme grundsätzlicher Art zu haben.“
Und wieder ein Griff in die längst verblaßten Hits der Oldie-Hitparade des vergangenen Jahres.
am Dienstag, 27.01.2015, 13:56
Lieber Herr Klasen, #28
„Auf statistischen Erfahrungssätzen beruhende Schlüsse sind daher mit einer ebenfalls im Erfahrungssatz ausgedrückten Unsicherheit behaftet.““
Hier geht es aber nicht um „Erfahrungssätze“, sondern einfach um die Anwendung von Mathematik/Stochastik, nämlich die Quantifizierung einer Unsicherheit, die aus empirischen Daten folgt. Die Methode gilt natürlich für jede messtechnisch oder beobachterisch vorgenommene Verifikation einer Theorie: jeder Messwert hat nur eine endliche statistische Sicherheit und damit eine nichtverschwindende Unsicherheit, diese ist jedoch objektiv quantifizierbar. Und im Rahmen diese Unsicherheit wird die Beobachtung mit der Theorie verglichen. Sie scheinen in Ermangelung einer technisch-naturwissenschaftlichen Ausbildung damit Probleme grundsätzlicher Art zu haben.
Was sagt uns das „Leibniz-Institut für Astrophysik Potsdam (AIP)“ dazu?
Bewiesen wird mit Logik, nicht mit Statistik:
Wir sehen uns die Voraussetzungen an und schließen dann. Die Hauptfehlerquellen sind das Übersehen von Voraussetzungen und die Verletzung der Schlussregeln, und wenn beides gezielt angewandt wird, kann dann von allem Möglichen behauptet werden, dass es bewiesen ist. Das geht mit statistischen Argumenten besonders eindrucksvoll, weil der geneigte Hörer glaubt, er könne ebenfalls richtig zählen. Wir wollen uns ansehen, wie das funktioniert, und die Ehre des Statistik retten.
Was beweist Statistik?
• Statistik beweist nichts, will nichts beweisen: sie ist eine Entscheidungshilfe. Sie setzt ein Modell (das der Zufallsvariablen) axiomatisch voraus, ohne das die Schlüsse und Rechnungen nicht durchführbar sind.
• Ein Beweis hat eine bestimmte Struktur: Er benennt die Voraussetzungen (Hypothesen), den Schlussweg, den Schluss. Die Hauptfehler sind das manchmal absichtliche Vergessen der Hypothesen, die manchmal absichtlich falsche Verwendung der Schlussfiguren.
• Eine Theorie lebt davon, mit wenigen Hypothesen und richtigen Schlussfiguren die ansonsten unverständlichen Beobachtungen zu erklären. Eine Theorie ermöglicht so Verständnis. Der landläufige Gebrauch des Attributs „theoretisch“ ist dagegen eine Verunglimpfung, weil er im Allgemeinen nur Vermutungen betrifft und die Wolkigkeit derselben als Vertuschung der eigenen Unlust zum Denken benutzt.
• Eine Vermutung ist noch nicht einmal eine Hypothese. Das wird sie erst, wenn man sie als Fundament nehmen und eine Theorie darauf aufbauen kann, die den Zusammenhang verschidener Beobachtungen gestattet und sie damit erklärt. Beobachtungen müssen erklärt werden, und die Erklärung ist eine Theorie.
• Eine Theorie sollte richtig sein (d.h. logisch richtig aus den Prinzipien hergeleitet sein), es gibt aber keinen logischen Schluss auf ihre Anwendbarkeit. Die Anwendbarkeit (d.h. die Produktivität der als Prinzipien akzeptierten Vermutungen) muss durch Experiment und Beobachtung getestet werden. Diese Tests haben wiederum nur dann Beweiskraft, wenn das Ergebnis negativ ist, d.h. die Erwartung enttäuscht. Negative Ergebnisse beweisen, dass die Anwendbarkeit eingeschränkt oder ausgeschlossen ist. Positive Ergebnisse stützen natürlich die Theorie, beweisen aber nicht ihre Anwendbarkeit. Dennoch ist es eine gute Strategie, gut gestützte Theorien zu verwenden.
„Auf statistischen Erfahrungssätzen beruhende Schlüsse sind daher mit einer ebenfalls im Erfahrungssatz ausgedrückten Unsicherheit behaftet.““
Hier geht es aber nicht um „Erfahrungssätze“, sondern einfach um die Anwendung von Mathematik/Stochastik, nämlich die Quantifizierung einer Unsicherheit, die aus empirischen Daten folgt. Die Methode gilt natürlich für jede messtechnisch oder beobachterisch vorgenommene Verifikation einer Theorie: jeder Messwert hat nur eine endliche statistische Sicherheit und damit eine nichtverschwindende Unsicherheit, diese ist jedoch objektiv quantifizierbar. Und im Rahmen diese Unsicherheit wird die Beobachtung mit der Theorie verglichen. Sie scheinen in Ermangelung einer technisch-naturwissenschaftlichen Ausbildung damit Probleme grundsätzlicher Art zu haben.
Und von der Einzelmeinung eines Lehrbeauftragten kann ebenfalls nicht die Rede sein, denn ich kenne eigentlich keinen meteorologischen Fachmann, der eine andere Meinung hat; es ist nur ein Einzelfall, dass seine Meinung auch medial veröffentlicht wird.
In der gesamten Fachwelt hat sich Herr Hager jedenfalls großen Respekt erworben.
Sehr geehrter Herr Paesler,
es liegt mir fern, Herrn Hagers Arbeit im Allgemeinen schmäler zu wollen.
Nur gehen Sie auf meine Anmerkungen insbesondere Punkt 2 nicht ein.
Wie ich schon an anderer Stelle sagte,
http://tinyurl.com/Kritik-Hager
hatte Herr Hager auch teile der von ihm zitierte Literatur recht frei interpretiert.
Und aus den 0,93K mittleren Abweichung der täglichen Max-Werte eine 0,9K Abweichung der Mitteltemperatur zu machen ist wohl fahrlässig – wer auch immer dafür verantwortlich sein mag.
Dass Herr Hager mit seinem Interview ins Fettnäpfchen getreten ist, war ja klar. Und dass die Uni Augsburg nach solchen Äußerungen eines Mitarbeiters um ihre Drittmittel fürchtet, auch.
Extrem witzig, aber bei einer Person wie dem Institutsleiter, Herrn Jucundus Jacobeit, nicht überraschend, ist die Behauptung, dass man sich in seinem Institut „einer wissenschaftliche fundierten Behandlung dieser bedeutsamen Themenfelder verpflichtet sieht.“
Dazu ist zu sagen, dass Jacobeit von Meteorologie, Physik und verwandten Bereichen soviel Ahnung hat, wie ein Fisch vom Fahrrad fahren und etwas, was er für falsch hält, mit Sicherheit richtig sein muss!
Und von der Einzelmeinung eines Lehrbeauftragten kann ebenfalls nicht die Rede sein, denn ich kenne eigentlich keinen meteorologischen Fachmann, der eine andere Meinung hat; es ist nur ein Einzelfall, dass seine Meinung auch medial veröffentlicht wird.
In der gesamten Fachwelt hat sich Herr Hager jedenfalls großen Respekt erworben.
Wird das der Superhit des Jahres 2015?
„… ist aber bewiesen, nur nicht so, daß Sie es intellektuell begreifen könnten. Wissenschaft ist für Sie unerreichbar.“
Autor: Pseudonym NicoBaecker
Die Aussage ist eigentlich nicht mehr zu toppen.
„Das erwartete Signal ist hier, daß die Deutschlandtemperatur durch die CO2-Zunahme die letzten Jahrzehnte in etwa 0,2 °C pro Dekade steigt. Das ist offensichtlich jedoch statistisch nachweisbar.“
Was sagt uns die einfachste aller Quellen (Wikipedia) dazu:
„Auf statistischen Erfahrungssätzen beruhende Schlüsse sind daher mit einer ebenfalls im Erfahrungssatz ausgedrückten Unsicherheit behaftet.“
„für diese aus der Luft gegriffenen Behauptungen gibt es keinen Beweis“
… ist aber bewiesen, nur nicht so, daß Sie es intellektuell begreifen könnten. Wissenschaft ist für Sie unerreichbar.
„Das erwartete Signal ist hier, daß die Deutschlandtemperatur durch die CO2-Zunahme die letzten Jahrzehnte in etwa 0,2 °C pro Dekade steigt. Das ist offensichtlich jedoch statistisch nachweisbar.“
Merke: für diese aus der Luft gegriffenen Behauptungen gibt es keinen Beweis,
„Herr Langer, steigender CO2-Gehalt führt zu Temperaturerhöhung;“
Nicht bewiesen, wer es glaubt wird selig…
„Und solch einen selbstverstärkenden Effekt nann man nun mal positive Rückkopplung“
Und einen Post wie Ihren nennt man blödes Gequatsche
„Am 10. Januar 2015 ist in der Augsburger Allgemeinen Zeitung ein Interview mit Herrn Klaus Hager zur Thematik Klimawandel und Klimaschutz unter dem Titel „Die Leute werden an der Nase herumgeführt“ veröffentlicht worden.
Da Herr Hager Lehrbeauftragter am Institut für Geographie der Universität Augsburg ist, sieht sich die Institutsleitung zu folgender Klarstellung veranlasst:
Die in der AAZ wiedergegebenen Aussagen stellen ausschließlich persönliche Auffassungen von Herrn Hager dar und geben nicht die Art und Weise der Behandlung solch komplexer Themenfelder wie Klimawandel und Klimafolgen in der Augsburger Geographie wieder. Das Institut für Geographie, das sich ausgewiesenermaßen einer wissenschaftlich fundierten Behandlung dieser bedeutsamen Themenfelder verpflichtet sieht, kann nicht assoziiert werden mit der medial verbreiteten Einzelmeinung eines Lehrbeauftragten.“
Nachzulesen bei
http://www.geo.uni-augsburg.de/
Man sollte also etwas vorsichtiger sein mit Formulierungen wie: „Wären die in Augsburg festgestellten 0,9 Grad Messfehlererwärmung auf ganz Deutschland übertragbar, dann würde der 2000er Jahres-Wert von 9,9 C nur 9 Grad betragen, also ähnlich wie die Jahrestemperaturen reihenweise vor 1985 schon waren.“
Meines Erachtens berichtet zwar Herr Hager in der Augsburger Allgemeinen über eine Abweichung von +0,9K (im Mittel) in der Beilage zur Berliner Wetterkarte spricht er nur vom diesem Vergleich:
„[ . . . ] Vergleichsmessungen von Quecksilber-MAXIMUM-Glasthermometern in einer Wetterhütte und Pt 100 Widerstandsthermometer in einer Aluhütte jeweils unbelüftet vorgenommen wurden. An den 3144 Tagen ergab sich eine mittlere Differenz von + 0,93 Grad – Pt 100 höher als Quecksilber. Die maximal erfasste Tagesdifferenz betrug gar 6,4 Grad ! [ . . . ] „
Dazu zwei Anmerkungen:
1) Die Instrumentierung (Aluhütte, passiv belüftet) in Augsburg weicht von DWD-Standard ab.
2) Den Vergleich der Maximum-Temperaturen sollte man nicht verallgemeinern und daraus eine allgemeine Erhöhung um 0,9K ableiten.
Und solch einen selbstverstärkenden Effekt nann man nun mal positive Rückkopplung.
Nicht schwer zu verstehen und kein Grund ausfallend zu werden.
Gruß
Hans Jung
Die todsichere Methode ist: Sie messen gleich nur ein Datenpaar (die beiden Größen, die korreliert sind, je einmal). Wenn es nur ein Datenpaar gibt, gibt es auch nichts, mit dem man es korrelieren kann.
Das erwartete Signal ist hier, daß die Deutschlandtemperatur durch die CO2-Zunahme die letzten Jahrzehnte in etwa 0,2 °C pro Dekade steigt. Das ist offensichtlich jedoch statistisch nachweisbar. Damit ist erstmal widerlegt, daß es keine Korrelation zum CO2 gäbe. Die Zeitreihen von Herrn Kowatsch sind so kurz (15 Jahre), daß man überhaupt keine Trends dieser Größe signifikant nachweisen kann, schließen also a priori schon einen empirischen Nachweis aus. Es sei denn, er würde erwarten, daß das CO2-Signal so groß sein müßte (also mehr als 0,2C pro Dekade), daß seine 15 Jahres Reihen zum Nachweis geeignet wären, wenn es existieren würde.
Merke: Das Poppersche Falsifizieren ist nicht so gemeint, daß man durch genügend unzureichende Untersuchungen alles falsifizieren kann. Es muß vorher nachgewiesen sein, daß das vermutete Signal überhaupt nachgewiesen kann, wenn es da wäre.
beim Kommentar von Herrn Jung (#18) gibt es nicht nur haarsträubende fachliche Fehler, man kann allein an diesem einen Kommentar die ganze Diskussionsstrategie der AGW-Sekte ablesen!
Herr Jung beginnt damit, dass er Ihrem Beispiel für eine Ursache-Wirkungs-Beziehung „Ein tödlicher Schuss und der Tod des Opfers“ mit „Schüsse fallen oft auch NACHDEM und WEIL vorher jemand tot umgefallen ist.“ begegnet. Erst verfälscht Herr Jung Ihre Aussage, indem er das „tödlich“ weglässt um dann die gefälschte Aussage zu widerlegen. Sein Argument ist somit ein klassisches Strohmannargument.
Nachdem er dann seinen logischen Unfug von sich gegeben hat (s. „Rückkopplungen“), sagt er: „Diese Gesetzmäßigkeiten sind recht einfach zu verstehen und jedem Physiker bekannt.“ Er stellt damit automatisch alle Personen, die nicht seiner Auffassung sind, als inkompetent und jenseits der Wissenschaft dar.
Seine Argumentation besteht demnach aus drei Bestandteilen:
– mathematisch-naturwissenschaftlicher Unfug,
– Strohmannargument,
– argumentum ad hominem.
Was er dabei aber eben nicht begreift, ist die Tatsache, dass man mit solchen „Argumenten“ nur innerhalb der religiösen Sekte punkten kann, der man angehört. Es würde also Sinn machen, wenn er so etwas bei primaklima oder auf der klimalounge von sich gibt – hier auf EIKE ist es albern!
MfG
http://tinyurl.com/nny2xqv
wo sehen Sie hier eine positive Rückkoplung?
Hier verändert sich das CO2 immer NACH der Temperaturveränderung mit Korrelation. Warum das auch so sein muss beantwortet das Henry Gesetz.
Für einen AGW-Vertreter darf also erst gestorben werden
und DANACH der tödliche Schuss kommen.
Schöne Demonstration. Ihnen ist also kein Logigfehler zu blöd.
mfG
„Ein tödlicher Schuss und der Tod des Opfers.“
Sie müssen den Satz schon korrekt interpretieren.
Hier ist die Kausalität bereits festgeschrieben – Ein tödlicher Schuss, es muss also der Tod des Opfers eintreten. Das Bindewort „und“ stellt hier die logische Verknüpfung zwischen diesen beiden Ereignissen her.
Mfg
Werner Holtz
über die sogar in der AGW Szenen gelegentlich heftig gestritten wird:
Es geht da um die ganz ganz schwierige fundamentale Frage der Physik,
ob nur zuerst die Wirkung oder die Ursache der Wirkung eintritt.
Einfaches Beispiel.
Ein tödlicher Schuss und der Tod des Opfers,
was ist zuerst?
Fällt erst das Opfer tot um
oder fällt erst der Schuss?
Herr Paul, beides ist möglich.
Schüsse fallen oft auch NACHDEM und WEIL vorher jemand tot umgefallen ist.
Das nennt man Eskalation, und ist in jedem militärischen Konflikt zu beobachten.
Übertragen auf die Physik würde man es als positive Rückkopplung bezeichnen. Und ist, im Gegensatz zu ihrer Wahrnehmung keineswegs eine schwierige fundamentale Frage.
Diese Gesetzmäßigkeiten sind recht einfach zu verstehen und jedem Physiker bekannt.
Ich hoffe sie haben es jetzt auch endlich verstanden.
Gruß
Hans Jung
Nun, es ging da auch um Ihr eigenes Thema der Korrelation:
http://tinyurl.com/nny2xqv
Hier sieht es doch tatsächtlich so aus,
als ob erste das Opfer (Temperatur) tot umfällt
und dann erst der Schuss (CO2) fällt.
über die sogar in der AGW Szenen gelegentlich heftig gestritten wird:
Es geht da um die ganz ganz schwierige fundamentale Frage der Physik,
ob nur zuerst die Wirkung oder die Ursache der Wirkung eintritt.
Einfaches Beispiel.
Ein tödlicher Schuss und der Tod des Opfers,
was ist zuerst?
Fällt erst das Opfer tot um
oder fällt erst der Schuss?
In der AGW Physik hört man immer, dass erst das Opfer tot umfällt und dann der Schuss fällt.
Der gesunde Menschenverstand würde sagen,
dann könnte aber der Schuss daneben gehen?
Wie sehen Sie das?
mfG
Hier werden Sie geholfen:
http://tinyurl.com/oybzywl
also:
KEINE KORRELATION
„bitte zeichnen doch Sie einmal eine Korrelationskurve zwischen dem gleichmäßigen Anstieg der C02-Konzentrationen in den letzten 100 Jahren und dem Temperaturverlauf Deutschlands wie wir ihn in den drei Diagrammen dargestellt haben. Ich hätte gerne gewußt, was Sie da im Kopf haben.“
Eine Korrelationskurve würde Ihnen nichts helfen, da Sie die Mathematik der Kreuzkorrelation nicht kennen. Wie man außerdem ja an den Kurven von CO2 und Deutschlandtemperatur, die Sie ja schon liefern, ja ohnehin schon sieht, ist der Korrelationskoeffizient so niedrig, daß eine empirisch signifikanten Korrelation zwischen der Deutschlandtemperatur und CO2 in Zeiträumen unter 20 Jahren nicht zu finden ist. Da Sie jedoch unterstellen, es müsse ein solcher bei kausalen Zusammenhängen zu sehen sein, so sollen Sie mir mal zeigen, was Sie dafür erwarten wollen. Ich glaube, Sie überschätzen den CO2-Einfluß auf die Deutschlandtemperatur und damit das SNR (= Verhältnis CO2-Signal-zu-natürlichem Klimarauschen) dafür und suchen deswegen vergeblich nach einem Signal, weil Ihre Methode untauglich für einen Nachweis ist. Merke: Erst mal feststellen, ob man überhaupt mit der Methode überhaupt das nachweisen kann, wonach man sucht.
Einen kausalen Zusammenhang zwischen Temperaturentwicklung auf einem Gebiet wie Deutschland und einem Zeitraum von weniger als 20 Jahren und der CO2-Entwicklung ist m.W. signifikant nicht möglich, da dazu das Klimarauschen zu stark ist und das SNR zum CO2-Signal demnach zu klein. Dies ist – wie Sie ja in der Fachwissenschaft sehen können – nur großräumiger und langfristiger möglich, da da das SNR größer ist.
Daher nochmal meine Frage: Wissen Sie überhaupt, wonach Sie suchen?
Seit 1998 gab es nur noch 2010 einen größeren El Nino, und die Temperatur konnte sich langsam wieder abkühlen.
Die El Ninos der 80er und 90er Jahre hängen wahrscheinlich auch mit der starken solaren Aktivität zusammen.
http://tinyurl.com/nhbkjue
Auch fiel ein Hoch der Ozeanzyklen in die Zeit um 2000. Genauso auch 200- 500- und 1000-Jahrzyklen. Da kann es nur noch abwärtsgehen.
http://tinyurl.com/mhgyujt
Noch eines muss man beachten: Die Deutschlandtemperaturen kann man nicht direkt mit den globalen Temperaturen vergleichen. Lokale Temperaturschwankungen sind immer stärker als globale, da ja von denen der Durchschnitt genommen wird. Hier viele einzelne Landtemperatur-Reihen von einzelnen Stationen:
http://tinyurl.com/q9r5vt7
Die Satelliten-Messungen zeigen global einen Anstieg um 0,3°C. Allerdings machen manche reinen Landtemperaturen global einen Sprung bis um 1 Grad – allerdings nur solche, die „homogenisiert“ wurden. Realistischere Land-Temperaturkurven mit wenig Homogenisierung zeigen nur 0,4°C.
Einen Vergleich der unterschiedlichen Klimakurven sieht man hier:
http://tinyurl.com/m2yrrup
Sie sind ein Verfechter der C02-basierten Erwärmung, bitte zeichnen doch Sie einmal eine Korrelationskurve zwischen dem gleichmäßigen Anstieg der C02-Konzentrationen in den letzten 100 Jahren und dem Temperaturverlauf Deutschlands wie wir ihn in den drei Diagrammen dargestellt haben. Ich hätte gerne gewußt, was Sie da im Kopf haben.
„Wie genau konnte man eigentlich damals Temperaturen messen?“
Gar nicht, das Thermometer wurde 1592 erfunden.
„Wie genau konnte man eigentlich damals Temperaturen messen? Macht es überhaupt Sinn, diese Daten im Sinne der Meßgenauigkeit mit den heutigen Daten zu vergleichen?“
Kann man nicht, denn die Eichung ist unbekannt bzw. nicht reproduzierbar.
In den USA wird beispielsweise mit einer Genauigkeit von 1 °F gemessen = 5/9 °C oder K.
Nur Klima ist nicht nur Temperatur, sondern auch Luftfeuchtigkeit + Niederschlag + Bewölkung. Aber das Interessiert die Temperaturmittelfetischisten nicht.
“der Temperaturanstieg fiel in die Zeit, in der sich die Rauchgasentschwefelungs-und Entstickungsanlagen der Kraftwerke auswirkten. Zufall?“
nein kein Zufall sondern höchst wahrscheinlich Ursache und Wirkung.
In den alten Industrieländern haben sie abgenommen, in den neu aufstrebenden Ländern zugenommen.
Es fällt ja auch auf, dass die Aerosole eigentlich nie so richtig als Grund für die Temperaturkonstanz der letzten 18 Jahre angeführt wird!
http://tinyurl.com/a9htvvs
Und nun ein Artikel, in dem man zum wiederholten Male komplett darauf verzichtet zu prüfen, ob die berechneten Trends signifikant sind.
Diese Bigotterie macht mich sprachlos.
„Im ganzen Zeitraum sind CO2-Konzentrationen der Atmosphäre gestiegen, während die Jahrestemperaturen immer wieder Sprünge aufweisen. “
Sie scheinen das als Widerspruch zu sehen. Um mal jedem zu verdeutlichen, was Ihnen im Kopf so vorschwebt, zeichnen Sie bitte eine Temperaturkurve für die Deutschlandtemperatur in Ihre Graphiken oben ein, wie sie nach Ihren Vorstellungen sein müßte, wenn das CO2 wirksam wäre.
einfach nach „Säkularstation Potsdam“ googeln!
MfG
MfG
Man muss aber zugeben, dass Deutschland seine „Temperaturkorrektur“ sehr viel geschickter macht als die Amerikaner, Australier, Neuseeländer mit dem plumpen Absenken der alten Temperaturen in der Datenbank!
Ich würde es aber begrüßen, wenn Sie die Datenquellen als Link angeben würden. „Datenquelle PIK Potsdam“ ist leider ziemlich nutzlos.
Der Mensche kann die „Kälte“ nicht abschaffen, dies kann nur die physiklischen Zusammenhänge in unseren Sonnen-Erdsystem. (Abstand zur Sonne, Erdachsen Neigungswinkel zur Sonne, Rotationsgeschwindigkeit der Erde, Veränderte Umlaufbahn der Erde um die Sonne).
Der Mensch kann sich nur Gut wie möglich an die „Kalten“ Perioden in den jeweiligen Breitengraden anpassen.