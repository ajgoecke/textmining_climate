Das Climate Forecast Application Network CFAN* hat seine Prognose-Bemühungen auf die Überbrückung dieser Lücke konzentriert, indem es Prognosen extremer Ziel-Abschätzungen des Vertrauens in die Vorhersage abgibt.
[*Man könnte das etwa übersetzen zu Netzwerk der Anwendung von Klima-Prognosen. Anm. d. Übers.]
Diese Abbildung illustriert das Konzept der probabilistischen Wettervorhersage mittels eines globalen Prognose-Systems von Ensemble-Modellen.
Für jede Vorhersage errechnet das globale Modell ein Ensemble multipler Vorhersagen, initialisiert mit leicht unterschiedlichen Anfangszuständen. Das Modell der europäischen Wetterzentrale ECMWF hat eine Ensemble-Größe von 51 Vorhersagen. Eine Einzelvorhersage (sagen wir mal der goldene Punkt in Abbildung 2) kann ziemlich weit entfernt liegen vom tatsächlich beobachteten Ergebnis (der rote Punkt). Falls das Ensemble groß genug ist, kann eine bedeutsame probabilistische Vorhersage gegeben werden. Ziel der probabilistischen Vorhersage ist es, das beobachtete Ergebnis (der rote Punkt) in einen Probabilitäts-Raum zu bringen (reflektiert durch die dunkelblaue Fläche), welcher deutlich kleiner ist als der der Klimatologie (hellblaue Fläche).
Die tatsächliche Modellprognose wird durch die grüne Fläche charakterisiert. Die potentielle Vorhersagbarkeit des Modells wird charakterisiert durch die dunkelblaue Fläche. Diese potentielle Vorhersagbarkeit kann sich in einer Vorhersage niederschlagen mittels Kalibrierung der Vorhersage und Verfahren der Interpretation der Ensembles.
Die Herausforderung der probabilistischen Klimavorhersage ist: um das beobachtete Ergebnis zu erfassen, muss die Ensemble-Größe sehr groß sein und so groß werden wie die Klimatologie. Die Herausforderung wird noch stärker, wenn sich das Klima ändert, etwa in Gestalt einer allmählichem globalen Erwärmung oder einer abrupten Verschiebung in einem Klimaregime wie etwa der Atlantischen Multidekadischen Oszillation AMO.
Für Wettervorhersagen in einer zeitlichen Größenordnung von 2 Wochen oder weniger können Ensemble-Vorhersagemodelle bedeutsame Probabilitäten liefern. Dieser Zeitrahmen wird zu einem Zeitrahmen kürzer als Jahreszeiten erweitert, potentiell bis zu 6 Wochen. Allerdings zeigen Vorhersagen, die über 2 Monate hinaus gehen, oftmals wenig Bezug zur Wirklichkeit, und derartige probabilistische Vorhersagen können tatsächlich Entscheidungsträger in die Irre führen. Im Zeitrahmen von Jahreszeiten werden typischerweise prognostische Einsichten vermittelt, während ein Prognostiker die Modellprognosen in eine Analyse von Analogien und vielleicht ein paar statistischen Vorhersageverfahren integriert.
Eine Lücke in der Vorhersagbarkeit ist um 1 Jahr erkennbar, sie ist dort nur sehr gering. Vergrößert man den Zeitrahmen, steigt die Vorhersagbarkeit wieder, und zwar assoziiert mit längerfristigen Klima-Regimes. Allerdings werden die Vorhersagen zunehmend unsicher, wenn man den Zeitrahmen immer mehr verlängert.
Mögliche Zukunfts-Szenarien können nummeriert, aber nicht eingeordnet werden, z. B. wegen Unsicherheit.
Eine brauchbare Langfristvorhersage lässt die Möglichkeit offen, falsch oder auch überraschend zu sein in Verbindung mit abrupten Änderungen oder Schwarzer-Schwan-Ereignissen. Es ist höchst sinnvoll, derartige Ereignisse von vornherein als Möglichkeit zuzulassen.
Die entscheidende Herausforderung der Vorhersage ist es, den Zeitrahmen für bedeutsame Probabilitäts-Vorhersagen und für die prognostischen Abschätzungen der Wahrscheinlichkeit zukünftiger Ereignisse auszuweiten.
Wie können wir diese Prognose-Horizonte erweitern?
ECMWF ENSO Prognosegüte
Verbesserungen der globalen Klimamodelle helfen, den Zeitrahmen für bedeutsame probabilistische Vorhersagen auszudehnen.
Die folgende Abbildung vergleicht Vorhersagen der El Nino Southern Oscillation ENSO mittels der jüngsten Version des europäischen Modells ECMWF im Vergleich mit der vorherigen Version dieses Modells. Die Y-Achse ist der Monat der Initiierung, und die X-Achse repräsentiert den Vorhersage-Zeithorizont in Monaten. Die Farben repräsentiert die Stärke der Korrelation zwischen historischen Vorhersagen und Beobachtungen.
Das bemerkenswerteste Phänomen in diesem Diagramm ist der Einbruch der Vorhersagbarkeit im Frühjahr [ein unter Synoptikern von Anfang an bekanntes Phänomen]. Initialisiert man eine Vorhersage im April, wird die Prognosegüte bis Juli rapide abnehmen, und der Korrelationskoeffizient sinkt unter 0,7 (weiße Fläche). Wird jedoch eine Prognose im Juli initiiert, bleibt die Vorhersagegüte für die folgenden 7 Monate und auch darüber hinaus sehr hoch.
Die Güte der neuen ECMWF-Version findet sich rechts, und man erkennt eine substantielle Verbesserung. Zwar unterscheidet sich das Farbschema etwas, doch kann man erkennen dass die weiße Fläche mit einem Korrelationskoeffizienten unter 0,7 viel kleiner ist. Dies ist ein Anzeichen, dass das Modell hinsichtlich des Einbruchs im Frühjahr viel besser agiert.
Die verbesserte Güte in Version 5 wird Verbesserungen des Ozean-Modells zugeordnet, ebenso wie Parametrisierungen der tropischen Konvektion.
In Zeitrahmen über ein paar Wochen hinaus besteht die Herausforderung darin, die vorhersagbaren Komponenten zu identifizieren. Unter diesen Komponenten sind:
● jedweder langfristige Trend
● Regimes und Fern-Wechselwirkungen
● sowie jedwede zyklische oder jahreszeitliche Effekte.
Hat man vorhersagbare Komponenten erst einmal identifiziert und isoliert, kann man loslegen.
Die Herausforderung besteht darin, die vorhersagbaren Komponenten vom ,Rauschen‘ zu trennen. Darunter sind:
● unvorhersagbare chaotische Komponenten
● Zufallsvariabilität des Wetters
● Modellfehler
Die größte Herausforderung sind Verschiebungen der Regimes, vor allem, wenn diese Verschiebungen durch Zufallsereignisse ausgelöst wurden. Man erinnere sich, im Jahre 2015 sah es wirklich so aus, als würde sich ein El Nino entwickeln. Dessen Entwicklung wurde jedoch vereitelt durch zufällige starke Ostwinde im tropischen Pazifik. Diese fehlgeschlagene Entwicklung des Jahres 2015 bahnte den Weg für den Super El Nino des Jahres 2016.
Die große Frage bei einer Klimavorhersage ist, ob man die Klimatologie schlagen kann. Die Vorhersagegüte ist von vielen Dingen abhängig.
Die Initialisierung einer Vorhersage relativ zum jahreszeitlichen Zyklus ist eine bedeutende Determinante der Güte. Auch ist eine Vorhersage, die während eines fest bestehenden Regimes initialisiert wird wie etwa einem El Nino, besser.
Eine der bedeutendsten prognostischen Erkenntnisse, den ein Prognostiker liefern kann ist, ob die aktuelle Vorhersage die Klimatologie schlagen kann.
Das Vorhersagefenster der Gelegenheit, Fenster bzgl. Raum und Zeit zu identifizieren ist größer, wenn die erwartete Vorhersagegüte größer als gewöhnlich ist, weil dann bestimmte Phasen großräumiger Zirkulationen vorherrschen.
Ich verwende oft eine ,Poker‘-Analogie, wenn ich dies Energiehändlern erkläre – man muss wissen, wie man weitermachen soll [im Original steht hier das unübersetzbare Wortspiel ,hold‘ or ,fold‘. Anm. d. Übers.]. Hinsichtlich einer Vorhersage ist dies der Unterschied zwischen Vorhersagen mit geringem oder hohem Vertrauen.
Statistische Vorhersagen wurden viele Jahrzehnte lang verwendet, bevor globale Klimamodelle entwickelt worden sind, besonders für die Monsunregen in Asien. Traditionelle statistische Vorhersagen waren Zeitreihen auf der Grundlage von Analogien während der Vergangenheit. Während in diese Verfahren Erkenntnisse der Klimadynamik einfließen, haben sie sich als zu simplizistisch erwiesen, und außerdem gibt es nur eine unzureichende Anzahl von Analogien während der Vergangenheit.
Die größte Herausforderung für statistische Vorhersagen ist, dass sie bei einer Verschiebung von Regimes keinerlei Aussagekraft mehr haben. Man erinnere sich an das Jahr 1995, als das statistische Hurrikan-Vorhersagemodell von Bill Gray nicht mehr funktionierte, nachdem sich die atlantische Zirkulation verändert hatte. Ein Beispiel aus jüngerer Zeit ist die Bewertung der Schneebedeckung im Oktober in Sibirien. Diese heranzuziehen funktionierte auch nicht mehr, nachdem sich das Klimaregime verändert hatte.
Gegenwärtig ist die Analytik von Big Data der letzte Schrei bzgl. der Vorhersage von Wetter und Klima. IBM-Watson ist ein Beispiel. Mathematiker und Statistiker bringen Verfahren der Datengewinnung und künstlicher Intelligenz ins Spiel für die Wetter- und Klimavorhersage.
Der Guru künstlicher Intelligenz Richard DeVeaux nennt das folgende Rezept dafür, erfolgreich zu sein:
Gute Daten + Fachkenntnisse + Datengewinnung + Nachdenken = Erfolg
Die eingrenzenden Zutaten sind Fachkenntnis und Nachdenken. Ohne gute Kenntnisse der Klimadynamik wird Katzengold das Ergebnis jedweder Klimavorhersage auf der Grundlage von Datengewinnung sein.
Der Weg zu einer Ausdehnung des Zeithorizonts für bedeutsame probabilistische Vorhersagen ist es, globale Klimamodelle mit Erkenntnissen von Vorhersageverfahren auf der Grundlage von Daten zu integrieren.
Das Problem der Klimamodell-Vorhersagen ist, dass sie nach ein paar Monaten unvermeidlich in die Klimatologie abgleiten. Das Problem von Vorhersagen auf der Grundlage von Daten ist deren schlechte räumlich-zeitliche Auflösung.
Diese können integriert werden, indem die Klimamodell-Ensemble-Mitglieder anordnet um Prädiktoren aus auf Daten basierenden Vorhersagen zu Gruppen zusammengefasst werden.
Vertrauensabschätzungen können vorgenommen werden auf der Grundlage der Wahrscheinlichkeit einer Regime-Verschiebung.
Vorhersagen auf Daten-Grundlage: Analyse der Klimadynamik
Bei Verfahren zur Klimavorhersage auf der Grundlage von Daten ist es unabdingbar, die Bandbreite der Klimaregimes zu kennen, welche unsere Vorhersage beeinflussen können. Diese Regimes zeigen die Erhaltensneigung im Klimasystem. Die Herausforderung besteht darin, die geeigneten Regimes zu identifizieren, deren Auswirkung auf die gewünschten Vorhersage-Variablen zu verstehen und die Vorhersage zukünftiger Verschiebungen dieser Regimes.
Die CFAN-Analyse der Klimadynamik enthält die Betrachtung dieser 5 Zeitrahmen und deren damit assoziierten Regimes. Sie reichen vom jährlichen Zyklus bis zu multidekadischen Zeitrahmen.
Zustände der Zirkulation: Quellen der Vorhersagbarkeit
Unsere Bemühungen zur Datengewinnung haben eine Anzahl neuer Zirkulations-Regimes identifiziert, die als Prädiktoren brauchbar sind über eine Bandbreite von Zeitmaßstäben. Darunter sind:
● Nordatlantische ARC-Zirkulation
● Indo-Pazifik-Atlantik-Zirkulation
● Anomalien hemisphärischer stratosphärischer Zirkulation auf beiden Hemisphären
● Bipolare Zirkulation in der Stratosphäre
● NAOX: Nordatlantische SLP/Windzirkulation
● Globale Zirkulationen von Nord-Süd-Winden in der oberen Troposphäre/unteren Stratosphäre
Nordatlantische ARC-Zirkulation
Im Atlantik ist aktuell eine faszinierende Entwicklung zu beobachten. Abbildung 10 zeigt Anomalien der Wassertemperatur im Atlantik für den Monat Mai. Man erkennt einen Bogen kalter blauer Temperaturanomalien, welcher sich vom äquatorialen Atlantik entlang der Küste von Afrika erstreckt und dann in ein von Ost nach West verlaufendes Band südlich von Grönland und Island mündet. Diese Verteilung bezeichnet man als die atlantische ARC-Zirkulation.
Eine Zeitreihe von Wassertemperatur-Anomalien im ARC-Gebiet seit 1880 zeigt, dass sich Änderungen mit scharfen Verschiebungen manifestieren. Man erkennt derartige Verschiebungen in den Jahren 1902, 1926, 1971 und 1995.
In der unteren Graphik erkennt man, dass die ARC-Temperaturen während der letzten paar Monate einen schroffen Rückgang zeigen. Ist dies jetzt lediglich eine Kalt-Anomalie wie im Jahre 2002? Oder wird hier eine Verschiebung in die Kaltphase eingeläutet?
Die CFAN-Forschungen haben Präzedenzen der Verschiebungen identifiziert. Gegenwärtig arbeiten wir aktiv daran, die jetzige Lage richtig einzuordnen.
Kaltphase der atlantischen AMO: Auswirkungen
Es wird erwartet, dass eine Verschiebung hin zur Kaltphase der AMO ausgeprägte Auswirkungen haben wird. Diese Erwartung speist sich aus Verschiebungen während der Vergangenheit:
● verringerte Hurrikan-Aktivität im Atlantik
● verstärkte Regenfälle in den USA
● verringerte Regenfälle in Indien und der Sahel-Zone
● Verschiebung der Fischbestände im Nordatlantik
● Beschleunigung des Meeresspiegel-Anstiegs an der nordöstlichen US-Küste
Die Atlantische Multidekadische Oszillation übt auf atlantische Hurrikane einen substantiellen Einfluss aus. Die obere Graphik zeigt die Zeitreihe der Anzahl starker Hurrikane seit dem Jahr 1920. Die Warmphasen der AMO sind gelb schattiert. Man erkennt eine substantiell höhere Anzahl starker Hurrikane während der gelb schattierten Zeiträume.
Einen ganz ähnlichen Effekt zeigt die Accumulated Cyclone Energy:
Im Gegensatz dazu erkennt man, dass die Warmphasen im Vergleich zu den Kaltphasen der AMO kaum Auswirkungen auf die Häufigkeit von auf das US-Festland übergreifende Hurrikane hat.
Allerdings hat die Phase der AMO einen gewaltigen Einfluss auf Florida. Während der vorangegangenen Kaltphase gab es zu keiner Jahreszeit mehr als einen Übertritt auf Florida, während es während der Warmphase mehrere Jahre gab mit drei derartigen Ereignissen oder mehr. Dass ein starker Hurrikan auf Florida übergreift ist mehr als doppelt so wahrscheinlich in einer Warmphase als in der Kaltphase.
Diese Variationen der Übertritte auf das Festland in Verbindung mit Änderungen der AMO haben einen substantiellen Einfluss auf die Entwicklung in Florida. Die Reihe von Hurrikanen des Jahres 1926 tötete den ökonomischen 1920 angefangenen Boom. Bevölkerung und Entwicklung beschleunigten sich während der siebziger Jahre, unterstützt durch eine Periode schwacher Hurrikan-Aktivität.
Die jahreszeitlichen Vorhersagen atlantischer Hurrikane von CFAN
Das CFAN-Verfahren untersucht globale und regionale Wechselwirkungen zwischen Ozean-, Troposphären- und Stratosphären-Zirkulationen. Vorlaufende Prozesse werden identifiziert durch Datenerfassung, interpretiert im Zusammenhang der Klimadynamik-Analyse. Damit werden dann statistische Tests mit Nachhersagen durchgeführt.
Wir betrachten in unserer Analyse drei Perioden, definiert durch gegenwärtige Regimes der Zirkulation:
●Die Periode seit 1995, welche mit der Warmphase der AMO korrespondiert
●Die Periode seit 2002, definiert durch eine Verschiebung der Nordpazifischen Oszillation im Jahre 2001
●Die Periode seit 2008, charakterisiert durch eine Vorherrschaft von El Nino-Ereignissen alle drei Jahre.
Vorige Woche haben wir unsere dritte Vorhersage für die atlantiche Hurrikan-Saison 2018 herausgegeben. Wir prognostizieren eine unternormale Aktivität mit einem ACE-Wert von 63 und 4 Hurrikanen.
Die Graphik rechts zeigt die Nachhersage-Verifikation unserer Juni-Vorhersage bzgl. der Anzahl von Hurrikanen. Die Prognose wird erstellt mittels historischer Daten aus drei verschiedenen Perioden, die jeweils mit den drei oben beschriebenen Regimes korrespondieren.
Die jahreszeitlichen Prädiktoren von CFAN werden für jede Vorhersage ermittelt durch ein Datengewinnungs-Verfahren mit unterschiedlichen Prädiktoren für jeden Zeitraum. Die ausgewählten Prädiktoren werden dann einer Klimadynamik-Analyse unterzogen, um zu verifizieren, dass die Prädiktoren aus verfahrenstechnischer Sicht sinnvoll sind.
Die von uns herangezogenen Prädiktoren sind bezogen auf atmosphärische Zirkulationsmuster. Unsere Prädiktoren unterscheiden sich substantiell von denen, die von anderen Gruppen für statistische Vorhersagen herangezogenen werden, welche sich vorherrschend auf die Wassertemperatur und den Luftdruck über dem Wasser stützen.
Jahreszeitliche Vorhersage 2017
Hier folgt die von uns ausgegebene Vorhersage von vor einem Jahr zur Hurrikan-Saison 2017. Wir prognostizierten eine aktive Saison mit 3 Übertritten auf das US-Festland. Diese Anzahl war korrekt, aber wir haben substantiell die ACE unterschätzt.
Aus der Perspektive des Finanzsektors ist es entscheidend, ob wir eine weitere extrem aktive Hurrikan-Saison erleben und wie viele Hurrikane auf das US-Festland übergreifen.
Wir führten ein Datensammel-Verfahren durch, um Verteilungen zu identifizieren, welche die extrem aktiven Saisons der Jahre 1995, 2004, 2005 und 2017 erklären. Unser gegenwärtiges Vorhersagemodell ist zwar hinsichtlich der Extreme in den Jahren 1995 und 2017 korrekt, nicht jedoch für die Jahre 2004 und 2005.
Der einzige Prädiktor, der 2004/2005 auftauchte, war ein Vorgang in der Stratosphäre nahe der Antarktis. Zu diesem Zeitpunkt haben wir keine Ahnung, ob dieser Vorgang ein plausibler Prädiktor auf physikalischer Grundlage für die atlantische Hurrikan-Aktivität ist. Verstörend ist, dass Prädiktoren der polaren Stratosphäre eine extrem aktive Saison 2018 vorhersagen. Dies steht im Gegensatz zu den anderen von uns herangezogenen Prädiktoren.
Fazit: Zu diesem Zeitpunkt wissen wir nicht, ob wir echtes Gold oder Katzengold ausgegraben haben. In jedem Falle ist dies ein gutes Beispiel des Nutzens und der Gefahren bei der Datensammlung.
Link: https://judithcurry.com/2018/06/07/beyond-enso-new-signals-of-seasonal-to-interannual-predictability/
Übersetzt von Chris Frey EIKE
EIKE präsentiert hier aus einer Vielfalt von Nachfolgern die ehrenwerte Judith Curry (Ein Name der auch eine bekannte Gewürzmischung ziert!)
Meine Hochachtung gilt dagegen immer wieder den vielen seriösen Meteorologen, denen es Tag für gelingt, uns mit einem wahrscheinlichen Wetter für mehrere Tage zu versorgen!!
Die vielen seriösen Meteorologen mögen zwar das Wetter für mehrere Tage gut vorhersagen, aber bei der Analyse der monatlichen Höchsttemperaturen in D wie im April und Mai bleiben doch einige Fragen offen. Lesen Sie z.B. den DWD-Monatsrückblick für Mai.
https://www.dwd.de/DE/klimaumwelt/aktuelle_meldungen/180604/waerme_mai_2018.html
Die Ursache der Höchsttemperaturen war offensichtlich ein stabiles Hoch über Skandinavien. Dann in Fettdruck: Immer häufiger Wärmerekorde, seit über sechzig Jahren kein Minimumrekord mehr. Heißt dies dass sich das stabile Hoch über Skandinavien im Mai immer häufiger ausbildet? Wenn ja, warum? Oder hilft da vielleicht der Bauern-Kalender weiter?
Ich halte das Forschungsvorhaben von Frau Judith Curry für sinnvoll. Es ist zwar schwierig, brauchbare Aussagen aus der chaotischen Natur des Wetters herauszufiltern. Die Prognosen werden also häufig daneben liegen. Die chaotische Natur bedeutet aber nicht, dass keines der Ereignisse prognostizierbar ist. Es wäre schon ein Fortschritt, wenn man diese unterscheiden könnte.
Nachweislich wurde die (ominöse) Mittlere Erdtemperatur in den 1990er Jahren in Deutschland regierungsamtlich mit über 15 °C angegeben. 2016/17 haben die Scharlatane ca. 14,8°C ermittelt.
Oder sollten wir uns M. Latif halten, der absolute Temperaturangaben generell als sinnlos bezeichnet und nur deltas propagiert, an die man einfach glauben muß?
Original M. Latif: „Wohl jeder Wissenschaftler ist damit vertraut, dass man in vielen Fällen Differenzen bzw. Veränderungen einfacher bzw. genauer messen kann als Absolutwerte. Um in Paris zu bleiben: gehe ich auf dem Eiffelturm eine Treppenstufe hinauf, kann ich leicht mit einem Lineal messen, wieviel höher ich dann stehe – aber wie viele Meter über dem Erdboden ich insgesamt bin, lässt sich schon schwerer feststellen.“
Nun frage ich mich, wie Herr Latif ein Lineal anlegen will, wenn er einmal 1990 auf einer Treppenstufe des Eiffelturms stand und ein zweites Mal 2017.
Kennt jemand irgendein Meßgerät, mit dem man Differenzen oder Veränderungen messen kann, am Beispiel Temperatur?
Auf welcher Unität oder Akamie hat der Mann wieviele Sylvester diriliert?
Zum Thema Messen sollte man doch einiges wissen:
Immer nur der „wahre Wert“ (einer physikalischen Größe, wie bspw. Temperatur) ist gesucht. Kein anderer interessiert zunächst. Alle anderen Werte (wie z.B. „Deltas“, also Temperaturunterschiede) ergeben sich erst aus diesem „wahren Wert“. Oder anders formuliert: Kein „Absolutwert“, kein Delta.
Und daß ein Meßwert nicht identisch sein kann mit dem gesuchten „wahren Wert“, der ganz grundsätzlich niemals exakt ermittelt werden kann. Man kann sich nur „annähern“. Das muß man erst einmal verinnerlichen. Diverse Meßfehlereinflüsse (z.B. gerätebezogene) müssen mit systematischen addiert und zusammen mit dem Meßwert angegeben werden.
Deshalb ist eine Angabe wie „Lufttemperatur 21,3 °C“ wertlos! Zu jedem Meßwert muß der gesamte Meßfehler mit angegeben werden. Also bspw. Meßwert 21,3 °C, gerätespezifischer Meßfehler +/- 0,5 °C, plus systematische Meßfehler +/- 0,1 °C). Dann liegt der wahre Wert zwischen 20,7 und 21,9 °C! Genauer geht es dann nicht!
Latif kommt ursprünglich aus den Wirtschaftswissenschaften. Die können zwar auch rechnen, haben aber – Ausnahmen bestätigen die Regel- vom Messen im physikalischen Sinn, keine Ahnung. Deswegen glaubt er auch, dass die Berechnung von Differenzen, die Genauigkeit erhöhen. Das Gegenteil ist der Fall, weil sich die Fehler (über die Wurzel der Summe der Quadrate) addieren und der größere Gesamtfehler auf eine viel kleinere Größe bezogen wird. Aber mit dieser irrigen Ansicht steht Latif nicht allein, gefühlte 97 % aller Klimawissenschaftler teilen sie.
„Der neue NASA-Chef Jim Bridenstine ist kein Freund extremen Klimaalarms. Im NASA-eigenen GISS-Institut heißt es nun zittern: Werden sie dort weiter Klimaalarm schmieden können? In einer kürzlichen Rede stellte Bridenstine klar, dass er durchaus eine gewichtige Rolle des CO2 an der Klimaerwärmung anerkennt. Es ist gut zu sehen, dass hier jemand mit einer ausgewogenen Sichtweise Verantwortung übernimmt und die Vertreter der Extreme in die Schranken weisen wird.“
Was heißt hier „Extreme“? Seit 30 Jahren gibt es keinen experimentellen Beweis, dass „ZehOhZwei“ etwas mit der – unstrittig stattgefundenen – leichten Erwärmung zu tun hat. Wenn nun Lüning und Vahrenholt die Alarmisten als „Extrem(ist)e(n)“ bezeichnen, d’accord, denn der Unsinn von dort ist schwer zu ertragen. Aber wieso bezeichnen sie Personen als „Extrem(ist)e(n)“, wenn diese nicht mehr als einen unantastbaren Beweis für den Zusammenhang zwischen Erwärmung und „ZehOhZwei“ fordern? Da es den nicht gibt, wäre die wissenschaftlich korrekte Herangehensweise, diese These zu verwerfen, bis sie eben bewiesen ist. Somit zählen Lüning und Vahrenholt m.E. genauso zu den Pseudowissenschaftlern wie die Klimasimulanten. Es geht um ganz andere Dinge, insbesondere in Deutschland um die Einführung einer sozialistischen Öko-Diktatur nach DDR-Vorbild. Zu was Menschen fähig sind, wenn die politischen Rahmenbedingungen stimmen, haben die Deutschen mehrfach gezeigt, anderswo ist es nicht anders. Im Kleinen sieht man das an den Dieselfahrverboten in Hamburg. Wie hieß es so schön, anfangs wolle man seitens der Polizei nur Hinweise geben und danach mit aller Härte durchgreifen. Ja, ja, gegen die eigene Bevölkerung „mit aller Härte“ durchgreifen – so sind sie eben, die Deutschen…..
Wieso? Die sind doch berechtigt. Dieselrußpartikel sind nun einmal gefährlich. Und je kleiner die sind, desto gefährlicher sind die. Und je größer die sind, desto simpler kann man die zu 99% aus dem Abgas entfernen. Und je größer die sind, desto ungefährlicher sind die für Mensch und Tier.
Das wissen nur unsere biologisch-physikalisch-technisch ungebildeten Politiker nicht. Der Industrie ist das egal, denn die Feinstdieselabgasvernichtung ist extrem teuer und das zahlt der Käufer. Den steigenden Gewinn kassieren die Unternehmen. Und es wird suggeriert, daß das die Menschen, die diese krebserregenden Feinstpartikel einatmen und in das Lungenfleisch bekommen, nicht schädigt.
Man braucht auch diese Dieselabgaslieferwagen und -LKW in den Städten nicht. Man könnte für die das Benzin billiger machen, so daß deren schädlichen Abgase wie bei Benziner-PKW fast bei Null liegt. In den USA werden fast keine Diesel-PKW verkauft.
Aber was solls, der hamburger CDU-Abgeordnete Dr. Christoph Ploß in Bundestag hat Geschichte und Politikwissenschaft studiert, ist aber im Ausschuß für Verkehr und digitale Infrastruktur. Dr. Ploß, den ich persönlich kenne, hat nicht die notwendigen naturwissenschaftlichen und ökonomischen Kenntnisse, um zu erkennen welch Quatsch die Regierung in Sachen Gesundheits- und Umweltschutz fabriziert.
Und da geht es ihm wie dem Klimaforscher. Das Kernproblem bei Klimamodellen sind die Modellfehler. Je mehr Modellfaktoren ich einbeziehe, desto mehr multiplizieren sich Modellfehler. Man muss sich immer vor Augen halten, dass die Klimafaktoren, sogar der offiziell identifizierte Haupttreiber, die Wolkenbedeckung, in ihrer Wirkung nicht ausreichend verstanden sind. Bei den vielen anderen Faktoren ist es genauso. Kopple ich aber z.B. 5 Klimafaktoren in einem Klimamodell, jeder mit einer Vorhersagewahrscheinlichkeit von 50% (und das wäre für Klimafaktoren schon richtig gut), dann bekomme ich eine Gesamtwahrscheinlichkeit für das Modell von 3% !!! Deshalb zeigen Klimamodelle meist nur das, was der Klima-Simulant selbst GLAUBT. Dem Klima-Simulant bleibt also nur Bluff or Fold. Bei Fold ist das Geld weg, also Bluff.
Offensichtlich muss dieser ganze Wahnsinn gegen die schon mehrfach zitierte Wand fahren – just gab es im SWR 2 eine „Diskussion“ : lauthals ohne irgendeinen Einwand sagte einer der Teilnehmer u.a. , wie schlecht doch die Luft in “ unseren Städten“ infolge der katastrophalen Dieselabgase sei. Natürlich war keinem der sonstigen Teilnehmer incl. Frauen irgendetwas bekannt über massiv zurueckgegangenen Feinstaubbelastungeni in den Staedten, den falschen Messstandorten, diesem irren „Grenzwett“ für die EUStickoxydgrenzwerte im Vergleich zu denen am Arbeitsplatz (950 mikrogramm pro qm), über die Ergebnisse des Bundestagsauschusses zum Diesel aus dem Jahr 2016 – die Ergebnisse sind allen!!!! bekannt, stellvertretender Vorsitzender ein Grüner, Vorsitzender ein Linker – unter anderem: 40 mikrogramm pro qm kann man vergessen! Und was machen „Berlin“, die Margarine-Barbara, die Kunsthistorikerin im Bundesumeklamt, v,a. die Merkel??? Die Union, die Sozis: manmadepoliticalcatastrophy – und auch die AfD ist ehrlich gesagt handzahm. Fragen werden so formuliert, daß die Regierung, etwajge Minister munter ausweichen können.
Nein, das Ding muss voll, wie der Endsieg, an die Wand fahren – und dann sind es natürlich die CO2-Skeptiker – Dolchstosslegende, ick hör dir trapsen – die an dieser manmadeclimatechangecatastrophy in going into cold verantwortlich sind. Wenn wir rechtzeitig gegengesteuert hätten …. es wird kälter, weil es eigentlich wärmer geworden ist! Aber die haben uns ja daran gehindert, diese K.imaleugner!!! Steigen aus dem Abkommen in Paris aus – das hat diese Klima-Katastrophe erst recht bewirkt. Mit Paris hätten wir alles im Griff gehabt. Fragt doch die Lichtgestalt Obama, sorry, nein, den Macron! Den Retter Europas.