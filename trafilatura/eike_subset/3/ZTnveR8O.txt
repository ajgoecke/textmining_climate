Video (in Englisch) des Vortrags von Lord Christoper Monckton (ehem. Science Adviser von Lady Margret Thatcher Premierministerin von Groß Britannien) gehalten anlässlich der 9. Internationalen Klima- und Energiekonferenz am 10. und 11.12.15 im Haus der Technik Essen.“Wie die Wissenschaft im Namen des Klimaschutzes geopfert wird „
„Die gequantelte Biegeschwingung kann aber erst bei 1,5R + 1R + 1R = 3,5R eintreten.“
Lieber Herr Holtz,
das kann man übrigens auch in Beschreibungen zum
Wirkprinzip vonCO2-Lasern nachlesen.
Was bedeutet das nun für Strahlungstransport mittels CO2 im releveanten Frequenzbereich und für den Treibhauseffekt insgesamt???
MfG
sie schreiben:
„Nee, kann ich leider nicht bestätigen. Aus dem Äquipartitionstheorem können sie auch die Planck’sche Strahlungsformel ableiten, hat also mit dem klassischen Grenzfall nichts zu tun“
Müssen sie gar nicht bestätigen.
In unserem Zusammenhang ist der Gleichverteilungssatz der Grenzfall, wenn T viel größer ist als die charakteristische Temperatur.
Also nur eine Näherung. Der Beitrag des Schwingungsfreiheitsgrades geht in diesem Grenzfall gegen R. In der Quantenstatistik wird der Schwingungsfreiheitsgrad gemäß der Temperatur „gewichtet“ und nicht „gezählt“ wie in der klassischen Statistik. Bei irdischen Temperaturen nehmen die Schwingungsfreiheitsgrade von CO2 nicht an der Gleichverteilung teil. Das bedeutet aber nicht, dass die Schwingungszustände nicht gemäß der entsprechenden Temperatur besetzt sind. Das dürfen sie nicht verwechseln.
Für die Besetzung der Schwingungszustände gilt ganz „normal“ die Quantenstatistik.
Sie schreiben:
„Die gequantelte Biegeschwingung kann aber erst bei 1,5R + 1R + 1R = 3,5R eintreten.“
Das ist falsch. Der Zustand für die Biegeschwingung ist gemäß der Temperatur des Ensembles besetzt.
Es geht noch einfacher: Photo-Akustischer Effekt (PAE), siehe z.B.
http://www.pas-analytik.com
Zitat: Sie betrachten offensichtlich nur Zwei-Teilchen-Stöße. Bei höheren Gasdichten sind wohl auch Mehr-Teilchen-Stöße denkbar.
Ja, die Wahrscheinlichkeit eines 3-Teilchen-Stoß ist bei normalen Drücken (um 1bar) sehr gering. Bei größeren Dichten/Drücken oder bei der Photo-Rekombination sind natürlich auch Mehr-Teilchen-Stöße vorhanden.
Ich betrachte Thermalisierung immer unter den folgende Gesichtpunkt:
Das Verhältnis N der freien Weglänge der Strahlung l(rad) zu der freien Weglänge zwischen den Stößen l(f) charakterisiert die Interaktionen, und daraus kann eine Thermalisierungslänge l(th) abgeleitet werden: l(th) = l(f)*sqrt(N) = l(f)*sqrt(l(rad)/l(f)) = sqrt(l(rad)*l(f)). Somit ergibt sich eine Thermalisierungslänge im IR in Oberflächennähe der trockenen Luft von l(th) = sqrt(16,5*68*10^-9) = 1,06*10^-3 m = 1 mm, und für feuchte Luft erhält man l(th) = sqrt(2,43*68*10^-9) = 0,4 mm für die Kombination von Strahlung und Stößen.
Die Thermalisierungslänge l(th) ist die Strecke, die ein Zustands-Teilchen, das aus einem Stoß-, Ionisations-, Absorptions- oder Emissionsprozeß hervorgegangen ist, zurücklegen muß, bevor es soviele weitere Stöße, Absorptions- oder Emissionsprozesse durchgemacht hat, daß es von der restlichen Zustands-Teilchenverteilung nicht mehr unterschieden werden kann. LTE-Bedingungen herrschen, wenn die Thermalisierungslänge kürzer ist als die Entfernung, über die sich die Temperatur merklich ändert (Achtung: „merklich“ im granular-molekularen Bereich!).
Mfg
Werner Holtz
Zitat: Ihre Schlussfolgerung, dass die Biegeschwingung nicht thermisch zugänglich ist, ist falsch.
Nee, kann ich leider nicht bestätigen. Aus dem Äquipartitionstheorem können sie auch die Planck’sche Strahlungsformel ableiten, hat also mit dem klassischen Grenzfall nichts zu tun.
Zitat: Das macht also 1.5 R + 1 R + 0.86 R + 0.05 R = 3.41 R aus den Zustandssummen für den Fall 288 K.
Das was Sie hier nicht beachten, das Energien immer gequantelt auftreten. Man kann zwar so eine Rechnung durchführen, aber es ist nunmal kein Bruchteil einer Energie für einen Quanten-Zustand möglich. Die Beiträge der Zustandssumme für die Schwingungen entstehen durch die Rotation oder besser gesagt durch Rotations-Schwingungs-Übergänge, einmal als Beitrag der Rotation zur Tragheit der Biegeschwingung und zum anderen, als Beitrag der Rotation zur Dehnung der Steckschwingung. Diese Beitrage der Rotation eines nicht-starrer Rotator zu den Schwingungsniveaus ist es, welches die summierten 4% Schwingungsanregung ausmachen. Die gequantelte Biegeschwingung kann aber erst bei 1,5R + 1R + 1R = 3,5R eintreten.
Mfg
Werner Holtz
„Temperaturmessung ist physikalisch sinnlos. Abgesehen davon, daß jede Temperaturmessung ohnehin zu träge wäre.“
Lieber Herr NicoBaecker,
es interessiert die Temperatur der N2- bzw.- O2-Moleküle. Nach einer Pulsanregung der CO2-Moleküle erhöht sich infolge von Stößen deren Bewegungsenergie und damit ihre Temperatur. Da sie auch miteinander stoßen, stellt sich ein lokales thermisches Gleichgewicht ein. Infolge von Wärmeausgleich zwischen den Gasatomen innerhalb und außerhalb des Laserstrahls relaxiert die Temperaturerhöhung im Strahl innerhalb von Mikrosekunden auf die Gastemperatur außerhalb. Als Thermometer könnte man ein optisches Verfahren wählen, z.B. Brillouin-Streuung oder die Mikrowellen-Emission von O2. Solche Experimente wurden sicher schon gemacht.
„Interessant wäre auch, ob die Thermalisierung nicht schon gemessen wurde. So ein Experiment müsste doch möglich sein. Man verwende einen gepulsten CO2-Laser und messe nach einem Puls die Gastemperatur.“
Interessante Überlegung. Sie wollen die Thermalisierung also zeitaufgelöst nach der Pulsanregung messen. Aber der Punkt ist – ich habe das schon oft hier erklärt-, daß der thermalisierte Zustand, also der Zustand, in dem das Gasensemble eine neue Temperatur angenommen hat, einige Zeit zum Erreichen benötigt. Direkt nach dem Puls findet die Thermalisierung statt, indem die von Puls angeregten Moleküle mit dem Rest des Gasensembles (welches noch die alte Temperatur hat) per Stöße Energie austauschen und die durch den Puls übertragene Energie von den angeregten Molekülen auf alle verteilen. Direkt nach dem Puls und im sich anschließenden Thermalisierungsprozeß hat das gesamte Gasensemble damit überhaupt keine definierte Temperatur. Temperaturmessung ist physikalisch sinnlos. Abgesehen davon, daß jede Temperaturmessung ohnehin zu träge wäre. Was aber mit den Stößen auch verloren geht ist, ist die Kohärenz von durch den Pulse angeregten Quantenzuständen. Das zeitliche Abklingen dieser Kohärenz kann man messen. Typische Thermalisierungszeiten liegen unter einer Nanosekunde.
so eil ich weiß verwendet die Nasa Atrans für Transmissionsberechnungen im Infraroten.
Globale Energiebilanzen sind ein anderes Thema.
sie schreiben:
„Höhere Schwingungsniveaus als der Grundzustand können nur durch Molekülstöße besetzt werden, wenn die beim Stoß zugeführte Translationsenergie zur Schwingungsanregung ausreicht. Da aber nur Translationszustände mit wesentlich kleineren Energien thermisch besetzt sind, kann beim Stoß kein Energieübertrag in den Schwingungsfreiheitsgrad erfolgen.“
Das ist falsch. In der Verteilung sind Moleküle vorhanden die ausrechend Translationsenergie haben, um die Biegeschwingung des CO2 anzuregen.
Sie schreiben:
„Im Temperatur-Bereich der Atmosphäre hat CO2 einen Wert von 5/2*R < Cv < 7/2*R, das bedeutet, dass die Biegeschwingung um 15µm (668 cm-1) nicht thermisch zugänglich ist, da mindestens zwei Schwingungsfreiheitsgrade erforderlich sind.“ Ihre Schlussfolgerung, dass die Biegeschwingung nicht thermisch zugänglich ist, ist falsch. Bei 255 K liegt Cv für CO2 bei 3.25 R und bei 288 K bei 3.42 R. Es gibt zwei entartete Biegeschwingungung (668 cm-1)die jede einen Beitrag von je 0.43 R zur Wärmekapazität leisten. Dazu kommt die symmetrische Streckschwingung (1388 cm-1) mit einem Beitrag von etwa 0.05 R. Das macht also 1.5 R + 1 R + 0.86 R + 0.05 R = 3.41 R aus den Zustandssummen für den Fall 288 K. Die Biegeschwingungen sind also sehr wohl thermisch zugänglich. Die Besetzungszahlen ergeben sich bei 288 K zu etwa 3.6% für die Biegeschwingung und 0.1% für die symmetrische Streckschwingung. Der Gleichverteilungssatz gilt eben nur im klassischen Grenzfall. Dieser klassische Grenzfall ist bei Schwingungsanregungen nicht erfüllt.
Da haben sie Recht. Meine Aussage
„Thermalisierung hat also nichts mit der Emission zu, sondern mit Absorption.“
Ist so nicht korrekt. Thermalisierung sorgt ja dafür, dass immer CO2 Moleküle im angeregten Zustand der Biegeschwingung vorhanden sind. Insofern hat es auch etwas mit Emission zu tun
Lieber Herr Holtz,
Sie betrachten offensichtlich nur Zwei-Teilchen-Stöße. Bei höheren Gasdichten sind wohl auch Mehr-Teilchen-Stöße denkbar. Interessant wäre auch, ob die Thermalisierung nicht schon gemessen wurde. So ein Experiment müsste doch möglich sein. Man verwende einen gepulsten CO2-Laser und messe nach einem Puls die Gastemperatur.
„Für die Atmosphäre werden die Transmissionsspektren heutzutage berechnet, da spielt die Eigenemission keine Rolle.“
Sehr geehrter Herr Hess,
für welche Atmosphäre: mit Wolkenbedeckung, Aerosolen, mit Niederschlägen. Wenn die Berechnung so gut funktionieren würde, würden sich die veröffentlichten globalen Energiebilanzen nicht so stark voneinander hinsichtlich der von der Oberfläche direkt in den Weltraum abstrahlten IR-Strahlung unterscheiden.
Zitat: Thermalisierung hat also nichts mit der Emission zu, sondern mit Absorption.
Das würde dem Äquipartitionstheorem (oder Gleichverteilungssatz) widersprechen, wobei der mögliche Ausgleich von Energiepotenzialen nicht stattfinden könnte.
+ CO2 (T < 225K) -> Cv = 5/2*R (3*Translationsfreiheitsgrade + 2*Rotationsfreiheitsgrade)
+ CO2 (225K < T < 310K) -> 5/2*R < Cv < 7/2*R (3*Translationsfreiheitsgrade + 2*Rotationsfreiheitsgrade + max. 1*Schwingungsfreiheitsgrad) + CO2 (T > 310K) -> Cv > 7/2*R (3*Translationsfreiheitsgrade + 2*Rotationsfreiheitsgrade + 2*Schwingungsfreiheitsgrade)
Im Temperatur-Bereich der Atmosphäre hat CO2 einen Wert von 5/2*R < Cv < 7/2*R, das bedeutet, dass die Biegeschwingung um 15µm (668 cm-1) nicht thermisch zugänglich ist, da mindestens zwei Schwingungsfreiheitsgrade erforderlich sind. Erst ab einer Temperatur von 310K kann die Biegeschwingung im Grundzustand besetzt werden. Die charakteristische Temperatur der Schwingung theta(vib) der Biegeschwingung vom CO2 (entartet) beträgt: theta(vib) = h*v/kB = 954K. Also erst ab einer Temperatur von 945K ist die Biegeschwingung vollständig thermisch (durch Stoß) zugänglich. Höhere Schwingungsniveaus als der Grundzustand können nur durch Molekülstöße besetzt werden, wenn die beim Stoß zugeführte Translationsenergie zur Schwingungsanregung ausreicht. Da aber nur Translationszustände mit wesentlich kleineren Energien thermisch besetzt sind, kann beim Stoß kein Energieübertrag in den Schwingungsfreiheitsgrad erfolgen. Der Gleichverteilungssatz ist dann nicht mehr gewährleistet. Solange der Mittelwert der Translationsenergie entlang einer Raumrichtung klein ist im Vergleich zur Schwingungsanregungsenergie, ist also kein Energieübertrag möglich. Jedes Molekül strebt den energetisch stabilsten (niedrigsten) Zustand in der momentanen Umgebung an, d.h., wo Energieaufnahme und -abgabe sich die Waage halten und möglichst gering ist. Welche Prozesse für die Energieaufnahme und -abgabe stattfinden, hängt von den Energiepotenzialen ab, die ausgeglichen werden müssen. Für die Thermalisierung ist das Äquipartitionstheorem oder der Gleichverteilungssatz anzuwenden, wobei die zentrale Größe die Zustandssumme des thermodynamischen Systems ist. Eines sollte man aber beachten, molekulardynamische Rechnungen sind nur bedingt geeignet für die Berechnung thermodynamischer Größen. Alle mikroskopischen Prozesse bzw. deren Gesetze sind alle invariant gegen die Umkehr der Zeit. Die mikroskopische Reversibilität sagt, dass die beiden Prozesse (Hin- und Umkehr-Prozess) mit der gleichen Wahrscheinlichkeit auftreten. Der Prozess der Emission ist aber nicht der Umkehr-Prozess der Absorption, sondern ein möglicher mikroskopischer Prozess. Eine Emission findet dann statt, wenn andere Möglichkeiten entweder energetisch verboten oder nicht die notwendige Effektivität aufweisen, um das Äquipartitionstheorem aufrecht zu erhalten. Zudem verstehen viele den Begriff der Temperatur und Thermalisierung falsch. Die Temperatur vom Zustandsraum wird von allen Prozessen und Energien bestimmt, und folglich beschreibt die Thermalisierung den Zustand/Vorgang, das ein Zustands-Teilchen, das aus Stoß-, Ionisations-, Absorptions- und Emissionsprozessen hervorgegangen ist, von der restlichen Zustands-Teilchenverteilung nicht mehr unterscheidbar ist. Mfg Werner Holtz
„Durch Stoßanregungen sind im stationären Zustand immer 3% der CO2 Moleküle im angeregten Schwingungszustand und können spontan Photonen emittieren.“
Lieber Herr Heß
„Angeregt“ heißt nicht, daß emittiert werden kann. Es gibt im CO“-Molekül viele Anregungszustände, die für eine Emission nicht ausreichend Energie beinhalten. Und auch wenn die Energie ausreicht, ist nicht gesagt, daß emittiert wird, da die Abregung auch wieder über die unterschiedlichen Möglichkeiten und Stufen darin erfolgen kann. Es wird also, wenn überhaupt, nur ein Bruchteil der 3% angeregten Moleküle emittieren.
„Thermalisierung ist nicht der Grund dafür, da liegen sie falsch. Die Transmission wird Null, weil absorbiert wird. Thermalisierung sorgt dafür, dass die Anregungsenergie auf Freiheitsgrade des absorbierenden Körpers, Gasvolumen oder Festkörper, verteilt wird.“
Würde nicht thermalisiert, bliebe das Molekül im angeregten Zustand oder würde wieder emittieren…
Es zeigt sich also immer deutlicher, daß von der gewaltigen Gegenstrahlung, die die Hälfte der Bodenabstrahlung an diesen zurück wirft nur ein armseliger Rest an Eigenstrahlung einer dünnen, an den Boden angrenzender CO2-Schicht verbleibt.
Nicht 3% der 400ppm CO2 strahlen, sondern nur der Bruchteil, der
a, durch Stoß ausreichend stark angeregt wird
b, sich spontan anregt mit einem in der Elektronenbahn für die Emission ausreichenden Energieniveau
und
c, nicht durch Stoß das ausreichende Energieniveau im Rahmen der mittleren Anregungszeit ganz oder zum Teil verliert.
Das dürfte dann bei Bodendruck so etwa 1 Promille der angeregten Moleküle betreffen.
0,0004 x 0,03 x 0,001 = 12×0,000000001 oder 12×0,0000001 % ist der geschätzte Anteil der mit Eigentemperatur (~ = Bodentemperatur!) gegen Boden strahlenden Moleküle der Atmosphäre.
Wow, hätte ich nicht gedacht!
Lieber Herr Heß,
jetzt müssen wir nur noch messen, welche Strahlungsleistung dabei an den Boden abgegeben wird.
Parallel dazu kann man auch rechnen:
Energie pro Photon mal Anzahl der Emissionsvorgänge innerhalb der mittleren freien Wegstrecke…
Die Eisbären werden schwimmen lernen müssen.
Wegen der menschlichen CO2-Emissionen!
Ganz klar!
Die Inseln werden untergehen und ganze Länder
im Meer versinken.
Von Dürren, Hungersnöten, Überschwemmungen (alle voll katastrophal, natürlich) Völkerwanderungen, Klimakriegen, Seuchen (wie Pest und Cholera, Malaria nicht zu vergessen)
ganz zu schweigen.
Im Ernst:
Es zeigt sich also wieder mal, daß von der CO2-Gefahr fürs Klima nix übrig bleibt.
Das einzige, was mir Sorge macht, ist daß niemand gegen Sorros und seine Kumpane in der Politik aufsteht.
Na ja, Trump vielleicht – schaun ma mal
MfG
sie fragen:
„Im Übrigen würde mich interessieren, wie Sie die Transparenz messen wollen, wenn Sie am Sensor nicht zwischen eben emittierten Photonen und solchen, die lange unterwegs waren unterscheiden können.“
Ganz einfach. Bei der Transmissionsmessung benutzt man einfach eine Lichtquelle die man durch den Körper und über einen Referenzweg schickt. Die Lichtquelle wählt man dann um Größenordnungen stärker als die Eigenemission des untersuchten Körpers.
Für die Atmosphäre werden die Transmissionsspektren heutzutage berechnet, da spielt die Eigenemission keine Rolle.
sie schreiben:
„Absorbierte Strahlung wird daher thermalisiert,
genau das ist der einzige Grund warum die Transparenz für 15µm-Strahlung 0 wird,
nach wenigen 100m ist sie verschwunden.“
Thermalisierung ist nicht der Grund dafür, da liegen sie falsch. Die Transmission wird Null, weil absorbiert wird. Thermalisierung sorgt dafür, dass die Anregungsenergie auf Freiheitsgrade des absorbierenden Körpers, Gasvolumen oder Festkörper, verteilt wird.
Thermalisierung hat also nichts mit der Emission zu, sondern mit Absorption. Thermalisiert wird die durch Photonen ins Gasvolumen eingetragene Anregungsenergie. Eine 100 m Gasschicht emittiert in den Wellenlängenbereichen in denen sie eine Transparenz von Null hat und thermisch angeregte Zustände hat, gemäß der Planckschen Strahlungsfunktion also wie ein schwarzer Körper.
Auch die Strahlungsenergie die ein Festkörper absorbiert wird thermalisiert. Das heißt sie wird durch Stöße mit Gitterschwingungen auf Freiheitsgrade verteilt. Genau wie das Gasvolumen hat der Festkörper thermisch angeregte Zustände die durch spontane Emission eines Photons in den Grundzustand übergehen.
sie schreiben:
„Es braucht Zeit, die bekannt ist, bevor eine Molekülschwingung Energie in Form von Strahlung abgeben kann.“
Diese Aussage ist falsch. Bei der spontanen Emission ist die Zeit nicht vorhersagbar wann emittiert wird.
Bei der spontanen Emission kann der angeregte Zustand innerhalb seiner natürlichen Lebensdauer zerfallen. Es ist eine durchschnittliche Zeit bis die Emission stattfindet und keine Mindestzeit nach der die Emission erst stattfinden kann wie sie falsch schreiben.
Der Zeitpunkt der Emission nach der Anregung und die Richtung sowie Phase und Polarisation sind dabei statistisch (zufällig).
Während es bei der induzierten Emission einer äußeren Einwirkung bedarf findet die spontane Emission ohne äußere Einwirkung statt. Der Zeitpunkt der spontanen Emission ist nicht vorhersagbar. Man kann nur die Wahrscheinlichkeit angeben, dass innerhalb einer bestimmten Zeitdauer eine Emission stattfindet. Das ist die mittlere Lebensdauer. Das ist die Zeitspanne innerhalb der eine Anzahl angeregter Moleküle emittiert hat und die Zahl der ursprünglich angeregten Moleküle auf 37% (1/e) abgesunken ist.
Stöße verkürzen lediglich diese Zeitspanne. Verhindern aber nicht die Emission. Stattdessen liefern sie auch immer wieder angeregte Moleküle nach die ebenfalls emittieren können.
Ein Laser ist eine kohärente Lichtquelle und beruht auf induzierter Emission. Die spontane Emission ist inkohärent und im Laser ein Störeffekt.
Mit dem Laser hat das nur insofern was zu tun als es einen angeregten Zustand mit einer ausreichenden mittleren Lebensdauer braucht damit im stationären Zustand genügend Moleküle im angeregten Zustand (oberes Laserniveau) sind.
So ähnlich ist das auch in der Atmosphäre. Durch Stoßanregungen sind im stationären Zustand immer 3% der CO2 Moleküle im angeregten Schwingungszustand und können spontan Photonen emittieren. Nach jedem Emissionsvorgang wird im Mittel durch Stoßanregung ein angeregtes Molekül nachgeliefert das wiederum emttieren kann. Wir beobachten die thermische Emission der Atmpsphäre.
Lieber Herr Heß,
ich zitiere auch noch mal gerne Dr. Paul für Sie:
„Es braucht Zeit, die bekannt ist, bevor eine Molekülschwingung Energie in Form von Strahlung abgeben kann.
Das ist nichts neues !!! „Laserstrahler“ gibt es bekanntlich seit 1960.
Der CO2-Laser, ein Gasplasma-Laser, kein Feststoff, heute noch ein Renner, der übrigens auch in der Medizin verwendet wird, wurde bereits 1964 erfunden und technisch realisiert.
Je stabiler so eine Molekülschwingung ist, desto länger ist diese Zeit, bis eine Spontanemission erfolgt. Das ist alles ausreichend erforscht, sonst gäbe es keine Laser!!!
In der tiefen Atmosphäre ist diese Zeit ZU LANG um eine Spontanemission zu ermöglichen und die Energie für Stoß-induzierte Emission durch Nachbarmoleküle (N2) reicht bei den normalen Temperaturen NICHT aus, um sie auszulösen. Die Atmosphäre ist hier kein Gasplasma.
Absorbierte Strahlung wird daher thermalisiert,
genau das ist der einzige Grund warum die Transparenz für 15µm-Strahlung 0 wird,
nach wenigen 100m ist sie verschwunden.“
MfG
Lieber Herr Heß,
folgende Frage ist noch nicht beantwortet:
„Im Übrigen würde mich interessieren, wie Sie die Transparenz messen wollen, wenn Sie am Sensor nicht zwischen eben emittierten Photonen und solchen, die lange unterwegs waren unterscheiden können.“
„Richtig ist, dass sich während der mittleren Lebensdauer eines angeregten Schwingungszustandes etwa 10^5 Stöße ereignen. Jeder dieser Stöße kann zu einer Abregung des Schwingungszustandes führen, aber auch zur Emission eines Photons. Es kann aber auch gar nichts passieren, wenn der Stoß elastisch ist.
Auch ein nicht angeregtes CO2 Molekül erfährt in dieser Zeit 10^5 Stöße und kann angeregt werden. Es werden also laufend CO2 Moleküle durch Stöße angeregt.
Falsch ist, dass diese mittlere Lebensdauer einer Zeit entspricht die ein Molekül braucht, um nach einer Anregung wieder abstrahlen zu können. Das dürfen sie nicht verwechseln. Darin liegt ihr Denkfehler.“
Ja nun, Herr Heß:
wir haben 3% der 400ppm im 10m Volumen angeregt,
davon wird der bei weitem überwiegende Teil auch durch Stoß wieder abgeregt und ein paar strahlen ab.
Die paar Photonen, die unter diesen Umständen den Boden erreichen können Sie persönlich mit Handschlag begrüßen.
Und über die 90W/qm müssen wir wohl gar nicht mehr reden.
MfG
sie schreiben:
„in der Zeit, die ein Molekül braucht um nach einer Stoßanregung wieder abstrahlen zu können,
ereignen sich bei Bodendruck 10^5 Stöße“
Diese ihre Aussage ist falsch.
Richtig ist, dass sich während der mittleren Lebensdauer eines angeregten Schwingungszustandes etwa 10^5 Stöße ereignen. Jeder dieser Stöße kann zu einer Abregung des Schwingungszustandes führen, aber auch zur Emission eines Photons. Es kann aber auch gar nichts passieren, wenn der Stoß elastisch ist.
Auch ein nicht angeregtes CO2 Molekül erfährt in dieser Zeit 10^5 Stöße und kann angeregt werden. Es werden also laufend CO2 Moleküle durch Stöße angeregt.
Falsch ist, dass diese mittlere Lebensdauer einer Zeit entspricht die ein Molekül braucht, um nach einer Anregung wieder abstrahlen zu können. Das dürfen sie nicht verwechseln. Darin liegt ihr Denkfehler.
„Nein, durch eine Rekombination, und diese kann auf verschiedene Art und Weise stattfinden.“
Hallo Herr Holtz,
wie sieht diese im Vergleich zu CO2 aus?
„Sie können sich ja mal die Frage stellen, wie es überhaupt zum Polarlicht kommt.“
Energiereiche Strahlung von der Sonne, welche von Sauerstoff absorbiert werden kann?
Dabei fließt die absorbierte Energie (oder ein Teil davon)in eine Erhöhung der Elektronenbahn.
Bei dem Rückfall auf die tiefere Bahn wird das „grüne“ Photon emittiert.
Kommen dann im notwendigen Zeitraum zu viele Stöße dazu, fließt die Energie nicht mehr in Richtung Erhöhung der Elektronenbahn.
In Etwa so richtig?
„Zudem wird die Temperatur vom Zustandsraum von allen Prozessen und Energien bestimmt, deshalb sind alle Prozesse zur Thermalisierung heranzuziehen, und nicht nur Stoßprozesse.“
In „unserem“ Zustandsraum wird die Temperatur ausschließlich durch die Molekülgeschwindigkeit der Gasmoleküle bestimmt. Soweit die absorbierte Energie oder Teile davon innerhalb des Moleküls umgelagert werden, hat dies keinen Einfluß auf die Temperatur.
MfG
Zitat: Ihrer Aussage steht die Beobachtung gegenüber, daß das grüne Polarlicht der angeregten Sauerstoffmoleküle ab einer gewissen atmosphärischen Tiefe erlischt. Es wird also durch Stoß abgeregt…
Nein, durch eine Rekombination, und diese kann auf verschiedene Art und Weise stattfinden.
Sie können sich ja mal die Frage stellen, wie es überhaupt zum Polarlicht kommt.
Zudem wird die Temperatur vom Zustandsraum von allen Prozessen und Energien bestimmt, deshalb sind alle Prozesse zur Thermalisierung heranzuziehen, und nicht nur Stoßprozesse.
Mfg
Werner Holtz
„Hier ist der Ansatz von Mittelwerten m.E. sehr problematisch, denn man beschreibt nicht mehr einen beobachtbaren und prüfbaren Prozess. Der Fokus ist also von der Beobachtung eines Prozesses abhängig.“
Das ist aber so nicht richtig. Denken Sie mal alleine an experimentelle Messungen. Da wird üblicherweise mehrmals unter nominell identischen Bedingungen gemessen. Die Messwerte x_i einer Größe X werden statistisch ausgewertet mit dem Ziel der Angabe eines höchstwahrscheinlichen Erwartungswertes x für die Größe X. x selber tauchte aber nie als Messwert in der Reihe von Messwerten x_i auf. Trotzdem x nie direkt gemessen wurde ist die Angabe von x als Wert für X genauer als jede Auswahl eines der tatsächlich gemessenen Werte x_i!
„Meteorologische Modelle sind aber grundsätzlich anders strukturiert wie Klimamodelle, die gar keine kurzräumige Wettervorhersage resultieren wollen. Klimamodelle starten auch nicht mit einem bestimmten Druckszenario und Zyklonmuster, sondern setzen sich ein oder mehrere Abstraktionsebenen über einem Wettermodell an.“
Nein, auch das ist so nicht richtig. Die GCMs sind ja Klimamodelle, die auf der konkreten Berechnung von Druck- und Windfelder basieren. Auch im Modell entstehen und vergehen Zyklonen. Die sind natürlich bei einer grid-Größe von 100 km nur rudimentär, aber die ersten operativ für die Wettervorhersage eingesetzten Wettermodelle in den 60igern haben mit noch größeren Zellen gerechnet und die Wettervorhersage dadurch nachweisbar verbessert.
„Bereits kleine Abweichungen können in chaotischen Systemen zu völlig anderen Funktionsverläufen führen.“
Nun, es ist ja die wissenschaftliche Herausforderung das Modell so aufzubauen, daß die Lösungen hinreichend genau sind. Bei Wetter- und GCmodellen laufen die berechneten und die wirklichen Zirkulationsmuster nach einigen Tagen auseinander. Für die Wettervorhersage ist das nicht zu gebrauchen. Die Lösungen sind dann aber noch statistisch zu gebrauchen, wenn das berechnete Zirkulationsmuster zur beobachteten Klimatologie passt. D.h. das berechnete Modellwetter für den z.B. 1.1.2016 trifft zwar nicht mit dem beobachteten Wetter am 1.1.2016 überein. Aber das Modellwetter zum 1.1.2016 ist Mitglied des statistischen Ensembles der am 1.1. (über mehrere Jahre) beobachteten Wetterzuständen, gehört also zur Klimatologie dieses Jahresabschnitts, daher Klima(!)modell.
Sie kritisieren:
„ 1. Die Wirkung auf Prozess-Ebene (z.B. Wolkenbildung) ist nur unzureichend bekannt.“
Ohne eine quantitative Definition von was „un-/ bzw zureichend“ ist, ist diese Aussage wissenschaftlich gesehen unbrauchbar. Wie genau ein Prozeß verstanden werden muß und mit welcher Genauigkeit, hängt von den darauf aufbauenden Anwendungen ab. Ihre emotionale Aussage ist unangebracht.
“2. Die Effekte sind qualitativ und quantitiv nur unzureichend beschreiben: Wie wirkt sich der variabel Sonnenwind, Sonnenspektren und kosmische Strahlung aus? Die Annahme, dass diese Einflüsse marginal sind, darf massiv bezweifelt werden.“
Zweifel ist ja gut, aber Ihre sind zu unkonkret. Man kann schlecht Effekte berücksichtigen, die man nicht kennt, denn dann weiß man nicht mal, ob sie überhaupt relevant sind.
In der Physik geht man eigentlich ziemlich einfach vor: man misst etwas und versucht, die Messergebnisse mit der bestehenden Theorie quantitativ zu erklären. Wenn die Messergebnisse systematisch von der Theorie abweichen, so hat man ein neues Forschungsfeld für Verbesserungen entdeckt. Aber das heißt nicht, daß die bestehende alte Theorie generell unbrauchbar ist. Es hängt davon ab, wie sich die Abweichungen zu dem durch die alte Theorie Erklärtem verhalten: eine 100% Abweichung zwischen Messung und Theorie fordert eine Notwendigkeit, eine systematische 0,001% Abweichung noch zu verbessern ist eine Arbeit für Detailverliebte.
„Auch ist die Frage, wie sehr die ozeanischen Zyklen, Sonnenzyklen etc. berücksichtigt werden, völlig unklar.“
Habe ich schon zigmal erklärt: die Ozeanischen Zyklen sind bereits intrinsisch in dem GCMs drin, die kann man nicht rein- oder raustun! Warum kapieren Sie das nicht?
Die bekannten und quantifizierten Auswirkungen der Solarzyklen sind schon drin. Unbekannte geht wie gesagt nicht.
„3. CO2 Quellen und Senken sind unzureichend beschrieben. So überraschten Satellitenmessungen, dass Urwälder keineswegs CO2 Senken darstellen, dafür aber aride Gebiete – z.B. Australien.“
Wozu brauchen Sie das fürs Klimamodell? Die historischen Daten sind empirisch drin und für die Projektionen gibt man welche vor. Das CO2 wird wie die Vulkanausbrüche oder die Land-Meerverteilung als Randbedingung extern vorgeschrieben.
„ 4. Massebilanzen der Eiskörper der Antarktis und Grönlands weisen oft gegenläufige, bzw. stark divergierende Werte auf. Ein Zusammenhang mit dem Klimawandel bleibt darum nur in einem weiten Fehlerband darzustellen. „
Was haben die Beobachtung mit den GCMs zu tun?
5. Ebenso unzureichend ist die Feststellung der Meerestemperaturen. Diese sind regional und bezogen auf den Tiefenhorizont im Kontext der Strömungen weitgehend zu grob, wenn überhaupt abzubilden.
Müssen Sie quantifizieren. So ist Ihr Argument wissenschaftlich unbrauchbar.
„6. Meteorolgische Systeme verhalten sich meist chaotisch: Es bilden sich Großwetterlagen heraus, die oft schwer langfristig vorhersehbar sind.“
Sicher, aber deren Klimatologie (=Statistik), siehe oben.
„Ob es hier statistische Trends gibt, die von wenigen Parametern gesteuert sind, und wie sich diese dann Verhalten ist weitgehend nicht begründet ermittelbar.“
Sie zeigen wieder, daß Sie keine Ahnung davon haben, was ein GCM ist. In einem GCM wird deren Statistik des Modellwetters aber nicht durch wenige Parameter gesteuert, sondern ist das Ergebnis der Modellphysik! Diese ist – wie ich oben und ebenfalls erschöpfend oft schon erklärt habe – nicht Statistik, sondern man rechnet die Dynamik von Ozean und Atmosphäre (deswegen heißt es ja auch GCM!) aus den fundamentalen Gleichungen der Physik! Die Statistik des aus der Modellphysik berechneten Modellwetters ergibt sich aus dem mit den dynamischen Gleichungen implementierten Chaos des GCMs. Wenn die Statistik des beobachteten Wetterchaos mit der Statistik des Modellwetters aus dem GCM übereinstimmt, so nennt man das gleiches Klima und das Modell erklärt das beobachtbare Klima.
„Statistische Mittel sind angesichts des chaotischen Charakters völlig unzureichend, um eine prozessnahe Modellierung durchzuführen.“
Es gibt in der Physik beliebig viele Beispiele, die Ihre Aussage widerlegen.
Ich rate Ihnen, GCMs erst einmal korrekt zu verstehen. Ihr Verständnis darüber ist fehlerhaft und ungenügend für eine solide Meinungsbildung.
„Ein angeregter Zustand muss nicht die Dauer erhalten bleiben die es für 10^5 Stöße braucht, um emittieren zu können.“
Lieber Herr Heß,
die Aussage heißt korrekt:
in der Zeit, die ein Molekül braucht um nach einer Stoßanregung wieder abstrahlen zu können,
ereignen sich bei Bodendruck 10^5 Stöße.
Diese Aussage kann hier auf Eike seit Jahren nachgelesen werden, ihr wurde m.W. nie begründet widersprochen.
Im Übrigen würde mich interessieren, wie Sie die Transparenz messen wollen, wenn Sie am Sensor nicht zwischen eben emittierten Photonen und solchen, die lange unterwegs waren unterscheiden können.
MfG
MfG
sie schreiben:
„Nun ganz so spontan wohl nicht und eben „können“ und nicht „müssen“. Der angeregte Zustand muß eine gewisse Dauer erhalten bleiben um emittieren zu können. In dieser Zeit haben wir bodennah aber die bekannten 10^5 weiteren Stöße.“
Genau da liegt ihr Denkfehler. Das ist falsch.
Ein angeregter Zustand muss nicht die Dauer erhalten bleiben die es für 10^5 Stöße braucht, um emittieren zu können.
„„Am Boden kommt bezüglich CO2 höchstens die thermische Strahlung aus dem 10m Streifen an (Für H2O mag eine andere Höhe richtig sein).“
Ihre Aussage bedeutet dann, dass der 10 m Streifen optisch dicht ist, also die Transmission Null hat. Das bedeutet dann, dass ihr Streifen im Wellenlängenbereich des CO2 eine thermische Emission hat, die der Intensität eines schwarzen Strahler mit der entsprechenden Temperatur des Streifens entspricht.“
Lieber Herr Heß,
Wäre das Problem mit der Emissionsfähigkeit nicht gegeben, würde ich Ihnen zustimmen.
„Ihre Aussage ist aber nur für den Zentralbereich der thermischen Emission des CO2 in der Atmosphäre richtig. Für andere Wellenlängen kommt die Strahlung aus höheren Schichten.“
Ja, deßhalb ja auch mein Hinweis auf H2O
„Selbstverständlich gibt es ein physikalisches Prinzip nennt sich mikroskopische Reversibilität. Thermalisierung bedeutet, dass durch Absorption angeregte Moleküle ihre Anregungsenergie an einen Stoßpartner übertragen das ist die Stoßabregung. Damit gibt es aber mikroskopisch gesehen ebenfalls die Gegenreaktion, dass Moleküle ihre kinetische Energie auf CO2 übertragen und dieses anregen. Das ist die Stoßanregung. In welchem Maße die stattfindet hängt davon ab, ob der angeregte Zustand thermisch angeregt werden kann. Das ist bei CO2 im Bereich um 15 µm der Fall, weil es sich um eine Schwingungsanregung handelt deren Anregungsenergie etwa 3.3 kT entspricht. Damit ist dieser Zustand thermisch signifikant angeregt, etwa 3% der Moleküle. Damit existieren zu jedem Zeitpunkt CO2 Moleküle in angeregten Zuständen, die spontan ein Photon emittieren können. Wenn Stoßprozesse dominieren, domineren sowohl die Stoßabregung als auch die Stoßanregung.“
Nun ganz so spontan wohl nicht und eben „können“ und nicht „müssen“. Der angeregte Zustand muß eine gewisse Dauer erhalten bleiben um emittieren zu können. In dieser Zeit haben wir bodennah aber die bekannten 10^5 weiteren Stöße.
„Die Behauptung, dass CO2 nicht emittiert ist also falsch aufgrund der physikalischen Prinzipien“
Es kommt auf die Umstände an. S.o.
„und aufgrund der Messergebnisse die Herr Landvogt zeigt.“
Meßergebnisse sind gut und richtig und wünschenswert.
Im Fall des Treibhauses gilt aber der bekannte Spruch:
Traue keiner Messung, die du nicht selbst hingedreht hast.
Ich sage da nur „Hamburger Wettermast“.
Ich akzepiere daher nur den auf 0°K gekühlten Sensor, der am Boden nach oben mißt.
„P.S. Anders sieht es bei elektronischen Anregung aus die einer Anregungsenergie größer 100 kT entspricht. Diese Zustände sind deshalb typischerweise nicht thermisch angeregt. Deshalb wird die thermische Anregung im Jablonski Schema für die UV/VIS Spektroskopie vernachlässigt.“
Ja, steht hier nicht zur Debatte.
MfG
„Unter diesen Umständen ist der Versuch eines GCMs, der realitätsnah die Klimaentwicklung abbildet, äußerst verwegen und erinnert an die Quadratur des Kreises. Es sind gleich eine Reihe von k.o.-Kriterien erfüllt.“
Sehr geehrter Herr Landvoigt,
ich sehe es nicht als primären Zweck von GCMs an, die zukünftige Klimaentwicklung abzubilden, sondern das Wettergeschehen im Zeitrahmen von Monaten bis einigen Jahren zu verstehen und die verschiedensten Beobachtungen in einem Modell zusammenzuführen. Z.B. kann man nicht direkt die in 2m Höhe gemessenen Lufttemperaturen mit den TLT-Satelliten-Temperaturen vergleichen. Insbesondere in der Arktis ist die Aussage von Temperaturmessungen problematisch, da die Ausdehnung des Meereises jahreszeitlich schwankt.
In der Physik ist es üblich Experiment und Theorie zu vergleichen. Dies ist lästig, da häufig einige Ungereimtheiten auftreten und eine Übereinstimmung ein eher langweiliges Ergebnis ist. Die Klimawissenschaftler geben sich deshalb offensichtlich nicht mit diesem Vergleich zufrieden, sondern konzentrieren sich auf die fernere Klimaentwicklung. Das geht wohl aus den von Ihnen genannten Gründen schief. Bescheidenheit und Redlichkeit sind nicht unbedingt Tugenden, die von allen Wissenschaftlern geteilt werden.
auf dieser Seite http://tinyurl.com/pg3bd8p wird allerdings das Wasser in der Stratosphäre konsequent auf Null gesetzt. Es bleibt bei etwa 85 W/m2 Standard US Atmosphäre.
Ich vermute auch, dass Extremfälle schlecht berechnet werden.Besser ist es sicher sich auf Fälle zu beschränken die auch vorkommen bzw. vorkommen können.
Für unsere Diskussion hier ist es ja eher ein didaktisches Modell und dafür ist es geeignet.
„Stöße sind ausgeschlossen, weil ein Molekülstoß die Schwingungsenergie nicht aufnehmen bzw. verteilen kann. Die Energie des Schwingungszustandes ist dE(f) = h*c/l = 6,6*10^-34*2,99*10^8/15*10^-6 = 1,31*10^-20 J und verglichen mit der Energie beim Molekülstoß dE(s) = k*T = 1,38*10^-23*300 = 4,14*10^-21 J.“
Sehr geehrter Herr Holtz,
Ihrer Aussage steht die Beobachtung gegenüber, daß das grüne Polarlicht der angeregten Sauerstoffmoleküle ab einer gewissen atmosphärischen Tiefe erlischt.
Es wird also durch Stoß abgeregt…
Und das bei Energien, die wesentlich höher sind als im IR-Bereich!
Im Übrigen gäbe es auch keine Thermalisierung der absorbierten Strahlung, sondern es müßte alle von einem Molekül absorbierte Strahlung von diesem selben auch wieder emittiert werden.
Ich denke, da waren wir schon weiter.
Oder missverstehe ich Sie?
MfG
MfG
sie schreiben:
„Am Boden kommt bezüglich CO2 höchstens die thermische Strahlung aus dem 10m Streifen an (Für H2O mag eine andere Höhe richtig sein).“
Ihre Aussage bedeutet dann, dass der 10 m Streifen optisch dicht ist, also die Transmission Null hat. Das bedeutet dann, dass ihr Streifen im Wellenlängenbereich des CO2 eine thermische Emission hat, die der Intensität eines schwarzen Strahler mit der entsprechenden Temperatur des Streifens entspricht.
Ihre Aussage ist aber nur für den Zentralbereich der thermischen Emission des CO2 in der Atmosphäre richtig. Für andere Wellenlängen kommt die Strahlung aus höheren Schichten.
Selbstverständlich gibt es ein physikalisches Prinzip nennt sich mikroskopische Reversibilität. Thermalisierung bedeutet, dass durch Absorption angeregte Moleküle ihre Anregungsenergie an einen Stoßpartner übertragen das ist die Stoßabregung. Damit gibt es aber mikroskopisch gesehen ebenfalls die Gegenreaktion, dass Moleküle ihre kinetische Energie auf CO2 übertragen und dieses anregen. Das ist die Stoßanregung. In welchem Maße die stattfindet hängt davon ab, ob der angeregte Zustand thermisch angeregt werden kann. Das ist bei CO2 im Bereich um 15 µm der Fall, weil es sich um eine Schwingungsanregung handelt deren Anregungsenergie etwa 3.3 kT entspricht. Damit ist dieser Zustand thermisch signifikant angeregt, etwa 3% der Moleküle. Damit existieren zu jedem Zeitpunkt CO2 Moleküle in angeregten Zuständen, die spontan ein Photon emittieren können. Wenn Stoßprozesse dominieren, domineren sowohl die Stoßabregung als auch die Stoßanregung.
Die Behauptung, dass CO2 nicht emittiert ist also falsch aufgrund der physikalischen Prinzipien und aufgrund der Messergebnisse die Herr Landvogt zeigt.
P.S. Anders sieht es bei elektronischen Anregung aus die einer Anregungsenergie größer 100 kT entspricht. Diese Zustände sind deshalb typischerweise nicht thermisch angeregt. Deshalb wird die thermische Anregung im Jablonski Schema für die UV/VIS Spektroskopie vernachlässigt.
Ich kann mir nicht vorstellen, daß 400ppm CO2 der 10m-Schicht 90W/qm Strahlungsleistung aus thermischer Eigenstrahlung an den Boden abgeben kann, wenn der Boden selbst über den gesamten Abstrahlbereich eines Schwatzkörpers lediglich ~350W/qm aufbringen kann.
—————-
Man muß da nur mal die beteiligten Massen betrachten.
Sehr geehrter Herr Keks,
Natürlich wollen wir uns Vorstellungen von der Realität machen. Manchmal leitet uns die Intuition aber in die Irre. Das kann man dann zuweilen in einem Gedankenexperiment überprüfen:
Stellen sie sich einen massiven Stahlblock vor, der 200°C warm ist. Die Strahlung wird man mit geeigneten Messgeräten feststellen können.
Jetzt stellen sie sich eine gleich große Fläche vor, die aus dem selben Stahlt gemacht ist, aber nur 0,1 mm Dick ist, aber die gleiche Temperatur hat. Werden sie ein Unterschied der Strahlung fesstellen? Sicher nicht!
Folglich spielt die Masse hier keine Rolle.
Vermutlich denken sie: Das Blech wird sich aber sehr schnell abkühlen, während der Block wohl seine Temperatur nur langsam abgibt … wie aber, wenn das Blech von der anderen Seite erhitzt wird?
Mit der Atmosphäre ist dies nicht ganz das selbe, aber ähnlich. Anstelle einer festen Oberfläche mit nur wenigen strahlenden Molekülen haben sie aufgrund der wesentlich geringeren Dichte eine effektiv strahlende Schicht – bezogen auf die Oberfläche und Frequenzband wenige Meter dick. Diese Schicht wird einerseits von Unten, durch die Bodenabstrahlung, andererseits von der Strahlung der darüber liegenden Schichten erwärmt, bzw. in dessen Abkühlung gemildert, so dass man durchaus von LTE ausgehen kann.
Darum sind die Werte der Rückstrahlung, die zunächst viel zu hoch aussehen, gar nicht so unplausibel.
————- #172: besso keks sagt:
—————
Es gibt auf jeden Fall kein Gesetz, daß ein IR-aktives Gas zwingt abzustrahlen, solange alternative, konkurrierende Entspannungswege offen stehen. Siehe auch Hug mit Verweis auf Jablonski.
Außerdem habe ich nichts gegen das Bisschen thermische Strahlung des CO2.
Ich sehe nur nicht, wie die paar Gramm CO2 in der 10m-Schicht bei 15°C ganze 90W/qm
an den Boden abgeben sollen (gut ein Viertel der gesamten Abstrahlleistung des Bodens!!!)
Ich war auch anfangs irritiert, als ich mir das Jablonski-Schema klar machte. Dies ist jedoch nur für molekulare Ebene auf Basis eines einzelnen Relaxationsprozess bedeutsam, nicht aber unter Einbezug eines gesamten Molekül-Ensembles, dass in ständiger Wechselwirkung steht. Denn hier geschehen neben den Relaxationsprozessen stets auch Anregungsprozesse durch Stoß und Absorption entgegen. Genau ist darum die zulässige vereinfachte Modellannahme LTE. Das heißt: Manche dieser Prozesse stehen durch die Statistik derart im Ausgleich, dass sie ihre Bedeutung verlieren. So ist die Stoß-Relaxation für ein Gasvolumen auch unter Beachtung von Jablonski durch die Stoß-Anregung zu Null zu saldieren. Es bleiben daher die kirchhoffschen Strahlungsgesetze unter LTE gültig.
————- #172: besso keks sagt:
————-
Nebenbei bemerkt: ich kann mich gut an die Anfänge der Diskussion um das Treibhaus hier auf EIKE erinnern:
erst gabs die Schicht in 8000m Höhe, die die IR-Strahlung des Bodens zurück reflektiert, …
Das sind die ‚didaktisch‘ gemeinten Modelle, wie sie auch Al Gore benutzt. Das ist natürlich grober Unfug, der hier nicht mehr als didaktisches Mittel entschuldbar bleibt, sondern einfach nur falsch ist.
————- #172: besso keks sagt:
————-
… dann war es der Strahlungstransport, der die Bodenabstrahlung als Gegenstrahlung zurückbringt.
Das ist zwar auch eine Vereinfachung, die so nicht uneingeschränkt zutreffend ist, kommt der Realität aber näher.
————- #172: besso keks sagt:
————
Jetzt soll die thermische Eigenstrahlung einer 10m-Schicht mit 400ppm die Quelle für die Gegenstrahlung in immer noch gleicher Stärke sein.
Die Höhe der Gegenstrahlung – eigentlich ein fragwürdiger Begriff, der sich auch eingebürgert hat – ist bedingt durch die physische Beschaffenheit der Luftschicht und der Temperatur. Sie setzt nicht notwendig eine Bodenabstrahlung voraus: Wenn eine warme Luftschicht über eine kalte Eisfläche weht, auch in der Nacht ohne Sonneneinstrahlung, wird die Eisfläche erwärmt. Darum fällt die Temperatur im antarktischen Winter nicht nahe des absoluten Nullpunktes.
Sie spüren das, wenn sie in eine kalte windstille Nacht nackt ins Freie gehen, im Gegensatz zu einer warmen Nacht. Im einen Fall kühlen sie schnell aus und könnten gar erfrieren, im anderen Fall kann es sehr angenehm sein. Der Unterschied ist vor allem die differierende Gegenstrahlung.
Die kalkulatorische Größe der Werte – es werden meist Mittelwerte angegeben – bestimmt sich aus dem Energie-Erhaltungssatz: Gehen sie von LTE aus, dass sie sich vereinfacht bei dt -> 0 vorstellen können.
In Worten: Zwischen zwei Zeitpunkten, die beliebig kurz hinter einander sein können, ändert sich die Temperatur nicht signifikant. Darum muss der Energiezufluss dem Energieabfluss entsprechen – und umgekehrt.
Und darum ist eine Bilanzierung völlig korrekt.
Ich halte es für richtig, wenn man nicht ohne Nachzudenken einfach dem glaubt, was einem die Wissenschaftler erklären wollen. Das ist auch nicht der Sinn der Wissenschaft. Darum halte ich Ihren kritischen Ansatz auch für grundsätzlich richtig.
Einiges aber bestätigt sich bei der Nachprüfung, auch wenn es zunächst unplausibel aussah. Eine kritische Herangehensweise, die aber die Problemlösung ignoriert, verliert auf der anderen Seite ihren Sinn.
Zitat: Es gibt auf jeden Fall kein Gesetz, daß ein IR-aktives Gas zwingt abzustrahlen, solange alternative, konkurrierende Entspannungswege offen stehen.
Diese anderen „Entspannungswege“ sind dem Molekül unter den gegebenen Bedingungen aber nicht zugänglich. Also, welche „alternative, konkurrierende Entspannungswege“ oder Energieverteilungs-Prozesse stehen dem Molekül offen?
Stöße sind ausgeschlossen, weil ein Molekülstoß die Schwingungsenergie nicht aufnehmen bzw. verteilen kann. Die Energie des Schwingungszustandes ist dE(f) = h*c/l = 6,6*10^-34*2,99*10^8/15*10^-6 = 1,31*10^-20 J und verglichen mit der Energie beim Molekülstoß dE(s) = k*T = 1,38*10^-23*300 = 4,14*10^-21 J.
Mfg
Werner Holtz
das Modtran Skript auf der Webseite setzt auch andere Gase und Aerosole nicht konsequent auf Null und hält die Temperatur bei Änderung der Zusammensetzung konstant.
———————–
Aher geehrter Herr Heß,
Ihre Beobachtung trifft offensichtlich zu. Beeinträchtigt das die Güte des Modelle, wenn man es im Normalbereich variiert, also wenn man nicht zu den Extremen kommt? Ich bin geneigt anzunehmen, dass diese Modellgrenzen nur bei den Extremen zu unzutreffenden Ergebnissen führen. Teilen sie diese Ansicht?
Verstehen Sie unter der konkreten Situation die molekulare Ebene? Dies ist die kleinste Größe einer „grid cell“. Doch dies ist nicht notwendig. Druck und Temperatur sind auch makroskopische Mittelwerte, die man messen kann.
————-
Sehr geehrter Herr Berberich
Ich sehe die Anwendung von physikalischen Gesetzmäßigkeiten in dem jeweiligen Fokus, indem diese erkannt wurden. So macht die Anwendung von Gasgesetzen und Fluiden auf molekularer Ebene keinen Sinn, denn sie beschreiben ja das zusammenspiel der Interaktionen und Wechselwirkungen. Allerdings denke ich nicht, dass es lediglich die Unterscheidung Sub-Atomar, Molekular, Mikroskopisch und Makroskopisch gibt, sondern der Begriff ‚Makroskopisch‘ ist Prozessabhängig. So können Zyklone nur auf dem Level betrachtet werden, in dem sie auch beobachtet werden, was mehrere Hundert Kilometer umfassen kann.
Dagegen kann die Evaporation einer Oberfläche nur im Kontext eine naturräumlichen Homogenität angesetzt werden. Die Evaporation einer Mischfläche aus Asphalt, Wiese, umgebrochenen Ackerland und einem dichten Laubwald ergibt keine leicht verständlichen Ergebnisse oder Kurvenverläufe bei gegebener Temperatur, Einstrahlung, Wind, Luftfeuchte und Bodenfeuchte.
Hier ist der Ansatz von Mittelwerten m.E. sehr problematisch, denn man beschreibt nicht mehr einen beobachtbaren und prüfbaren Prozess. Der Fokus ist also von der Beobachtung eines Prozesses abhängig.
————– #167: P. Berberich sagt:
—————-
Die Navier-Stokes-Gleichung bezieht sich auf makroskopische Größen. Die Wetter-Vorhersage-Modelle bauen auf dieser Gleichung auf. Man sollte vielleicht erst die Grenzen dieser Modelle diskutieren um die Leistungsfähigkeit von Klimamodellen abschätzen zu können.
Zum Einen beschreibt die Navier-Stokes-Gleichung einen beobachtbaren und prüfbaren Prozess. Es geht um das Stömungsverhalten von Fluiden unter Beachtung der Viskosität und bilden Turbulenz und Grenzschichten ab. Deren Einsatz in der Meteorologei macht vereinfachte Annahmen ohne detaillierte Verrechnung naturräumlicher Details . Unter anderem sind die Abschätzungen dieser Makro-Größen um ggf. mehrere Dimensionen einer der Gründe, warum die Reichweite einer Wettervorhersage zeitlich begrenzt bleibt.
Meteorologische Modelle sind aber grundsätzlich anders strukturiert wie Klimamodelle, die gar keine kurzräumige Wettervorhersage resultieren wollen. Klimamodelle starten auch nicht mit einem bestimmten Druckszenario und Zyklonmuster, sondern setzen sich ein oder mehrere Abstraktionsebenen über einem Wettermodell an. Somit ist die Frage, ob diese Abstraktionsschritte denn noch eine zutreffende Abbildung liefern erfolgskritisch. Eine Zutreffende Abbildung würde eine korrekte Abstraktion der physikalischen Verhältnisse auf dem gewählten Grid-Size erforderlich machen. Bereits kleine Abweichungen können in chaotischen Systemen zu völlig anderen Funktionsverläufen führen.
Meine fundamentalen Zweifel an der Brauchnbarkeit von CGMs noch mal zusammen gefasst:
1. Die Wirkung auf Prozess-Ebene (z.B. Wolkenbildung) ist nur unzureichend bekannt.
2. Die Effekte sind qualitativ und quantitiv nur unzureichend beschreiben: Wie wirkt sich der variabel Sonnenwind, Sonnenspektren und kosmische Strahlung aus? Die Annahme, dass diese Einflüsse marginal sind, darf massiv bezweifelt werden. Auch ist die Frage, wie sehr die ozeanischen Zyklen, Sonnenzyklen etc. berücksichtigt werden, völlig unklar.
3. CO2 Quellen und Senken sind unzureichend beschrieben. So überraschten Satellitenmessungen, dass Urwälder keineswegs CO2 Senken darstellen, dafür aber aride Gebiete – z.B. Australien.
4. Massebilanzen der Eiskörper der Antarktis und Grönlands weisen oft gegenläufige, bzw. stark divergierende Werte auf. Ein Zusammenhang mit dem Klimawandel bleibt darum nur in einem weiten Fehlerband darzustellen.
5. Ebenso unzureichend ist die Feststellung der Meerestemperaturen. Diese sind regional und bezogen auf den Tiefenhorizont im Kontext der Strömungen weitgehend zu grob, wenn überhaupt abzubilden.
6. Meteorolgische Systeme verhalten sich meist chaotisch: Es bilden sich Großwetterlagen heraus, die oft schwer langfristig vorhersehbar sind. Ob es hier statistische Trends gibt, die von wenigen Parametern gesteuert sind, und wie sich diese dann Verhalten ist weitgehend nicht begründet ermittelbar. Statistiken zeigen keine klaren Trends und das vermeintliche Signal-Rausch-Verhältnis ist sehr ungünstig.
7. Prozessuale Abstraktionsbildung auf festen Grid-Sizes, die über 100 km umfassen, können die prozessuale Wirkung grundsätzlich nicht darstellen. Statistische Mittel sind angesichts des chaotischen Charakters völlig unzureichend, um eine prozessnahe Modellierung durchzuführen.
Unter diesen Umständen ist der Versuch eines GCMs, der realitätsnah die Klimaentwicklung abbildet, äußerst verwegen und erinnert an die Quadratur des Kreises. Es sind gleich eine Reihe von k.o.-Kriterien erfüllt.
Kurz: Sie ist gar nicht in aussagekräftiger Güte zu erwarten – und zwar grundsätzlich nicht.
Andere bezeichnen diese darum zutreffend als Spielzeug-Modelle.
das Modtran Skript auf der Webseite setzt auch andere Gase und Aerosole nicht konsequent auf Null und hält die Temperatur bei Änderung der Zusammensetzung konstant. Das heißt durch die tropische Atmosphäre ist sehr viel gasförmiges Wasser enthalten das thermisch emittiert. Nimmt man nun die thermische Emission des CO2 weg spielt das keine große Rolle.
Übrigens wenn sie sich den Outputfile anschauen bleibt in der Stratosphäre Wasserdampf in dem Modtranskript egal welche Werte sie sie setzen.
Liebre Herr Keks #169,
„die Gegenstrahlung ist die thermische Emission aus der gesamten Atmosphäre, nicht eine etwaige Reemission der absorbierten Strahlung. Die Gegenstrahlung ist wenn sie das Wort Reemission gebrauchen möchten die Reemission der Stoßanregungung. Besser ist es sie schlichtweg als thermische Eigenemission der Atmosphäre Richtung Oberfläche zu betrachten.“
Hallo Herr Heß,
Zustimmung bis auf die „gesamte Atmosphäre“.
Am Boden kommt bezüglich CO2 höchstens die thermische Strahlung aus dem 10m Streifen an (Für H2O mag eine andere Höhe richtig sein).
„Herr Landvogt zeigt eine Messung derselben. Das Integral über den Bereich des CO2 aus der Messung ergibt etwa 90 W/m2 abgeschätz. Ein vergleichbares Ergebnis bekommt man aus Modtran für 400 ppm CO2, wenn man alles andere auf Null setzt.“
Ich kann mir nicht vorstellen, daß 400ppm CO2 der 10m-Schicht 90W/qm Strahlungsleistung aus thermischer Eigenstrahlung an den Boden abgeben kann, wenn der Boden selbst über den gesamten Abstrahlbereich eines Schwatzkörpers lediglich ~350W/qm aufbringen kann.
Man muß da nur mal die beteiligten Massen betrachten.
„Sie können sich auch folgendes klarmachen. Angenommen es existierte ein Gas das IR aktive Zustände hätte die bei 273K schon angeregt werden könnten wie das bei CO2 der Fall ist und dieses Gas würde nicht bei den Wellenlängen dieser Zustände thermisch emittieren.
Dann wären unsere Energieprobleme gelöst, weil wir vom Prinzip her ein Perpetuum Moboile bauen könnten.“
Keine Ahnung, wie Sie daraus ein Perpetuum Mobile bauen wollen.
Es gibt auf jeden Fall kein Gesetz, daß ein IR-aktives Gas zwingt abzustrahlen, solange alternative, konkurrierende Entspannungswege offen stehen. Siehe auch Hug mit Verweis auf Jablonski.
Außerdem habe ich nichts gegen das Bisschen thermische Strahlung des CO2.
Ich sehe nur nicht, wie die paar Gramm CO2 in der 10m-Schicht bei 15°C ganze 90W/qm
an den Boden abgeben sollen (gut ein Viertel der gesamten Abstrahlleistung des Bodens!!!)
„Die Aussage, dass CO2 nicht emittiert ist also nicht nur durch Messungen widerlegt wie Herr Landvogt oben zeigt, sondern verstößt auch gegen die Grundprinzipien der Physik.“
Nein, tut es nicht. Unabhängig davon kann es gerne mit Eigentemperatur strahlen.
Nebenbei bemerkt: ich kann mich gut an die Anfänge der Diskussion um das Treibhaus hier auf EIKE erinnern:
erst gabs die Schicht in 8000m Höhe, die die IR-Strahlung des Bodens zurück reflektiert, dann war es der Strahlungstransport, der die Bodenabstrahlung als Gegenstrahlung zurückbringt.
Jetzt soll die thermische Eigenstrahlung einer 10m-Schicht mit 400ppm die Quelle für die Gegenstrahlung in immer noch gleicher Stärke sein.
pffffffffffffffffffffffffft
MfG
Das Integral über den Bereich des CO2 aus der Messung ergibt etwa 90 W/m2 abgeschätz. Ein vergleichbares Ergebnis bekommt man aus Modtran für 400 ppm CO2, wenn man alles andere auf Null setzt.
————–
Sehr geehrter Herr Heß
Zunächst danke für die argumentative Unterstützung. Ich habe den Eindruck, dass einige meinen, wer nicht zu einer Radikalopposition in Sachen Treibhauseffekt kommt, würde bereits zum Lager der AGW-Propagandisten gehören. Das ist bedauerlich, denn es speltet die vernünftige Kritik. Immerhin sollte die Kritik jener, die intellektuelle Redlichkeit als wichtige Voraussetzung für eine überzeugende Argumentation erachten, auch schlagkräftigere Beiträge liefern können. Denn wie kann man Vernunft von der Allgemeinheit und den Meinungsgegnern erwarten, wenn man diese selbst nicht demonstriert.
Zu ihrem Beitrag … ich habe das nachgestellt:
Tropische Atmosphäre, wolkenlos, 0 km Höhe ‚Looking up‘
Wenn ich nur die 400 ppm CO2 auf 0 reduziere, erhalte ich eine Differenz von -7.22 W/m2
bei einem Strahlungsinput von 340.69 W/m2
wenn ich alle IR-aktiven Bestandteile der Luft auf Null setze, erhalte ich nur 27.987 W/m2 … also ist hier die solare Einstrahlung nicht enthalten. Ist das so zu verstehen, dass Modtran eben die anderen Frequenzen der solaren Einstrahlung nicht rechnet und nur den thermischen Anteil darstellt? Oder ist das außerhalb des Modellbereiches, dass Modtran hier keine vernünftigen Werte mehr angibt?
Wenn ich nur den Water Vapor Scale bei 1 lasse, kommt immerhin ein vernünftiger Wert heraus: Differenz -9.42 W/m2
Methan und Ozon machen dann einzeln betrachtet eine Differenz von -1.88 W/m2
Water Vapor auf 0 reduziert, bei 400 ppm CO2 führt zu einem IR Heat Flux 101.736 W/m2
IR Heat Loss (Background) 347.91 W/m2
… Difference, New – BG -246.18 W/m2
Wenn diese Werte stimmen, zeigt es, dass Wasserdampf um Dimensionen stärker wirkt als CO2, aber ich zweifele, ob Modtran in diesem Bereich richtig rechnet. Denn bereits bei einem Water Vapor Scale von 0.01 haben wir nur naoch eine Differenz von -140.61 W/m2
Wenn man dann CO2 auf 0 reduziert, ist die Differenz -68.51 W/m2.
Einerseits könnte man hinsichtlich der Pausibilität der Zahlen meinen, dass sich die einzelnen Komponenten eben überlagern, darum kann man nicht einfach Netto-Werte rechnen.
Dennoch erscheinen die Zahlen in den Extrembereichen der Simulation sehr merkwürdig. Ich vermute, dass die Rechnung dann außerhalb des zulässigen Bereichs liegt.
die Gegenstrahlung ist die thermische Emission aus der gesamten Atmosphäre, nicht eine etwaige Reemission der absorbierten Strahlung. Die Gegenstrahlung ist wenn sie das Wort Reemission gebrauchen möchten die Reemission der Stoßanregungung. Besser ist es sie schlichtweg als thermische Eigenemission der Atmosphäre Richtung Oberfläche zu betrachten.
Herr Landvogt zeigt eine Messung derselben. Das Integral über den Bereich des CO2 aus der Messung ergibt etwa 90 W/m2 abgeschätz. Ein vergleichbares Ergebnis bekommt man aus Modtran für 400 ppm CO2, wenn man alles andere auf Null setzt.
Sie können sich auch folgendes klarmachen. Angenommen es existierte ein Gas das IR aktive Zustände hätte die bei 273K schon angeregt werden könnten wie das bei CO2 der Fall ist und dieses Gas würde nicht bei den Wellenlängen dieser Zustände thermisch emittieren.
Dann wären unsere Energieprobleme gelöst, weil wir vom Prinzip her ein Perpetuum Moboile bauen könnten. Die Aussage, dass CO2 nicht emittiert ist also nicht nur durch Messungen widerlegt wie Herr Landvogt oben zeigt, sondern verstößt auch gegen die Grundprinzipien der Physik.
„—————- #160: besso keks sagt:
————–
Ich halte diesen Unterschied aber für die genannte Aufgabe aber nicht für so entscheidend:
Hug sagt ja, daß es in der bodennahen Atmosphäre praktisch keinen Strahlungstransport gibt.
Das eben nicht! Eine hohe Extimktion im 15 Mm Band heißt eben nur, dass es keine Transmission von der originalen Quelle direkt durch die Schicht gibt. Davon bleibt unberücksichtigt, dass es sowohl Absorption als auch Emission gibt. Auf diesem Wege bildet sich ein Gradient in der Schicht aus, die allerdings einen Strahlungstransport entspricht.“
Nein!
Alle Strahlung des Bodens wird im relevanten Bereich absorbiert. Alle!
Eine Reemission dieser Strahlung gibt es aufgrund der Thermalisierung nicht.
Die Thermalisierung führt zu einer höheren Eigentemperatur des Gasvolumens und erhöht dadurch lediglich dessen thermische Eigenstrahlung (Wenn überhaupt…)
Und verstärkt natürlich insbesondere die Konvektion.
„————– #160: besso keks sagt:
————-
Das müßte doch unabhängig von irgendwelchen Tabellenwerten und Systembetrachtungen möglich sein. Oder nicht?
Man kann zwar ausrechnen, wie sehr das CO2 bei einer gegebenen Temperatur und Dichte strahlt, aber es findet zugleich auch immer eine wieder-Absorption aus dem Volumen heraus statt. Darum ist es nicht so einfach.“
Ich habe nicht gesagt, daß es „einfach“ ist. Wäre es einfach, könnte ich es selbst 😉
„————– #160: besso keks sagt:
————–
Die selbe Rechnung kann dann angestellt werden mit 800ppm und entsprechend korrigierter Absorptionslänge. Oder nicht?
Mit Modtran ist das Ergebnis der Differenz zwischen 400 ppm und 800 ppm 1.57 W/m2
Merke: Es gibt keinen linearen Zusammenhang zwischen CO2 und Strahlung.“
Nun, es wird aber auch keine Sprünge geben.
Modran gegenüber bin ich so skeptisch, wie man dem Treibhausgeschreibsel gegenüber nur sein kann.
„————– #160: besso keks sagt:
————–
Immer vorausgesetzt, daß bei einem Bar wirklich was strahlt…
Dazu die Messung http://tinyurl.com/jooc842“
Na ja, „Messungen“ haben wir hier schon genug gesehen. Ich erinnere nur an dien Hamburger Wettermast und das dort verwendete „Messgerät“.
Z.B. AERI:
„The AERI was designed by the University of Wisconsin Space Science and Engineering Center (UW-SSEC) for the Department of Energy (DOE) Atmospheric Radiation Measurement (ARM) program. AERI instruments have been deployed worldwide at ground-based fixed and mobile sites, as well as in marine deployments.“
Hat für mich den Geruch einer Treibhäuslerentwicklung.
Es geht in diesem Bereich nichts über den Helium gekühlten Sensor!
„————– #160: besso keks sagt:
————–
Und alles, wirklich alles, was über diesen 10m in der Atmosphäre an Strahlungsvorgängen passiert ist dem Boden egal.
Nicht ganz, denn ein wesentlicher Teil des Wärmeflusses geschieht über den Strahlungstransport, das bestimmt auch den Temperaturgradienten, der wieder das Abstrahl-Verhalten bestimmt. Also: Selbst wenn man sich auf den reinen Strahlungstransport konzentriert, gibt es noch immer Rückkopplungen.“
Falsch!
Der Strahlungstransport funktioniert erst in größeren Höhen.
Bis dahin gibt es Konvektion.
Das Abstrahlverhalten in großer Höhe (direkt ins All) wird bestimmt von der vorhandenen Energie (Temperatur). Und diese wird zwar auch von Strahlung (aus dem Strahlungstransport), aber in erster Linie von Konvektion bestimmt, da diese der Flaschenhals zwischen Boden und den Höhen ist,
wo Strahlungstransport möglich ist.
„————– #160: besso keks sagt:
—————-
Mit einer Ausnahme: erhöht die steigende CO2-Konzentration die Abstrahlung ins All, verliert das System Energie und der Temperaturgradient in der Atmosphäre steigt.
Auch dieser Vorgang ist ein wenig komplizierter:
Es kann ja nicht mehr Energie abgestrahlt werden, als vorher empfangen wurde. Aber durch die größere Eigen-Absorption verschiebt sich der Abstrahl-Horizont nach oben.“
Selbstverständlich kann mehr abgestrahlt werden als empfangen wird.
Zumindest solange die Eigentemperatur des Erdsystems größer °K ist.
Es gibt ja kein Gesetz, was ein Strahlungsgleichgewicht TOA erzwingt.
Messungen zeigen ja , daß kein Gleichgewicht herrscht und Gerlich/Teuschner haben der Größe der Trägheit des Erdsystems einen eigenen Absatz gewidmet.
Auch das IPCC weist ja von sich aus auf diese Tatsache hin (einer der Dauerlinks von Herrn Dr. Paul)
„————– #160: besso keks sagt:
————–
Das würde die Rückstrahlung des Raumvolumens zum Boden beeinflussen.
Indirekt. Die lapse rate (atmosphärischer Temperaturgradient wird nur unwesentlich beeinflusst, durch die Anhebung des Abstrahl-Horizontes kann man auch die Anhebung der mittleren Bodentemperaturen verstehen.“
Eine Rückstrahlung Richtung Boden ist möglich, solange der Strahlungstransport funktioniert. Folge ist eine angehobene Temperatur in den entsprechenden Höhen verbunden mit einer Reduktion der vertikalen Konvektion.
MfG
Ihre Punkte will ich noch komplettieren.
„2. Innerhalb der Grid cell wird mit jeweils statistischen Variablen gearbeitet. D.h. die jeweiligen Parameter werden über die Zelle gemittelt und damit gerechnet. Die jeweilige kleinräumigen Verhältnisse im physikalischen Kontext werden nicht im Detail verrechnet. Korrekt oder nicht?“
Ich habe Ihnen nun hoffentlich mit #166 so viel erklärt, Daß Sie Ihre Irrtümer erkannt haben. Die Sache ist natürlich noch etwas komplexer aber das bringt Sie jetzt nicht weiter. Sie müssen erstmal die GCMs grundlegend korrekt verstehen und Ihre fehlerhaften Vorstellungen davon revidieren. Die subskaligen Prozesse innerhalb des grids werden tatsächlich berechnet. Der Modelloutput sind ja Zeitreihen für jeden grid-Punkt für jede berechnete physikalische Größe. Man kartiert der Globus mit den grid Ergebnissen. Die Auswirkung der subskalig (im grid Gitter) wirkenden Prozesse auf die physikalischen Zustände in den grid-Punkten werden ja durch die Parametrisierung berechnet.
„3. Eine detaillierte Rechnung über komplexe Systeme sind damit aber grundsätzlich nicht möglich, denn sie liefern keine empirisch prüfbaren Werte. Sie unterscheidet sich damit erheblich von Ihrem vorgetragenen Vergleich, der damit invalide ist.“
Wie gesagt, man testet die Ergebnisse der Parametrisierung natürlich schon mit den Beobachtungen. Man macht ja so auch das tuning, indem man die Parametrisierungsparameter so (im Rahmen physikalisch möglicher Werte natürlich) modifiziert, daß die Beobachtungen im der Einzelprozesse (wie Tröpfchenspektrum etc.) passen. Die Parametrisierung muß natürlich auch ein wenn auch vereinfachtes physikalisches Modell sein und die Beobachtungen erklären. Ein Beispiel ist die bei den Wettervorhersagemodellen benutzte Parametrisierung der Konvektion oder der Wolkeneigenschaften. Die Parametrisierung eines subskaligen Prozesses vergleicht man auch durch Modellierung mitgrößerer Detailtiefe. Man kann also so feststellen, ob die durch die Parametrisierung in Kauf genommene vergröberte Beschreibung des Einzelprozesses im Vergleich zur detaillierten Modellierung auf Basis fundamentalerer Gleichungen akzeptabel ist, wie also die Fehler mit der grid-Größe skalieren. Und damit, ob die beim globalen CM gewählte grid-Größe noch hinreichend genaue Werte liefert.
„Sie unterscheidet sich damit erheblich von Ihrem vorgetragenen Vergleich, der damit invalide ist.“
Nein, das haben Sie wieder mal nicht verstanden.
„Sie vergleichen Äpfel mit Birnen. Die CGMs rechnen auf Basis von sich verändernden Systemen und wollen damit Aussagen über die Realität machen. Sie müssen damit also zu den Beobachtungen der realen Welt passen, wenn sie nicht völlig irrelevante Spielzeug-Daten liefern wollen.“
Was sind hier die Äpfel und was die Birnen? In dem Satz, den Sie hier kommentieren, habe ich Ihnne nur erklärt daß Ihre Vorstellung, daß GCMs die zukünftige Klimaentwicklung durch Extrapolation aus einem Modell fürs gegenwärtige Klima gewinnen, falsch ist. Im Modell wird nichts extrapoliert, man ändert nur die Randbedingungen. Ich erkläre Ihnen dies nochmal mit dem Motormodell a): ein einmal so konstruiertes physikalisches Modell funktioniert auch bei einem Modellmotor, der einen anderen Zylinderdurchmesser hat als der Modellmotor, an dem Sie das Modell validiert haben. Denn es handelt sich ja um ein physikalisches Modell, was ein Abbild der universell gültigen Naturgesetze darstellt. So läuft dies bei GCMs auch, wenn man die Randbedingungen verändert. Die bei den Klimaprojektionen veränderten Randbedingungen wie ein erhöhtes CO2 radiative forcing von z.B. 3 W/m2 ist ja im Vergleich zu dem Bereich des bei der Validierung überstrichenen Strahlungsbereichs von einigen 100 W/m2 durch tägliche und saisonale Variation nur ein kleiner offset.
„die sich natürlich als Extrapolation korrekt bezeichnen lassen.“
Nein, das ist -wie schon erklärt- falsch. Da die Projektionesergebnisse nicht durch Extrapolationen entstehen, ist die Bezeichnung als eine solche falsch und irreführend!
„Ich habe Sie bereits oben aufgefordert, dass sie die Logik nicht in offensichtlich sinnentstellender Weise bemühen sollten. Darum nochmals:“
Nun, wenn Sie mich nicht verstehen, so fragen Sie mich konkret.
„„Ich habe Ihnen doch schon erklärt, daß man das ‚tuning‘ so macht, daß der modellierte Einzelprozeß mit den Beobachtungen des Einzelprozesses gut zusammen passen soll. Man betrachtet das Gesamtsystem dabei nicht. Sie sehen an der Variation der Modellergebnisse untereinander, daß sich Ihre befürchtete „Fragilität“ in Grenzen hält.“
Und ich habe Ihnen gesagt, dass ich ihrer Darstellung nicht folge. Ich behaupte, dass derartig selbstkonsistente Modell ohne Abgleich mit Beobachtungsdaten gar nicht sinnvoll möglich sind.“
Ähm, also oben habe ich explizit geschrieben „daß der modellierte Einzelprozeß mit den Beobachtungen des Einzelprozesses gut zusammen passen soll“. Sie antworten darauf „dass derartig selbstkonsistente Modell ohne Abgleich mit Beobachtungsdaten“. Können Sie nicht lesen, oder verdrehen Sie meine Aussage mit Absicht? Ich habe offensichtlich das Gegenteil dessen geschrieben, was Sie mir unterstellen!!
„Um es deutlich zu sagen: Ich halte Ihre Behauptung, dass genau das nicht geschähe, für rundum gelogen.“
Darf ich von Ihnen jetzt auch nun genau erfahren, was ich erlogen haben sollte? Ich komme bei Ihren Vorstellungen nicht mehr ganz mit. Ich habe geschrieben, daß man beim tuning der Einzelprozesse das Gesamtergebnis des GCMs nicht heranzieht, sondern die Beobachtungen des Einzelprozesses. Ein Beispiel: Sie wollen das Tropfenspektrum einer Kumuluswolke fürs GCM parametrisieren und tunen ein paar Parameter, die dieses Spektrum quantifizieren. Dazu vergleichen Sie natürlich das durch die Parametrisierung modellierte Tropfenspektrum mit Messdaten an realen Kumuluswolken und tunen danach, daß beide möglichst übereinstimmen, aber nicht danach, daß der damit modellierte Klimaverlauf möglichst gut mit der Realität übereinstimmt. Das Modell soll ja ein physikalisches Modell sein und nicht nur das Klima (auf umständliche Art) fitten.
„Die Vergleichbarkeit der Modellergebnisse lassen keinen Schluss zu, dass diese damit eher der Realität entsprechen wenn sie ausdrücklich nicht mit der Realität abgestimmt sind“
Wieder nicht verstanden… Wenn verschiedene Parametrisierungen von Einzelprozessen im Gesamtergebnis konsistente Ergebnisse reproduzieren und zudem (natürlich) auch noch die Beobachtungen. Sie sehen doch, daß die Modelle insgesamt den Klimaverlauf konsistent reproduzieren. Die Abweichungen von Modell und Beobachtungen in Form von „Hiatusse“ sind ja klein im Vergleich zur reproduzieren Verlauf. Also können bei einem solch komplexen System die Modelle nicht so schlecht sein, wenn Sie aus beobachteten Randbedingungen das beobachtete Klima mit einer gewissen Genauigkeit reproduzieren, so sollte sie auch davon leicht abweichende Randbedingungen das zugehörige Klima mit vergleichbarer Genauigkeit berechnen können.
„- sondern das man gemeinsamen Grundannahmen folgt, die beliebig falsch sein können.“
Nun gemeinsame Grundannahme ist die allgemein bekannte Physik rein? Bei der Parametrisierung derselben gibt es „Gestaltungsspielraum“, aber die Modelle der Parametriserung werden ja auch an den Beobachtungen der damit beschrieben Einzelprozesse getestet.
„Eine Kombination mehrer, jeweils für sich stehender ‚korrekter‘ Wörter ergibt damit keinen notwendig zutreffenden Satz.“
Ja, aber genau das trifft ja bei den GCM zu. Im GCM wirken die Einzelprozesse zusammen und das Gesamtergebnis reproduziert nach das beobachtete Klima.
„Meine Kritik war ja auch, dass bei diversen Einzelprozessen, z.B. der Wolkenbildung, noch keine hinreichend genaue Bestimmung möglich ist, um zuverlässige Vorhersagen treffen zu können.“
Nun, aber Ihre Kritik ist substanzlos. Grundsätzlich funktioniert das doch auch bei der Wettervorhersage. Was meinen Sie dazu?
„Ich habe zur Kenntnis genommen, dass die globale Wolkenbedeckung schwankt, aber bislang von keiner hinreichenden Modellierung gehört, die diese erklärt.“
Was meinen Sie konkret, zeitlich oder räumlich? Ich habe nicht gehört, das die Wolkenbedeckung in den Beobachtungen zeitlich stärker schwankt als modelliert wird.
„und das sie dem vorher vehement widersprachen: Ein Abgleich mit der Realität.“
Sie haben mich da nicht verstanden. Ich hoffe Sie kapieren es mit dem oben gesagten jetzt besser.
„Ihre vorgeschlagenes Kriterium ist – so weit ich es erkennen kann – die Ähnlichkeit von Modellen, denen Sie eine hinreichende Unabhängigkeit unterstellen.“
Das haben Sie – wie gesagt – völlig falsch „erkannt“. Ihre Schlußfolgerung ist somit falsch.
„Für Teilmodelle wie MODTRAN kann man dies bestätigen, aber die Bedeutung dieser Herleitung in CGMs bleibt gewagt. Hier werden nicht konkrete Situationen, sondern gemittelte Szenarien auf grid cell-Ebene berechnet, die auf nicht transparenten Durchschnitten aufbauen können.“
Verstehen Sie unter der konkreten Situation die molekulare Ebene? Dies ist die kleinste Größe einer „grid cell“. Doch dies ist nicht notwendig. Druck und Temperatur sind auch makroskopische Mittelwerte, die man messen kann. Die Navier-Stokes-Gleichung bezieht sich auf makroskopische Größen. Die Wetter-Vorhersage-Modelle bauen auf dieser Gleichung auf. Man sollte vielleicht erst die Grenzen dieser Modelle diskutieren um die Leistungsfähigkeit von Klimamodellen abschätzen zu können.
„Ich nehme zur Kenntnis, dass sie meine Argumente zur Kritik am CGM ansatz missachten und in ihren Argumenten ignorieren. Was also sei die Realität?“
Ich korrigiere eigentlich Ihre Fehler. Wenn ich zu Ihren richtigen Aussagen nichts schreibe, so heißt das nicht, daß ich sie ignoriere.
„1. Trifft es zu, das CGMs mit Grid-Sizes von meist mehr als 100 km Kantenlänge arbeiten oder nicht? Nach meinen Recherchen ist das so.“
Stimmt etwa für die globalen GCMs. Für regionale Klimamodelle geringer.
„2. Innerhalb der Grid cell wird mit jeweils statistischen Variablen gearbeitet. D.h. die jeweiligen Parameter werden über die Zelle gemittelt und damit gerechnet.“
Ja und Nein. Das hängt von der physikalischen Größe ab. Größen wie Temperatur, Windvektor, Luftdruck, Vorticity, Dampfdruck, Bodentemperaturen, Strahlungs- und sonst. Energieflüsse etc. und davon abgeleitete Felder werden ja für jeden grid-Punkt dynamisch aus den Parametern des gesamten grids und den im grid definierten externen Randbedingungen nach den Differentialgleichungen berechnet. Wie schon unzählige Male erklärt berechnet ein physikalisches Modell (wie das „Motormodell“ nach a) oder die GCMs) diese Parameter numerisch aus dem Differentialgleichungssystem der entsprechenden fundamentalen physikalischen Gesetzen in jedem grid-Punkt. Die Lufttemperatur z.B. aus dem 1. HS der Thermodynamik oder davon abgeleiteten Gleichungen, der Wind oder die Meeresströmungen aus den Navier-Stokes-Gleichungen der Hydrodynamik, die Bodentemperaturen aus der Wärmeleitungsgleichung etc.
Parametrisiert werden nun komplexe Größen wie Wolkenbedeckungsgrad – und art, Niederschlagsmenge- und Art, Albedo, Vegetationsindizes, chemische Zusammensetzung, Austausch, Reibungstensoren, etc.. Deren Berechnung aus den fundamentalen Gleichungen der Physik ist zu kompliziert wäre. Daher greift man dafür auf separat getestete quantitative Zusammenhänge zurück. Z.B. die Beschreibung turbulenter Prozesse bei der Konvektion durch Austausch, Berechnung von Vegetationsindizes durch Multiregressionen mit anderen Parametern etc. Diese Parametrisierungen werden natürlich mit Realdaten getestet. Die heutigen Beobachtungsdaten überdecken durch räumliche und zeitliche Variation des Wetters und Klimas einen Raum, der die Zustände in einem veränderten Klimas auch abdeckt.
„Die jeweilige kleinräumigen Verhältnisse im physikalischen Kontext werden nicht im Detail verrechnet. Korrekt oder nicht?„
Die nötige Tiefe der Detailrechnung kann man ja anhand der Beobachtungen testen.
„3. Eine detaillierte Rechnung über komplexe Systeme sind damit aber grundsätzlich nicht möglich, denn sie liefern keine empirisch prüfbaren Werte. Sie unterscheidet sich damit erheblich von Ihrem vorgetragenen Vergleich, der damit invalide ist.“
Braucht man ja auch nicht. Klar ist ja, daß das physikalische Klimamodell nur das Klima und nicht das Wetter in jedem grid-Punkt modellieren soll. Wie das „Motormodell“ a) kann man bei einem GCM dann, wenn das Modell auf physikalischer Basis arbeitet, auch „Experimente“ machen für Randbedingungen außerhalb des Validierungsraumes. Mich stört an Ihren Argumenten, daß Sie ohne inhaltlichen physikalischen Grund solche Anwendungen als nicht „aussagekräftig“ einstufen. Eine solche Beurteilung ist nur quantitativ diskutierbar – nicht pauschal mit blumigen Firlefax !
Im übrigen sind GCM deduktiv. Das deduktiv bezieht sich auf die Durchführungsmethode (nämlich deduktiv aus den physikalischen Grundgesetzen zu Ergebnissen in Form eines Modell fürs Klima zu kommen im Gegensatz zur induktiven Methode, bei der nach nur aus Beobachtungen ein Modell entwickelt) und nicht ob Sie das nachvollziehen können oder nicht!
Lieber Herr Berberich, #162
„Sehr geehrte Herren Landvoigt und NicoBaecker,
ich verfolge Ihre Diskussion schon seit einiger Zeit mit Interesse. Ich befürchte, dass im Augenblick die Diskussion zu keinem konstruktivem Ergebnis führt. Man sollte sich zunächst auf einen Grund-Konsens einigen:“
Ganz richtig!
So wie ich ihn verstehe, bezweifelt Herr Landvoigt aber bereits Punkt (2), weil der die eine falsche Vorstellung davon hat, wie dem Klimamodellieren „Gesetzmäßigkeiten durch Abstraktion experimenteller Ergebnisse“ abgeleitet werden.
Sie haben recht, eine mittlere freie Wegstrecke von 16m ist was anderes als 99,4% Absorption nach 10m.
—————
Sehr geehrter Herr Keks
Ich bin mir nicht ganz im klaren, was hier mit mittlere freie Wegstrecke gemeint ist. Wenn gilt: ‚Die mittlere freie Weglänge \lambda ist die durchschnittliche Weglänge, die ein Teilchen (z. B. Atom, Molekül, Ion oder Elektron) in einem gegebenen Material ohne Stoß (irgendeiner Art) mit anderen Teilchen zurücklegt.‘
Dann ist die Berechnung von Herrn Holtz irrtümlich, denn er rechnet von 400 ppm. Ein Stoß aber erfolgt mit sehr viel höherer Wahrscheinlichkeit mit eine N2 oder O2 Molekül im mm oder cm Bereich.
Herr Hug errechnete dagegen die Absorption. Die auch einen Rahmen für die Emission ergibt.
—————- #160: besso keks sagt:
————–
Ich halte diesen Unterschied aber für die genannte Aufgabe aber nicht für so entscheidend:
Hug sagt ja, daß es in der bodennahen Atmosphäre praktisch keinen Strahlungstransport gibt.
Das eben nicht! Eine hohe Extimktion im 15 Mm Band heißt eben nur, dass es keine Transmission von der originalen Quelle direkt durch die schicht gibt. Davon bleibt unberücksichtigt, dass es sowohl Absorption als auch Emission gibt. Auf diesem Wege bildet sich ein Gradient in der Schicht aus, die allerdings einen Strahlungstransport entspricht.
————– #160: besso keks sagt:
————–
Also verbleibt als Quelle für die ominöse Gegenstrahlung nur die Eigenstrahlung des Raumvolumens über dem Boden.
Ominös nur, weil Sie auf das falsche Pferd gesetzt sind.
————– #160: besso keks sagt:
————–
Rechnet man nun mit Hug, ist eine angenommene Schichtdicke von 10m mehr als ausreichend genau.
Für die vereinfachte Fragestellung ja. Allerdings ist noch immer nicht trivial, die Strahlungsleistung aus dem Volumen zu berechnen. Modtran bleibt eine gute Wahl.
————– #160: besso keks sagt:
—————–
Also lautet nun die Aufgabe:
Welche Strahlungsleistung (W/qm) gibt das Raumvolumen von 10m Schichtdicke an den Boden ab.
R.B: 15°C, 400ppm.
Immer noch der Wert aus Modtran als Differenz zwischen 0 ppm und 400 ppm in der tropischen Atmosphäre ohne Wolken und Regen über alle Bänder des CO2: 7.22 W/m2
————– #160: besso keks sagt:
————-
Das müßte doch unabhängig von irgendwelchen Tabellenwerten und Systembetrachtungen möglich sein. Oder nicht?
Man kann zwar ausrechnen, wie sehr das CO2 bei einer gegebenen Temperatur und Dichte strahlt, aber es findet zugleich auch immer eine wieder-Absorption aus dem Volumen heraus statt. Darum ist es nicht so einfach.
————– #160: besso keks sagt:
————–
Die selbe Rechnung kann dann angestellt werden mit 800ppm und entsprechend korrigierter Absorptionslänge. Oder nicht?
Mit Modtran ist das Ergebnis der Differenz zwischen 400 ppm und 800 ppm 1.57 W/m2
Merke: Es gibt keinen linearen Zusammenhang zwischen CO2 und Strahlung.
————– #160: besso keks sagt:
—————
Die Höhe des Treibhauseffektes wäre dann der Unterschied zwischen den beiden Werten (die sich gefühlt kaum unterscheiden werden, da das relevante Strahlungsvolumen mit steigender Konzentration von CO2 geringer wird)
Die Transmissivität sinkt mit steigender Konzentration, aber die Rückstrahlung steigt – leicht – an.
Der sogenannte Treibhaus-Effekt bezieht sich aber nicht rein auf die Oberfläche, sondern die bodennahe Lufttemperatur. Und die kühlt darum wesentlich weniger stark ab.
————– #160: besso keks sagt:
————–
Immer vorausgesetzt, daß bei einem Bar wirklich was strahlt…
Dazu die Messung http://tinyurl.com/jooc842
————– #160: besso keks sagt:
————–
Und alles, wirklich alles, was über diesen 10m in der Atmosphäre an Strahlungsvorgängen passiert ist dem Boden egal.
Nicht ganz, denn ein wesentlicher Teil des Wärmeflusses geschieht über den Strahlungstransport, das bestimmt auch den Temperaturgradienten, der wieder das Abstrahl-Verhalten bestimmt. Also: Selbst wenn man sich auf den reinen Strahlungstransport konzentriert, gibt es noch immer Rückkopplungen.
————– #160: besso keks sagt:
—————-
Mit einer Ausnahme: erhöht die steigende CO2-Konzentration die Abstrahlung ins All, verliert das System Energie und der Temperaturgradient in der Atmosphäre steigt.
Auch dieser Vorgang ist ein wenig komplizierter:
Es kann ja nicht mehr Energie abgestrahlt werden, als vorher empfangen wurde. Aber durch die größere Eigen-Absorption verschiebt sich der Abstrahl-Horizont nach oben.
————– #160: besso keks sagt:
————–
Das würde die Rückstrahlung des Raumvolumens zum Boden beeinflussen.
Indirekt. Die lapse rate (atmosphärischer Temperaturgradient wird nur unwesentlich beeinflusst, durch die Anhebung des Abstrahl-Horizontes kann man auch die Anhebung der mittleren Bodentemperaturen verstehen.
„ich möchte klar stellen, dass sich diese Folgerungen auf meine Auswertungen mit MODTRAN bezogen. Ich möchte Ihnen noch ein Auswertungsergebnis vorstellen. Modell-Version:
http://climatemodels.uchicago.edu/modtran/
Standard-Parameter, Altitude 0 km, tropical atmosphere, IR heat flux (W/m^2)
; Upward; Downward; Net
No clouds or rain; 417; 348; 69″
Lieber Herr Berberich,
das tztztztztz bezog sich auf das Fehlen des Strahlungstransportes un den unteren Schichten.
Das ist ja im Wesentlichen das, worauf Herr Dr. Paul nicht müde wird hinzuweisen.
Wenn wir also annehmen, Strahlungstransport gibt es gegen den Boden nicht, verbleibt lediglich die thermische Eigenstrahlung (sofern wir wenigstens daran glauben) der atmosphärischen Schicht innerhalb der Absorptionslänge über dem Boden.
Die Absorptionslängen sind je nach IR-aktivem Träger unterschiedlich lang,
bei CO2 c.a. 10m.
Ich werde NIE im Leben glauben, daß diese erste Schicht GAS im Fall ohne Bewölkung 348W/qm aus thermischer Eigenstrahlung zu Boden strahlt. Das ist fast der Bodenabstrahlwert („Schwarzkörper!!!) im Modell.
Darüber hinaus möchte ich wissen, wie hoch der Anteil der 400ppm CO2 daran sein soll.
Denn darum geht es eigentlich ja nur.
mfG
ich verfolge Ihre Diskussion schon seit einiger Zeit mit Interesse. Ich befürchte, dass im Augenblick die Diskussion zu keinem konstruktivem Ergebnis führt.
——————
Sehr geehrter Herr Berberich
Danke für ihr Interesse. Ich gehe auch nicht davon aus, dass wir zu einem Konsens kommen können, aber das liegt in der Natur der Sache: Ohne hinreichende Überprüfbarkeit bleiben diese Modelle fragwürdig.
Für mich ist es aber durchaus ein konstruktives Ergebnis, wenn man die Kritikpunkte formuliert und zur kritischen Prüfung einstellt.
————– #162: P. Berberich sagt:
——————
Man sollte sich zunächst auf einen Grund-Konsens einigen:
(1) Klima-Modelle sind notwendig und nützlich.
Dem würde ich nur in bedingter Form zustimmen:
Modelle sind in der Physik, auch Atmosphärenphysik unverzichtbar. Das schleißt jedoch nicht ein, dass jeder Modellansatz auch notwendig und richtig ist. Im Besonderen erscheint mir der gesamte CGM Ansatz weder notwendig noch nützlich zu sein, denn die Freiheitsgrade durch Unwissen und extreme Modellkomplexität, bei fehlender Prüfbarkeit liefert eher Aussagen, die eine falsche Sicherheit vorspiegelt.
————– #162: P. Berberich sagt:
————–
(2) Die Modelle basieren auf den Gesetzmäßgkeiten der Naturwissenschaften, die auf der Abstraktion experimenteller Ergebnisse beruhen.
Für Teilmodelle wie MODTRAN kann man dies bestätigen, aber die Bedeutung dieser Herleitung in CGMs bleibt gewagt. Hier werden nicht konkrete Situationen, sondern gemittelte Szenarien auf grid cell-Ebene berechnet, die auf nicht transparenten Durchschnitten aufbauen können.
————– #162: P. Berberich sagt:
————–
————–
—————-
(3) Ein Modell muss nachvollziehbar sein
Ja !
————– #162: P. Berberich sagt:
(4) Ein Modell muss überprüfbar sein.
Ja !
————– #162: P. Berberich sagt:
Die Kritik an den GCM-Modellen lässt sich hauptsächlich in den Punkten (3) und (4) einordnen. Mein Vorschlag wäre: die GCM-Modellierer konzentrieren sich mehr auf die Beschreibung zeitnaher Ereignisse wie das El-Nino-Phänomen, Smog, das Auftreten von Dürre-Perioden, usw.
Das verkennt allerdings den Charakter der CGMs, die gar keine Wettervorhersagen sein wollen, sondern die abstrakte Größe Klimawandel im Groben vorhersagen will. Aber auch her ist der Tod im Topf, denn nicht alle Einflüsse sind qualitativ und quantitativ hinreichend bekannt. Eine Modell-Abbildung bleibt damit auch im Best-Case beliebig ungenau, da die Anzahl der Variablen den Lösungsraum übersteigt. Es ist zwar kein lineares Gleichungssystem, aber es ist vergleichbar, als wollte man eine Lösung aus N Gleichungen suchen die aber N + X Variablen bestimmen soll.
Sehr geehrte Herren Landvoigt und NicoBaecker,
ich verfolge Ihre Diskussion schon seit einiger Zeit mit Interesse. Ich befürchte, dass im Augenblick die Diskussion zu keinem konstruktivem Ergebnis führt. Man sollte sich zunächst auf einen Grund-Konsens einigen:
(1) Klima-Modelle sind notwendig und nützlich.
(2) Die Modelle basieren auf den Gesetzmäßgkeiten der Naturwissenschaften, die auf der Abstraktion experimenteller Ergebnisse beruhen.
(3) Ein Modell muss nachvollziehbar sein
(4) Ein Modell muss überprüfbar sein.
Die Kritik an den GCM-Modellen lässt sich hauptsächlich in den Punkten (3) und (4) einordnen. Mein Vorschlag wäre: die GCM-Modellierer konzentrieren sich mehr auf die Beschreibung zeitnaher Ereignisse wie das El-Nino-Phänomen, Smog, das Auftreten von Dürre-Perioden, usw.
„tz,tz,tz,…“
Sehr geehrter Herr Keks,
ich möchte klar stellen, dass sich diese Folgerungen auf meine Auswertungen mit MODTRAN bezogen. Ich möchte Ihnen noch ein Auswertungsergebnis vorstellen. Modell-Version:
http://climatemodels.uchicago.edu/modtran/
Standard-Parameter, Altitude 0 km, tropical atmosphere, IR heat flux (W/m^2)
; Upward; Downward; Net
No clouds or rain; 417; 348; 69
Cumulus cloud base; 417; 418; -1
Altostratus; 417; 404; 13
Stratus cloud base; 417; 420; -3
Nimbo stratus; 417; 424; -7
5 mm/hr light rain; 417; 423; -6
Standard Cirrus model; 417; 350; 67
LOWTRAN 6 model; 417; 350; 67
Man sieht, dass der Netto- IR- Fluss bei Bewölkung in den meisten Fällen negativ ist (Ausnahme Altostratus)
„————- #156: besso keks sagt:
————-
Als einzige Eingangsgröße reichen das Strahlungsvolumen, die Temperatur (15°C) und die Konzentration des CO2 (400ppm).
Ich meine, man sollte es sich so einfach wie möglich machen, nur nicht einfacher. Das atmosphärische System, und darin der Strahlungstransport, ist physikalisch eine recht komplexe Angelegenheit. ich wüsste nicht, wie sie das einfacher als mit MODTRAN rechnen könnten.
————- #156: besso keks sagt:
————-
Die mittlere freie Weglänge ist 16m.
Ich habe gelesen, was #103: Werner Holtz sagte und wie Sie das in #119 interpretierten. Ich habe darauf hin erklärt, dass ich mit dieser Aussage nicht viel anfangen kann, denn diese Darstellung passt nicht zu diesen Ergebnissen: Heinz Hug hat dies experimentell bestimmt und vorgerechnet in: http://tinyurl.com/jbvlkl2“
Sehr geehrter Herr Landvoigt,
Sie haben recht, eine mittlere freie Wegstrecke von 16m ist was anderes als 99,4% Absorption nach 10m.
Ich halte diesen Unterschied aber für die genannte Aufgabe aber nicht für so entscheidend:
Hug sagt ja, daß es in der bodennahen Atmosphäre praktisch keinen Strahlungstransport gibt. Also verbleibt als Quelle für die ominöse Gegenstrahlung nur die Eigenstrahlung des Raumvolumens über dem Boden.
Rechnet man nun mit Hug, ist eine angenommene Schichtdicke von 10m mehr als ausreichend genau.
Also lautet nun die Aufgabe:
Welche Strahlungsleistung (W/qm) gibt das Raumvolumen von 10m Schichtdicke an den Boden ab.
R.B: 15°C, 400ppm.
Das müßte doch unabhängig von irgendwelchen Tabellenwerten und Systembetrachtungen möglich sein. Oder nicht?
Die selbe Rechnung kann dann angestellt werden mit 800ppm und entsprechend korrigierter Absorptionslänge. Oder nicht?
Die Höhe des Treibhauseffektes wäre dann der Unterschied zwischen den beiden Werten (die sich gefühlt kaum unterscheiden werden, da das relevante Strahlungsvolumen mit steigender Konzentration von CO2 geringer wird)
Immer vorausgesetzt, daß bei einem Bar wirklich was strahlt…
Und alles, wirklich alles, was über diesen 10m in der Atmosphäre an Strahlungsvorgängen passiert ist dem Boden egal.
Mit einer Ausnahme: erhöht die steigende CO2-Konzentration die Abstrahlung ins All, verliert das System Energie und der Temperaturgradient in der Atmosphäre steigt.
Das würde die Rückstrahlung des Raumvolumens zum Boden beeinflussen.
Also?
MfG
Nun behaupten Sie weiterhin, GCM‘s würden nicht wie der Fall a) der physikalischen Modelle arbeiten und die Zeitentwicklung der (im Falle der GCMs) Atmosphäre und des Ozeans bzw. (im Falle des Motors) auf Basis der grundlegenden Differentialgleichungen für die Fluide berechnen. Das ist aber einfach falsch! Korrigieren Sie also Ihre Auffassung und halten Sie sich an die Realität.
Sehr geehrter Herr Baecker,
Ich nehme zur Kenntnis, dass sie meine Argumente zur Kritik am CGM ansatz missachten und in ihren Argumenten ignorieren. Was also sei die Realität?
1. Trifft es zu, das CGMs mit Grid-Sizes von meist mehr als 100 km Kantenlänge arbeiten oder nicht? Nach meinen Recherchen ist das so.
2. Innerhalb der Grid cell wird mit jeweils statistischen Variablen gearbeitet. D.h. die jeweiligen Parameter werden über die Zelle gemittelt und damit gerechnet. Die jeweilige kleinräumigen Verhältnisse im physikalischen Kontext werden nicht im Detail verrechnet. Korrekt oder nicht?
3. Eine detaillierte Rechnung über komplexe Systeme sind damit aber grundsätzlich nicht möglich, denn sie liefern keine empirisch prüfbaren Werte. Sie unterscheidet sich damit erheblich von Ihrem vorgetragenen Vergleich, der damit invalide ist.
Diese These trug ich vor und ich sehe hier außer einer pauschalen Behauptung der Falschheit kein Argument.
———— #157: NicoBaecker sagt:
————
Also zum x-ten Male: GCMs gewinnen die Klimaentwicklung der Zukunft nicht aus Extrapolationen, sondern aus dem mit dem GCM berechneten Modellwetter, welches sich zu dem Zeitpunkt ergibt. Für den Zeitpunkt ist völlig egal, ob er in der realen Zukunft oder Vergangenheit liegt.
Sie vergleichen Äpfel mit Birnen. Die CGMs rechnen auf Basis von sich verändernden Systemen und wollen damit Aussagen über die Realität machen. Sie müssen damit also zu den Beobachtungen der realen Welt passen, wenn sie nicht völlig irrelevante Spielzeug-Daten liefern wollen. Damit Extrapolieren sie in diesem Modellansatz auch die Realität und liefern Projektionen in die Zukunft – also modellierte funktionale Beziehungen die sich einer empirischen Überprüfung verwehren. Das es sich darin nicht um eine lineare Extrapolation im trivialen Sinn handelt ist völlig klar, aber es schreibt diverse Szenarien über Entwicklungen fort, die sich natürlich als Extrapolation korrekt bezeichnen lassen.
Ihre Kritik basiert auf völlig falschen Annahmen.
———— #157: NicoBaecker sagt:
————
Daher ist Ihre Schlußfolgerung unlogisch!
Ich habe Sie bereits oben aufgefordert, dass sie die Logik nicht in offensichtlich sinnentstellender Weise bemühen sollten. Darum nochmals:
1. Was glauben Sie, als eine Schlussfolgerung meinerseits erkennt zu haben? Ich vermute, dass sie wirre Annahmen mit meinem Text verwechseln.
2. Um einen Fehler der Logik zu behaupten, benötigen sie das Aufzeigen eines Widerspruchs. Das fehlt hier völlig.
3. Aus dem Fehlen einer Herleitung begründet sich: ‚Non Sequitur‘ !
———— #157: NicoBaecker sagt:
————
Also, daß Sie das ‚tuning‘ beim Parametrisieren als ‚intelligent guessing‘ bezeichnen ist wirklich eine gelungene Kombination aus Arroganz und bodenloser Unwissenheit. Ich habe Ihnen doch schon erklärt, daß man das ‚tuning‘ so macht, daß der modellierte Einzelprozeß mit den Beobachtungen des Einzelprozesses gut zusammen passen soll. Man betrachtet das Gesamtsystem dabei nicht. Sie sehen an der Variation der Modellergebnisse untereinander, daß sich Ihre befürchtete „Fragilität“ in Grenzen hält.
Und ich habe Ihnen gesagt, dass ich ihrer Darstellung nicht folge. Ich behaupte, dass derartig selbstkonsistente Modell ohne Abgleich mit Beobachtungsdaten gar nicht sinnvoll möglich sind.
Um es deutlich zu sagen: Ich halte Ihre Behauptung, dass genau das nicht geschähe, für rundum gelogen.
Die Vergleichbarkeit der Modellergebnisse lassen keinen Schluss zu, dass diese damit eher der Realität entsprechen – wenn sie ausdrücklich nicht mit der Realität abgestimmt sind – sondern das man gemeinsamen Grundannahmen folgt, die beliebig falsch sein können.
———— #157: NicoBaecker sagt:
————
Ein GCM ist offensichtlich per Konstruktion deduktiv, siehe Fall a). Lernen Sie das!
Was soll denn das? Wollen sie damit dokumentieren, dass sie über profunde Defizite in der Lesekompetenz verfügen?
Ich habe mit dem Verweis auf mangelnde empirische Überprüfbarkeit erklärt, dass hier keine methodisch klare Deduktion vorliegt.
Sie haben auf meine Darstellung, dass man nicht mehr von konkreten physikalischen und prüfbaren Vorgängen ausgeht, sondern eine virtuelle und unüberprüfbare Modellwelt verwendet, kein Argument vorgetragen. Eine Deduktion ist aber der Schluss von der Theorie auf die Empirie. Dies ist damit nicht gegeben.
———— #157: NicoBaecker sagt:
————
Aber die Überprüfung, ob die Parametrisierung eines Einzelprozesses auch diesen Einzelprozeß an sich hinreichend genau beschreibt, ist ein wesentliches Element bei der Modellentwicklung!
Notwendig, aber nicht hinreichend. Denn das Wesentliche komplexer Modelle ist ja das Postulieren eines zutreffenden Zusammenhanges der Einzelprozesse. Eine Kombination mehrer, jeweils für sich stehender ‚korrekter‘ Wörter ergibt damit keinen notwendig zutreffenden Satz.
Meine Kritik war ja auch, dass bei diversen Einzelprozessen, z.B. der Wolkenbildung, noch keine hinreichend genaue Bestimmung möglich ist, um zuverlässige Vorhersagen treffen zu können.
Ich habe zur Kenntnis genommen, dass die globale Wolkenbedeckung schwankt, aber bislang von keiner hinreichenden Modellierung gehört, die diese erklärt. Ansätze wie die von Svensmark sind empirische noch nicht hinreichend erwiesen oder widerlegt.
———— #157: NicoBaecker sagt:
————
Sie glauben wohl, daß man das Modell nur auf globalen output trimmt und auf den einzelnen grid-Punkten unrealistischen output zuließe.
Ihre falsche Inferenz widerspricht ihrem eigenen Argument. Denn wenn man keinen unrealistischen output zulässt, muss es offensichtlich Regeln oder Verfahren geben, die diese Art Fehler erkennt. Damit nähern wir uns aber hinsichtlich des Modell-Tunings genau meiner Darstellung, dass eben jenes verhindert wird – und das sie dem vorher vehement widersprachen: Ein Abgleich mit der Realität.
———— #157: NicoBaecker sagt:
————–
Das ist falsch, gucken Sie sich die Ergebnisse der Modelle doch im Detail an! Die Fehler im einzelnen grid sind zwar größer aber völlig absurde Ergebnisse kommen da nicht raus.
Abgesehen davon, dass sie sich selbst widersprechen, folgt aus dem Fehlen von großen Differenzen zwischen Realität und Modell noch nicht zwingend. Folgende Erklärungen könnten dafür zutreffen:
1. Das Modell entspricht hinreichend der Realität (Ihre These bleibt möglich)
2. Das Modell entspricht beliebig nicht der Realität, wird aber durch Tuning so getrimmt, dass erkennbare Unplausibilitäten unterbleiben, bzw. in einem tolerierbarem Maß bleiben.
Welche der beiden Thesen zutrifft, müsste eine Qualitätsprüfung zeigen. Ihre vorgeschlagenes Kriterium ist – so weit ich es erkennen kann – die Ähnlichkeit von Modellen, denen Sie eine hinreichende Unabhängigkeit unterstellen. Das aber ist kein logisch zutreffendes Argument.
Differenzbetrachtungen aus dubiosen Quellen meinte ich nicht …
—————–
Sehr geehrter Herr Keks
Damit wollen Sie wohl sagen, das MODTRAN eine dubiosen Quelle sei. Wie das? Grundlos eine Quelle als dubios zu bezeichnen, weckt in mir den Verdacht, das man die Quelle darum ablehnt, weil man eben die Ergebnisse nicht mag. Das wäre vor mich kein zulässiger Grund.
————- #156: besso keks sagt:
————-
Als einzige Eingangsgröße reichen das Strahlungsvolumen, die Temperatur (15°C) und die Konzentration des CO2 (400ppm).
Ich meine, man sollte es sich so einfach wie möglich machen, nur nicht einfacher. Das atmosphärische System, und darin der Strahlungstransport, ist physikalisch eine recht komplexe Angelegenheit. ich wüsste nicht, wie sie das einfacher als mit MODTRAN rechnen könnten.
————- #156: besso keks sagt:
————-
Die mittlere freie Weglänge ist 16m.
Ich habe gelesen, was #103: Werner Holtz sagte und wie Sie das in #119 interpretierten. Ich habe darauf hin erklärt, dass ich mit dieser Aussage nicht viel anfangen kann, denn diese Darstellung passt nicht zu diesen Ergebnissen: Heinz Hug hat dies experimentell bestimmt und vorgerechnet in: http://tinyurl.com/jbvlkl2
Wie sollte nun ihrer Meinung nach gerechnet werden?
————- #156: besso keks sagt:
————-
Welche Strahlungsleistung (W/qm)wird aus diesem Volumen an den Boden übertragen?
Ich bleibe bei dem Ergebnis aus Modtran: 7.22 W/m2 am Beispiel der tropischen Atmosphäre. Ich wüsste keinen Grund, warum das nicht zuträfe.
Naja, mit Ihren fehlerhaften Vorstellungen über GCMs kommen Sie hier nicht weiter. Sie müssen sich mit dem Gegenstand, über den Sie urteilen wollen, schon beschäftigen. Ich habe Ihnen durch einen Vergleich mit dem „Motormodell“ erklären wollen, was GCMs machen. Nun behaupten Sie weiterhin, GCM‘s würden nicht wie der Fall a) der physikalischen Modelle arbeiten und die Zeitentwicklung der (im Falle der GCMs) Atmosphäre und des Ozeans bzw. (im Falle des Motors) auf Basis der grundlegenden Differentialgleichungen für die Fluide berechnen. Das ist aber einfach falsch! Korrigieren Sie also Ihre Auffassung und halten Sie sich an die Realität.
Und dann behaupten Sie immer noch (trotzdem ich auch hier schon mehrmals erklärt, daß dies falsch ist!):
„Der indikator, dass man dies im Nahbereich von wenigen zehntel Grad – Mittels System-tuning -leistet, ist noch kein sicheres Kriterium, dass weitere Extrapolationen verlässliche Werte liefern.“
Also zum x-ten Male: GCMs gewinnen die Klimaentwicklung der Zukunft nicht aus Extrapolationen, sondern aus dem mit dem GCM berechneten Modellwetter, welches sich zu dem Zeitpunkt ergibt. Für den Zeitpunkt ist völlig egal, ob er in der realen Zukunft oder Vergangenheit liegt. Daher ist Ihre Schlußfolgerung unlogisch!
Dann behaupten Sie noch:
„Genau das ist mein Punkt: es liegt ein um Dimensionen zu großes Unwissen vor, wenn es um eine Vielzahl von Parametern geht. Das Tuning ist dann ein mehr oder minder ‚intelligent guessing‘ dass aber angesichts der Gesamtkomlexität zu einem fragilen Kartenhaus wird, sprich eine virtuelle Modellierungswelt, die kein ermittelbaren Bezug zur Wirklichkeit mehr aufweist.
Also, daß Sie das ‚tuning‘ beim Parametrisieren als ‚intelligent guessing‘ bezeichnen ist wirklich eine gelungene Kombination aus Arroganz und bodenloser Unwissenheit. Ich habe Ihnen doch schon erklärt, daß man das ‚tuning‘ so macht, daß der modellierte Einzelprozeß mit den Beobachtungen des Einzelprozesses gut zusammen passen soll. Man betrachtet das Gesamtsystem dabei nicht. Sie sehen an der Variation der Modellergebnisse untereinander, daß sich Ihre befürchtete „Fragilität“ in Grenzen hält.
„während ich den Punkt mit Nachdruck vertrete, dass bei hoher Systemkomplexität und chaotischem verhalten die deduzierende Methode wesentlich erfolgversprechender, und damit ‚wissenschaftlicher‘ ist.“
Ein GCM ist offensichtlich per Konstruktion deduktiv, siehe Fall a). Lernen Sie das!
„Eine empirische Überprüfbarkeit ist damit weitgehend ausgeschlossen.“
Das postulieren Sie. Aber die Überprüfung, ob die Parametrisierung eines Einzelprozesses auch diesen Einzelprozeß an sich hinreichend genau beschreibt, ist ein wesentliches Element bei der Modellentwicklung! Sie glauben wohl, daß man das Modell nur auf globalen output trimmt und auf den einzelnen grid-Punkten unrealistischen output zuließe. Das ist falsch, gucken Sie sich die Ergebnisse der Modelle doch im Detail an! Die Fehler im einzelnen grid sind zwar größer aber völlig absurde Ergebnisse kommen da nicht raus.
„—————- #119: besso keks sagt:
—————-
Können Sie die resultierende, am Boden ankommende Strahlungsleistung in W/qm mir bzw. uns mal bitte vorrechnen?
Die Rechnung ist ein wenig komplizierter, da sehr viele wechselwirkung zwischen Absorption und Emission statt findet, und dies Frequenzspezisch jeweils neu zu berechnen ist. Dafür gibt es entsprechende Modelle wie MODTRAN http://tinyurl.com/pg3bd8p
Man kann zwe vesrchiedene Szenarien miteinander vergleichen. Das Standard-Szenario in den Tropen geht von 400 ppm CO2 aus. Man kann dann die Höhe auf 0 km setzen und ‚Looking up‘ wählen. Dies kann man sich dann mit Button ‚Save This Run to Background‘ merken.
Für den zweiten Lauf rechenen wir mal mit 0 ppm CO2, aber sonst gleichen Einstellungen – Ergebnis:
Downward IR Heat Flux 340.69 W/m2
IR Heat Loss (Background) 347.91 W/m2
… Difference, New – BG -7.22 W/m2
Die direkte Gegenstrahlung auf die Oberfläche ist allerdings nur ein relativ kleiner Anteil
Wenn man diese Unterscheide an der Tropopause ( angesetzt mit 18 km Höhe ) vergleicht, kommt man zu einer entsprechend größeren Differenz:
Upward IR Heat Flux 324.676 W/m2
IR Heat Loss (Background) 289.51 W/m2
… Difference, New – BG 35.17 W/m2
Ground Temperature 299.7 K“
Lieber Herr Landvoigt,
Differenzbetrachtungen aus dubiosen Quellen meinte ich nicht und braucht man auch nicht:
Als einzige Eingangsgröße reichen das Strahlungsvolumen, die Temperatur (15°C) und die Konzentration des CO2 (400ppm).
Die mittlere freie Weglänge ist 16m.
Welche Strahlungsleistung (W/qm)wird aus diesem Volumen an den Boden übertragen?
MfG
„Mein Fazit: unterhalb von 2,7 km kann man in diesem Fall den IR-Strahlungstransport vollkommen vernachlässigen. Der Temperaturunterschied zwischen unterer Atmosphäre und Oberfläche ist allein durch Konvektion bedingt.“
tz tz tz tz tz tz tz tz
MODTRAN ergibt bei „Cumulus cloud base 0,66 km, TOP 2,7 km eine mittlere Transmittanz Null.
———–
Sehr geehrter Herr Berberich
Vermutlich wird die Gesamt-Transmittanz durch die Atmospähre ermittelt. duch die Unpassierbarkeit von Strahlung durch Wolken wird diese dann notwendig 0. Nur ist die Angabe ‚mittlere‘, bzw. average unklar: Was wird da gemittelt?
————- #153: P. Berberich sagt:
————–
Mein Fazit: unterhalb von 2,7 km kann man in diesem Fall den IR-Strahlungstransport vollkommen vernachlässigen.
Das habe ich anders verstanden. Wir haben immer einen signifikanten Strahlungstransport. So auch von Oberfläche bis zur Unterkante Wolken in 660 m. Im besondern wenn man weiß dass in der unteren Troposphäre bereits Emission und Absorption beim CO2 in wenigen Metern vollzieht. Innerhalb der Wolken gibt es stärkere Turbulenzen, aber der Strahlungsfluss ist von der Dichte abhängig.
————- #153: P. Berberich sagt:
————
Der Temperaturunterschied zwischen unterer Atmosphäre und Oberfläche ist allein durch Konvektion bedingt.
Unterhalb von Wolken dürfte die Konvektion eher gering bis vernachlässigbar sein, denn die Wolken blockieren einen Wärmefluss. eine geringe Lapse Rate verhindert Konvektion.
————- #153: P. Berberich sagt:
————–
Die Temperatur der Oberfläche ist festgelegt durch die Temperatur der Atmosphäre oberhalb von 2,7 km und durch die sog. „Lapse rate“.
Die Lapse Rate ist ein statistischer Wert, der lokal schwankt. Mehrere Wärmetransport-Mechnismen, einschließlich des Stahlungstransport führen dann zur mittleren Lapse Rate.
Die Wolken wirken aber eher wie eine Isolationsschicht. Die darüber liegenden Temperaturen haben m.E. einen eher geringen Einfuss als bei clear sky.
„das ist zwar richtig, aber für was wollen Sie die mittlere Transmittanz denn haben? Sie ist schwer zu ermitteln und stark von der Wolkenbedeckung abhängig.“
Sehr geehrter Herr Landvoigt,
MODTRAN ergibt bei „Cumulus cloud base 0,66 km, TOP 2,7 km eine mittlere Transmittanz Null. Mein Fazit: unterhalb von 2,7 km kann man in diesem Fall den IR-Strahlungstransport vollkommen vernachlässigen. Der Temperaturunterschied zwischen unterer Atmosphäre und Oberfläche ist allein durch Konvektion bedingt. Die Temperatur der Oberfläche ist festgelegt durch die Temperatur der Atmosphäre oberhalb von 2,7 km und durch die sog. „Lapse rate“.
Nun, Sie haben das tuning eben nicht verstanden, obwohl ich Ihnen dies schon öfter erklärt habe.
—————-
Mit einer derartig oberlehrerhaften Attitüde können sie vielleicht bei Claqueuren und Fans punkten. In einer offenen Diskussion verspielen sie lediglich Vertrauen.
————- #148: NicoBaecker sagt:
————-
Sie glauben immer noch, man würde die Modelle so tunen, da die Globaltemperatur möglichst gut stimmen würde. Das ist aber so einfach.
Ich denke sehr wohl dass ich mich in die Arbeit von Modellieren hervorragend hinein versetzen kann. Jeder der mit mehr oder minder umfangreichen Implementierung von Rechnmodellen zu tun hatte, testet die Plausibilität der getroffenen Annahmen und Abbildungen. Das ist das Handwerkszeug, und das geht auch bei CGMs, wenngleich wesentlich komplexer, im Prinzip auch nicht anders. Wenn die ermittelten werte weit jenseits der Erwartungswerte rangieren, ist die Vermutung eines Modellfehlers sehr stark.
————- #148: NicoBaecker sagt:
—————-
Man macht das Tuning bei physikalischen Einzelprozesse, die parametrisiert sind und für Parameter, deren Wert nicht ausreichend genau gemessen werden können und versucht damit, den Einzelprozeß mit seinen Beobachtungen in Übereinstimmung zu bekommen, z.B. die Größenverteilung von Wolkentröpfchen der verschiedenen Wolkentypen und für Aerosole, die geographisch aufgelösten Strahlungsbilanzen, Windfelder, Meeresströmungen,… .
Genau das ist mein Punkt: es liegt ein um Dimensionen zu großes Unwissen vor, wenn es um eine Vielzahl von Parametern geht. Das Tuning ist dann ein mehr oder minder ‚intelligent guessing‘ dass aber angesichts der Gesamtkomlexität zu einem fragilen Kartenhaus wird, sprich eine virtuelle Modellierungswelt, die kein ermittelbaren Bezug zur Wirklichkeit mehr aufweist.
————- #148: NicoBaecker sagt:
—————–
Wenn man diese Prozesse individuell tuned, so ist der daraus resultierende Verlauf der globale Mitteltemperatur eine „Überraschung“. Das Tunen der im Einzelnen parametrisierten Prozesse kann man nicht so machen, daß ein gewünschter Temperaturverlauf rauskommt,
Ich habe auch nicht gesagt, dass es trivial ist.
Man benötigt lediglich sehr viele Testläufe und evolutionäre Tuning-Algorithmen.
————- #148: NicoBaecker sagt:
——————-
Das ist auch gar nicht der wissenschaftliche Sinn eines Klimamodells. Das Modell soll ja das Klima erklären und nicht nur einen einzigen Parameter reproduzieren.
Hier kommen wir zu einer wissenschaftstheoretischen Dissens. Sie beschreiben die synthetische, induzierte Methode als die allein wissenschaftliche, während ich den Punkt mit Nachdruck vertrete, dass bei hoher Systemkomplexität und chaotischem verhalten die deduzierende Methode wesentlich erfolgversprechender, und damit ‚wissenschaftlicher‘ ist. Sie zeigen lediglich wissenschaftstheoretische Mängel, wenn sie dieser Methode die Wissenschaftlichkeit absprechen wollen.
Zudem arbeitet ihre Argumentation auch mit dem synthetischen Ansatz nicht konsequent. Denn hier müssten sie eine detailierte Effektwirkung rechnen – Also:
Wie verhält sich eine Wiese mit gegeben Pflanzenbewuchs und Bodenzustand, Feuchte, Bewölkung, Sonneneinstrahlung und Wind hinsichtlich der Evaporation. Dieses müsste für jede naturräumliche Parzelle einzeln durchgerechnet werden. Denn nur hier können sie natürliche physikalische Zusammenhänge auch ausmodellieren.
Natürlich würde eine hinreichend vollständiges Modell eines Waldstückes schnell an die Verarbeitungskapazität von Supercomputern stoßen und ist damit für eine komplette Welt nicht mehr praktisch leistbar.
Darum wird die Welt in Grid Sizes von meist über 100 km Kantenlänge aufgeteilt, und dann mit mittlern Werten statistisch mehr oder minder abgesicherten Parametern gerechnet. Eine empirische Überprüfbarkeit ist damit weitgehend ausgeschlossen. Somit haben sie auch nicht mehr den physikalischen Prozess mehr im Fokus, sondern eine Meta-Ebene, die weder Synthetisch-induktiv ist, noch empirisch-deduktiv. An der Wissenschaftlichkeit dieses Ansatzes muss gezweifelt werden!
————- #148: NicoBaecker sagt:
—————
Wenn es Sie wundert, warum die Modelle es nicht hinbekommen, die globale Mitteltemperatur besser zu fitten, so haben Sie hier die Antwort: weil es nicht das alleinige Ziel ist.
Sie verstehen den Punkt nicht! Es geht nicht um ein exklusives Ziel, sondern um ein Testkriterium, dass die Qualität des Modell sichern soll hinsichtlich der Abbildung der realen Welt. Ansonsten bliebe jede Aussage eine reine Spielwiese. Und da gibt es sicher unterhaltsamere Computer-Games.
————- #148: NicoBaecker sagt:
————-
Erklären Sie mir Ihre unlogische Schlußfolgerung, …
Sie schreiben inkonsistenten Quatsch, der mit Wissenschaft nichts mehr zu tun hat.
Entweder sie meinen, ich hätte eine Schlussfolgerung getätigt, die den Anspruch auf logik erhebt, aber fehlerhaft sei. Oder irgend etwas anderes, was ich nun gar nicht mehr nachvollziehen kann. Trifft meine Vermutung zu, impliziert die Behauptung eines Fehlers in der Herleitung, dass dieser auch klar gezeigt werden muss. Das aber fehlt.
————- #148: NicoBaecker sagt:
————-
Schlußfolgerung, wie Sie aus den Abweichungen zu den Beobachtungen von ein paar Zehntel Grad nun schlußfolgern, daß die Modelle keine Temperaturänderungen von mehreren Grad verlässlich simulieren können. Was hat das eine mit dem anderen denn physikalisch zu tun? Erklären Sie das sauer, statt hanebüchene Behauptungen zu posten.
Vermutlich bitten Sie um eine ’saubere‘ Formulierung, dann auch auf Provokationen regiere ich oft nicht sauer. Ich mache selbst oft genug Tippfehler und will das Ihnen nicht vorwerfen … nur der Klärung halber …
Sie haben das korrekte Kriterium identifiziert: ‚Zuverlässigkeit‘ ! Genau diese wird von physikalischen Modellen gefordert. Für gewöhnlich stellt man diese durch empirische Tests her. Dazu wählt man entsprechend testbare Parameter, um dieses Qualitätssiegel zu erstellen. Wird kein sicheres Testkriterium vorgelegt, kann man auch nicht von einer Zuverlässigkeit ausgehen. Da dies bei CGMs nahezu durchgängig fehlt, kann man eben nicht von einer Zuverlässigkeit ausgehen.
Der indikator, dass man dies im Nahbereich von wenigen zehntel Grad – Mittels System-tuning -leistet, ist noch kein sicheres Kriterium, dass weitere Extrapolationen verlässliche Werte liefern. Aber se wäre kein k.o.-Kriterium
Tatsächlich senkt eine Modellabweichung von der Realität deren Vertrauen in die Zuverlässlichkeit, aber es wären Varianten denkbar, dass ein kurzfristiges Rauschen die Qualität der Modelle langfristig nicht kompromittiert. Dazu aber bedürfte es anderer Kriterien, auf die sich die Erwartung einer Zuverlässigkeit gründen können. M.E. fehlen diese aber völlig.
Zurück zur Behauptung eines logischen Fehlers: Sie würden vermutlich ein ’non sequitur‘ beanstanden, wenn ich behaupten würde, dass mit dem fehlenden Fit der zwingende Beweis mangelnder Güte erbracht sei.
Nur habe ich das nicht behauptet, sondern mit dem weichen Kriterium des Vertrauens und der Abschätzung argumentiert. Dies trifft eher als ein ‚good will‘-Argument zu, denn angesichts des fehlenden Qualitätskriterium ist bereits einfach, die Modelle zu verwerfen. Ich habe aber eingeräumt, darüber hinaus eine mögliche Plausibilität in Betracht zu ziehen.
————- #148: NicoBaecker sagt:
————-
Das Modell von Weiß et al. ist ja im Gegensatz zu GCMs kein physikalisches Modell. Der Temperaturverlauf ergibt sich nicht aus einem simulierten Wetterverlauf auf grid-Punkten, sondern ist nur eine Transformation von der Messdaten in den Fourierraum und Abschneiden der Höherharmonischen. Da steckt keine Physik drin und deswegen erklärt dieser Fit nichts.
Das ist mehrfach fehlerhaft, denn es ist ein wissenschaftlich deduzierender Ansatz, der natürlich absolut zulässig bleibt. Es ist keineswegs ausschließlich eine reine FFT Analyse, sondern es fragt nach bekannten physikalischen Zyklen die zu den ermittelten Frequenzen passen. Und darin wurde man bereits recht plausibel fündig.
Ihre Fehler sind hier eine fehlerhaftes wissenschaftstheoretisches Verständnis, dass zulässige Verfahren exkludieren will, und zum Anderen eine Falschdarstellung des Verfahrens, die aus der ermittelten Empirie nach physikalischen Erklärungen sucht.
————- #148: NicoBaecker sagt:
————-
————-
Der Computer berechnet nun auf dem grid die chemische Reaktion nach Zündung, die Ausbreitung der Verbrennungsfront von der Zündkerze ausgehend in den Zylinder, die dadurch induzierte Änderung des thermodynamischen Zustands des Verbrennungsgemisches und mit dem damit gegebenen Druck die resultierende Bewegung des Kolbens etc.. Dies macht man aus den gegebenen physikalischen Grundgleichungen, die die Einzelprozesse (chemische Thermodynamik des Verbrennungsvorgangs, Mechanik der Motorteile etc.), beschreiben, indem man die Zeitentwicklung der entsprechenden Differentialgleichungen numerisch löst.
Ihr Erklärungsversuch würde sehr schön einen induktiven detaillierten Modellansatz beschreiben, der aber in CGMs nicht zum Einsatz kommt, da anstelle detaillierter Abläufe mit Mittelwerten und Parameterabschätzungen gearbeitet wird. Siehe meine o.g. Einwände.
————- #148: NicoBaecker sagt:
Fall a) entspricht einem GCM, Fall b) dem „Weiß-Modell“. Erkennen Sie den fundamentalen Unterschied? a) ist ein physikalisches Modell, b) nicht!
Wie gesagt: Der Vergleich bei a) ist unzutreffend, da hier mehrere Dimensionen von Abstraktionsebenen unterschlagen werden.
Und b) ist unzutreffend, weil sie die Methoden der empirischen Wissenschaften offensichtlich nicht beherrschen.
Ihr Zitat von Trenberth über die heutige Qualität von regionale Klimamodellen hilft Herrn Landvoigt bei dem von mir geforderten Beweis für seine Behauptung kaum weiter.
„Das Tunen der im Einzelnen parametrisierten Prozesse kann man nicht so machen, daß ein gewünschter Temperaturverlauf rauskommt,“
Oje, der Gute Allwissende weiß nicht, was die Modellierer so alles an Tuning betreiben, damit zumindest die Mitteltemperatur halbwegs paßt. Geht es dann an TX und TN wird es abenteuerlich mit den Abweichungen von der gemessenen Realität. Da hat das Pseudonym recht: Die kann man so nicht tunen oder genauer gesagt, man hat das beim Tunen nicht beachtet, daß jemand kommt, der sich diese Temperaturen anschaut.
nehmen Sie doch einfach zur Kenntnis, was K. Trenberth in nature.com zu dem Wert von modellen geschrieben hat:
None of the models used by IPCC are initialized to the observed state and none of the climate states in the models correspond even remotely to the current observed climate. In particular, the state of the oceans, sea ice, and soil moisture has no relationship to the observed state at any recent time in any of the IPCC models. There is neither an El Niño sequence nor any Pacific Decadal Oscillation that replicates the recent past; yet these are critical modes of variability that affect Pacific rim countries and beyond. The Atlantic Multidecadal Oscillation, that may depend on the thermohaline circulation and thus ocean currents in the Atlantic, is not set up to match today’s state, but it is a critical component of the Atlantic hurricanes and it undoubtedly affects forecasts for the next decade from Brazil to Europe. Moreover, the starting climate state in several of the models may depart significantly from the real climate owing to model errors. I postulate that regional climate change is impossible to deal with properly unless the models are initialized.
Damit ist zum Wert von Modellen eigentlich allse gesagt.
MfG
„Hindcasts sollten mit Modell-Tuning nun wirklich keine Kunst sein, aber auch da kann der Verlauf m.E. keine überzeugende Abbildung liefern: Warum gab es in bis 1940 eine so starke Erwärmung, dann eine so lange Abkühlung?“
Nun, Sie haben das tuning eben nicht verstanden, obwohl ich Ihnen dies schon öfter erklärt habe. Sie glauben immer noch, man würde die Modelle so tunen, da die Globaltemperatur möglichst gut stimmen würde. Das ist aber so einfach. Man macht das Tuning bei physikalischen Einzelprozesse, die parametrisiert sind und für Parameter, deren Wert nicht ausreichend genau gemessen werden können und versucht damit, den Einzelprozeß mit seinen Beobachtungen in Übereinstimmung zu bekommen, z.B. die Größenverteilung von Wolkentröpfchen der verschiedenen Wolkentypen und für Aerosole, die geographisch aufgelösten Strahlungsbilanzen, Windfelder, Meeresströmungen,… . Wenn man diese Prozesse individuell tuned, so ist der daraus resultierende Verlauf der globale Mitteltemperatur eine „Überraschung“. Das Tunen der im Einzelnen parametrisierten Prozesse kann man nicht so machen, daß ein gewünschter Temperaturverlauf rauskommt, Das ist auch gar nicht der wissenschaftliche Sinn eines Klimamodells. Das Modell soll ja das Klima erklären und nicht nur einen einzigen Parameter reproduzieren. Wenn es Sie wundert, warum die Modelle es nicht hinbekommen, die globale Mitteltemperatur besser zu fitten, so haben Sie hier die Antwort: weil es nicht das alleinige Ziel ist. Ich denke, das widerspricht grundlegend Ihren Vorstellungen über den Sinn von Klimamodellen ;-). Einen optimalen Fit an die Beobachtungen der globalen Mitteltemperatur bekäme man schon mit weniger als 10 kB Daten hin, dafür benötigte man keinen Supercomputer. Ist Ihnen das klar?
Erklären Sie mir Ihre unlogische Schlußfolgerung, wie Sie aus den Abweichungen zu den Beobachtungen von ein paar Zehntel Grad nun schlußfolgern, daß die Modelle keine Temperaturänderungen von mehreren Grad verlässlich simulieren können. Was hat das eine mit dem anderen denn physikalisch zu tun? Erklären Sie das sauer, statt hanebüchene Behauptungen zu posten.
„Das Modell von Weiß und Lüdecke versucht dies mit natürlichen Zyklen überlagernder Frequenzen zu erklären und erreicht damit einen besseren Fit. Mit welcher Begründung sollte man überhaupt Modellen trauen, die sowohl hinsichtlich forcasts, als auch hindcasts dagegen empirisch nicht überzeugen konnten?“
Das Modell von Weiß et al. ist ja im Gegensatz zu GCMs kein physikalisches Modell. Der Temperaturverlauf ergibt sich nicht aus einem simulierten Wetterverlauf auf grid-Punkten, sondern ist nur eine Transformation von der Messdaten in den Fourierraum und Abschneiden der Höherharmonischen. Da steckt keine Physik drin und deswegen erklärt dieser Fit nichts. Ich mache Ihnen den Unterschied mal an einem Beispiel einer Simulation eines Verbrennungsmotors klar.
a) Die Geometrie des Motors wird auf einem Grid beschrieben. Es wird ein Benzin-Luft-Gemisch mit bestimmter Verbrennungswärme und ein Zündfunke angeboten. Der Computer berechnet nun auf dem grid die chemische Reaktion nach Zündung, die Ausbreitung der Verbrennungsfront von der Zündkerze ausgehend in den Zylinder, die dadurch induzierte Änderung des thermodynamischen Zustands des Verbrennungsgemisches und mit dem damit gegebenen Druck die resultierende Bewegung des Kolbens etc.. Dies macht man aus den gegebenen physikalischen Grundgleichungen, die die Einzelprozesse (chemische Thermodynamik des Verbrennungsvorgangs, Mechanik der Motorteile etc.), beschreiben, indem man die Zeitentwicklung der entsprechenden Differentialgleichungen numerisch löst. Als output wählt man dann die resultierende Kolbenbewegung des „Computermotors“. Man vergleicht dies mit den beobachteten Kolbenbewegung des Prototypen im Labor.
b) Man fittet im Computer die beobachteten Kolbenbewegungen des Prototypen im Labor durch eine Handvoll Sinusfunktionen, ermittelt die Koeffizienten und verwirft die Harmonische mit der geringer Amplitude. Die daraus gewonnene vereinfachte Fitkurve vergleicht man mit der beobachteten Kolbenbewegung des Prototypen im Labor.
Fall a) entspricht einem GCM, Fall b) dem „Weiß-Modell“. Erkennen Sie den fundamentalen Unterschied? a) ist ein physikalisches Modell, b) nicht!
„das ist zwar richtig, aber für was wollen Sie die mittlere Transmittanz denn haben?“
Ich habe ein Computer-Programm auf Basis eines ortsaufgelösten Energiebilanzmodells geschrieben (siehe z.B. E. Boeker Environmental Physics, 2.Aufl., Kap. 3). Da geht die IR-Transmittanz der Atmosphäre explizit ein. Wenn ich eine globale Erd-Oberflachentemperatur definieren kann, kann ich auch eine IR-Transmittanz der Atmosphäre definieren.
„Allerdings sehe ich den Zusammenhang zwischen Transmissivität und CO2 nicht. Denn für die CO2 Banden ist die Atmosphäre ohnehin nicht transparent.“
Vernachlässigen Sie bitte nicht dass in der Atmosphäre spektrale Diffusion auftritt (siehe mein Beitrag #108)
Da man keine Standard-Atmosphäre auswählen kann, kann man mit MODTRAN keine mittlere Transmittanz berechnen.
—————-
Sehr geehrter Herr Berberich,
das ist zwar richtig, aber für was wollen Sie die mittlere Transmittanz denn haben? Sie ist schwer zu ermitteln und stark von der Wolkenbedeckung abhängig.
———— #145: P. Berberich sagt:
—————-
Deshalb halte ich es für unsinnig mit MODTRAN abzuschätzen wie stark sich die Oberflächentemperatur bei einer Verdopplung der CO2-Konzentration erhöht.
Das ist auch nur bezogen auf die Szenarien und dann bezogen auf den reinen Strahlungstransport gegeben. Modtran ist nicht für globale Simulationen geeignet und will das auch nicht sein. Allerdings sehe ich den Zusammenhang zwischen Transmissivität und CO2 nicht. Denn für die CO2 Banden ist die Atmosphäre ohnehin nicht transparent.
„Zitat: Eingangsparameter: Tropical atmosphere …
Kleine Anmerkung, Sie müssen schon die Parameter richtig wählen.“
Danke, Sie haben recht. Ich habe „NOAA Cirrus model (LOWTRAN 6 Model)“ gewählt. Wählt man „No clouds or rain“ so erhält man eine geringfügig größere „Average transmittance „. Wählt man dagegen „Cumulus cloud base 0.66 km TOP 2.7 km“, so ist = 0. Da man keine Standard-Atmosphäre auswählen kann, kann man mit MODTRAN keine mittlere Transmittanz berechnen. Deshalb halte ich es für unsinnig mit MODTRAN abzuschätzen wie stark sich die Oberflächentemperatur bei einer Verdopplung der CO2-Konzentration erhöht.
Nein, das hat er nicht getan. Außerdem enthält seine Probe viel zu viel Wasserdampf.
Zitat: „Bild 2 zeigt das unbearbeitete Spektrum der 15 ?m-Bande für 357 ppm CO2 und 2.6% H2O.“
Durch den Wasserdampf von 2,6% (2600 ppmv, rel. Feuchte: 60%) wird die Transmission extrem verringert.
Gehen Sie mal auf die MODTRAN-Page: http://forecast.uchicago.edu/Projects/modtran.orig.html
Wählen Sie bei „hold water vapor: Rel.Hum.“ und geben Sie einmal 0% und 60% ein und wählen Sie 0.010 km.
Mfg
Werner Holtz
Es ist das arithmetische Mittel der Einzel-Transmissionen T(fi) zwischen 100 cm-1 und 1500 cm-1. Man kann nun T(fi) mit dem Emissionsspektrum der Erdoberfläche falten und dann den Mittelwert bilden.
——————
Sehr geehrter Herr Berberich,
Ich habe das Averaging hier nicht ganz verstanden. Denn MODTRAN integriert ja nicht über die Erdoberfläche, sondern rechnet nur über die jeweiligen Szenarien. Ferner weiss ich nicht, ob hier ein Average über definierte Weglängen gemeint sind, z.B. je Kilometer, oder ob die Transmittance über die gesamte Atmosphäre gemeint ist – dann aber wäre ‚Average‘ ein irreführender Begriff. Ebenso bleibt für mich nicht geklärt, ob hier die atmosphärische Eigenstrahlung bereits heraus gerechnet wurde – was ich allerdings annehme.
Insgesamt zweifele ich nicht an der Korrektheit der Rechnung, auch wenn sie nur eine Näherung darstellt. Denn die anderen hochauflösenden LBL-Programme kommen zu sehr ähnlichen Ergebnissen.
———— #142: P. Berberich sagt:
———–
Ich habe weiterhin das Problem dass MODTRAN eine viel größere mittlere globale Transmittanz ergibt als andere Publikationen.
Das war der Grund, warum ich auf möglicherweise abweichende Definitionen verwies. Transmittance ist kein allgemein gut definierter Wert. Darum rate ich zur Vorsicht beim Vergleich aus unterschiedlichen Quellen.
Vielleicht haben Sie bei MODTRAN auf ‚Clear Sky‘ berechnet, aber die andere Literatur mittelt über eine durchschnittliche Wolkenbedeckung. Das würde die großen Unterschiede erklären. Bei Bewölkung geht die Transmittance durch die Atmosphäre gegen Null.
„Ich sehe viele Möglichkeiten, wie die ‚Average Transmittance‘ unterschiedlich aufgefasst werden kann. So ist die Weglänge l nicht fest vorgegeben und unklar bleibt.“
Sehr geehrter Herr Landvoigt,
die Definition der „Average Transmittance“ in MODTRAN kann man aus der Tabelle ableiten, die vor der Angabe der „Average transmittance“ zu finden ist. Es ist das arithmetische Mittel der Einzel-Transmissionen T(fi) zwischen 100 cm-1 und 1500 cm-1. Man kann nun T(fi) mit dem Emissionsspektrum der Erdoberfläche falten und dann den Mittelwert bilden. Dieser Mittelwert hängt nun von der Emissions-Temperatur der Erdoberfläche ab. Für Tropical/MidLatSum/MidLatWin/SubArctSum/SubArcWin sind die Mitteltemperaturen 299/288/281/264/248 K. Man erhält daraus eine gefaltete „Average transmittance“ von 0,13/ 0,16/0,24/0,17/0,25. Diese sind nicht viel anders als die nicht gefalteten Werte: 0,13/0,16/0,24/0,19/0,28. Ich habe weiterhin das Problem dass MODTRAN eine viel größere mittlere globale Transmittanz ergibt als andere Publikationen. Wie bereits gesagt: „Ein wesentliches Element der Naturwissenschaften ist die Nachvollziehbarkeit und Überprüfbarkeit der Ergebnisse.“
am Dienstag, 05.04.2016, 01:25
#126: Martin Landvoigt sagt:
Zitat: Dies entspricht einer Transmission von T = 10^-3.21 = 0,6 Promille. Mit anderen Worten: Bereits nach 10 m sind 1 – T = 99,94% der IR-Strahlung absorbiert. Das entspricht reziprok auch der Gegenstrahlung: Das Meiste der Gegenstahlung stammt aus dem ersten Meter. Das, was in 10 m Höhe abgestrahlt wird, wird auf dem Weg zur Oberfläche zu 99,94% absorbiert.
————-
Der Herr Hug rechnet mit dem „Extinktionskoeffizient im Maximum vom reinen CO2“, eigentlich hätte er den effektiven Extinktionskoeffizienten nehmen müssen, also den Banden-gewichteten Mittelwert.
Sehr geehrter Herr Holtz
Genau das hat Heinz Hug auch getan. Siehe http://tinyurl.com/jbvlkl2
———–
———–
Setzt man den molaren Extinktionskoeffizient e für die n2-Bande sowie die Volumenkonzentration in mol/m3 (357 ppm CO2) in das Lambert-Beersche-Gesetz ein und nimmt eine Schichtdicke von 10 m an, resultiert eine Extinktion von …
Da wir mittlerweile eher 400 ppm haben dürfte die Extinktion noch höher sein.
Das schöne an der Arbeit von Heinz Hug ist, dass er die Kurve von der theoretischen Herleitung mit Formelapparat über die Messung hin zur praktischen Vorstellung liefert. Viele andere Arbeiten begnügen sich mit formelmäßiger Darstellung auf einem abstrakten Niveau, die ein konkretes Verständnis der Beobachtungen nicht unterstützt. Da hat mit die Vorstellung, dass bodennah die CO2-Absorption und Emission innerhalb weniger Meter statt findet, sehr geholfen.
#129: Martin Landvoigt Sie wollten sich doch nicht äußern!!!! Und jetzt klauen Sie mir auch noch die Differenzmessung für Ihre Zwecke
————
Sie reden wirr. Lesen Sie bitte zuerst, was geschrieben steht und erfinden nichts Neues.
———— #135: Dr.Paul sagt:
————
Sie verwechseln leider a) und b)
das ist nun wirklich lächerlich, ähnlich wie die lächerliche Verteidigung der Pyrgeometerbetruges.
Zum Ersten: Ich beschäftige mich nicht mit Pyrgeometern.
Zum Zweiten: Ich verwechsele nichts, sondern kann offensichtlich sogar lesen, was da steht. Wenn Sie aber ihre eigenen Links nicht lesen, kommt dann nur richtiger Unsinn heraus, in dem Sie Ihr Unverständnis lediglich dokumentieren.
Es stünde ihnen besser an, zu erklären, was es Ihrer meinung bedeutet, wenn da steht: LONGWAVE CLOUD RADIATIVE FORCING AT THE SURFACE – Was wurde da gemessen? Sie können auch gerne meine Erklärung übernehmen. Falls sie eine andere Erklärung haben, außer: ‚beides kann nicht gleichzeitig richtig sein, entweder a) oder b)‘
Dann hätten Sie konsequenter Weise erklären müssen, was denn nun richtig sei. Aber ach an dieser einfachen Logik wartet der Leser vergeblich.
————- #135: Dr.Paul sagt:
————-
Das mit der abenteuerlichen Begründung der „forcing“-Überschrift hat ihnen Hess oder wer zugeflüstert, …
LESEN SIE IHREN EIGENEN LINK!!!! TUN SIE ES JETZT!!!! SCHREIBEN SIE NICHT WEITER, BEVOR SIE GELESEN HABEN WAS DA STEHT!!!
————- #135: Dr.Paul sagt:
————-
Denn wir haben in beiden Diagrammen exakt die GLEICHE Ordinate (links):
Radiance = Strahldichte [mW/sr/m²],
Ihnen sollte auch die Skalierung aufgefallen Sein: In b) von 0 – 100 in a) von 0 – 40. Wenn sie die Differenz von zwei Werten der gleichen Dimenension bilden, dann ist dieser Wert selbstverständlich der gleichen Dimension. Nehmen sie b) ‚mitte‘ und subtrahieren davon die Werte von b) ‚oben‘ und tragen das in ein neues Diagramm auf.
Und entsprechend schreibt auch das Diagramm: CLOUDY – CLEAR: Das ist als ein MINUS zu verstehen.
Das sollte dann exakt so ausssehen wie a) ‚mitte‘. Wenn Ihnen da noch immer kein Licht aufgegangen ist, dann wiederholen sie dies Übung mit b) unten und vergleichen das Ergebnis mit a) unten.
Ich hoffe, Sie wissen was das heißt: Es gibt hier eine glasklare Erklärung, was die Diagramme aussagen!
————- #135: Dr.Paul sagt:
————
Zusätzlich ist im untersten Diagramm von a) rechts noch die ankommende Bestrahlungsstärke in W/m2 eingezeichnet
und hier steht bei jeder Bewölkung im undurchdringlichen „CO2-Bereich“ 0,0,0
Und das ist auch völlig korrekt! Denn die Wolken machen eine Null-Differenz zur Abstrahlung in Bodennähe. Das habe ich bereits erklärt.
————- #135: Dr.Paul sagt:
————-
bei einer maximalen Bestrahlung über alle Frequenzen (Blau 80%bewölkt) von 35 W/m2.
Exakt das ist das ‚longwave CLOUD radiative forcing‘. Es ist nicht die ‚Radiance‘ und auch nicht die ‚total CLOUD radiative forcing‘, denn dann müsste die Reduktion im Kurzwelligen Sonnenspektrum mit gerechnet werden und das Forcing wird negativ.
————- #135: Dr.Paul sagt:
————–
Maximal 35 W/m2. Soviel können Wolken dort leisten
und man will uns weis machen, das Spurengas CO2 mit
Die Zahl sagt ohne Kontext nicht viel. Denn wenn eine konstante Bewölkung angenommen wird, gibt es dadurch keine Klimaveränderung. Da vor allem aber ‚total CLOUD radiative forcing‘ von Relevanz wäre, die hier gar nicht behandelt wurde, sind weiter gehende Rückschlüsse ein wenig gaga. Lediglich wird erkennbar, dass die Wolken einen ungleich größere Wirkung haben können.
IPCC-Autoren behaupten ja auch einen Zuwachs an Bewölkung, denn durch die Erhöhung der Erdtemperatur steigert sich die Evaporation. Das sei dann ein Verstärkungsfaktor (positives Feedback) zum Treibhaus-Effekt.
Daran ist falsch, dass zum einen hier die Gesamtwirkung von Wolken nicht vollständig verstanden wird, und auch die Parameter zum Entstehen und Abregenen nicht in der nötigen Detailtiefe bekannt sind. Aber dies kann man nicht dadurch feststellen, wenn man sich damit brüstet, die Auswertungen nicht zu verstehen.
Zitat: Eingangsparameter: Tropical atmosphere …
Kleine Anmerkung, Sie müssen schon die Parameter richtig wählen.
Tropische Atmosphäre: 0-23,5° (Man nimmt meist die Werte von: 15N/15S)
Subtropische Atmosphäre: 23,5-40° (Man nimmt meist die Werte von: 30N/30S)
+ Sahara
Luft-Temperatur: 35°C (Sommer-Tag im Mittel) ; 16°C (Sommer-Nacht im Mittel)
relative Feuchte: 10% – Tag, 40% – Nacht
Emissionsgrad: e(air,rF:10%) = 0,53, e(air,rF:40%) = 0,62
Albedo: 0,35 – 0,40
Die Erd-Atmosphäre hat im flächen-gewichteten Mittel eine relative Feuchte von 71,8%. Im tropischen Atmosphären-Bereich schwankt die relative Feuchte zwischen 80 – 40%.
Mfg
Werner Holtz
Zitat: Dies entspricht einer Transmission von T = 10^-3.21 = 0,6 Promille. Mit anderen Worten: Bereits nach 10 m sind 1 – T = 99,94% der IR-Strahlung absorbiert. Das entspricht reziprok auch der Gegenstrahlung: Das Meiste der Gegenstahlung stammt aus dem ersten Meter. Das, was in 10 m Höhe abgestrahlt wird, wird auf dem Weg zur Oberfläche zu 99,94% absorbiert.
Der Herr Hug rechnet mit dem „Extinktionskoeffizient im Maximum vom reinen CO2“, eigentlich hätte er den effektiven Extinktionskoeffizienten nehmen müssen, also den Banden-gewichteten Mittelwert.
Siehe: Howard J. N., Burch D. E., Williams D. (1956): Infrared Transmission of Synthetic Atmospheres. J. Opt. Soc. Am. 46, Issue 4, 237-245
+ H2O-freie synthetische Luft mit 0,03% CO2 bei 101325 Pa und 20°C
CO2-Bande Wellenlängenbereich mittlerer Absorptionsgrad längs einer Strecke/Schicht von
µm µm 50m 500m 5000m
15 12,50 bis 18,18 0,31 0,53 0,75
Mfg
Werner Holtz
„Wenn die Empirie eben nicht zur Deckung mit den Modellen kommt, ist der Modellierungsansatz invalidiert.“
Das ist nicht korrekt. Zwischen jedem Modell und der Messung gibt es immer einen Unterschied, das Modell muß nach der relativen Abweichung bewertet werden. So läuft das in den anturwissenschaften.
„Das ist direkt ersichtlich. Was erwarten sie dann noch für Studien?“
Quantitative, was anderes läßt man in der Physik nicht zu. Ihnen scheint gar nicht aufzufallen, wie groß die Übereinstimmung zwischen Modell und Beobachtung in der Gesamtbewertung ist. Sie zoomen nur keine Unterschiede heraus und ignorieren die großen Anteil der Beobachtung, die das Modell erklärt.
„Ist das nicht ein wenig albern? Sie scheinen hier kein wissenschaftliches Interesse zu haben und den Sachverhalt aufklären zu wollen, sondern mit engen Zielvorgaben ein Forschungsprogramm aufsetzen zu wollen.“
Nein, die Ergebnisse gibt es doch, freilich keine wissenschaftliche, die Ihre Meinung unterstützen würden. Sie finden keine wissenschaftlichen paper, die die Modelle samt und sondern nur wegen der Hiatus-Abweichung verwerfen.
„Was nun, wenn ein Paper tatsächlich Ihren Vorgaben entspräche? Dann würden sie zwei weitere, die das selbe sagen, fordern? Was aber, wenn man eben keine vernünftige Erklärung für die Schere zwischen Modell und Realität hat“
Wieso, es gibt doch Erklärungen und, wenn Sie sich mal unsehen würden, so wird der Hiatus nicht als große Überraschung gesehen, solche Abweichungen sieht man ja auch in Phasen in der Vergangenheit. Der Hiatus tritt ja nicht nur gegenwärtig aus, sondern die Modelle zeigen solche „Hiatusse“ auch für Abschnitte in der Vergangenheit. Meine Vorgaben sind doch nun physikalisch trivial:ich will objektive Erkenntnisse in Form von Zahlen sehen. Womit Sie sich zufrieden geben ist eben unzureichend, denn es bringt das Risko, daß Sie sich etwas einreden, weil Sie isch durch selektive Daten täuschen lassen. Deshalb fordere ich Sie ja zu wissenschaftlichen papern auf, Ihre Meinung basierend auf ein paar Abbildungen ist alleine kein ernstzunehmendes Argument.
“ … wollen sie dann eine Auftragsarbeit zum Erfinden vorgeschobener Gründe produzieren?“
Nein, ich rede ja von Wissenschaft.
Sie vertauschen leider a) und b)
das ist nun wirklich lächerlich, ähnlich wie die lächerliche Verteidigung der Pyrgeometerbetruges.
Auch Wolken können nur durch „freie Fenster“ strahlen“.
Wissen Sie nicht was ein freies Fenster ist?
Das mit der abenteuerlichen Begründung der „forcing“-Überschrift hat ihnen Hess oder wer zugeflüstert, das war auch früher schon falsch wie Ihre abwegige Forderung der fehlenden „Amplitude“ bei einer spektralen Transparenzmessung, die nur dimensionslos angegeben wird.
Denn wir haben in beiden Diagrammen exakt die GLEICHE Ordinate (links):
Radiance = Strahldichte [mW/sr/m²], ich hoffe Sie wissen was das heißt.
http://tinyurl.com/bso5jkc
Zusätzlich ist im untersten Diagramm von a) rechts noch die ankommende Bestrahlungsstärke in W/m2 eingezeichnet
und hier steht bei jeder Bewölkung im undurchdringlichen „CO2-Bereich“ 0,0,0
bei einer maximalen Bestrahlung über alle Frequenzen (Blau 80%bewölkt) von 35 W/m2.
Maximal 35 W/m2. Soviel können Wolken dort leisten „at the surface“, das was unten ankommt.
und man will uns weis machen,
das Spurengas CO2 mit
Sie verwechseln leider a) und b)
das ist nun wirklich lächerlich, ähnlich wie die lächerliche Verteidigung der Pyrgeometerbetruges.
Auch Wolken können nur durch „freie Fenster“ strahlen“.
Wissen Sie nicht was ein freies Fenster ist?
Das mit der abenteuerlichen Begründung der „forcing“-Überschrift hat ihnen Hess oder wer zugeflüstert, das war auch früher schon falsch wie Ihre abwegige Forderung der fehlenden „Amplitude“ bei einer spektralen Transparenzmessung, die dimensionslos angegeben wird.
Denn wir haben in beiden Diagrammen exakt die GLEICHE Ordinate (links):
Radiance = Strahldichte [mW/sr/m²], ich hoffe Sie wissen was das heißt.
Zusätzlich ist im untersten Diagramm von a) rechts noch die ankommende Bestrahlungsstärke in W/m2 eingezeichnet
und hier steht bei jeder Bewölkung im undurchdringlichen „CO2-Bereich“ 0,0,0
bei einer maximalen Bestrahlung über alle Frequenzen (Blau 80%bewölkt) von 35 W/m2.
Maximal 35 W/m2. Soviel können Wolken dort leisten
und man will uns weis machen,
das Spurengas CO2 mit
Welch köstliche Nullsätze:
„Nein, denn die Atmosphäre ist in diesem Frequenzband nicht durchlässig. Die Strahlung ist bei gleicher Temperatur weitgehend konstant, und hat demgemäß auch bei unterschiedlichen Wolkenbedeckungen keine Unterschiede.“
Negativbeweis einfordern? Mutieren Sie zum Trollo:
„Nun, dann zitieren Sie bitte mindestens drei wissenschaftlichen paper“
Was beweist denn die von Ihnen behauptete Nichtexistenz dieser drei Paper?
„Wenn Sie das nicht können, so werte ich Ihre Aussage als vorlaut und naiv unwissend.“
Am Besten fangen Sie bei sich an, wegen des unsinnigen „Negativbeweises“.
Gibt es ein Paper über die Nutzung des Jadebusens als Gezeitenkraftwerk?
Sie lassen sich so gut ärgern: 🙂
„Trotzdem führt die fehlende Transparenz der Luft zwischen Wolke und Erdoberfläche zu einem FEHLEN der 15µm-Strahlung.“
Dann kraxeln Sie mit nem Meßgerät die Berge rauf zu den Wolken und messen unterwegs.
Oder Sie steigen ins Flugzeug und nähern sich der Wolkenuntergrenze (der Wolke) mit dem Meßgerät.
Was messen Sie denn dann bei Annäherung an die Wolke?
In Hamburg gibt es jetzt eine mit extra CO2 angereicherte (Wolke). Nix wie hin mit dem Meßgerät. 🙂
Würde CO2 tatsächlich strahlen, würde sich der daraus resultierende Strahlungsanteil zur Graukörperstrahlung der Wolken DAZU ADDIEREN.
————–
Nein, denn die Atmosphäre ist in diesem Frequenzband nicht durchlässig. Die Strahlung ist bei gleicher Temperatur weitgehend konstant, und hat demgemäß auch bei unterschiedlichen Wolkenbedeckungen keine Unterschiede.
———— #127: besso keks sagt:
————–
Die zur Hypothese (Achtung: Heinzow;-) ) der AGW-Pappnasen passende Kurve der am Boden gemessenen Werte müßte also eine entsprechende Ausbuchtung nach oben ausweisen, da zusätzliche Strahlungsenergie dazukommt.
Das ist fast korrekt, denn die Ausbuchtung nach oben ist auch gut erkennbar, wenn sie nicht das Differenz-Forcing, sondern die Radiance im CO2-Band 600 – 800 betrachten:
http://tinyurl.com/jooc842 – Erster Quadrant rechts oben.
Allerdings hat das mit der Wolkendecke nichts mehr zu tun.
————- #127: besso keks sagt:
————-
Oder sehe ich das falsch?
Jetzt hoffentlich nicht mehr … 😉
Ein wesentliches Element der Naturwissenschaften ist die Nachvollziehbarkeit und Überprüfbarkeit der Ergebnisse.
————-
Sehr geehrter Herr Berberich,
Das sehe ich genau so. Vielen Dank für die Aufklärung. Sie verwenden anscheinend die ältere Ältere Oberfläche, aber der Textoutput gibt die gleiche Version an: MODTRAN3 Version 1.3 12/1/95.
Ich habe die MODTRAN-Version
http://forecast.uchicago.edu/Projects/modtran.orig.html verwendet. Eingangsparameter: Tropical atmosphere, vapor standard, 400 ppm CO2, 1,8 ppm CH4, NOAA Cirrus model. –> Submit the calculation –> View the whole output file. In der 8. letzten Zeile findet man eine „Average transmittance“ von 0,1263 = 13%
Beim neueren Interface kommt heraus:
AVERAGE TRANSMITTANCE =0.1346
Hmmm … vermutlich wurden einige Parameter etwas geändert, aber wohl kaum die Definition.
Ich sehe viele Möglichkeiten, wie die ‚Average Transmittance‘ unterschiedlich aufgefasst werden kann. So ist die Weglänge l nicht fest vorgegeben und unklar bleibt, ob hier die Eigenemission heraus gerechnet wird (mit Strahlungstransportgleichung) oder nicht. Man könnte somit eine Normierung der Transmissivität auf ein Schichtpaket, einen Meter oder ein gesamtes Volumen ermitteln. Ohne nähere Erklärung sagt die Zahl recht wenig. Im unmittelbaren Vergleich, z.B. zwischen Modell-Läufen, kann die Veränderung der Transmissivität durchaus eine Aussagekraft haben, nicht aber kontextfrei aus verschiedenen Quellen.
zwei andere Strahlungsmessungen,
————————–
mit der GLEICHEN Messtechnik,
beide vom GLEICHEN US- Atmospheric Radiation Measurement (ARM) Program
So lange es um fachliche Fragen geht, werde ich gegebenenfalls auch kommentieren.
Jedwede Messergebnisse müssen verstanden werden, was da eigentlich gemessen und ausgewertet wurden. So können Sie mit einem Multimeter natürlich den Strom und die Spannung messen. Beide haben unterschiedliche Werte und je nach Messbedingungen u.U. wenig miteinander zu tun.
Ein AERI – Atmospheric Emitted Radiance Interferometer – kann sowohl Differenzmessungen durchführen, als auch spektrale Strahlungsmessungen.
————– #124: Dr.Paul sagt:
————–
beides kann nicht gleichzeitig richtig sein,
entweder a) oder b)
In Diagramm a) ist zu lesen: ‚Cloud Radiative Forcing‘ Hier handelt es sich also um Differenzmessungen. Auch daran zu erkennen, dass teilweise die Nullinie geschnitten wird.
Zu erwarten ist, dass Wolken im CO2 Band keinen Unterschied machen, denn in den Wellenzahlen 600 – 800 (15µm Band) geht die Transmissivität gegen null.
Diagramm b) ist keine Differenzmessung, sondern eine Strahlungsmessung, die das gleiche Ergebnis zeigt, jedoch ohne die Differenzen auszurechnen: Im Bereich von 600 – 800 haben wir ein sehr starkes Downwelling vom CO2, dass weitgehend unbeeinflusst von der Wolkendecke ist, aber im atmosphärischen Fenster 800 – 1000 haben wir deutliche Unterschiede in der Strahlung je nach Wolkenbedeckung. Wenn man sich die Differenzen zwischen den Diagrammen in b) denkt, kommt man zu dem Diagramm a)
————— #124: Dr.Paul sagt:
——————-
Trotzdem führt die fehlende Transparenz der Luft zwischen Wolke und Erdoberfläche zu einem FEHLEN der 15µm-Strahlung.
Transparenz = 0
keine 15µm-Strahlung
Um das Cloud-Forcing zu berechnen, muss man die Differenz zwischen Wolken und nicht-Wolken darstellen.
Sie haben offensichtlich das Konzept der Differenzmessung nicht verstanden. Wenn es keine Differenzen zwischen den Zustanden gibt, so sind diese NULL, was aber nicht heißt, dass keine Strahlung existiert, sondern im Gegenteil eine gleichmäßig starke Strahlung vorliegt.
Deutlicher wird dies bei einer höheren Auflösung:
http://tinyurl.com/jooc842
Man sollte es vermeiden, die Begriffe Radiance, Transmission, Forcing etc. bunt zu vermischen, dann kommt es auch nicht zu vermeintlichen Widersprüchen.
„Es ist mir zu absurd, irgend welche der Arbeiten zu zitieren, die den Hiatus der Erwärmung erklären wollten.“
Ok, Sie sehen den „Hiatus über 18 Jahre“ als Indikator.
—————
Sehr geehrter Herr Baecker
Das ist korrekt. Haben sie eine Erklärung, wieso alle Modelle einen entsprechende Erwärmung behauptet haben und nicht den beobachteten Verlauf prognostizierten?
Wenn die Empirie eben nicht zur Deckung mit den Modellen kommt, ist der Modellierungsansatz invalidiert. Das ist direkt ersichtlich. Was erwarten sie dann noch für Studien?
————— #122: NicoBaecker sagt:
—————
Nun, dann zitieren Sie bitte mindestens drei wissenschaftlichen paper, die aufgrund des Hiatus zum Schluß kommen, daß die Fehlergrenzen in den Projektionen für die kommenden 100 Jahre größer sein müssen als z.B. in den letzten IPCC reports. Und zwar so groß, daß eine kritische Erwärmung (z.B. mehr als 2 Grad bis 2100 wärmer als heute) bei konstanter bzw. ansteigender Treibhausgasmenge nicht mehr signifikant impliziert werden kann.
Ist das nicht ein wenig albern? Sie scheinen hier kein wissenschaftliches Interesse zu haben und den Sachverhalt aufklären zu wollen, sondern mit engen Zielvorgaben ein Forschungsprogramm aufsetzen zu wollen. Was nun, wenn ein Paper tatsächlich Ihren Vorgaben entspräche? Dann würden sie zwei weitere, die das selbe sagen, fordern? Was aber, wenn man eben keine vernünftige Erklärung für die Schere zwischen Modell und Realität hat … wollen sie dann eine Auftragsarbeit zum Erfinden vorgeschobener Gründe produzieren?
———— #122: NicoBaecker sagt:
————
Wenn Sie das nicht können, so werte ich Ihre Aussage als vorlaut und naiv unwissend.
Das fürchte ich fast schlimmer als den Tod und erschrecke … nein, Spaß beiseite: Es steht ihnen ebenso frei, von mir zu denken was Sie wollen, ebenso wie es jedem anderen freisteht, sich selbst über mich oder Sie eine Meinung zu bilden.
————– #122: NicoBaecker sagt:
„Oder haben sie hierfür eine Erklärung die auch tragfähig ist?“
Die müssen Sie liefern, denn rein physikalisch ist nicht zu sehen, wie man aus einer Abweichung im globalen Mittel von ein paar Zehntel Grad über einen Zeitraum 18 Jahre auf eine Abweichung derselben von einigen Grad über mehrere Jahrzehnte schließen kann, zumal auch die Modellierung der historischen Daten bis 1750 zurück eine solche große Abweichung nicht zeigen.
————
Hindcasts sollten mit Modell-Tuning nun wirklich keine Kunst sein, aber auch da kann der Verlauf m.E. keine überzeugende Abbildung liefern: Warum gab es in bis 1940 eine so starke Erwärmung, dann eine so lange Abkühlung?
Das Modell von Weiß und Lüdecke versucht dies mit natürlichen Zyklen überlagernder Frequenzen zu erklären und erreicht damit einen besseren Fit. Mit welcher Begründung sollte man überhaupt Modellen trauen, die sowohl hinsichtlich forcasts, als auch hindcasts dagegen empirisch nicht überzeugen konnten?
Und die Erklärung habe ich bereits geliefert: Zu viele Variablen, um ein zuverlässiges GC-Modell zu produzieren, problematische Grid-Sizes und unzureichende Kenntnisse der Atmosphärenphysik – z.B. Wolkenbildung – verknüpft mit chaotischen meteorologischen Systemen machen jeden Versuch, ein zuverlässiges GCM zu entwickeln, von vorne herein aussichtslos.
Wenn Sie nun an die Experten denken, die davon leben … denke ich an den Spruch: Wenn man einen Sumpf trocken legen will, muss man nicht die Frösche fragen.
„a)http://tinyurl.com/bso5jkc
oder
b)http://tinyurl.com/bpk4yqw
beides kann nicht gleichzeitig richtig sein,
entweder a) oder b)“
Sehr geehrter Herr Dr. Paul,
Sie sind wirklich Ihr Geld wert – klasse!
Ich würde noch ein Stück weiter gehen:
Man sieht Abhängigkeit der Strahlungsstärke von der Temperatur (Nov, Dez, Jan)
Würde CO2 tatsächlich strahlen, würde sich der daraus resultierende Strahlungsanteil zur Graukörperstrahlung der Wolken DAZU ADDIEREN.
Die zur Hypothese (Achtung: Heinzow;-) ) der AGW-Pappnasen passende Kurve der am Boden gemessenen Werte müßte also eine entsprechende Ausbuchtung nach oben ausweisen, da zusätzliche Strahlungsenergie dazukommt.
Oder sehe ich das falsch?
MfG
-Genauso wie es keine ausgeglichene Strahlungsbilanz am Boden gibt, muß es auch keine ausgeglichene „Strahlungsbilanz“ (Absorpt = Emiss.) im Gas geben.
———
Grund: es stehen andere, konkurrierende Entspannungsmöglichkeiten offen
Sehr geehrter Herr Keks
Dazu LTE: Gemeint is beim Lokalen thermodynamischen Equilibrium, dass sie auf ein beliebig kleines Volumen bei dt -> 0 keinen Energiezuwachs oder Energieabfluss unterstellen. siehe http://tinyurl.com/zk89mb5
Auch Prof. Kramm sagt, dass dies bis zu einer Höhe von 60 km gegeben ist.
Wenn sie sich spezielle Prozesse anschauen, wie z.B. die Konvektion oder Evaporation, hilft diese Annahme nicht weiter, aber bei dt -> 0 trifft sie auch dann zu.
—————- #119: besso keks sagt:
—————-
Das beste Beispiel ist wie schon häufig erwähnt die Nordlichtstrahlung durch O2, die unter einer bestimmten Höhe aufhört.
Ich denke, das Nordlichter im Sonnenwind sehr speziell sind, und darum hier eher verwirren als erklären.
—————- #119: besso keks sagt:
—————-
-Es gibt keine feste Zeit, das ist richtig.
Aber es gibt eine Mindestzeit, die ein Molekül angeregt sein muß, bevor es abstrahlen kann.
Hier wäre ich für eine Quellangabe dankbar.
—————- #119: besso keks sagt:
—————-
-Es ist richtig, daß alle absorbierte Strahlungsenergie erst mal thermalisiert wird.
Es gibt aber keinen Beweis dafür, daß die durch Stoß übertragene Energie ausreicht ein Elektron anzuheben.
Es wird unterschieden zwischen elastischen und nicht-elastischen Stößen.
Der Begriff des ‚thermalisieren‘ wird oft in unterschiedlicher Bedeutung verwendet. Gemeint ist hier wohl, dass die Wärme = Kinetische Energie der Moleküle durch Absorption ansteigt und durch Emission absinkt. Absorption nd Emission ereignen sich nicht instantan.
—————- #119: besso keks sagt:
„Wie kommen Sie da drauf? Welche Messung sollte das sein? Aus der Graphik geht nicht hervor, wie die Transmissivität ermittelt wurde. Entsprechend ist auf der y-Achse die Transmission, nicht die Amplitude der gemessenen Frequenz aufgetragen.“
Nun, wenn sie Null ist, so konnte nichts gemessen werden.
—————-
Das Photon trägt ja keinen Herkunftsnachweis mit sich.
Meine Frage bezieht sich darauf, wie sie eine 0-Messung behaupten. Ich sehe hier nichts, worauf sich diese Behauptung bezieht.
—————- #119: besso keks sagt:
„Wenn hier überhaupt eine Messung dahinter steht, würde ich vermuten, dass man die Eigenstrahlung des CO2 und anderer IR-aktiver Komponenten heraus gerechnet hat, so wie man auch bei einer Gewichtsmessung das Tara herausrechnet.“
Wie will man diese „herausrechnen“?
—————-
Nur ein Beipiel eines Gedankenexperimentes in 2 Varianten:
1. Stellen sie sich eine breitbandige Strahlenquelle mit einem definierten Frequenzspektrum vor: Diese können si im Vakuum oder in unmittelbarer Nähe zur Quelle mesen. Diese sei von einem definierten Abstand zum Detektor im Medium und zunächst einer Isolation getrennt. Der Detektor misst zuerst das Spektrum ohne die Strahlenquelle. Dann wird die Isolation entfernt und zeitnah das neue Spektrum gemessen. Die Differenz ergibt die Tranmission.
2. Anstelle einer breitbandigen Strahlenquelle können sie auch ine monchromatische Strahlenquelle, die jedoch variabel ist, verwenden, dann reduziert sich der Messaufwand am Detektor.
—————- #119: besso keks sagt:
„Wenn sie gemessene Spektrogramme betrachten, in denen die Amplitudenhöhe zu unterschiedlichen Bedingungen frequenzabhängig gemessen werden, werden sie erhebliche Unterschiede auf den ersten Blick erkennen. Da ist dann auch stets eine deutliche Amplitude bei 15µm erkennbar. “
Dann kann man ja auch die Gegenstrahlungsleistung im 15µm Band messen.
—————-
In Watt/qm zum Beispiel. Soweit ich informiert bin, gibt es diese Messungen nicht.
Sehr interessant, nicht wahr?
Ich wüsste jetzt nicht was daran interessant ist, dasss sie einiges nicht wissen. Das geht vielen leuten so. Einige erwerben sich darum dieses Wissen. Schauen sie sich die Spektrogramme an!
Z.B. http://tinyurl.com/3uumw4c Abbildung 4 für das 4,2 µm Band. Das ist analog genau so für das 15µm Band.
—————- #119: besso keks sagt:
—————-
—–
—–
Laut Herrn Holtz beträgt die mittlere freie Weglänge bei 400 ppm 16m.
D.h. nur Strahlung, die in im Raumvolumen mit 16m Höhe (nach Ihrer Vorstellung) durch Stoß generiert wird, kann den Boden erreichen.
Der Begriff ‚mittlere freie Weglänge‘ ist hier irreführend. Besser ist hier die Extinktion zu verwenden. Heinz Hug hat dies experimentell bestimmt und vorgerechnet in: http://tinyurl.com/jbvlkl2
„Dies entspricht einer Transmission von T = 10^-3.21 = 0,6 Promille. Mit anderen Worten: Bereits nach 10 m sind 1 – T = 99,94% der IR-Strahlung absorbiert.
Das entspricht reziprok auch der Gegenstrahlung: Das Meiste der Gegenstahlung stammt aus dem ersten Meter. Das, was in 10 m Höhe abgestrahlt wird, wird auf dem Weg zur Oberfläche zu 99,94% absorbiert.
—————- #119: besso keks sagt:
—————-
Können Sie die resultierende, am Boden ankommende Strahlungsleistung in W/qm mir bzw. uns mal bitte vorrechnen?
Die Rechnung ist ein wenig komplizierter, da sehr viele wechselwirkung zwischen Absorption und Emission statt findet, und dies Frequenzspezisch jeweils neu zu berechnen ist. Dafür gibt es entsprechende Modelle wie MODTRAN http://tinyurl.com/pg3bd8p
Man kann zwe vesrchiedene Szenarien miteinander vergleichen. Das Standard-Szenario in den Tropen geht von 400 ppm CO2 aus. Man kann dann die Höhe auf 0 km setzen und ‚Looking up‘ wählen. Dies kann man sich dann mit Button ‚Save This Run to Background‘ merken.
Für den zweiten Lauf rechenen wir mal mit 0 ppm CO2, aber sonst gleichen Einstellungen – Ergebnis:
Downward IR Heat Flux 340.69 W/m2
IR Heat Loss (Background) 347.91 W/m2
… Difference, New – BG -7.22 W/m2
Die direkte Gegenstrahlung auf die Oberfläche ist allerdings nur ein relativ kleiner Anteil
Wenn man diese Unterscheide an der Tropopause ( angesetzt mit 18 km Höhe ) vergleicht, kommt man zu einer entsprechend größeren Differenz:
Upward IR Heat Flux 324.676 W/m2
IR Heat Loss (Background) 289.51 W/m2
… Difference, New – BG 35.17 W/m2
Ground Temperature 299.7 K
Skalierungsumrechnung:
Wellenlänge [µm] entspricht
10.000 / Wellenzahl [1/cm]
Der gestrichelte Bereich liegt also
zwischen 16,7µm (600/cm) und 13,3µm (750/cm)
Landvoigt bitte NICHT antworten!
mfG
stelle ich die Frage an alle anderen, die auch nur ein kleines bischen an einen CO2-Treibhaus Effekt glauben, das ist jetzt nicht negativ gemeint, viele sind ja verunsichert:
Die Frage lautete:
„Eine von den beiden „Strahlungsmessungen“ muss falsch sein, es kann nicht beides gleichzeitig existieren.“
nehmen wir zur besseren Vergleichbarkeit
zwei andere Strahlungsmessungen,
mit der GLEICHEN Messtechnik,
beide vom GLEICHEN US- Atmospheric Radiation Measurement (ARM) Program
a)http://tinyurl.com/bso5jkc
oder
b)http://tinyurl.com/bpk4yqw
beides kann nicht gleichzeitig richtig sein,
entweder a) oder b)
Die Antwort habe ich schon in 117 gegeben.
In a) sieht man sehr schön, dass eigentlich nur die Wolken strahlen (was auch die Strahlenphysik verlangt). Sie sind KEINE selektiven Strahler.
Trotzdem führt die fehlende Transparenz der Luft zwischen Wolke und Erdoberfläche zu einem FEHLEN der 15µm-Strahlung.
Transparenz = 0
keine 15µm-Strahlung
wie hier:
http://tinyurl.com/q987lyc
Es wird mir zu bunt. Auf ihre impertinenten Postings werde ich i.d.R. nicht antworten und mir lediglich vorbehalten, einige Ihrer Falschaussagen richtig zu stellen. In Gänze allerdings wäre dies ein Sisyphos-Arbeit.
Meines Erachtens sind es Leute wie Sie, die mit fortwährendem Insistieren auf Unsinnsbehauptungen den Ruf von EIKE nachhaltig schädigen und keinerlei Erkenntnisfortschritt zeigen.
„Es ist mir zu absurd, irgend welche der Arbeiten zu zitieren, die den Hiatus der Erwärmung erklären wollten.“
Ok, Sie sehen den „Hiatus über 18 Jahre“ als Indikator. Nun, dann zitieren Sie bitte mindestens drei wissenschaftlichen paper, die aufgrund des Hiatus zum Schluß kommen, daß die Fehlergrenzen in den Projektionen für die kommenden 100 Jahre größer sein müssen als z.B. in den letzten IPCC reports. Und zwar so groß, daß eine kritische Erwärmung (z.B. mehr als 2 Grad bis 2100 wärmer als heute) bei konstanter bzw. ansteigender Treibhausgasmenge nicht mehr signifikant impliziert werden kann. Wenn Sie das nicht können, so werte ich Ihre Aussage als vorlaut und naiv unwissend.
„Oder haben sie hierfür eine Erklärung die auch tragfähig ist?“
Die müssen Sie liefern, denn rein physikalisch ist nicht zu sehen, wie man aus einer Abweichung im globalen Mittel von ein paar Zehntel Grad über einen Zeitraum 18 Jahre auf eine Abweichung derselben von einigen Grad über mehrere Jahrzehnte schließen kann, zumal auch die Modellierung der historischen Daten bis 1750 zurück eine solche große Abweichung nicht zeigen.
„ad hominem“ heißt, dass Sie statt auf Sachfragen zu antworten hier versuchen meine Person abzuwerten mit falschen Unterstellungen! Und nicht zum ersten mal, sondern in permanenter Wiederholung!
Verstoß gegen die Forenregeln 2,3,4
Die Frage lautete:
„Eine von den beiden „Strahlungsmessungen“ muss falsch sein, es kann nicht beides gleichzeitig existieren.“
mfG
„Also noch mal: Was genau meinen Sie? Vergleichen Sie vielleicht Äpfel mit Birnen?“
Sehr geehrter Herr Landvoigt,
Ein wesentliches Element der Naturwissenschaften ist die Nachvollziehbarkeit und Überprüfbarkeit der Ergebnisse. Ich habe die MODTRAN-Version
http://forecast.uchicago.edu/Projects/modtran.orig.html verwendet. Eingangsparameter: Tropical atmosphere, vapor standard, 400 ppm CO2, 1,8 ppm CH4, NOAA Cirrus model. –> Submit the calculation –> View the whole output file. In der 8. letzten Zeile findet man eine „Average transmittance“ von 0,1263 = 13%
„Tatsächlich kann eine Relaxation einer Anregung durch unterschiedliche Effekte erreicht werden. Allerdings muss beachtet werden, dass es keine Festen Zeiten gibt, nachdem eine Emission erfolgt, sondern eine Verteilungsfunktion. Diese aber wird nicht durch die Stoß-Relaxation reduziert, denn in etwa gleichem Maße, in dem eine Stoß-Relaxation erfolgt, erfolgt auch eine Stoß Anregung – unter LTE. Also ein Nullsummen-Spiel.“
Lieber Herr Landvoigt,
diese Aussage kann ich nicht nachvollziehen.
-Genauso wie es keine ausgeglichene Strahlungsbilanz am Boden gibt, muß es auch keine ausgeglichene „Strahlungsbilanz“ (Absorpt = Emiss.) im Gas geben.
Grund: es stehen andere, konkurrierende Entspannungsmöglichkeiten offen
Das beste Beispiel ist wie schon häufig erwähnt die Nordlichtstrahlung durch O2, die unter einer bestimmten Höhe aufhört.
-Es gibt keine feste Zeit, das ist richtig.
Aber es gibt eine Mindestzeit, die ein Molekül angeregt sein muß, bevor es abstrahlen kann.
-Es ist richtig, daß alle absorbierte Strahlungsenergie erst mal thermalisiert wird.
Es gibt aber keinen Beweis dafür, daß die durch Stoß übertragene Energie ausreicht ein Elektron anzuheben. Siehe auch das Beispiel Sauerstoff/Nordlicht
„Wie kommen Sie da drauf? Welche Messung sollte das sein? Aus der Graphik geht nicht hervor, wie die Transmissivität ermittelt wurde. Entsprechend ist auf der y-Achse die Transmission, nicht die Amplitude der gemessenen Frequenz aufgetragen.“
Nun, wenn sie Null ist, so konnte nichts gemessen werden.
Das Photon trägt ja keinen Herkunftsnachweis mit sich.
„Wenn hier überhaupt eine Messung dahinter steht, würde ich vermuten, dass man die Eigenstrahlung des CO2 und anderer IR-aktiver Komponenten heraus gerechnet hat, so wie man auch bei einer Gewichtsmessung das Tara herausrechnet.“
Wie will man diese „herausrechnen“?
„Wenn sie gemessene Spektrogramme betrachten, in denen die Amplitudenhöhe zu unterschiedlichen Bedingungen frequenzabhängig gemessen werden, werden sie erhebliche Unterschiede auf den ersten Blick erkennen. Da ist dann auch stets eine deutliche Amplitude bei 15µm erkennbar. “
Dann kann man ja auch die Gegenstrahlungsleistung im 15µm Band messen.
In Watt/qm zum Beispiel. Soweit ich informiert bin, gibt es diese Messungen nicht.
Sehr interessant, nicht wahr?
Laut Herrn Holtz beträgt die mittlere freie Weglänge bei 400 ppm 16m.
D.h. nur Strahlung, die in im Raumvolumen mit 16m Höhe (nach Ihrer Vorstellung) durch Stoß generiert wird, kann den Boden erreichen.
Können Sie die resultierende, am Boden ankommende Strahlungsleistung in W/qm mir bzw. uns mal bitte vorrechnen?
Mfg
Ich erkläre Ihnen nun nicht, was ‚ad hominem‘ heißt, dass Sie hier falsch anwenden. Sie belegen damit lediglich, dass Sie selbst einfache Grundbegriffe nicht korrekt verwenden.
Ferner behaupten Sie, dass Sie sich auf eine ‚Strahlungsmessung‘ bezogen hätten. Das ist nicht korrekt. Sie haben lediglich auf ein Diagramm verwiesen, das die Transmissivität angibt ohne zu zeigen, wie diese ermittelt wurde.
Sie sind die Erklärung schuldig geblieben, ob sie denn tatsächlich das Kirchhoffsche Strahlungsgesetz bestreiten oder nicht. Genau das habe ich aus Ihrer Behauptung hergeleitet, dass es keine Gegenstrahlung gäbe.
Wenn ja: Worüber regen Sie sich auf?
Wenn nein: Wie können Sie dann die Gegenstrahlung bestreiten?
die Treibhausvertreter,
hier der Vielschreiber Landvoigt,
bestehen immer noch auf der immaginären Gegenstrahlung,
müssten also den Gegenstrahlungshähnchengrill verwirklichen können.
Können sie nur nicht,
wie peinlich.
Mit der Sonne war das schon im 18.Jahrhundert möglich, 1767 von Horace Bénédict de Saussure
http://tinyurl.com/q987lyc
Die Transmission wird üblicherweise mit dem numerischen Wert zwischen 0 und 1 angegeben,
gelegentlich auch in % zwischen 0 und 100%
Ein „Amplitude“ (Landvoigt) als Transmissionskriterium ist völlig abwegig und zeigt einmal mehr das (vorsätzliche) physikalische Chaos dieses Forentrolls.
Seine Reaktion zeigt aber,
nicht nur der Pyrgemeter ist institutioneller Betrug,
sondern auch die CO2-Strahlungsmessung mit dem FTIR-Spektrometer.
Ein Blick auf so ein Diagramm zeigt schon, dass es sich hier um eine „Differenzmessung“ handelt,
also ein EXAKTES SPIEGELBILD der Transmission.
In so einem „Messgerät“ befinden sich zwei Schwarzkörperstrahler.
SCHWARZKÖRPERSTRAHLER.
Deren Spektrum wird „verglichen“ mit der dort vorhandenen Transmission durch die Luft
und anschließend wird die Schwarzkörperstrahlung davon subtrahiert.
Übrig bleiben dann die nicht strahlenden Frequenzen, die dann zur Strahlung erklärt werden.
Für so etwas gibt der Staat Geld aus!
Vorsätzlicher Betrug.
mfG
„Eine von den beiden „Strahlungsmessungen“
muss falsch sein, es kann nicht beides gleichzeitig existieren.“
… war die einfache Frage.
hic rhodos, hic salta
%= 100*thermische Abstrahlung der Erdoberfläche TOA (W/m^2)/thermische Abstrahlung der Erdoberfläche insgesamt (W/m^2)
…
—————-
(4) MODTRAN Average transmittance at h=0km: Tropics 12%, MidLatSum 16%, MidLatWin 24%, SubArctSum 19%, SubArctWin 27%: gewichtetes Mittel 18%
Sehr geehrter Herr Berberich:
Es bleibt mir noch immer nicht ganz klar, was sie meinen. Denn Transmission ist m.E, die Abstrahlung im atmosphärischen Fenster. Eine Absorbtion und Re-Emission ist nach meinem Verständnis keine Transmission.
Wenn sie also meinen: Bodenabstrahlung im Verhältnis zur Abstrahlung an TOA dann kann ich das versuchen, nachzuvollziehen.
Modtran weist die Prozentzahlen nicht direkt aus, aber man kann diese hinsichtlich der Ergebnisse vergleichen:
Beispiel tropische Atmosphäre ohne Wolken bei 400 ppm CO2 (Grundeinstellung)
In 100 km Höhe (TOA) 289.225 W/m2
Auf Bodenhöhe 417.306 W/m2
Differenz 128.08 W/m2
Das sind offensichtlich nicht die von Ihnen genannten 12 %.
Also noch mal: Was genau meinen Sie? Vergleichen Sie vielleicht Äpfel mit Birnen?
Ich glaube nicht, dass es sinnvoll ist, ihnen haarklein die Grundlagen der Physik darzulegen. Bereits zu den Anfangsgründen weigern sie sich, diese anzuerkennen, z.B. das Kirchhoffsches Strahlungsgesetz. Diese sind aber Voraussetzung für jede fachlich weitergehende Diskussion.
Ich frage mich zwei Dinge:
————–
1.Es wird hier immer wieder betont, strahlungsfähige Gase müßten auch „strahlen“.
Ist es nicht so, daß sie statt dessen „entspannen“ m ü s s e n?
Und diese Entspannung a u c h durch Strahlung geschehen kann, aber nicht m u ß ?
Sehr geehrter Herr Keks
Die Frage ist korrekt und bezieht sich auf das Jablonski-Schema.
Tatsächlich kann eine Relaxation einer Anregung durch unterschiedliche Effekte erreicht werden. Allerdings muss beachtet werden, dass es keine Festen Zeiten gibt, nachdem eine Emission erfolgt, sondern eine Verteilungsfunktion. Diese aber wird nicht durch die Stoß-Relaxation reduziert, denn in etwa gleichem Maße, in dem eine Stoß-Relaxation erfolgt, erfolgt auch eine Stoß Anregung – unter LTE. Also ein Nullsummen-Spiel.
Darum kann man diese Effekte weitgehend vernachlässigen. Und darum ist der Absorbtionskoeffizient gleich zum Emissionskoeffizient.
————– #110: besso keks sagt:
————-
2.Was das Chart von Dr. Paul anbelangt:
es zeigt im 15µm-Bereich die Strahlungsstärke „0“.
Wie kommen Sie da drauf? Welche Messung sollte das sein? Aus der Graphik geht nicht hervor, wie die Transmissivität ermittelt wurde. Entsprechend ist auf der y-Achse die Transmission, nicht die Amplitude der gemessenen Frequenz aufgetragen.
Wenn hier überhaupt eine Messung dahinter steht, würde ich vermuten, dass man die Eigenstrahlung des CO2 und anderer IR-aktiver Komponenten heraus gerechnet hat, so wie man auch bei einer Gewichtsmessung das Tara herausrechnet.
————– #110: besso keks sagt:
————–
Das Messgerät kann nicht sagen, woher ein 15µm-Photon stammt:
-Ist es originär vom Sender emittiert oder von einem CO2-Molekül reemittiert?
-Oder stammt es aus der (angeblichen) Eigenstrahlung des CO2-Feldes aufgrund dessen Temperatur?
Es sieht nur keine Strahlung. Also ist da keine.
Wenn sie gemessene Spektrogramme betrachten, in denen die Amplitudenhöhe zu unterschiedlichen Bedingungen frequenzabhängig gemessen werden, werden sie erhebliche Unterschiede auf den ersten Blick erkennen. Da ist dann auch stets eine deutliche Amplitude bei 15µm erkennbar.
Es ist bei der Interpretation von Graphiken stets auf die Aussage zu achten. Wenn man eine Grafik falsch lesen will, kann man auch ein Schnittmuster für Kleidungsstücke als Straßenkarte auffassen.
Die Moleküle absorbieren und emittieren bei der gleichen Frequenz: Doppler-Effekt und Stoßverbreiterung sind vernachlässigbar.
———–
Sehr geehrter Herr Berberich,
Das Thema Linienbreite ist in der Tat komplex und leicht missverständlich. Ihr Urteil aber scheint nicht der Literatur zu entsprechen. Ich verweise hier auf:
http://tinyurl.com/j8hhvzf
Dieser Text erklärt den Zusammenhang sehr gut und schreibt:
‚Bei Gasen mit niedrigem Druck ist die Dopplerverbreiterung die dominierende Ursache
der beobachteten Linienbreite.‘ S.27
Die Einschränkung besteht, denn die Stoßverbreiterung ist bei höherem Druck dominierend.
Ohne den Formelapparat bis ins letzte verstehen zu wollen, geht es mir um eine Vorstellung, wie entsprechende Messungen zu deuten sind. Darum in meinen Worten:
Die jeweiligen Emissions- und Absorptionslinien sind extrem dünn und sehr geringer natürlicher Breite – darum spricht man auch von Linien. In der Natur – auch beim CO2 beobachtet man dagegen Bänder beachtlicher Breite. Diese stellen allerdings nicht einfache Ergebnisse jener Druckverbreiterungen dar, sondern sind verschmolzene Linienscharen. Mit abnehmendem Druck werden die einzelnen Linien weniger breit, so dass dies im Frequenzspektrum erkennbar werden. Demnach ist die Stoßverbreiterung ein wesentliches Merkmal der zu beobachtenden Spektren und keineswegs vernachlässigbar.
Siehe auch http://tinyurl.com/kxuvk7q
und http://tinyurl.com/hrx82pe
können Sie nun Ihre Behauptungen belegen, daß GCM Ergebnisse und Klima-Beobachtugen über einen Zeitraum der letzten 250 Jahre systematische Abweichungen zeigen? Ich habe Sie um mindestens drei wissenschaftliche paper gebeten, die zu dieser Aussage kommen. Wenn Sie das nicht können, so werte ich Ihre Aussage als vorlaut und naiv unwissend.
—————
Sehr geehrter Herr Baecker
Es ist mir zu absurd, irgend welche der Arbeiten zu zitieren, die den Hiatus der Erwärmung erklären wollten. Tatsache ist, dass die CGMs keinen Hiatus über 18 Jahre prognostizierten. Oder haben sie hierfür eine Erklärung die auch tragfähig ist?
„Wie kommen Sie bei einer Transmission gleich null darauf, dass keine Strahlung emittiert werden kann?“
Sehr geehrter Herr Holtz,
bitte entschuldigen Sie, wenn ich mich hier einmische (kann mich auf Grund persönlicher Rahmenbedingungen z.Z. leider nicht an der Diskussion hier beteiligen, habe aber eben mal ein paar Minuten)
Grundsätzlich:
Transmission = Durchlässigkeit eines Mediums für die Übertragung von Wellen wie Schall oder Licht (Wiki)
Ich frage mich zwei Dinge:
1.Es wird hier immer wieder betont, strahlungsfähige Gase müßten auch „strahlen“.
Ist es nicht so, daß sie statt dessen „entspannen“ m ü s s e n?
Und diese Entspannung a u c h durch Strahlung geschehen kann, aber nicht m u ß ?
2.Was das Chart von Dr. Paul anbelangt:
es zeigt im 15µm-Bereich die Strahlungsstärke „0“.
Das Messgerät kann nicht sagen, woher ein 15µm-Photon stammt:
-Ist es originär vom Sender emittiert oder von einem CO2-Molekül reemittiert?
-Oder stammt es aus der (angeblichen) Eigenstrahlung des CO2-Feldes aufgrund dessen Temperatur?
Es sieht nur keine Strahlung. Also ist da keine.
Ich würde Ihrer Argumentation zustimmen, wäre außerhalb der freien Weglänge (z.B. in 100m Höhe) ein Sender, der im 15µm-Bereich Richtung Boden pulsen wurde und dieses Pulsen innerhalb der freien Weglänge identifiziert werden könnte und nach einem Vielfachen der freien Weglänge als konstanteres Signal (Absorption und Reemission würden das Signal immer mehr glätten und schwächen) den Boden erreichen würde und so gemessen werden könnte.
Nur, da ist nichts.
Also wird weder was emittiert noch was reemittiert…
Was sehe ich da nicht richtig?
MfG
Sie können einfache Fragen wieder nicht beantworten und flüchten hilflos in nicht genanntes „Lehrbuchwissen“
und,
das ist noch weniger akzeptabel,
in abwertende Polemik wie „Privattheorie“.
Selbst bei Zitaten der IPCC oder einem bekannten Treibhaus-blog (CO2-cooling rate) sprechen völlig hilflos von meiner Privatmeinung!
Ein Regelverstoß! Mehr fällt Ihnen nicht ein?
Merke:
Eine Messung ist keine Therorie
und die Messung, die Ihnen nicht passt, stammt nicht von mir!
Merke:
THERMALISIERUNG VON STRAHLUNG IST LEHRBUCHWISSEN eigentlich schon bekannt seit 1767 von Horace Bénédict de Saussure, der die solar betriebene Kochkisten erfunden hat, übrigens auch von dem bekannt gründlichen Gerlich erwähnt, gegen den Sie auch meinen, nebulös anstinken zu dürfen. Nach Ihrer FALSCHEN physikalischen Vorstellung (Einstrahlung=Ausstrahlung) müsste die Kochkiste kalt bleiben.
Und auch Sätze wie diese,
Zitat: „Sie sind nicht auf ein Pyrgeometer angewiesen,“
zeigen Ihre Agenda überdeutlich, Sie decken hier auf EIKE vorsätzlichen Betrug.
Hinter Ihnen versteckt sich offensichtlich ein back-office-team, was mich zum Schweigen bringen möchte. Aber gerade über Betrug, der uns Bürger viel Geld kostet, muss man reden,
nich schweigen, Herr Martin Landvoigt !
Wenn Sie mir jetzt den Knochen FTIR-Spektrometer als „Gegenargument“ vor die Füße werfen,
ein Gegenargument zur fehlenden 15µm-Strahlung,
begeben Sie sich dummerweise wieder auf Glatteis, genau wie beim Pyrgeometer.
Wissen Sie denn, wie der funktioniert, wahrscheinlich wollen Sie darüber nicht reden, oder?
Jetzt fragen Sie doch einfach mal ihr kluges back-office,
welche von beiden MESSUNGEN denn gelogen sein muss.
diese:
http://tinyurl.com/q987lyc
oder Ihre
alternative FTIR-Spektrometer-Messung.
Oder wollen Sie uns zumuten zu glauben,
eine 15µm Strahlung kann GLEICHZEITIG
nicht existieren oder doch existieren???
Zuzutrauen ist den Treibhauskünstlern ja alles.
Etwas ähnliches habe ich Sie ja bereit beim „CO2-Trichter“ gefragt,
der nach Meinung der Treibhauskünstler ja nur in eine Richtung wirken darf.
Nach oben ja, nach unten nein,
Kindergartenphysik also und vorsätzlicher,
staatlich unterstützter institutioneller Betrug.
Und stellen Sie keine Ersatzfragen, sondern antworte Sie mal
und kneifen Sie nicht wieder.
Eine von den beiden „Strahlungsmessungen“
muss falsch sein, es kann nicht beides gleichzeitig existieren.
Es kann auch kein Beweis für den CO2-Treibhauseffekt sein, wenn es kälter wird.
mfG
„Viel wichtiger als das was Professoren sagen ist es zu verstehen, dass aus Transmission = Null
Nicht folgt, dass es keine Emission gibt. Im Gegenteil Transmission gleich Null in einem Wellenlängenbereich und in einem Temperaturbereich in dem Zustände thermisch angeregt werden können bedeutet eine signifikante Eigenemission.“
Bei der Diskussion von Emission und Absorption IR aktiver Moleküle in der Atmosphäre wird das Phänomen der spektralen Diffusion meist vernachlässigt. Die Moleküle absorbieren und emittieren bei der gleichen Frequenz: Doppler-Effekt und Stoßverbreiterung sind vernachlässigbar. Temporäre Clusterbildung gibt es nicht. Die breitbandige Absorption und Emission von Aerosolen, Eiskristallen und Wassertropfen ist vernachlässigbar. Eine wunderbar einfaches Modell.
„Diese Aussage kann ich nicht nachvollziehen. Worauf beziehen sich die Prozentangaben?“
Sehr geehrter Herr Landvoigt:
%= 100*thermische Abstrahlung der Erdoberfläche TOA (W/m^2)/thermische Abstrahlung der Erdoberfläche insgesamt (W/m^2)
(„All sky“)
(1) Roedel 2000, Physik unserer Umwelt (S.51): 20,5/373= 5,5%
(2) Trenberth 2009, Earth’s Global Energy Budget: 40/396= 10,1%
(3) Stephens 2012, An update on Earth’s energy balance in light of the latest global observations: 20/398= 5,0%
(4) MODTRAN Average transmittance at h=0km: Tropics 12%, MidLatSum 16%, MidLatWin 24%, SubArctSum 19%, SubArctWin 27%: gewichtetes Mittel 18%
können Sie nun Ihre Behauptungen belegen, daß GCM Ergebnisse und Klima-Beobachtugen über einen Zeitraum der letzten 250 Jahre systematische Abweichungen zeigen? Ich habe Sie um mindestens drei wissenschaftliche paper gebeten, die zu dieser Aussage kommen. Wenn Sie das nicht können, so werte ich Ihre Aussage als vorlaut und naiv unwissend.
#98: Admin, es ist die mehrfach gestellte SACHLICHE Frage wie diese hochempfindlichen Strahlendetektoren
—————–
http://tinyurl.com/cvrssgr
CO2 -Emissionen IGNORIEREN sollen!!!
Da Sie abermals fragen, noch mal eine Erklärung: In Ihrem Link steht ein Diagramm zur Durchlässigkeit der Atmosphäre – siehe auch http://tinyurl.com/jrdby6g . Es ist an dem Diagramm nicht erkennbar, wie es erstellt wurde Ob es überhaupt gemessen oder errechnet wurde, ist hieran nicht erkennbar. Offensichtlich haben sie die Geschichte von den Instrumenten dazu erfunden, zumindest bleibt sie unbelegt. Auch wäre es falsch, wenn Transmissivität dargestellt werden soll, dass dann Eigenstrahlung abgebildet würde. Ich gehe darum davon aus dass Sie schlicht die Grafik falsch interpretieren.
———– #101: Dr.Paul sagt:
———–
Auch der Versuch einfach eine Temperatur der Luft als Strahlungsquelle zu bezeichnen ist grobe VORSÄTZLICHE Fälschung (Pyrgeometer).
Sie sind nicht auf ein Pyrgeometer angewiesen, wenn sie die Strahlung der Luft messen wollen. Dazu eignen sich auch FTIR-Spektrometer. Aber auch das sollten Sie aus unzähligen Postings bereits wissen.
———– #101: Dr.Paul sagt:
———–
Und beachten Sie welche Entgleisungen sich Herr Landvoigt gegen Andersdenkende erlaubt, OHNE das sachlich zu begründen.
Es wäre schon ein Schritt weiter, wenn Sie benennen würden, was sie überhaupt für eine Entgleisung halten. Ich tappe hier völlig im Dunkeln.
———– #101: Dr.Paul sagt:
———–
Und erst wenn diese Transparenz NICHT mehr 0 ist, (in der Stratosphäre) ist die Moleküldichte der Luft so stark gesunken, dass die Zeit für die CO2-Moleküle reicht auch mit der Emission von Strahlung zu beginnen, soweit sie aktiviert sind.
Sie haben sich eine private Physik gebastelt, die weder durch Empirie und Lehrbücher bestätigt wird, und die auch nicht von den Professoren unterstützt wirf, die sie gerne als Zeugen benennen. Z.B. hat Prof. Kramm ausdrücklich die Strahlungstranportgleichung bestätigt.
In den 2. Regel für Beiträge lese ich: ‚Auch lange Präsentationen von Amateur-Theorien bitten wir zu vermeiden.‘ Genau dafür halte ich aber ihre stetiges Insistieren auf Sachverhalte, die nirgends in der Literatur beschrieben sind.
Wie kommen Sie bei einer Transmission gleich null darauf, dass TROTZDEM Strahlung der gleichen Wellenlänge emittiert werden kann?
Sie können das Wunder der nicht messbaren Strahlung also nicht erklären?
Noch einmal,
wie soll bitte das Messgerät „transmittierte“ von „emittierten“ 15µm-Strahlen unterscheiden können???
Haben diese angeblich emittierten Strahlen vielleicht eine Tarnkappe?
Sie können zwar rechnen,
haben aber von Strahlenphysik keine Ahnung.
Wirklich keine Ahnung.
Emission ist keine Spiegelung!!!
Es braucht Zeit, die bekannt ist, bevor eine Molekülschwingung Energie in Form von Strahlung abgeben kann.
Das ist nichts neues !!! „Laserstrahler“ gibt es bekanntlich seit 1960.
Der CO2-Laser, ein Gasplasma-Laser, kein Feststoff, heute noch ein Renner, der übrigens auch in der Medizin verwendet wird, wurde bereits 1964 erfunden und technisch realisiert.
Je stabiler so eine Molekülschwingung ist, desto länger ist diese Zeit, bis eine Spontanemission erfolgt. Das ist alles ausreichend erforscht, sonst gäbe es keine Laser!!!
In der tiefen Atmosphäre ist diese Zeit ZU LANG um eine Spontanemission zu ermöglichen und die Energie für Stoß-induzierte Emission durch Nachbarmoleküle (N2) reicht bei den normalen Temperaturen NICHT aus, um sie auszulösen. Die Atmosphäre ist hier kein Gasplasma.
Absorbierte Strahlung wird daher thermalisiert,
genau das ist der einzige Grund warum die Transparenz für 15µm-Strahlung 0 wird,
nach wenigen 100m ist sie verschwunden.
Die Priorität dieses Vorgangs (Thermalisierung) hängt mit der Häufigkeit der Kollision mit Nachbarmolekülen (N2)zusammen,
also ihrer freien Wegstrecke und ihrer Geschwindigkeit, das können Sie gerne ausrechnen.
Auch beim CO2-Laser ist N2 im „Plasma“ ein wesentlicher Bestandteil, freie Elektronen schaffen das nicht.
Ich halte Sie für intelligent genug um den Begriff der Thermalisierung, der hier schon oft genug exakt erklärt wurde selbst zu recherchieren.
Deshalb ist es auch kein Unsinn, wenn in der Stratosphäre diese freie Wegstrecke so groß wird, dass Emission (zeitlich) wieder möglich wird und auch GEMESSEN werden kann,
mit einem ersten Maximum ca. in 50.km Höhe.
Das sind dann die infrared-cooling-rates, vom Satellit messbar
http://tinyurl.com/ccqjv38
(ein Treibhaus-blog! dem müssen Sie doch glauben)
Diese Strahlung erreicht noch viel weniger die Erdoberfläche, wie die 15µm-Strahlung der Erdoberfläche das Weltall erreichen kann.
mfG
Zitat: Na klar stört die Transparenz von 0 für 15µm die Treibhaustheorie mächtig, sie kann nicht geleugnet werden.
Zitat: Und erst wenn diese Transparenz NICHT mehr 0 ist, (in der Stratosphäre) ist die Moleküldichte der Luft so stark gesunken, dass die Zeit für die CO2-Moleküle reicht auch mit der Emission von Strahlung zu beginnen, soweit sie aktiviert sind.
So ein grober Unsinn. Wie kommen Sie bei einer Transmission gleich null darauf, dass keine Strahlung emittiert werden kann?
Allgemein gilt: R(n,k) + T(n,k) + E(n,k) + S(n,k) = 1, wenn die Transmission T(n,k) gleich 0 ist, bedeutet das, R(n,k) + E(n,k) + S(n,k) = 1
Natürlich strahlt jedes strahlungsfähige Molekül in der Atmosphäre, dass ist nun mal ein Faktum. Für die Atmosphäre gibt es ebenso auch Absorptions- und Emissionsspektren.
Betrachtet man den effektiven Massenabsorptionskoeffizient um die 15µm-Bande vom reinen CO2 von ka = 16,3 m^2/kg, so ergibt sich eine mittlere freie Weglänge der Strahlung von l(rad,CO2) = 1/(ka*rho) = 50,7*10^-3 m = 50,7 mm. Der effektive Massenabsorptionskoeffizient der Luft mit einem CO2-Gehalt von 400ppmv ist ka(cd) = 0,05 m^2/kg über den IR-Wellenlängenbereich der Atmosphäre bei Standardbedingungen, und damit ergibt sich eine mittlere freie Weglänge der Strahlung von l(rad,CO2 bei 400ppmv) = 1/(ka*rho) = 16,5 m. Das bedeutet, dass der Transmissionsgrad vom CO2 bei 400 ppmv gerechnet auf 1m Schichtdicke T = 0,94 und auf 1km Schichtdicke T = 0 beträgt.
Mfg
Werner Holtz
weil er nicht erklären kann, wie so ein IR Strahlungsdetektor 15µm Strahlung „sortieren“ könnte.
Es wäre sicher ein Fortschritt, wenn alle Diskussionsteilnehmer diese Lehrbuchwissen, das empirisch bestens abgesichert ist, anerkennen würden.
Welches Lehrbuch?
welche empirischen Nachweise? (Messung)
da stockt Landvoigt REGELMÄßIG
Das ist die Empirik:
http://tinyurl.com/cvrssgr
= 0 µm – Wellen
also keine CO2-Strahlung von oben auf die Erdoberfläche!
Landvoigt ist ein Mensch,
der offenbar wirklich glaubt, dass eine am Tag um ca. 80°C KÜHLENDE Atmosphäre erwärmt?????
bitte merken:
80°C KÜHLENDE Atmosphäre
80°C KÜHLENDE Atmosphäre
80°C KÜHLENDE Atmosphäre
80°C KÜHLENDE Atmosphäre
80°C KÜHLENDE Atmosphäre
80°C KÜHLENDE Atmosphäre
80°C KÜHLENDE Atmosphäre
80°C KÜHLENDE Atmosphäre
… die Erdoberfläche erwärmt???
… Strahlung, die NICHT von der Sonne kommt,
die man natürlich nicht messen kann,
besonders im 15µm-Bereich kann man sie nicht messen.
Aber diese nicht messbare 15µm-Strahlung soll die Erdoberfläche erwärmen.
Dann müsste allerdings die materielle Konvektionskühlung noch stärker sein als 80°C.
Da kann man nur noch schallend lachen, wenn das nicht so bösartig wäre.
Die Wärmequelle bleibt die Sonne und nicht die Erdoberfläche und nicht das Spurengasmolekül CO2
NUR DAS SONNENLICHT und keine andere (natürliche) Strahlung schafft gebündelt (Linse) ca.300 Watt/cm2,
Sie haben richtig gelesen cm, nicht Meter.
Das ist etwa doppelt soviel wie z.B. die preisgekrönten Brennerplatten von Schwank für die Gastronomie, womit Sie jedes Hühnchen verkohlen können.
Warum gelingt es dann nicht den überzeugten Gegenstrahlungspredigern nur mit solchen Linsen, ganz ohne Gasbrenner wenigstens ein Hühnchen zu grillen?
Ja warum wohl nicht???
Wo ist denn nun der empirische Nachweis?
Wo steht das denn im Lehrbuch?
Gegestrahlungsvertreter leben in einer wahrhaft kindlichen Phantasiewelt wenn sie nicht VORSÄTZLICH lügen.
mfG
http://tinyurl.com/cvrssgr
CO2 -Emissionen IGNORIEREN sollen!!!
Wie soll das denn technisch physikalisch überhaupt möglich sein,
das möge bitte Herr Günter Heß, Herr Berberich und Herr Landvoigt endlich einmal erklären.
Es ist doch kein Geheimnis, dass die Treibhausvertreter mit Fälschungen arbeiten (müssen) um ihre Hypothese glaubhaft zu machen.
Auch der Versuch einfach eine Temperatur der Luft als Strahlungsquelle zu bezeichnen ist grobe VORSÄTZLICHE Fälschung (Pyrgeometer).
Fälschung muss man Fälschung nennen sonst nimmt das nie ein Ende!!!
Und beachten Sie welche Entgleisungen sich Herr Landvoigt gegen Andersdenkende erlaubt, OHNE das sachlich zu begründen.
Na klar stört die Transparenz von 0 für 15µm die Treibhaustheorie mächtig,
sie kann nicht geleugnet werden.
Es ist doch grotesk dann einfach zu behaupten,
GERADE DESHALB gäbe es so viele 15 µm Strahlung,
einfach eine Frechheit,
und eine kalkulierte Unterstellung der Dummheit des Volkes.
Und erst wenn diese Transparenz NICHT mehr 0 ist, (in der Stratosphäre) ist die Moleküldichte der Luft so stark gesunken, dass die Zeit für die CO2-Moleküle reicht auch mit der Emission von Strahlung zu beginnen, soweit sie aktiviert sind.
mfG
… verstehen, dass aus Transmission = Null
————–
Nicht folgt, dass es keine Emission gibt.
Sehr geehrter Herr Heß
Danke für die Ergänzung. Die Begriffe werden oft genug durcheinander gebracht. Im Atmosphärischen Fenster haben wir Transmission, in den Banden der IR-Aktiven Gasen je nach Weglänge nicht. Die dennoch messbare Strahlung beruht auf emitierter Strahlung der Gase.
————- #94: Günter Heß sagt:
————-
Im Gegenteil Transmission gleich Null in einem Wellenlängenbereich und in einem Temperaturbereich in dem Zustände thermisch angeregt werden können bedeutet eine signifikante Eigenemission.
Es wäre sicher ein Fortschritt, wenn alle Diskussionsteilnehmer diese Lehrbuchwissen, das empirisch bestens abgesichert ist, anerkennen würden.
Hier auf EIKE ist kein Fortschritt in der Diskussion über den atmosphärischen Treibhaus-Effekt zu erkennen.
————–
Sehr geehrter Herr Berberich
Sie haben die falsche Kategorie. Denn Der Kommentarbereich auf EIKE ist eine weitgehend freie Plattform, auf de man den Mitwirkenden wenig Vorschriften machen kann. Wenn sich einige weigern, bestimmte Erkenntnisse und Belege anzuerkennen, sagt das nicht viel über die Plattform oder über andere Mitwirkende. Fortschritte kann in der Regel nur der Einzelne hinsichtlich seiner Erkenntnis erreichen. Ich teile allerdings ihre enttäuschte Erwartung, das auch im Diskussionsverlauf eine Entwicklung erkennbar sein sollte. Dagegen verdichtet sich der eindruck eines perpetuierten Grabenkrieges.
————– #91: P.Berberich sagt:
—————–
Dass Treibhausgase wie Wasserdampf,CO2 oder Methan zu einer Aufheizung der Erdoberfläche führen können sollte nicht mehr bestritten werden. Es ist nur von Interesse wie groß der Effekt ist. Dazu sind Klimamodelle notwendig.
Hierzu meine Zustimmung. Grundsätzlich aber sollte in Frage stehen, ob Modelle, und wenn ja, auf welcher Abstraktionstiefe dazu valide Aussagen machen können.
Der oft zitierte Prof Gerlich und auch Prof. Kramm haben ja eine grundsätzliche Ablehnung im Besonderen der komplexen CGM Modelle, da sie die komplexität weder korrekt, noch hinreichend abbilden können. Auch bei einfacheren Modellen geben sie keine Zustimmung, da sie auch diese für unzureichend halten.
Die Modelle basieren auf gemessenen Parametern wie der z. B. der Sonneneinstrahlung (1), der Reflexion der kurzwelligen Strahlung (Albedo) von Atmosphäre und Oberfläche (2) und der langwelligen Transmission (IR) der Atmosphäre (3). (1) und (2) sind durch Messungen (siehe Ceres Datensätze) gut bekannt, (3) nicht. Die atmosphärische IR-Transmission kann man mithilfe der Ceres-Datensätze berechnen, wenn die Asymmetrie fa der atmosphärischen IR-Strahlung bekannt ist. fa kann man z. B. MODTRAN entnehmen.
Hier gibt es Grenzen. Globale Parameter und statistische Werte lassen sich nur bedingt nachmodellieren, da detaillierte Wirkketten, also der physikalische Zusammenhang oft nur unzureichend verstanden sind. Dies trifft im Besonderen bei der Wolkenbildung zu.
Mit Modtran kann man näherungsweise ein Fi (immidiate Forcing) ermitteln, nicht aber Fa (adjusted Forcing) Allerdings sollte das Fa geringer sein als der Fi Wert.
————- #91: P.Berberich sagt:
————-
Ich finde dann einen Wert von 7% (jährliches globales Mittel), während MODTRAN selbst einen Wert von 18% ergibt.
Diese Aussage kann ich nicht nachvollziehen. Worauf beziehen sich die Prozentangaben?
————- #91: P.Berberich sagt:
————–
Zu betonen ist dass dies keine Messungen sind, sondern in beiden Fällen Ergebnisse von Strahlungs-Transfer-Rechnungen.
Diese Modelle sind zwar immer noch komplex genug, dass Laien Schwierigkeiten haben, sie zu verstehen. Verglichen mit CGMs sind es einfache Modelle, die allerdings den Vorteil der Nachvollziehbarkeit und der empirischen Bestätigung haben. Durch entsprechende Vergleich zwischen gemessenen Spektren und errechneten Spektren können wir hier davon ausgehen, dass auch die anderen errechneten Spektren einer potentiellen Messung weitgehend entsprechen würden.
———— #91: P.Berberich sagt:
————
Die Ergebnisse der Klimamodelle sind so gut wie die Unsicherheit der Eingangsparameter.
Nicht nur, denn die Modell, wie wohl von den Eingangsparametern, sind auch vom Modellaufbau abhängig. Korrekte Eingangsparameter würden bei unzureichender Modellmechanik noch immer keine guten Ergebnisse hervorbringen.
Wie wollen Sie den den Messgeräten beibringen,
dass sie CO2-Moleküle unterscheiden lernen woher sie stammen?
Die Frage konnte noch keiner von Ihnen beantworten.
In der Regel folgt dann immer die saublöde Antwort,
dass die Transmission von 0 gar nicht gemessen wird sondern ERRECHNET wird, ha, ha, ha
Dafür kühlt man dann den Strahlendetektor auf nahe 0K und konzentriert alle Strahlen mit gigantischen Kollektoren etc.
ich kann das nicht mehr hören.
MESSUNGEN werden IGNORIERT von den Treibhausvertretern!
Zitat: Sie finden bestimmt Hunderte oder gar Tausende von solchen „Arbeiten“ …
Na ja, so viele sind es nicht. Ich kenne 5 ausführliche Betrachtungen zu diesem Sachverhalt, wobei die Arbeit von Gerlich und Tscheuschner zu den nicht so detailliert-beschriebenen gehört. Zudem ist die Arbeit von Gerlich und Tscheuschner im amerikanischen Raum nicht so bekannt, deshalb wird sie wenig zitiert.
Und ja, es sind alles Modell-Betrachtung mit „realen Messergebnissen“, leider kann man keinen Mond oder die Erde nachbauen, und ins Labor verfrachten. Auch die „realen Messergebnisse“ werden durch modell-bezogene Betrachtungen gewonnen, das nennt man dann Messvorschrift.
Mfg
Werner Holtz
Zitat: Zudem bestätigen Messergebnisse eher die verbreitete Ansicht, dass dieser Effekt eher mit den 33 K anzusetzen ist.
Das ist eben nicht der Fall. Diese 33K setzen sich aus 15K strahlungs-bedingter und aus 18K thermodynamisch-bedingter Temperatur-Änderung zusammen. Wenn man den Artikel aufmerksam gelesen hätte.
Die Strahlungstemperatur von 255K am TOA setzt sich aus der Abstrahlung direkt vom der Oberfläche mit 68 W/m^2 und der atomsphärischen Abstrahlung von 170 W/m^2 zusammen. Damit ergibt sich eine effektive Strahlungstemperatur der strahlungswirksamen Atmosphäre von ca. 242K.
Mfg
Werner Holtz
die alle Fakten ignorieren und dann noch wie Sie fordern „sollte nicht bestritten werden“.
Besonders kindisch ist daran das Festklammern an Wasser, das nachweislich kühlt.
Denn zur Verdunstung braucht es Energie, die der Erdoberfläche entzogen wird, das weiß auch meine Frau, wenn sie die Terrasse im Sommer nass macht, damit sie sich abkühlt.
Wenn dann „Wärme“ und andere Energie „in die Atmosphäre wandert“ wird eben gerade die Erdoberfläche GEKÜHLT und nicht erwärmt, das hat wirklich etwas mit 1. und 2. HS zu tun!
Und was strahlende Wolken betrifft (Wasserdampf strahlt nicht nach unten) so kühlen sie ebenfalls, weil die die Wärmequelle nun mal die Sonne ist auch das weiß meine Frau, wenn sie auf der Terrasse liegt und es ziehen Wolken auf.
Es sind wirklich des Kaisers neue Kleider und Sie sind so frech und verlangen ohne jeden Nachweis,
man soll des Kaisers neue Kleider bitte nicht bestreiten.
„Strahlung“ erfordert allerdings etwas Physikkenntnisse,
siehe Mond,
selbst der ist kein Schwarzkörper, wenn man denn halt mit S&B noch rechnen könnte, dafür ist er viel zu heiß.
Der allergrößte physikalische Bockmist ist jedoch, die Luft selbst zum Schwarzkörper zu machen.
Das ist organisierter Betrug.
Der sollte eigentlich vor Gericht.
mfG
Viel wichtiger als das was Professoren sagen ist es zu verstehen, dass aus Transmission = Null
Nicht folgt, dass es keine Emission gibt. Im Gegenteil Transmission gleich Null in einem Wellenlängenbereich und in einem Temperaturbereich in dem Zustände thermisch angeregt werden können bedeutet eine signifikante Eigenemission.
Dabei zeigt sich gleichzeitig die Unsinnigkeit von „Durchschnittstemperaturen“,
denn am Tag wird es am Mond ca.80°C wärmer also extrem heiß, max. ca 130°C!!!
was wieder einmal einen strahlungsbedingten Erwärmungseffekt auf der Erde AUSSCHLIEßT!!!
Der Link von Herrn Holz ist wieder mal nur ein Modell das nicht zuende gedacht ist weil diese wichtige Konsequenz einfach nicht ausgesprochen wird. Dabei werden Gedanken von Gerlich übernommen, der nur leider nicht zitiert wird.
mfG
Aber natürlich hat sich dieser Unsinn weit verbreitet. Sie finden bestimmt Hunderte oder gar Tausende von solchen „Arbeiten“, die ihn mehr oder weniger behaupten oder unterstützen. Ich sage es noch mal an dieser Stelle: „Klimawissenschaft“ ist keine Wissenschaft, so einfach ist es. Das alle schlimmste ist aber das, dass sie für politische Zwecke massiv ausgenutzt wird. Sonnst hat es niemanden interessiert.
Hier zum Nachlesen und Nachrechnen:
———————
On the average temperature of airless spherical bodies and the magnitude of Earth’s atmospheric thermal effect – Den Volokinand Lark ReLlez
http://tinyurl.com/zagu99h
Sehr geehrter Herr Holtz das steht so ziemlich genau so in der disputierten Arbeit von Gerlich und Tscheuschner. http://arxiv.org/abs/0707.1161
Diese Berechnung ist zwar nachvollziehbar, und wurde ebenso von Prof. Kramm vorgetragen, hat aber auch einiges an Diskussion hinter sich: Denn zum einen ist es ein vereinfachtes Modell, das Wärmekapazitäten im Kontext des rotierenden Körpers nicht hinreichend berücksichtigt. Zudem bestätigen Messergebnisse eher die verbreitete Ansicht, dass dieser Effekt eher mit den 33 K anzusetzen ist.
Wichtig aber bleibt, dass alle beteiligten Professoren in keiner Weise in Frage stellen, dass hieran auch der Strahlungstransport, einschließlich Absorption und Emission durch IR-Aktive Gase eine wichtige Rolle spielen.
„Ihr Problem besteht darin, daß Sie die Differenzen der Hindcasts über eine Periode von 80 Jahren von 2,8 °C für ein dreimonatiges TMAX-Mittel eines beliebig ausgewählten Gitterpunktes ignorieren. Wenn es dort um 1,6 K kälter wird und das Modell 1,2 K Erwärmung anzeigt, liegt was vor?“
Kann sein, zeigen Sie mal dieses Modell und diese Werte.
Wollen Sie damit andeuten, daß man bei einem systemtischen bias von z.B. 3 K einen systematischen Effekt von 1 K ignorieren darf, weil er darunterligt? Wenn Sie so ignorant gegenüber Effekten arbeiten, ist mir klar, warum Sie keinen naturwissenschaftlichen Abschluß erlangt haben.
Zitat: Den „100 Grad Atmosphäreneffekt“ kann es nicht geben, da eine solche wärmere Oberfläche mehr abstrahlen würde, als sie eingestrahlt bekommt.
Hier zum Nachlesen und Nachrechnen:
On the average temperature of airless spherical bodies and the magnitude of Earth’s atmospheric thermal effect – Den Volokinand Lark ReLlez
http://tinyurl.com/zagu99h
Mfg
Werner Holtz
Den „100 Grad Atmosphäreneffekt“ kann es nicht geben, da eine solche wärmere Oberfläche mehr abstrahlen würde, als sie eingestrahlt bekommt.
Völlig Wurst, ob man diese nicht existierende Differenz zum „Treibhauseffekt“ oder „Atmosphäreneffekt“ oder was auch immer erklärt.
Welch weiser Nullsatz:
“
Wie gesagt, der Maßstab sind die Beobachtungen. Wie doof wäre man, wenn man sich gemeinsam auf etwas einigen wollte, was systematisch von den Beobachtungen abweicht, ist doch völliger Schwachsinn.
Da wirkt dann der „Konformitätsdruck“ (besser: Qualifikation und Arbeitsauftrag) der Wissenschaftscommunity dagegen, daß man sich einige kollektiv auf unwissenschaftliches Arbeiten einigen.“
Ihr Problem besteht darin, daß Sie die Differenzen der Hindcasts über eine Periode von 80 Jahren von 2,8 °C für ein dreimonatiges TMAX-Mittel eines beliebig ausgewählten Gitterpunktes ignorieren. Wenn es dort um 1,6 K kälter wird und das Modell 1,2 K Erwärmung anzeigt, liegt was vor?
wenn Sie auf Laienblogs wie Science-Skeptical oder Spiegelonline mit anderen aufgeblasen eingebildeten Laien über ihnen sachfremde Themen herumschwadronieren …
Ich nehme ihre Anregung zur Kenntnis, dass ich mit solchen Laien wie Ihnen, die noch nicht mal ein einziges Sachargument zusammen bekommen, mich nicht zu unterhalten brauche. Erstaunlich ist lediglich, dass solche Beiträge wie der Ihre überhaupt Veröffentlichung finden.
Wenn Sie sich irgendwo mit ad hominem Triaden auskotzen wollen, dann sollte EIKE nicht die geeignete Plattform sein.
@Admin: Ich kann nicht verstehen, warum ein derartiger Beitrag, der vollständig den Regeln 2 und 4 widerspricht, nicht im Spam-Filter hängen bleibt.
„Nicht notwendig. Sowohl bewusste Prozesse der Abstimmung als auch unbewusster Konformitätsdruck können Seitens der Modellierer wirksam werden.“
Wie gesagt, der Maßstab sind die Beobachtungen. Wie doof wäre man, wenn man sich gemeinsam auf etwas einigen wollte, was systematisch von den Beobachtungen abweicht, ist doch völliger Schwachsinn.
Da wirkt dann der „Konformitätsdruck“ (besser: Qualifikation und Arbeitsauftrag) der Wissenschaftscommunity dagegen, daß man sich einige kollektiv auf unwissenschaftliches Arbeiten einigen.
„Der Verdacht alleine ist zwar kein Beweis“
Genau, daher rate ich Ihnen, sich lieber um die wissenschaftlichen Fakten zu bemühen statt Verdächtigungen zu kreieren, damit ich Sie auch ernst nehmen kann.
„Hier deutet sich an performative Widerspruch, bzw. ein Zirkelschluss an. Wenn man das zu Erklärende, nämlich die Klimavariabilität, durch ein vermeintliches Rauschen mit einer beliebigen Unschärfe versieht, stellt sich die Frage nach der Validität des behaupteten Effekts.“
Das ist grundsätzlich richtig, betrifft aber nicht meine Aussage. Denn ich sprach nicht von der Klimasensitivität, sondern der Physik der Treibhaugase, die auf den Treibhauseffekt wirkt. Diese ist vergleichsweise einfach zu modellieren.
„Kann man da so sicher sein?“
Sie werden ja wohl unterscheiden können, ob Sie nur spielen oder Beobachtungen erklären wollen, halten Sie die Leute für zu doof?
„Zudem ergeben sich noch eine ganze Reihe weiterer Motive. Wenn manschen die Welt retten wollen, aber die unvoreingenommen Fakten rechtfertigen diesen Ansatz nicht, ist die Versuchung groß, die Daten ein wenig zu frisieren.“
Ich habe Ihnen schon einmal gesagt, daß ich solche Argumente nicht zulasse, wenn Sie keine qualifizierten Fakten dazu liefern (damit meine ich Ergebnisse von evaluation boards oder Untersuchungskommissionen, wie Sie bei Vergehen im Wissenschaftsbereich eingesetzt werden). Wenn Sie meinen, daß Wissenschaftler auf diesem Gebiet durch andere Motive („Weltrettung“, „Geld“, „Ruhm“,…) dadurch wissenschaftlich schlampig arbeiten, so müssen sie dafür Beweise liefern. Ich gehe davon aus, daß auch in den Klimawissenschaften der wissenschaftliche Prozeß genau so arbeitet wie in jedem anderen Wissenschaftsbereich, denn ich sehe die gleichen Strukturen wie überall (Forschungsaufträge, peer reviews, Uniprojekte, Vergabe von Lehr- und Bildungsaufträge, …)
„Eine andere Motivation ist Geld, Macht, Angst und Ruhm: Wer durch ‚falsche‘ Ergebnisse riskiert, als Skeptiker eingeordnet zu werden, kann Probleme bekommen, aus den Fördermitteln ausgeschlossen zu werden und aus der Community verbannt zu werden. „
Wie gesagt, wenn Ihre Argumentation nun nur noch auf dunkle „Totschlagsargumente“ basiert, so haben Sie sich für eine wissenschaftliche Diskussion disqualifiziert. Ein solches Vorgehen wäre bei uns grundgesetzwidrig und würde eine Mißstand in der Gesellschaft indizieren, der noch viel weiterginge als die Klimaproblematik, denn er würde zeigen, daß es in unserer Gesellschaft schiefgeht. Nur für klimawissenschaftliche Frage erklärt dies nicht!
„Es gibt ganze Artikelserien, die sich mit den Diskrepanzen der Modellergebnisse bezogen auf Temperaturrekonstruktionen und Ergebnisse von Szenarien befassen. Eine gute Korrelation lässt sich trotz Tunig nicht finden. Suchen sie sich einfach einen Artikel der vielen aus.“
Kenne ich nicht. Nennen Sie mir bitte mal drei Beispiele für wissenschaftliche paper, welches einen signifikanten Unterschied zwischen den Modelle und den Beobachtungen der des Klimas der letzten 250 Jahre indiziert und daraus ableitet, daß man damit nicht die beim IPCC angegebenen Temperaturzunahmen für die kommenden 100 Jahren unter gegebenen Projektionen ableiten könnte.
Ihre Aussage mag bislang nur auf dem suggestiven Gefasel, welches hier verbreitet wird, basieren. Ich möchte Fakten in Form von wissenschaftlichen paper dazu sehen. Zudem muß Ihre Behauptung darin explizit aufgeführt sein. Nicht, daß Sie die Ergebnisse in Ihre eigenwilligen Vorstellungen umkreieren und nonsense daraus schließen.
„Wenn Sie von der Modellierung über mehrere Jahrtausende oder gar –millionen sprechen, so müssen Sie beachten, daß diese Modelle nicht mit den Modellen zu vergleichen sind, die das Klima nur über Jahrhunderte modellieren!
—————-
Das bleibt aber methodisch fragwürdig. Denn die Faktoren, die vor Tausenden und Millionen von Jahren wirksam waren, könnten ebenso die rezenten Änderungen bewirken. Wenn man zu wenig weiß, um das Klimageschehen auch über länger Zeiten zu verstehen, sollten alle Veröffentlichungen eben vorsichtiger sein. „
Was soll da „methodisch fragwürdig“ sein? Man sieht doch an der Physik quantitativ, welche Klimafaktoren auf welcher Zeitskala wichtig sind. Das Problem ist eher, daß uns aus der Erdgeschichte weniger Beobachtungen überliefert vorliegen, so daß der Vergleich zwischen Modell und Beobachtungen dort viel gröber ausfällt als im Fall des rezenten Klimas. Aber klar ist, daß die Physik auch in der Erdvergangenheit grundsätzlich die gleiche war.
„So in etwa. ‚Belegen‘ ist mir allerdings zu scharf. Denn die Fakten geben einen zuverlässigen Schluss, auch in diese Richtung, nicht her. Ich würde es eher so sagen: Die Beobachtungen begründen einen Verdacht.“
…was an der Faktenlage nicht nachvollziehbar ist. Müssen Sie belegen.
Das ist falsch, er spricht von Absorption.
„Chuzpe oder Ignoranz – vermutlich beides“ ist es, hier im Forum PERMANENT den leider schon verstorbenen Gerlich anzugreifen, ohne auch nur ein einziges mal einen konkreten Fehler zu nennen!!
—-
—-
Am einfachsten sollte es Ihnen doch bei Punkt 1) fallen:
(1) Die üblichen Erklärungen der atmosphärischen Kohlendioxid-Treibhauseffekte widersprechen physikalischen Experimenten und sind deshalb physikalisch falsch.
Sie meinen ja,
„in der Pauschalität geht dieses Urteil ins Leere.“
dann mal Butter bei die Fische Herr Landvoigt:
Welche „Treibhauserklärung“ steht denn im Einklang mit physikalischen Experimenten?
Sie haben recht,
dass ich nicht selbst Gerlich bin,
deshalb benutze ich selbstverständlich noch viel mehr Argumente als er, wie die vielen MESSUNGEN, die Sie alle beharrlich ignorieren.
Fehlende Korrelation
http://tinyurl.com/oybzywl
Sie konnten bisher nicht erklären,
wo sich hier ein Treibhauseffekt verstecken könnte,
oder
das Henry-Gesetz,
das zu einer positiven Rückkopplung führen müsste, gäbe es einen CO2-Treibhauseffekt.
Sie sind wirklich nur ein Schwätzer,
da muss man Franz Zuber leider recht geben.
mfG
Sie begeben sich auf Landvoigtniveau ohne wie er Gerlich überhaupt verstanden zu haben.
—————
Wir könnten zwar meinen, dass es unentschieden wäre wenn wir uns wechselseitig magelndes Verständnis vorwerfen.
Tatsächlich aber können Argumente und Fakten hier ien unzweifelhafte Klärung erwirken:
Weder prof. Kramm, noch Prof. Gerlich bestreiten, dass das CO2 auch bodennah In den jeweiligen Absorptionsbanden auch auch emittiert. Das ist so glasklar, dass ich mich in der Tat wundere, wie Sie jene als Zeugen ihrer Sache benennen, obwohl sie genau das Gegenteil behaupten.
Dann auch noch mir vorwerfen wollen, ich hätte jene nicht verstanden … dazu gehört entweder ein gerüttelt Maß an Chuzpe oder Ignoranz – vermutlich beides. Suchen Sie sich was aus.
Leser Landvoigt demaskiert sein profundes Nicht-Verstehen schon wieder, indem er sagt: „Sogar Prof. Kramm erklärt, dass der Strahlungstransport heute sehr gut bekannt ist. Weder Gerlich noch Kramm bestreiten, dass die IR aktiven Gase spezifische Frequenzen absorbieren und auch emittieren“.
In Deutsch haben Sie es wohl auch nicht so: „Sogar Kramm erklärt, dass Strahlungstranport … bla bla bla“. Das klingt so, als wäre Kramm der Letzte, dem Sie dies zutrauen würden“. Und: „Weder Gerlich noch Kramm betreiten…“ Ja Herrgottnocheins, Landvoigt, plustern Sie sich doch nicht immer so auf: SIE sind ja der Laie mit krampfhaften Profilierungssüchten in Gebieten ohne jede Ausbildung, ohne substanzielles Grundverständnis der wichtigsten Zusammenhänge. Sie denken laienhaft beschränkt, dass wenn Sie auf Laienblogs wie Science-Skeptical oder Spiegelonline mit anderen aufgeblasen eingebildeten Laien über ihnen sachfremde Themen herumschwadronieren, dass Sie dann an Substanz und Kompetenz gewonnen haben. Pustekuchen, haben Sie natürlich nicht. Ihre Einwürfe sind deshalb so ärgerlich, weil Kramm und Gerlich natürlich mindestens Hunderttausend Mal besser als SIE verstehen, was Strahlungstransport und Absorption von Strahlung in der Atmosphäre bedeuten. Deshalb ist Ihr „Sogar Kramm versteht … bla bla bla ..“ schon wieder eine so anmassende Frechheit Ihrerseits. SIE sind und bleiben in dieser Debatte das kleine, unbedeutende Licht, das Sie sind und bleiben, auch wenn dies Ihrem Selbstdarstellungsdrang massivst stinkt, während Kramm Professor und Lehrbuchautor auf dem Gebiet ist. Das müssen Sie aber schlucken, denn auf dem Fachgebiet haben SIE gar nichts, aber auch gar nichts vorzuweisen.
Nun aber zum Hauptpunkt, Leser Landvoigt: wollen oder können Sie Kramm nicht verstehen, was er Ihnen schon x-mal zu erklären versucht hat und was auch ganz einfach zu verstehen ist, wenn er ausführt, dass durch Vergleich mit den Verhältnissen auf den Mond, der Atmosphäreneffekt der Erdatmosphäre etwa 100 Grad ausmacht. Das kapieren Sie wohl nicht, GELLE!!!!!
Versuchen Sie doch einmal zu ergründen, welcher Zusammenhang der Aussage Kramms zur CO2-Besessenheit von Klimalaien wie Ihnen, Bäcker, Rahmstorf etc. besteht. Wahrscheinlich kapieren Sie ja nicht einmal meinen letzten Satz, was schon wieder äusserst erbärmlich geistig schwach wäre.
Ich helfe Ihnen aber jetzt ein wenig auf die Sprünge (auch Bäcker, Fischer, Ebel, M. Müller und Konsorten sollen jetz mal ganz genau aufpassen): wenn Kramm von einem Atmosphäreneffekt der Erdatmosphäre von etwa 100 Grad spricht, meint er damit
A) dass der Einfluss der „Treibhausgase“ (vor allem Wasserdampf, CO2, Methan, etc.) auf die Oberflächen-nahe Temperatur 100 etwa Grad betrüge ?
oder
B) dass die Existenz der Atmosphäre der Erde als Ganzes (nicht nur die Existenz der „Treibhausgase“ darin) im Vergleich zu den Durchschnittstemperaturen der Mondoberfläche ein Plus von etwa 100 Grad bei den Oberflächen-nahen Erdtemperaturen ausmache?
Wenn Sie die korrekte Antwort selbst herausfinden (da klemmt es ja bei Ihnen bislang ja immer, aber auch Bäcker und andere Treibhausfanatiker stehen da wie Ochsen vor der Wand), dann dürfen Sie sich an die nächste „schwere“ Frage heranwagen: wenn B vorhin richtig wäre, meint dann Kramm, dass
A2) der Anteil der „Treibhausgase“ an den erwähnten ca. 100 Grad Atmosphäreneffekt die ohnmächtig blöden 32 Grad der vom Grünaktivismus getriebenen Pseudoklimawissenschaftler von Wikiblödia bis zu dumm-dreisten Klimalaienblogs, wo sich Dummköpfe wie Eli Rabett vulgo dem miserablen Chemiker Halpern (dem dumm-fachfremden „Verbesserer“ von Gerlich und Tscheuschner) herumtreiben, beträgt?
B2) dass ein hypothetisch postulierter „Treibhauseffekt“ der „Treibhausgase“ insgesamt und besonders des CO2, nicht quantifizierbar ist und mit der Herleitung der blöden 32Grad aus Strahlungstemperatur der Erde auf TOA minus gefälschte bodennahe“Globaltemperatur“ rein gar nichts bzw. nichts näher Quantifizierbares zu tun hat.
Versuchen Sie doch für einmal nachzudenken und Ihr Verständnis für einmal wirklich etwas zu vertiefen, als nur eitel seicht im üblichen Stil herumzuschwadronieren und mit Bäcker endlos herumzublödeln.
Dabei ist natürlich die Voraussetzung, daß es keinen systematischen bias gibt. Den sprechen wahrscheinlich Sie mit Ihren Bedecken an:
„Es könnte heißen, was Sie wohl implizieren, dass man sich mittlerweile über die korrekten Zustände immer sicherer wird und darum eine Übereinstimmung ein Qualitätsmerkmal ist.
…
—————-
Es könnte aber genau so heißen, dass die Modellierer im Tuning sich an den anderen Modellen orientieren und darum eher eine Abstimmung auf eine scheinbare Modell-Realität stattfindet.“
Es macht wohl wenig Sinn, wenn man sich auf ein falsches „tuning einigt“. Die Qualität der Modelle mißt sich selbstverständlich an der Reproduzierbarkeit des empirischen Klimas. Ich halte daher Ihre zweite Möglichkeit für abwegig, denn wenn Ihnen schon ein signifikanter bias auffiele, so wäre es erst recht ja den beteiligten Wissenschaftlern aufgefallen, ist irgendwie logisch, oder?
Nicht notwendig. Sowohl bewusste Prozesse der Abstimmung als auch unbewusster Konformitätsdruck können Seitens der Modellierer wirksam werden. Es mag auch sein, dass ein gemeinsamer Mind-Set einen Bias liefert, selbst wenn es keine direkte Abstimmung zu anderen Modellen entsteht. Mir ist in Communities unterschiedlicher Couleur immer wieder aufgefallen, dass eine bestimmte Art von Betriebsblindheit nahezu unvermeidlich erscheint. Und das sind nicht nur dumme oder unkritische Menschen, an denen man genau das oft beobachten kann. Der Verdacht alleine ist zwar kein Beweis, aber der Verweis auf eine derartige Logik ist ebenso wenig geeignet, den Verdacht zu zerstreuen.
————– #79: NicoBaecker sagt:
—————–
Das liegt daran, das die natürlichen Zyklen im Vergleich zum Treibhauseffekt eine komplexere Physik haben, die man schwer modellieren kann. Die Prognosegenauigkeit wird also durch die Variabilität des Klimasystems limitiert.
Hier deutet sich an performative Widerspruch, bzw. ein Zirkelschluss an. Wenn man das zu Erklärende, nämlich die Klimavariabilität, durch ein vermeintliches Rauschen mit einer beliebigen Unschärfe versieht, stellt sich die Frage nach der Validität des behaupteten Effekts.
—————- #79: NicoBaecker sagt:
—————-
Denn man will die Natur ja erklären und nicht nur mit dem Computer spielen.
Kann man da so sicher sein? Zudem ergeben sich noch eine ganze Reihe weiterer Motive. Wenn manschen die Welt retten wollen, aber die unvoreingenommen Fakten rechtfertigen diesen Ansatz nicht, ist die Versuchung groß, die Daten ein wenig zu frisieren.
Eine andere Motivation ist Geld, Macht, Angst und Ruhm: Wer durch ‚falsche‘ Ergebnisse riskiert, als Skeptiker eingeordnet zu werden, kann Probleme bekommen, aus den Fördermitteln ausgeschlossen zu werden und aus der Community verbannt zu werden.
Wenn der Einsatz in dem Spiel so hoch ist, wäre es ein Wunder, wenn man da völlig unvoreingenommen bleiben kann.
Oft setzen dann bestimmte psychologisch erklärbare Prozesse ein: Man will ganz gewiss nicht bewusst manipulieren, doch wenn ein existenziell gefährlicher Kurs ansteht, wird man eher die These verfolgen, dass Daten, die nicht zu den konformen Erwartungen passen, eben fehlerhaft sein müssen. Und gewiss findet man dann auch die Indizien dazu.
—————- #79: NicoBaecker sagt:
„Da aber das gros der Modelle weder die Vergangenheit gut erklärt noch hinsichtlich ihrer Vorhersagen eine empirische Bestätigung liefert, halte ich die zweite Erklärung für zutreffender.“
Das kann ich nicht nachvollziehen. Dazu müssen Sie mir Daten zeigen. Welche Vergangenheit und welche Vorhersagen meinen Sie?
—————–
Es gibt ganze Artikelserien, die sich mit den Diskrepanzen der Modellergebnisse bezogen auf Temperaturrekonstruktionen und Ergebnisse von Szenarien befassen. Eine gute Korrelation lässt sich trotz Tunig nicht finden. Suchen sie sich einfach einen Artikel der vielen aus.
—————- #79: NicoBaecker sagt:
—————-
Wenn Sie von der Modellierung über mehrere Jahrtausende oder gar –millionen sprechen, so müssen Sie beachten, daß diese Modelle nicht mit den Modellen zu vergleichen sind, die das Klima nur über Jahrhunderte modellieren!
Das bleibt aber methodisch fragwürdig. Denn die Faktoren, die vor Tausenden und Millionen von Jahren wirksam waren, könnten ebenso die rezenten Änderungen bewirken. Wenn man zu wenig weiß, um das Klimageschehen auch über länger Zeiten zu verstehen, sollten alle Veröffentlichungen eben vorsichtiger sein.
—————- #79: NicoBaecker sagt:
—————
Wenn Ich Sie richtig verstehe, so postulieren Sie, daß diese Vergleiche belegen würden, daß es einen signifikanten bias zwischen den Beobachtungen und dem „Schwerpunkt“ der Modellergebnisse zum Reproduzieren des Klimas der letzten 250 Jahre gibt und damit einer Prognose bzw. Projektion für die kommenden 100 Jahre.
So in etwa. ‚Belegen‘ ist mir allerdings zu scharf. Denn die Fakten geben einen zuverlässigen Schluss, auch in diese Richtung, nicht her. Ich würde es eher so sagen: Die Beobachtungen begründen einen Verdacht.
„Ich zweifele nicht, dass die Streuungen zwischen den Modellen nicht mehr so groß ist. Doch was heißt das?“
Was das heißt, hängt immer vom Verhältnis der Streubreite zur benötigten Genauigkeit ab. Dabei ist natürlich die Voraussetzung, daß es keinen systematischen bias gibt. Den sprechen wahrscheinlich Sie mit Ihren Bedecken an:
„Es könnte haeßen, was Sie wohl implizieren, dass man sich mittlerweile über die korrekten Zustände immer sicherer wird und darum eine Übereinstimmung ein Qualitätsmerkmal ist.
Es könnte aber genau so heißen, dass die Modellierer im Tuning sich an den anderen Modellen orientieren und darum eher eine Abstimmung auf eine scheinbare Modell-Realität stattfindet.“
In den letzten Jahrzehnten hat sich gezeigt, daß komplexere Modelle die Streubreite nicht mehr wesentlich verringern. Das liegt daran, das die natürlichen Zyklen im Vergleich zum Treibhauseffekt eine komplexere Physik haben, die man schwer modellieren kann. Die Prognosegenauigkeit wird also durch die Variabilität des Klimasystems limitiert.
Es macht wohl wenig Sinn, wenn man sich auf ein falsches „tuning einigt“. Die Qualität der Modelle mißt sich selbstverständlich an der Reproduzierbarkeit des empirischen Klimas. Ich halte daher Ihre zweite Möglichkeit für abwegig, denn wenn Ihnen schon ein signifikanter bias auffiele, so wäre es erst recht ja den beteiligten Wissenschaftlern aufgefallen, ist irgendwie logisch, oder? Denn man will die Natur ja erklären und nicht nur mit dem Computer spielen.
„Da aber das gros der Modelle weder die Vergangenheit gut erklärt noch hinsichtlich ihrer Vorhersagen eine empirische Bestätigung liefert, halte ich die zweite Erklärung für zutreffender.“
Das kann ich nicht nachvollziehen. Dazu müssen Sie mir Daten zeigen. Welche Vergangenheit und welche Vorhersagen meinen Sie? Wenn Sie von der Modellierung über mehrere Jahrtausende oder gar –millionen sprechen, so müssen Sie beachten, daß diese Modelle nicht mit den Modellen zu vergleichen sind, die das Klima nur über Jahrhunderte modellieren!
Wenn Ich Sie richtig verstehe, so postulieren Sie, daß diese Vergleiche belegen würden, daß es einen signifikanten bias zwischen den Beobachtungen und dem „Schwerpunkt“ der Modellergebnisse zum Reproduzieren des Klimas der letzten 250 Jahre gibt und damit einer Prognose bzw. Projektion für die kommenden 100 Jahre.
„Von Wettervorhersagen redet Gerlich gar nicht!
Sondern von Klimamodellen, in die WILLKÜRLICHE Parameter eingegeben werden, wie z.B. das CO2.“
Stimmt, der hat das gesagt (sagen Sie!):
„(4) Die Computersimulationen haben keine physikalischen Grundlagen, sondern sind künstliche Konstrukte, die die gewünschten Ergebnisse ohne die Berücksichtigung physikalischer Gesetze produzieren.“
„Sondern von Klimamodellen, in die WILLKÜRLICHE Parameter eingegeben werden, wie z.B. das CO2.“
Es gibt keine Klimamodelle. Ob Sie das jemals begreifen werden?
Die Modelle, die zur Simulation des Land-Ozean-Atmosphäre-Systems entwickelt wurden simulieren die globale Zirkulation und heißen deswegen Global-Circilation-Models (GCM). Inzwischen sind die um etliche Module erweitert worden und heißen Earth-System-Models (ESM).
Vorgänger sind die numerischen Wettervorhersagemodelle, die parallel zu steigenden Rechnerkapazität als barotrope dann barokline Modelle begannen und jetzt neben Feuchte und Strahlung noch so allerlei anderes beinhalten.
Sie können sicher sein, daß ich über die Modelle mehr weiß als Sie. Ich habe nämlich deren Werden von Beginn an vor Ort erlebt, als die ersten Modelle zur Sturmflutberechnung (des Orkans 1976 mit dem höchsten Wasserstand in Hamburg) noch auf der Cyber76 in Hannover zum Laufen gebracht wurden, weil die TR440 in Hamburg zu langsam war.
Aber Sie wollten ja nur mit Ihrem angelesenen Wissen „glänzen“.
Kennen Sie eigentlich die wichtigste Fähigkeit eines Arztes?
Und wo trifft man warum die beiden letzten ex-Bürgermeister von Hamburg und Berlin garantiert nicht an? Und wen hätte man da ebenfalls nicht angetroffen?
Als Mediziner müßten Sie das wissen.
Sie begeben sich auf Landvoigtniveau ohne wie er Gerlich überhaupt verstanden zu haben.
Wenn Sie von numerischen Wettervohesagen reden,
dann kennen Sie (hoffentlich) deren Eingangsparameter, da ist übrigens CO2 NICHT drin, das weis sogar Wiki
UND
dann wissen Sie auch, dass damit nur Vorhersagen von wenigen Tagen möglich sind. Auch die sind manchmal falsch.
Also für langfristige Prognosen schon innerhalb eines einzigen Jahres VÖLLIG UNBRAUCHBAR.
Wer hat denn den warmen Februar und wer hat denn den kalten März 2016 vorrausgesagt???
Das liegt übrigens NICHT an der Rechnergröße,
totaler Böldsinn.
Sondern an der „Instabilität einer Bewegungsgleichung mit exponentiellen Faktoren“
(=nicht lösbar!)
Von Wettervorhersagen redet Gerlich gar nicht!
Sondern von Klimamodellen, in die WILLKÜRLICHE Parameter eingegeben werden, wie z.B. das CO2.
shit in shit out heißt das.
und so ist es ja auch.
Wie sollen denn „Klimamodelle“,
die für die Vergangenheit zweifellos VERSAGEN, in die Zukunft auf einmal richtig sein.
Das ist schlicht kollektiver Betrug.
Das mit der Chaostheorie,
der Indeterminiertheit bestimmter Gleichungen haben Sie nicht kappiert.
googeln Sie mal nach Ljapunov
Diese Klimamodelle und die CO2-Treibhaushypothese sind des Kaisers neue Kleider.
Meine Frau, die an Geister glaubt, weis aber ganz sicher,
dass die Sonne wärmt und Wolken kühlen, wie das Kind das den nackten Kaiser sofort sieht,
Martin Landvoigt, Johannes Herbst offenbar auch Herr Singer und jetzt auch Sie? wissen es NICHT?
Glauben kann zwar keine Berge versetzen, dazu braucht man Bagger, aber den Verstand ausschalten.
mfG
„Die AGW-Vertreter rechnen dann aber noch mit Verstärkungsfaktoren durch positive Feedbacks, während die Skeptiker hier stärkere negative Feedbacks ermitteln.“
Heutige komplexe Modelle streuen aber nicht mehr so weit in den feedback-Resultaten, daß das Gesamtfeedback negativ ausfiele. Die besten Schätzungen finden Sie in den IPCC reports.
—————–
Sehr geehrter Herr Baecker
Ich zweifele nicht, dass die Streuungen zwischen den Modellen nicht mehr so groß ist. Doch was heißt das?
Es könnte haeßen, was Sie wohl implizieren, dass man sich mittlerweile über die korrekten Zustände immer sicherer wird und darum eine Übereinstimmung ein Qualitätsmerkmal ist.
Es könnte aber genau so heißen, dass die Modellierer im Tuning sich an den anderen Modellen orientieren und darum eher eine Abstimmung auf eine scheinbare Modell-Realität stattfindet.
Sicher sind noch mehr Varianten möglich. Exemplarisch auf diese beiden Positionen verdichtet: Was trifft eher zu? Da aber das gros der Modelle weder die Vergangenheit gut erklärt, noch hinsichtlich ihrer Vorhersagen eine empirische Bestätigung liefert, halte ich die zweite Erklärung für zutreffender.
Das IPCC repräsentiert eine selektierte Mehrheitsmeinung, die zudem durch internationale Anerkennung und erheblichen Mittelzufluss korrumpiert ist, zumindest liegt der Verdacht nahe. Das schließt zwar nicht aus, dass auch korrekte Beobachtungen, Modelle und Schlussfolgerungen getätigt werden, aber ein vertrauenswürdiges Qualitätsversprechen liefert das IPCC nicht.
„(4) Die Computersimulationen haben keine physikalischen Grundlagen, sondern sind künstliche Kon- strukte, die die gewünschten Ergebnisse ohne die Berücksichtigung physikalischer Gesetze produzieren.“
Das stimmt nicht, denn das hieße, daß die numerischen Vorhersagemodelle der Wetterdienste die Physik der Atmosphäre nicht berücksichtigen würden. Und auf denen basieren die GCM.
Das Hauptproblem besteht darin, daß wegen der Beschränkung der Rechenkapazitäten die Modelle immer nur ein sehr grober Abklatsch der Realitäten sind.
Segelflieger können an staubtrockenen Tagen beobachten, wie der Start der Segelflugzeuge an der Winde die Thermik vorzeitig auslöst und somit das lokale Aufwindsystem beeinflußt. Fast jeder Segelflugplatz hat seinen Hausbart … .
Das kann niemand mit einem meteorologischen Modell simulieren. Die Rechenkapazität der Rechner reicht dazu nicht aus.
Die Limitierung der Modellierer erfolgt durch die limitierte Rechenkapazität, die durch Parametrisierung „ersetzt“ werden muß und somit die reale physikalische Repräsentation einschränkt.
Gerlich … Zusammenfassung
—————–
Da sie mich persönlich adressierten, einige Anmerkungen:
———- Gerlich:
———-
(1) Die üblichen Erklärungen der atmosphärischen Kohlendioxid-Treibhauseffekte widersprechen physikalischen Experimenten und sind deshalb physikalisch falsch.
Es gibt natürlich falsche Darstellungen, aber in der Pauschalität geht dieses Urteil ins Leere. Einige Darstellungen sind eher didaktischer Natur und sollen ein fragwürdiges Verständnis wecken. Andere Darstellungen mangeln an der Präzision, sind aber durchaus im Groben korrekt. Manche Darstellungen sind urchaus hinreichend präzise. Diese kann man ggf am Punkt kritisieren.
———- Gerlich:
———-
(2) Mittelwerte der Temperatur kann man nicht zur vierten Wurzel vom Mittelwerten der vierten Po- tenz der absoluten Temperatur gleichsetzen. Die Beziehung ist eine mathematische Ungleichung.
Natürlich haben wir hier Ungleichungen, mit denen wir aber sehr wohl auch rechnen können. Wer allerdings glaubt, mit diesem Rechenwerk eine hinreichend verlässliche Aussage produzieren zu können, um unser gesamtes Leben und Wirtschaften nachhaltig zu ändern, irrt.
———- Gerlich:
———-
(3) Die Absorption der Ultrarotstrahlung in der Erdatmosphäre geschieht überwiegend durch Wasser- dampf. Der Wellenlängen- bzw. Frequenzanteil, den CO2 absorbiert, ist nur ein kleiner Teil des ul- traroten Spektrums und wird nicht wesentlich durch Erhöhen des Partialdruckes des CO2 verändert (Prof. A. Schack).
Die Einschätzung hinsichtlich wesentlich, signifikant oder nicht, ist hier nicht präzise getroffen. Man kann mit Strahlungstransportmodellen recht genau den Umfang – zumindest hinsichtlich der Dimension – bestimmen.
———- Gerlich:
———-
(4) Die Computersimulationen haben keine physikalischen Grundlagen, sondern sind künstliche Kon- strukte, die die gewünschten Ergebnisse ohne die Berücksichtigung physikalischer Gesetze produzieren.
Dies kann auf einige Modelle durchaus zutreffen, aber in der Pauschalität ist es eine unwissenschaftlich und unpräzise. Auch Zusammenfassungen rechtfertigen keine derartigen Formulierungen.
———- Gerlich:
———-
(5) Wegen der willkürlich gewählten, genäherten, praktisch unbekannten Randbedingungen, die wesentlich die Lösungen von partiellen Differentialgleichungen bestimmen, sind die Prognosen der Klimarechenzentren völlig wertlos.
Ich teile die kritische Sicht auf CGMs, die m.E. nicht mehr hinreichende Transparenz bezüglich Verfahren und Parameter aufweisen können.
Dies gilt aber nicht grundsätzlich für belibige Modelle. So kann man vereinfachte Modelle durchaus als zulässige Abstraktionen, z.B. zum Strahlungstransport verstehen. Sogar Prof. Kramm erklärt, dass der Strahlungstransport heute sehr gut bekannt ist. Weder Gerlich noch Kramm bestreiten, dass die IR aktiven Gase spezifische Frequenzen absorbieren und auch emittieren.
———- Gerlich:
———-
(6) Die riesigen Wassermassen (nicht nur der Wasserdampf) und die Verteilung der Landmassen zwischen den Meeren bestimmen die Klimate auf der Erde. Die Wasserverdunstung über den Ozeanen ist vom Menschen nicht zu beeinflussen. Allein schon deshalb kann der Mensch nicht das Wetter und die Klimate auf der Erde beeinflussen.
Im Groben stimmt das, allerdings gibt es durchaus Änderungen durch kulturelle Aktivitäten. So wurde z.B. der Aral-See so stark übernutzt, dass er über viele km² trocken gefallen ist. Das verändert sehr wohl das lokale Klima. Hier ist aber das Thema, in wie weit CO2 Emissionen klimaprägend sind. Ich meine, dass dieses ‚Forcing‘ in Bezug zu den anderen Faktoren eher gering ist, auch wenn er nicht Null ist.
———- Gerlich oder Dr. Paul (?):
———-
Meine Meinung ist, dass die Veränderungen der mittleren Temperaturen in der Nähe des Erdbodens oder der Meeresoberflächen wesentlich durch die Veränderungen der Wolkenbedeckung bestimmt sind. Hierfür wieder eine Ursache zu suchen, überlasse ich gerne anderen. Auf keinen Fall sind es die Veränderungen der 0,05 Gewichtsprozent Kohlendioxid in der Atmosphäre der Erde.
Im Wesentlichen würde ich zustimmen. Mir ist nur die Formulierung ‚auf keinen Fall‘ bedenklich, denn so sicher ist dieses Urteil nun nicht.
Sehr geehrter Herr Dr.Paul,
diese Zusammenfassung enthält die wesentlichen Erkenntnisse der Naturwissenschaft.
Diese Erkenntnisse kann ich nach 40 Jahren Betriebserfahrung mit thermodynamischen Vorgängen im Kleinen wie im Großen bestätigen.
Diese schöne Zusammenfassung von Herrn Gerlich war mit bis heute nicht bekannt.
Sie wird eingerahmt und an die Virtuelle Wand gehängt.
Mit herzlichem Glückauf
Die physikalischen und mathematischen Grundlagen der Treibhauseffekte und globaler Klimamodelle. Vortrag am 24. 9. 2011 in Großbothen.
10) Zusammenfassung
(1) Die üblichen Erklärungen der atmosphärischen Kohlendioxid-Treibhauseffekte widersprechen physikalischen Experimenten und sind deshalb physikalisch falsch.
(2) Mittelwerte der Temperatur kann man nicht zur vierten Wurzel vom Mittelwerten der vierten Po- tenz der absoluten Temperatur gleichsetzen. Die Beziehung ist eine mathematische Ungleichung.
(3) Die Absorption der Ultrarotstrahlung in der Erdatmosphäre geschieht überwiegend durch Wasser- dampf. Der Wellenlängen- bzw. Frequenzanteil, den CO2 absorbiert, ist nur ein kleiner Teil des ul- traroten Spektrums und wird nicht wesentlich durch Erhöhen des Partialdruckes des CO2 verändert (Prof. A. Schack).
(4) Die Computersimulationen haben keine physikalischen Grundlagen, sondern sind künstliche Kon- strukte, die die gewünschten Ergebnisse ohne die Berücksichtigung physikalischer Gesetze produzieren.
(5) Wegen der willkürlich gewählten, genäherten, praktisch unbekannten Randbedingungen, die we- sentlich die Lösungen von partiellen Differentialgleichungen bestimmen, sind die Prognosen der Klimarechenzentren völlig wertlos.
(6) Die riesigen Wassermassen (nicht nur der Wasserdampf) und die Verteilung der Landmassen zwischen den Meeren bestimmen die Klimate auf der Erde. Die Wasserverdunstung über den Ozeanen ist vom Menschen nicht zu beeinflussen. Allein schon deshalb kann der Mensch nicht das Wetter und die Klimate auf der Erde beeinflussen.
Meine Meinung ist, dass die Veränderungen der mittleren Temperaturen in der Nähe des Erdbodens oder der Meeresoberflächen wesentlich durch die Veränderungen der Wolkenbedeckung bestimmt sind. Hierfür wieder eine Ursache zu suchen, überlasse ich gerne anderen. Auf keinen Fall sind es die Veränderungen der 0,05 Gewichtsprozent Kohlendioxid in der Atmosphäre der Erde.
„Die Erwärmung ist die Folge eines komplexen Systemumfeldes, dass sich in Modellen abbilden und durchrechnen lässt.
Wir sprechen hier allerdings rein vom Strahlungstransport, ohne Feedbacks. Diese kann man als Fi (imidiate Forcing) oder als Fa (adjusted Forcing) ermitteln. Die Werte schwanken je nach Modellansatz überwiegend zwischen 2 und 4 W/m² bei einer Verdopplung des CO2-Anteils. Die Literatur nennt meist 3,7 W/m²“
Wie ich Ihnen in dem „Meschugge“-blog gezeigt habe, ergibt sich mit komplexen Modellen ein Fa von 3,7 W/m2 ca. +/- 10%. Ihr 2-4 ist etwas zu weit gegriffen.
„Das bedeutet ein Brutto Strahlungsantrieb bei Verdoppelung von etwa 0,7 – 1,2 Grad.“
Die bodennahe Temperatur wird durch ein Fa von 3,7 W/m2 etwa 1,1 °C steigen.
„Die AGW-Vertreter rechnen dann aber noch mit Verstärkungsfaktoren durch positive Feedbacks, während die Skeptiker hier stärkere negative Feedbacks ermitteln.“
Heutige komplexe Modelle streuen aber nicht mehr so weit in den feedback-Resultaten, daß das Gesamtfeedback negativ ausfiele. Die besten Schätzungen finden Sie in den IPCC reports.
Und auch am N, dem Nitrogenium, da werden von den Alpha-X-Ray(Strahlen), manche halt zu dann zu sein zu Sauerstoff „verbraucht“
, mit dann „OH“ zu Wasser, klar auch oxidiert:
wie das war in Fukushima
:an den Wassertanks des Kühlwasser
– ja dann auch passiert.
Welches man ja dann in Japan
so ganz ungeniert
in den Ozean geleitet hat
, weil ist ja Wasser nur
– aus nurmal so durchdacht!
Und auch am N, dem Nitrogenium, da werden von den Alpha-X-Ray(Strahlen), manche halt zu dann zu sein zu Sauerstoff „verbraucht“
, mit dann „OH“ zu Wasser, klar:
wie das war in Fukushima
an den Wassertanks zum Kühlen
dann ja auch.
Sie haben keine Ahnung von Physik wie Sie in #63 wieder einmal darlegen. Was Sie schreiben ist nur Geschwurbel, aber das hat ihne Herr Kramm schon viel besser gesagt als ich.
MfG
auf den Zigarettenschachteln steht: Rauchen kann tödlich sein, nicht Rauchen ist tödlich.
Sie merken den Unterschied.
Mfg
Nun also die Anmerkungen:
Wenn man die Diskussion zu dem Beitrag allgemein verfolgt, könnte man meinen, man nähme an einer irreale Veranstaltung teil. Denn es ist doch völlig unerheblich, ob der menschliche Anteil an dem Eintrag von CO2 in die Atmosphäre klimawirksame Auswirkungen hat oder nicht. Es herrscht hier doch wohl Einigkeit darüber, daß der deutsche Anteil hierbei die Winzigkeit von rund 3 % hat. Also auch bei einer angenommen tatsächlichen Schuld des CO2 an der Klimaerwärmung, was immer das auch sein mag, hätte die vollständige Eliminierung der dt. Beteiligung lediglich zur Folge, daß der „Hitzetod“ der Erde sich um etwa 14 Tage verschieben würde. Also viel Lärm um nichts. Und auch das evtl. Argument der „Vorbildfunktion“ zieht hier nicht, wie die Geschichte zeigt. Denn bisher hat das Bestreben, die Welt solle am Deutschen Wesen genesen, immer nur Unglück gebracht; den Deutschen selbst und auch den Nachbarn.
Sollte zu meinem Diskussionsbeitrag ein Antwort erfolgen, so wird sie meinerseits ohne Reaktion bleiben, nach dem Motto, das ich übrigens aus „Eike“ habe (ja, Eike bildet), wenn man länger als 30 Sek. mit einem Deppen diskutiert, diskutieren zwei Deppen.
Wenn Sie sich die Zigarettenschachteln anschauen, ist darauf die „Theorie“ gedruckt, daß Rauchen tötet, oder Rauchen Krebs erzeugt, und zwar unabhängig von anderen Faktoren.
Diese vom Gesetzgeber behauptete Theorie ist durch H. Schmidt falsifiziert worden. Der ist nicht vorzeitig (entsprechend der Lebenserwartung seines Jahrgangs) gestorben, hat mehr geraucht als jeder andere Mensch.
Mehr habe ich nicht festgestellt. Das führt natürlich zu dem Schluß, daß auch andere Faktoren für die Entstehung von Krebs durch Tabakqualm vorhanden sein oder fehlen müssen.
Deshalb ist ja die ganze CO2-Diskussion unsinnig, weil 1. die Atmosphäre nicht trocken ist und die Erdoberfläche alles andere als homogen. Ein System mit unlimitierter Anzahl von Freiheitsgraden, ist nicht berechenbar. Damit ist eine vermutete Kausalität nicht beweisbar.
Da Naturwissenschaftler es aber in der Regel während ihrer Ausbildung mit Systemen mit wenigen Freiheitsgraden zu tun bekommen, ist der Glaube entstanden, man könne das auf komplexere Systeme auch anwenden.
Wirtschafts- und Sozialwissenschaftler kennen das Problem, daß Volk nicht, denn sonst würden sie nicht an die „Chef“-Volkswirte glauben, die mit simplen Methoden versuchen nationalökonomische Kaffeesatzleserei zu betreiben.
#55: Martin Landvoigt sagt:
—-
—-
—————-
Das Kraftwerk heißt Erde und sorgt dafür, dass wir hier nicht erfrieren.
Das ist FALSCH,
oder aben sie sich nur vertippt?
Sie beziehen sich doch gerne auf Gerlich, Tschchner und Kramm. Haben sie eigentlich jemals gelesen, was diese schreiben? Sie haben gezeigt, dass die Durchschnittstemperaturen auf der Erde ohne eine Atmosphäre deutlich geringer wäre. Zwar kann man sich über das Berechnungsmodell streiten, nicht aber um das wirksame Prinzip.
————— #60: Dr.Paul sagt:
—————
Richtig:
Das Kraftwerk heißt SONNE und sorgt dafür, dass wir hier nicht erfrieren.
Was aber, wenn die Sonne ebenso strahlt wie bisher, und Ihre experten Recht haben? Dann wird es hier nicht nur luftarm, sondern auch sehr kalt.
———— #60: Dr.Paul sagt:
————
Und wenn Wolken dazwischen sind, wird es kälter.
Meinen sie bei Tage oder in der Nacht? Oder im Durchschnitt?
Wwenn das CO2 tatsächlich die Oberflächentemperatur um 1 °C erhöht, dann beginnt diese stärker zu strahlen und zwar über den ganzen Frequenzbereich. Woher wissen denn jetzt die CO2- Moleküle, daß sie mehr zurückstrahlen müssen nur um auf dem 1° höheren Temperaturniveau zu bleiben.
——————–
Die CO2-Moleküle wissen nichts, sondern sie strahlen gemäß ihrer Materialeigenschaften in einer demgemäß modifizierten Planck-Funktion die Energie ab, die sie vorher durch Absorption oder Stoß-Anregung erhalten haben.
Die Erwärmung ist die Folge eines komplexen Systemumfeldes, dass sich in Modellen abbilden und durchrechnen lässt.
Wir sprechen hier allerdings rein vom Strahlungstransport, ohne Feedbacks. Diese kann man als Fi (imidiate Forcing) oder als Fa (adjusted Forcing) ermitteln. Die Werte schwanken je nach Modellansatz überwiegend zwischen 2 und 4 W/m² bei einer Verdopplung des CO2-Anteils. Die Literatur nennt meist 3,7 W/m²
Dazu gibt es auch gemessene Spektrogramme, die die Modelle bestätigen. Das bedeutet ein Brutto Strahlungsantrieb bei Verdoppelung von etwa 0,7 – 1,2 Grad.
Die AGW-Vertreter rechnen dann aber noch mit Verstärkungsfaktoren durch positive Feedbacks, während die Skeptiker hier stärkere negative Feedbacks ermitteln. Der Netto-Wert reicht darum einerseits von marginal bis 4,5 Grad – immer auf eine CO2 Verdopplung bezogen.
Sie sind doch jemand der so auf der Wissenschafttheorie „herumreitet“. Dann sollten Sie doch wissen, daß der Zusammenhang zwischen Rauchen und Lungenkrebs nur ein statistischer ist. Das sagt nichts über einen Einzelfall aus.
MfG
Sie verstehen ganz offensichtlich nicht von Physik. Wenn sie die Darstellung für Laien von Herrn Ermecke dchon überfordern, dann macht es keine Sinn, die Arbeiten von Gerlich und kramm dazu zu lesen.
Beantworten Sie doch einfach die folgende Frage:
Wwenn das CO2 tatsächlich die Oberflächentemperatur um 1 °C erhöht, dann beginnt diese stärker zu strahlen und zwar über den ganzen Frequenzbereich. Woher wissen denn jetzt die CO2- Moleküle, daß sie mehr zurückstrahlen müssen nur um auf dem 1° höheren Temperaturniveau zu bleiben.
Das Kraftwerk heißt Erde und sorgt dafür, dass wir hier nicht erfrieren.
Das ist FALSCH,
oder aben sie sich nur vertippt?
Richtig:
Das Kraftwerk heißt SONNE und sorgt dafür, dass wir hier nicht erfrieren.
Und wenn Wolken dazwischen sind, wird es kälter.
mfG
„Interessanterweise zeigen tatsächliche Messungen, dass die Erde mehr Energie abstrahlt als sie DURCH SOLARLICHT empfangen hat. Die Frage ist also: Woher kommt der Rest?“
So viel Fehler auf einmal!!!
Das ist weder physikalisch möglich noch gemessen.
Es ist nun wirklich kein Geheimnis,
dass es physikalisch FALSCHE STRAHLENMODELLE gibt.
Die von mir zitierten MESSUNGEN ignorieren Sie einfach.
Die Erde strahlt am Tag und regional am Äquator nicht mehr, sondern WENIGER ab, als sie von der Sonne erhält
und nachts und regional über den Polen dafür mehr.
Es ist also KÄLTER am Tag und am Äquator, als eine Strahlungsbilanz erklären könnte
und WÄRMER nachts und an den Polen.
Das führt zu geringeren Temperaturschwankungen
und deshalb zu einer errechenbaren höheren Durchschnittstemperatur als ohne Atmosphäre genau deshalb,
weil diese erwärmte Atmosphäre die Wärme speichert und vergleichsweise NICHT (=minimal) strahlt.
Es strahlt also DURCH die Atmosphäre, nicht AUS der Atmosphäre, schon gar nicht nach unten, sondern nur in den Weltraum. Es gibt keine „Treibhausgase“.
Die NICHT strahlende Atmosphäre 99,96% führt zur Erwärmung. Siehe Mond ohne Atmosphäre.
Alles messbar, keine Theorie!
mfG
„Es kommt also eine Wärmeeinstrahlung (von über 213 K) von oben an.“
das ist FALSCH!
Sie haben das Pyrometerprinzip nicht verstanden.
Lesen Sie bitte die Gebrauchsanweisung.
Ebenso wie das Gerät kein kurzwelliges Licht messen kann,
ist es nicht in der Lage langwelligere Strahlen zu messen.
Die „Temperatur“ ist dabei keine Messung, sondern eine BERECHNUNG.!!!
Hier geht es aber nicht um eine „Temperatur sondern um die Frage ob auf der Erdoberfläche 15µm – Strahlen ankommen.
Und das geht mit ihrem Gerät schon mal gar nicht. Das ist auch in der Gebrauchsanweisung nachlesbar.
Lesen Sie nochmal #10
mfG
Stimmt das oder nicht?
—————–
Es stimmt!
—————– #54: Johannes Herbst sagt:
—————–
Mir erscheint es so, dass hier im Forum jedes Argument gesucht wird, um die Klimaalarmisten zu wiederlegen – aber es wird kein Wert darauf gelegt, ob es auch hieb- und stichfest ist. Das ist ja genau das, was Monckton den Alarmisten vorwirft.
Volle Zustimmung. Auch Klimarealisten haben die Wahrheit nicht gepachtet. Es ist eine Verpflichtung, sich um Korrektheit zu bemühen. Nicht nur, um auch andere überzeugen zu können und sich selbst nicht zu diskreditieren. Wir sollten Propaganda ablehnen – und zwar von allen Seiten.
—————– #54: Johannes Herbst sagt:
—————–
In einer wissenschaftliche Debatte hingegen sollte alles ergebnisoffen sein. Es gibt keine absolute Wahrheit. Es gibt nur Annahmen und Sie gelten nur solange, bis sie widerlegt sind. Darauf kann ich mich als ehemaliger Grüner und Freund von Erneuerbaren Energien berufen – sonst wäre ich nicht hier.
Und das sollte eigentlich selbstverständlich sein!
Schauen Sie mal nach, was auf den Zigarettenschachteln so alles draufsteht. Die dort vertretene „Theorie“ wurde von H. Schmidt falsifiziert.
Was die AfD betrifft, so wurde die übernommen und hat mit der Ursprungsidee und Ursache nicht mehr viel am Hut. Das ist so wie mit der CDU im Südwesten, wo Stupsnase nicht kapiert, daß er eine der Ursachen des zukünftigen Bettvorlegerdaseins ist.
Glückwunsch, Sie haben das Perpetuum Mobile der 2. Art gefunden! Wann stellen Sie das Kraftwerk vor, das diesen Effekt nutzt und für alle Zeiten unsere Energieversorgung sichert?
——————-
Oder haben Sie am Ende nur nicht die Hauptsätze der Thermodynamik verstanden….?
Sehr geehrter Herr Pesch
Das Kraftwerk heißt Erde und sorgt dafür, dass wir hier nicht erfrieren. Allerdings gibt es keine zusätzliche Energie, sondern es sorgt nur dafür, dass die Wärme vom Boden und bodennahen Luftschichten netto nicht so schnell abfließt, wie sie es ohne Atmosphäre täte. Denn wir haben natürlich netto einen Energieabfluss und haben auch kein Problem mit dem 2. HS.
Anmerkung: Man muss die Physik nicht mit Ignoranz strafen, wenn man die AGW-Hysterie als unwissenschaftlich entlarven will.
Es kommt also eine Wärmeeinstrahlung (von über 213 K) von oben an. Satelliten messen als Hintergrundstrahlung des Weltalls nur 3 K, also über 200 K weniger. Ich vermute, dass es IR-Strahlung von nicht sichtbaren IR-aktiven Gasen ist. Ob und in welchen Verhältnis das nun Wasserdampf, CO2 oder Methan ist,kann ich nicht aussagen. Da auch Wissenschaftler, die sich täglich mit dieser Materie befassen wie z.B. DrRoySpencer.com (der als Klimaskeptiker die UAH-Satelliten-Temperaturkurven erstellt), auf solche Geräte verweisen, kann das Ganze nicht so daneben sein.
Wie neugierig ein Mensch sein darf, darüber haben wir anscheinend verschiedene Ansichten.
Auch wenn Verfechter einer anscheinend falschen Theorie ein Argument anwenden, das ihre Theorie stützt, kann man sie dennoch nicht als von vorneherein als falsch und bekämpfenswert ansehen.
Das Argument muß überprüft werden und wenn es stimmt, dann ist es halt so. Wenn es die Gegenstrahlung gibt, dann gibt es dennoch viele Punkte, bei denen die Klimaalarmisten nicht recht haben. Und da müssen wir ansetzen.
Mir erscheint es so, dass hier im Forum jedes Argument gesucht wird, um die Klimaalarmisten zu wiederlegen – aber es wird kein Wert darauf gelegt, ob es auch hieb- und stichfest ist. Das ist ja genau das, was Monckton den Alarmisten vorwirft.
In einer wissenschaftliche Debatte hingegen sollte alles ergebnisoffen sein. Es gibt keine absolute Wahrheit. Es gibt nur Annahmen und Sie gelten nur solange, bis sie widerlegt sind. Darauf kann ich mich als ehemaliger Grüner und Freund von Erneuerbaren Energien berufen – sonst wäre ich nicht hier.
https://goo.gl/eTk9K2
Die Erde empfängt ein gewisses Maß an Solarer Lichtstrahlung,die auf der Oberfläche in Wärme umgewandelt wird. Interessanterweise zeigen tatsächliche Messungen, dass die Erde mehr Energie abstrahlt als sie DURCH SOLARLICHT empfangen hat. Die Frage ist also: Woher kommt der Rest?
Und ein Erklärungsversuch ist der, dass IR-aktive Gase (die es wirklich gibt) aus der Atmosphäre IR-Strahung auf die Erdoberfläche einstrahlen, und dort zu einer zusätzlichen Erwärmung führen.
Das machen sie aber nicht nur seit ein paar Jahren, sondern seit uralten Zeiten.
Dass es eine IR-Gegenstrahlung von oben gibt, dass habe ich versucht nachzuweisen. Aussagen, dass etwas aus dem vorhandenen Gleichgewicht gekommen ist, kann und will ich damit nicht beweisen.
Im Labor beobachtete Moleküle strahlen in eine zufällige Richtung ab, also im Schnitt in alle Richtungen – oder zur Hälfte nach oben und nach unten. Ich denke, sie tun es in freier Wildbahn auch. Wenn nicht, dann braucht man eine Zusatzhypothese, um diese Annahme aufrecht zu erhalten.
Desweiteren findet bei ihm der Wärmetransport von der Erdoberfläche zur TOA (obere Atmosphäre) großteils durch Konvektion statt.
Nur wird dabei übersehen, dass IR-Strahlung mit Lichtgeschwindigkeit stattfindet. Auch nach einigem hin und her der Strahlung ist sie im Sekundenbereich am TOA angelangt. Da kommt die Konvektion nicht mit.
Übrigens kommen auch alle Luftmoleküle auf Ihrer Konvektionsreise nach oben mit IR-aktiven Gasen in Berührung, die von ihnen Energie aufnehmen und wiederum in alle Richtungen abstrahlen können.
Die ganze Treibhaus-Angelegenheit(egal, ob sie nun gefährlich ist oder nicht, oder ob sie überhaupt große Auswirkungen hat und welche Regelmechanismen es noch gibt) hängt an einer einzigen Aussage:
Die IR-Aktiven Gase Wasserdampf, CO2 und Methan,sowie Wassertröpfchen absorbieren IR-Wärmestrahlung und strahlen sie zeitversetzt ab oder geben sie durch Kontaktkollision an andere Moleküle ab. Desgleichen können sie von anderen Molekülen Wärme aufnehmen und
sie in eine zufällige Richtung abstrahlen.
Stimmt das oder nicht? Und wenn nicht, Warum?
Der Link zum Ermecke-Papier:
http://www.ke-research.de/downloads/Treibhaus.pdf
Nach einem schönen Frühlingstag ist die Luft endlich so warm, dass mein bis -60°C reichendes Infrarot-Thermometer auch die Rückstrahlung der Treibhausgase bei klarem Himmel messen kann.
Lufttemperatur 12° im Schatten
Senkrecht in den Klaren Himmel: -55 bis – 60°C
45° in den klaren Himmel: ca 30°C
Senkrecht neben dem Klaren Himmel auf eine dunkle Wolke: -13°C
Senkrecht auf ein helle Wolke, aus der Sonnenlicht durchsickert: – 35°C
45°C auf eine dunkle Wolke: -5°C
Hier nochmal das Ganze mit Erklärungsversuchen:
Senkrecht in den klaren Himmel: -55 bis – 60°C (213 Kelvin)
>>> Endlich haben sich die Treibhausgase soweit erwärmt dass ihre IR-Strahlung ausreicht, um eine Reaktion auf meinem IR-Thermometer auszulösen.
45° Neigung in den klaren Himmel: ca -35°C (248 K)
>>> Der Thermometer empfängt mehr Strahlen aus dem unteren Bereich der Atmosphäre, wo es wärmer ist und die Energiemenge demzufolge höher.
Senkrecht neben dem klaren Himmel auf eine dunkle Wolke: -13°C (260 K)
>>> Der Unterschied von über 40°C zwischen einer Wolkenunterseite und dem klaren Himmel ist schon verblüffend. Wassertröpfchen (Wolken): hohe Rückstrahlung. Unsichbare Treibhausgase einschl. Wasserdampf: relativ niedrige Rückstrahlung.
Zusätzlich befinden sich die Wolken ja im unteren Bereich der Atmosphäre, wo die Temperatur höher ist als im oberen Bereich (Top of Atmosphere / TOA) bei bis über 10 km Höhe.
Senkrecht auf ein helle Wolke, aus der Sonnenlicht durchsickert: – 35°C (248 K)
>>> Das ist eine interessante Erfahrung. Normalerweise könnte ja man meinen, dass das einfallende Sonnenlicht die Temperatur stärker ansteigen lässt. Aber die helle Wolke bleibt ca. 20°C kühler als die dunkle. Warum?
1. Das IR-Thermometer reagiert anscheinend wirklich nicht auf Sonnenlicht, was auch so sein soll.
2. Die durchscheinende Wolke fängt weniger IR-Strahlen auf und sendet auch weniger zurück
45°C auf eine dunkle Wolke: -5°C (268 K)
>>> Zusätzlich zur Rückstrahlung aus der dunkeln Wolke addiert sich die IR-Strahlung der unsichtbaren klimaaktiven Gase aus den unteren, wärmeren Atmosphärenschichten.
Somit scheint die Theorie mit der Beobachtung übereinzustimmen:
Klimaaktive Gase strahlen IR Strahlung gleichmäßig in alle Richtungen ab
Je niedriger die Schichten sind, desto höher ist die Energiedichte
Wassertröpfchen (Wolken) strahlen stärker zurück, als die unsichtbaren Klimaaktivengase, sind also vor allem nachts eine gute Wärmeisolierung der Erde.
Anmerkung 1: Hiermit wird weder ein katastrophale Klimaerwärmung bewiesen, noch dass eine Zunahme des CO2-Gehalts die Temperatur ansteigen lässt.
Anmerkung 2: Bei Kritik an meinen Ausführungen bitte keine Rundumschlag abgeben, sondern exakt zitieren und sachliche Kritik üben.
am Freitag, 25.03.2016, 05:50
An die Herren und Paul, Uhrban und House:
2. Die Erdoberfläche strahlt im Mittel deutlich mehr Energie ab, als sie von der Sonne durch Einstrahlung empfangen hat. Es gibt also die Rückstrahlung.
#####################################################,
Glückwunsch, Sie haben das Perpetuum Mobile der 2. Art gefunden! Wann stellen Sie das Kraftwerk vor, das diesen Effekt nutzt und für alle Zeiten unsere Energieversorgung sichert?
Oder haben Sie am Ende nur nicht die Hauptsätze der Thermodynamik verstanden….?
Ich kann Ihnen als Einstieg nur diese beiden Arbeiten von Prof. Hebert empfehlen:
—————–
http://bit.ly/1kRjgyF
Sehr geehrter Herr Pesch
Prof. Hebert gibt eine nüchterne Darstellung und entspricht damit eher dem, was man unter einem moderaten Skeptiker einordnen kann.
Bei Durchsicht des Textes sind mir einige kleine Ungenauigkeiten aufgefallen:
Abbildung 3 ist etwas irreführend, denn die beiden Plankfunktionen haben etwa die gleiche Amplitudenhöhe und entsprechen hinsichtlich des Kurvenverlaufs nicht der Darstellung, wie er sie auch in Abb.4 verwendete.
Sein Ergebnis auf Seite 9
——————
—————-
Umfangreiche Untersuchungen zum CO2-Kreislauf und Modellrechnungen zur Heizrate des CO2 in der Atmosphäre (DIETZE, 2000) führen zu einem Wert von 3,7 W/m2 für den Fall der Verdopplung
des CO2-Gehaltes.
Dieser Wert wird in der Literatur, auch in der IPCC-nahen meist genannt. Möglicherweise ist dieser für Fa – also reinen Strahlungstransfer um bis zu 30% geringer, wenn man die unterschiedlichen Geopositionen und Wetterlagen gewichtet verrechnet. Allerdings berücksichtigt die eben keine Feedbacks, die vor allem des IPCC eher als verstärkend ansetzt. Andere Autoren gehen von negativen Feedbacks aus.
Dennoch: Ein empfehlenswerter Text, der sich darum bemüht, möglichst neutral die wissenschaftlichen Fakten darzustellen.
Auch so ein Perpetuum mobile ohne Bezug zur Wirklichkeit und das kann jeder jederzeit auf meiner Homepage nachlesen, war hier an dummem Zeug über mich verbreitet wird.
—————-
Sehr geehrter Dr. Stehlik
Ich wüsste nicht, was ich an ihrer Position falsch dargestellt habe. Wir sind uns sicher in so weit einige, dass die Wirkung des CO2 in der Stratosphäre kühlend ist. Wir sind uns nicht einig, dass dies ebenso für die untere Troposphäre gilt.
Ich beziehe mich z.B. auf Modtran, das auch durch Messungen bestätigt wird.
Alle drei physikalisch möglichen Arten von Wärmetransport werden von der NASA und damit auch von mir behandelt und dass bei Interesse an fachlicher Tiefe auf Punkt und Komma: direkte Wärme, latente Wärme und Strahlungswärme!
Hier geht es vor allem um den Strahlungstransport. Diesen kann man ziemlich genau durchrechnen, denn die Linien der bekannten IR-aktiven Gase wurden sehr genau vermessen.
Es ist davon auszugehen, dass die von der Erdoberfläche ausgehnde IR-Strahlung auf die vorhandenen Teilchen auftreffen und diese auch wieder Strahlung zurücksenden. Demnach müsste eine Strahlung aus der Atmosphäre messbar sein.
—————-
Sehr geehrter Herr Herbst
Ihre Überlegungen sind völlig korrekt, und auch der Versuchsaufbau ist nachvollziehbar.
Die einzige Schwäche bleibt, den Frequenzgang der IR-Thermometers nicht genau zu kennen, bzw. nennen. Es könnte darum sein, dass sie die CO2-Bande messen, die H2O Bande, beides oder im atmosphärischen Fenster.
—————- #39: Johannes Herbst sagt:
————–
Keine Aussage ist darüber zu machen:
– Wie stark der Einfluss der Rückstrahlung auf das Klima ist.
– Welche Wärmeflüsse ansonsten in der Atmosphäre stattfinden.
– ob eine Erhöhung des CO2-Gehalts die Atmosphäre stark oder auch nur signifikant erwärmt.
Auch das ist völlig korrekt.
Ein wenig weiter kommt man mit spektrometrischen Messungen und Strahlungstransportmodellen – z.B. MODTRAN. Die so ermittelten Angaben kann man bei Verdopplung des CO2-Anteils je nach Standort und Wetter zwischen 1 und 5 W/m² für Fi ermitteln. Darin bleibt aber zunächst unberücksichtigt, wie die anderen Feedbacks darauf reagieren. bei negativen Feedbacks (Lindzen, Harde) reduziert sich dieses Wirkung weiter. Bei positiven Feedbacks (IPCC) erhöht sich diese Wirkung.
Wählen Sie lieber die AfD als mich zu ärgern.
wenn Ihr „Infrarot-Thermometer der gehobenen Klasse, Messbereich -60°C bis + 550°C“
Senkrecht nach oben unter 60°C zeigt,
misst er überhaupt keine Strahlung!!!!
Siehe #10 und folgende.
Dass feste und flüssige Körper (Wolken) temperaturabhängig strahlen bestreitet keiner, das kann aber nicht zu einem Treibhauseffekt führen sagt die Physik UND das kann man messen,
denn Energie kann nicht aus dem NICHTS entstehen:
Die Wärmequelle ist die Sonne, nicht die Erdoberfläche und die Wolken blockieren nun mal diese Wärmequelle auf dem Weg zur Erdoberfläche,
nicht nur durch Reemission, sondern ganz erheblich auch durch Reflexion von Sonnenlicht in den Weltraum, das sieht auch der Satellit
http://tinyurl.com/hm6hhjb
oder
http://tinyurl.com/zy9tg8s
Trotz Strahlung der Wolken auch nach unten ÜBERWIEGT also die Abkühlung
http://tinyurl.com/ns3jeha
und das misst man auch.
Das ist daher erledigt
Es geht aber um das CO2-Spuren-Gas von 0,04% mit einer nur selektiven theoretischen Strahlungsmöglichkeit bei 15µm
Bitte nur das nachweisen!
nichts anderes!
mfG
Ihr Versuchsaufbau wird auch durch Staubpartikel in der Luft beeinflußt. Und die strahlen im selben Spektralbereich wie der Erdboden.
Interessanter wäre eine Messung mit einem IR-Spektrometer ausschließlich der Kennlinien von CO2 in verschiedenen Höhen.
Noch interessanter wäre es allerdings, wenn man dabei auch noch die Anzahl der eintreffenden Photonen zählen könnte. Bei der gängigen Strahlentheorie und annähernder Gleichverteilung von CO2 müßte die Zahl der eintreffenden Photonen in jeder Richtung und in jeder Höhe etwa gleich sein.
„Auf der anderen Seite ist zuweilen Dr. Stehlik zu hören, der zu recht darauf verweist, dass CO2 durch seine Emission eben durchaus eine Kühlwirkung hat, aber darin ignoriert, dass die Wirkung in den bodennahen Schichten von anderen Wirkungen im Systemkontext überlagert wird.“
Auch so ein Perpetuum mobile ohne Bezug zur Wirklichkeit und das kann jeder jederzeit auf meiner Homepage nachlesen, war hier an dummem Zeug über mich verbreitet wird.
Alle drei physikalisch möglichen Arten von Wärmetransport werden von der NASA und damit auch von mir behandelt und dass bei Interesse an fachlicher Tiefe auf Punkt und Komma: direkte Wärme, latente Wärme und Strahlungswärme!
http://www.gerhard-stehlik.de Oder Google findet mich!
http://bit.ly/1kRjgyF
http://bit.ly/1BJ3FHU
Das vervollständigt das Bild
http://bit.ly/1TBQf5O
Danach müssen Sie nicht mehr glauben was Medien und Politik verkünden….
„gegen die herrschende CO2-Treibhaustheorie“
Haben Sie immer noch nicht begriffen, daß das eine Hypothese ist und keine Theorie?
Die Verursachung von Lungenkrebs durch Tabakrauch ist eine Theorie, war aber mal eine Hypothese. Sie wird auch nicht durch H. Schmidt falsifiziert, nur weil der nicht am Lungenkrebs starb. Falsifiziert wird nur die Theorie, daß Tabakrauch die alleinige Ursache ist.
googln Sie einmal Klaus Ermecke KEResearch. Da finden Sie auch eine für Laien verständliche Darstellung warum es keinen Treibhauseffekt gibt. Eigentlich hat Wood dies schon mit seinem Experiment gezeigt. Überlegen Sie doch einmal folgendes, wenn das CO2 tatsächlich die oberflächentemperatur um 1 °C erhöht, dann beginnt diese stärker zu strahlen und zwar über den ganzen Frequenzbereich. Woher wissen denn jetzt die CO2- Moleküle, daß sie mehr zurückstrahlen müssen nur um auf dem 1° höheren Temperaturniveau zu bleiben.
Mfg
a)durch Infrarote Strahlung in eine zufällige Richtung oder
b) durch Kontakt-Kollision an ein anderes Atmosphärisches Molekül einschließlich O2 und N2 ab.
O2 und N2 können Wärme durch IR-Strahlung weder aufnehmen noch abgeben, sondern nur durch Kontaktkollission.
Es ist davon auszugehen, dass die von der Erdoberfläche ausgehnde IR-Strahlung auf die vorhandenen Teilchen auftreffen und diese auch wieder Strahlung zurücksenden. Demnach müsste eine Strahlung aus der Atmosphäre messbar sein.
VERSCHSAUBAU:
Infrarot-Thermometer der gehobenen Klasse, Messbereich -60°C bis + 550°C. Messwinkel 1:12
Funktionsweise: Gerät funktioniert durch Vergleich der Eigen/Umgebungstemperatur mit der eingehenden Strahlung mittels einer Thermosäule. Einflüsse durch sichtbares und Sonnenlicht werden weitestgehend abgeschirmt.
Gerät funktioniert nicht durch Direktkontakt und nicht unter Wasser. Infrarote Strahlen können nicht durch Glas hindurch, deshalb wird die Wärmeabstrahlung des Glases gemessen. PE-Folien können teilweise durchdrungen werden.
Voraussetzung: Die Hintergrundstrahlung des Weltalls liegt ca. 3°C über dem absoluten Nullpunkt, also ca. 3 Kelvin oder -270°C. Das ist ein durch Satellitenmessungen allgemein anerkannter Wert. dieser liegt über 200°C niedriger als das o.g. Thermometer messen kann. wenn das Thermometer etwas anzeigt, dann ist tatsächlich eine nennenswerte IR-Strahlung Richtung Erdoberfläche vorhanden.
Messungen:
Bodentemperatur ca 0°- 10°C
1. Bedeckter Himmel
senkrecht: ca. -10 bis -5°C
Richtung 45° zum Himmel: ca. -5 bis 0°C
15° über dem Horizont: ca. 0 bis 5°C
2. bei klarem Himmel:
-Senkrecht: Tiefer als 60°C
-45°C zum Himmel: Kommt in den Messbereich des Thermometers ca. -30 bis -50°C
-15°über dem Horizont 0 bis -20°C
Schlussfolgerungen
a) Bei bedecktem Himmel dominieren die Wolken (Wassertröpfchen)und senden deutlich stärkere IR-Strahlung als bei klarem Himmel aus.
b) bei klarem Himmel (ohne Wassertröpfchen) ist die IR-Strahlung wesentlich geringer, der Thermometer zeigt zig Grade weniger an. Die Wassertröpfchen des bedeckten Himmles senden eine sehr deutliche und kräftige IR-Strahlung aus.
c) Bei Neigung des Messwinkels auf 45° oder bis auf 15° über dem Horizont geht eine deutlich stärkere Strahlung ein als beim Messen senkrecht nach oben. Senkrecht beträgt die Strecke bis zum oberen Ende der Atmosphäre ca. 10 KM, bei Neigung 15° ü. Horizont sind es ca. 40 KM, wobei vermehrt Strahlung aus der unteren und wärmeren Atmosphäre eintrifft.
Durch die Messergebnisse ist anzunehmen, dass die o.g. Atmosphärenbestandteile tatsächlich in Richtung Erdoberfläche zurückstrahlen, wobei Wolken (Wassertröpfchen) einen sehr viel stärkeren Anteil ausmachen. Das lässt sich auch durch die allgemeine Beobachtung bestätigen, dass ein Wolkige himmel wärmere Nächte mit sich bringt als ein klarer Nachthimmel.
Damit lassen sich die im Laboratorium erforschten Eigenschaften der klimasensitiven Anteile der Atmosphäre auch auf die Realität übertragen.
Keine Aussage ist darüber zu machen:
– Wie stark der Einfluss der Rückstrahlung auf das Klima ist.
– Welche Wärmeflüsse ansonsten in der Atmosphäre stattfinden.
– ob eine Erhöhung des CO2-Gehalts die Atmosphäre stark oder auch nur signifikant erwärmt.
Im Sommer wurden auch bei senkrechtem Messungen und wolkenlosem Himmel Temperaturen von – 20°C und höher gemessen – es kommt also auch da tatsächlich IR-Strahlung aus den unsichtbaren Teichen der Atmosphäre an.
Soweit mal die Theorie und die Messungen.
Da ist der echte Philosoph und Wissenschaftler wesentlich bescheidener mit dem klassischen:
„scio nescio“ das Sokrates zugeschoben wird:
„ich weis, dass ich nichts weis“ mit der darin enthaltenen Mahnung,
Glauben und Wissen gut auseinander zu halten.
Wenn man nun mit der fehlenden Messbarkeit eines CO2-Erwärmungseffektes nicht zufrieden ist und auch hier nach dem WARUM fragt,
so kann auch hier der eigentlich überflüssige Gedankensport beginnen, die bekannten physikalischen Gesetze bei dieser Theorie anzuwenden und man wird erkennen können, WARUM es keinen CO2-Erwärmungs-Effekt für die Erdoberfläche geben kann.
Da nur das CO2 für die falsch handelnde Politik relevant ist, sollte man alle Nebenschauplätze eher meiden, obwohl man eigentlich überall wo man näher nachbohrt, bei den primitiven „Klimarettern“ grobe Fehler findet, wie den Untergang der armen Eisbären etc..
Besonders verräterisch ist der Betrug, wenn gleichzeitig von den „Klimagift-CO2-Vertretern“ auch die für die Atmosphäre emissionsfreie Kernenergienutzung fanatisch bekämpft wird.
mfG
Solche Nutznießer entsprechen Parasiten, die irgendwann selbst aussterben müssen weil sie alle ihre Opfer getötet haben.
Es werden mit dieser falschen Ideologie rießige Resourcen einfach vernichtet, die sowohl für die Natur als auch für den Mensch, der mir ehrlich gesagt viel näher steht nutzbringender eingesetzt werden müssen. Das gilt auch für die betrügerische Wissenschaft.
Kurz zusammengefasst:
Jeder behauptete physikalische Effekt („CO2 führt zur Temperaturerhöhung der Erdoberfläche“)
muss auch physikalisch MESSBAR sein.
Für diese Notwendigkeit kann und darf es KEINE Ausnahme geben.
Man kann prinzipiell sowohl CO2 in der Luft wie die Temperatur der Erdoberfläche messen, mal abgesehen von der Genauigkeit.
Die existierende Ungenauigkeit reicht aber völlig aus, um langfristig KEINEN Zusammenhang zwischen diesen beiden Werten zu bestätigen!
http://tinyurl.com/oybzywl
Einen weiteren VERNICHTENDEN Befund gegen eine Treibhauswirkung von CO2 liefert das Henry´Gesetz mit der Temperaturabhängigkeit der Löslichkeit von CO2 im Wasser, da die Erde ein Wasserplanet ist und mehr als 50-mal soviel CO2 in Wasser GELÖST ist, als in der gesamten Atmosphäre.:
http://tinyurl.com/c9g4txy
Die MESSUNG zeigt hier, dass entsprechend diesem Gesetz, die CO2-Konzentration in der Atmosphäre mit zeitlicher Verzögerung der Meerestemperatur FOLGT.
Auch das stört die Treibhausvertreter überhaupt nicht, im Gegenteil sie meinen man könnte Ursache und Wirkung einfach umkehren.
Wenn also ein Jäger einen Hasen mit dem Gewehr erschießt, entspricht es der physikalischen Logik der Treibhausvertreter,
dass zuerst der Hase tot umfällt
und danach erst der Schuss des Jägers erfolgt.
Damit sollte man eigentlich die ganze Diskussion beenden,
zumal sowohl ein Temperaturanstieg wie ein CO2 Anstieg nützlich für Natur und Mensch ist,
auch das versteht jeder normale Mensch.
mfG
Fortsetzung:
Die fehlende Transmission in einem Wällenlängenbereich ist eine MESSUNG.
Also ein Detektor, der sehr hochempfindlich für diese Wellenlänge ist, kann 0 = keine Strahlung dieser Wellenlänge registrieren.
Die Astronomen haben zusätzlich gigantische fokussierende Spiegel und „optische Linsen“ um sozusagen alle Strahlung in einem großen Bereich auf einen Punkt zu konzentrieren.
Und auch hier ist da Ergebnis 0 = nicht, KEINE Strahlung.
Wie wollen Sie bitte einem normal denkenden Menschen erklären, dass ausgerechnet solche 15µm Strahlen DOCH existieren?????
Ist das eine geheime „para-15µm-Srahlung“ die man nicht messen kann?
Und nur Menschen mit dem „Treibhaus-Para-Gehirn“ sind in der Lage solche nicht messbaren Strahle wahrzunehmen,
oder einfach zu „errechnen“ fuck doch die Messungen!
mfG
Bisher habe ich immer noch nicht verstanden, worum es dabei wirklich geht.
—————-
Sehr geehrter Herr Herbst
Das Thema ist in so fern verwirrend, da Dr. Paul und Andere se nicht genug damit sein lassen, dass die AGW-Hysterie schädlich ist und darum auch argumentativ zu bekämpfen ist, sondern er und andere legen entscheiden Wert darauf, dass es gar keinen Treibhaus-Effekt gibt. Das wird dann von ihm und einigen anderen zur reinen Lehre erhoben und alle Ketzer, die irgend etwas anderes sagen, zu Feinden erklärt.
Dabei werden offensichtliche Fakten und gut belegtes Lehrbuch-Wissen kurzerhand umgedeutet. Und Leute in den Zeugenstand gerufen, die offensichtlich völlig anders als er argumentieren.
So bezieht sich Dr. Paul gerne auf die Arbeit von Prof. Gerlich und Tscheuschner, die keineswegs bestreiten, dass es IR aktive Gase gibt, die durchaus wirksam das Erwärmungsverhalten der Atmosphäre beeinflussen. Deren Argumentation gegen den TE geht verstärkt auf den definitorischen und quantifizierenden Ansatz. Ebenso Prof. Kramm, der wegen der Komplexität der Atmosphärenphysik eine Definition eines TE ablehnt, darin aber natürlich nicht die Absorbtion und Emission des CO2 bestreitet. Die Widersprüche, in die sich Dr. Paul und andere sich in Bezug auf ihre Kronzeugen verwickelt, sind darum am Besten als ideologische Fixierung zu verstehen, die letztlich der Sache der AGW-Kritik nicht nutzt.
Auf der anderen Seite ist zuweilen Dr. Stehlik zu hören, der zu recht darauf verweist, dass CO2 durch seine Emission eben durchaus eine Kühlwirkung hat, aber darin ignoriert, dass die Wirkung in den bodennahen Schichten von anderen Wirkungen im Systemkontext überlagert wird.
Insgesamt ergibt es ein buntes Bild derer, die die AGW-Propaganda scharf ablehnen, aber in sich keineswegs hinsichtlich der Physik einig sind.
Bedauerlich daran ist, dass man bei derartigen Streit zu Detailfragen das große Ziel, nämlich die wirksame Bekämpfung der verderblichen AGW-Hysterie, aus den Augen verliert und sich mit Grabenkämpfen verzettelt.
„Der empirisch Nachweis für einen Treibhauseffekt ist recht einfach: Wer ein ganz normales Infrarotthermomether in Richtung Himmel hält, erhält Werte, die deutlich über dem absoluten Nullpunkt (-273°C oder 0 Kelvin) liegen.“
Das ist die typische Physik eines Gläubigen an das Treibhaus. Und mit diesem Glauben hat er ja auch völlig recht. Nur sollte er die Messung nicht in der Luft machen sondern unter Wasser. Da wird auch nicht –273°C gemessen.
In der Luft senkrecht nach oben werden je nach Wetterlage, also bei klarem Himmel ein –35°C Treibhaus gemessen und bei Regen nur ein +15°C Treibhaus gemessen.
Unter Wasser in der Karibik würde man ein +25C Treibhaus messen.
Die physikalische Dummheit dabei ist, beim Treibhauseffekt geht es primär nicht um gemessene Temperaturen, die sagen wie hier gezeigt wurde, gar nichts aus, sondern um den Fluss an infraroter Wärmestrahlung in W/m2 und den kann man nur durch eine Differenz der Strahlungstemperaturen messen. Mann muss also mal senkrecht nach unten und dann senkrecht nach oben messen.
Ob Stehlik, Paul oder Herbst verstehen, was da gemessen wird, ist nicht relevant.
Wird im Wasser senkrecht nach unten und nach oben gemessen, kommt in beiden Fällen in der Karibik +28°C heraus. Es fließt nur Energie nach oben oder unten, die so klein ist, dass sie mit so einem einfachen Gerät nicht messbar ist.
Wird „meteorologisch in Luft von 2 m Höhe“ senkrecht nach oben und unten gemessen, kommt das elektromagnetische Kühlhaus dabei heraus: Unten ist es immer wärmer als oben und es findet Strahlungskühlung, aber keine Erwärmung statt.
Ohne IR-Aktivität würde sich die Atmosphäre tatsächlich wie ein Treibhaus aufheizen, weil ihr von unten immer Wärme von der Sonne zugeführt wird, die aus ihr niemals wieder heraus käme, weil sie keine Strahlungsenergie an Weltall abgeben kann.
Mein ALDI IR-Thermometer würde also ohne kühlende IR-aktive Bestandteile in der Luft noch höhere Luft-Temperaturen messen als mit CO2!
Der Betrug über die elektromagnetische Leitfähigkeit von Energie durch CO2 ins All und der nicht vorhanden elektromagnetischen Leitfähigkeit von N2 und O2 ist ein gigantischer!
Dass Paul und Herbst von elektromagnetischer Induktion als physikalisches Prinzip Heizung von Töpfen geeigneter Bauart (!), zur induktiven elektrischen Aufladung von Zahnbürsten und zur Messung von Strahlungstemperaturen ist nur ein Teilaspekt, der diesen gigantischen Betrug sehr erleichtert.
Dass die Administratoren von EIKE da mitspielen, ist auch ein solcher Teilaspekt.
Es wäre mal wirklich sehr nett, wenn Sie uns Ihre Theorie der Spurengase (CO2/Wasserdampf/Methan) für Laien kurz und einfach verständlich darlegen könnten.
Bisher habe ich immer noch nicht verstanden, worum es dabei wirklich geht.
Wissenschaft muss nicht immer rein deduktiv vorgehen – siehe 14:30. Das ist keine Anforderung der wissenschaftlichen Methode. Darum sind auch Betrugsvorwürfe hier ebenso unbegründet, wie auch auf das Fehlen von expliziter Idealtemperatur zu verweisen: Es ist ein gutes Argument, dieses Fehlen zu thematisieren, aber es ist überzogen, daraus einen Betrugsvorwurf zu machen.
Oder 15:50 Der Ozean würde sich in den tieferen Schichten erwärmen. Das sei ein Faktum. und das wäre durch eine vulkanische Aktivität zu erklären. So einfach ist es aber nicht. Denn einerseits konnte in dem relativ kurzen Beobachtungszeitraum keine eindeutige Erwaärmung der tieferen Schichten sicher nachgewiesen werden, andererseits sind thermohaline Strömungen durchaus für das Absinken und aufsteigen von Wassermassen verantwortlich. Eine entsprechende Beobachtung, so sie überhaupt gesichert nachgewiesen werden könnte, kann ohne komplexe Modell nicht erklärt werden.
Das unkritische Behaupten von Sachverhalten, die unzureichend belegt sind, weckt allerdings Zweifel an der vorgetragenen These.
2+2=5
Habs grad mit Excel ausprobiert und es funktioniert mit Hilfe der Darstellung von gerundeten Zahlen (0 Nachkommastellen).
Eingabe: (Feld1) 2,4 (Feld2) 2,4 =Summe (Feld3) 4,8
Angezeigt: (Feld1) 2 (Feld2) 2 =Summe (Feld3) 5
Es ist also nur eine Frage der sichtbaren Darstellung.
Weil die ja wegen Photosynthes aus der Umgebung Energie aufnehmen.
„hindurch“ sollten sie noch schreiben um etwaige Übersetzungsfehler, von lediglich nur Sprachwissenschaftlern zu vermeiden. Denn DURCH kann ja auch wie aus dem lateinischen bekannt „per“ bedeuten, dass es also aufgrund dessen aus der Atmosphäre Dasein strahlt.
Was es ja auch ein wenig tut – angetrieben aus der Sonne strahlen, halt jedoch in anderen Banden. Also bei wolkenlos halt Himmelsblau
Zitat: Mit Abstand am empfindlichsten sind die astronomischen IR-Teleskope, die zeigen bei 15µm wie bekannt 0 Strahlung, also eine Widerlegung einer CO2-Strahlung http://tinyurl.com/cvrssgr
Wie kommen Sie bei einer Transmission gleich null darauf, dass keine Strahlung emittiert werden kann?
Allgemein gilt: R(n,k) + T(n,k) + E(n,k) + S(n,k) = 1, wenn die Transmission T(n,k) gleich 0 ist, bedeutet das, R(n,k) + E(n,k) + S(n,k) = 1
Mfg
Werner Holtz
Zitat: IR-Thermometer gegen den Himmelgehalten, misst in einem Bereich von ca. 5 Winkelgraden. Die digitale Gradanzeige zeigt dann einen Wert an, der einem Gegenstand in der Nähe entspricht, der die entsprechende Temperatur hat und eine entsprechende IR-Strahlung aussendet.
Ein IR-Thermometer ist für strahlungs-undurchlässige Objekte konzipiert, denn nur für undurchlässige Objekte gilt: R = 1-E (Reflexionsgrad des Objektes). Auf dieser Grundlage arbeitet ein IR-Thermometer. Die Vermessung von transmitterenden Objekten mit einem IR-Thermometer ist folglich mit relativ großen Fehlern belastet.
Mfg
Werner Holtz
es hat mich nachdenklich gestimmt, wie Sie den Frieden mit der Naturwissenschaft beschreiben.
Das gesprochene Wort oder das geschriebene Buch hat immer subjektive Eigenheiten.
Aus diesem Grund macht Naturwissenschaft Beobachtungen und Experimente.
Und was dann für alle Interessierten zum Konsens wird, macht Sinn.
Entweder für das allgemeine Verständnis und besser noch für eine sinnvolle ,technische Anwendung.
Warum wird der Klimawandel nicht vom Antrieb her diskutiert?
Wenn man sich sicher ist, wie dieser Antrieb funktioniert, kann man in fortgeschrittenem Stadium sich auch über die „Abgaswerte“ unterhalten.
Es hat immer mit Missbrauch zu tun,wenn Angst erzeugt wird.
So tickt nun mal menschliches Gehirn.Und so werden damit nichtseriöse Geschäfte gemacht.
Im Alter verliert sich die Angst.Dann ist es auch kein Problem mehr Respekt zu zeigen,gegenüber Menschen die ein anderes Verständnis äußern,wie die Zusammenhänge um uns herum ineinander wirken.
Nur um mal zu sehen ob der Groschen gefallen ist oder nicht.
In dieser kleinen Bildsequenz habe ich die grundlegenden Elemente fotografiert.
http://tinyurl.com/jgghrdy
Und ein Gedanke noch zum Schluss:
Der Dampfdruck von Wasser ist temperaturabhängig.Diese Auswirkungen finde ich in keinem Klimamodell.Da haben die Wissenschaftler auch keine Chance was zu verändern.
Beim sinnvollen „googlen“ hat jeder die Möglichkeit nochmal nachzulesen, welche Voraussetzungen erfüllt sein müssen,damit von wissenschaftlicher Tätigkeit die Rede sein kann.Ich meine die Erläuterungen von Dr.-Ing. Heiner Grimm aus Clausthal-Zellerfeld.
Mit herzlichem Glückauf
es sollte Ihnen zumindest klar sein, dass Ihre Behauptungen dieser gleich sind: „Wieso ist 2+2=5 falsch? Das ist nicht wahr! Ich habe es mit einem Gerät nachgemessen, es stimmt genau: 2+2=5!“
Es ist überraschend scharf, weil in diesem Bereich die Streuung geringer ist.
Hier ist ein echtes „Wärmebild“ durch das offene atmosphärische Fenster von einem Haus:
http://tinyurl.com/q5sn7j8
und auch hier ist der Himmel schwarz, weil er nicht strahlt.
Auch hier kann Reflexion enthalten sein, weshalb man bei solchen Fotos immer auch die Umgebung mit beachten muss.
Militärisch gibt es im 500°C Bereich auch Fernaufklärung (Schiffsschornstein, Flugzeugtriebwerke)
Mit Abstand am empfindlichsten sind die astronomischen IR-Teleskope,
die zeigen bei 15µm wie bekannt 0 Strahlung,
also eine Widerlegung einer CO2-Strahlung
http://tinyurl.com/cvrssgr
mfG
und lesen Sie meinen Beitrag #10
oder wollen Sie nicht?
Das gezeigte IR-Bild ist jedenfalls kein Irrtum, sondern ein Bild OHNE Strahlung aus dem blauen Himmel im Bereich der IR-Kamera!
Am leichtesten macht es sich immer unser Physikexperte Landvoigt,
der das Bild ganz ohne Sachargumente offensichtlich für extreme Ideologie hält 🙂
Und unterstellen Sie mir einfach nichts was ich nicht gesagt habe.
Mit der ominösen „Gegenstrahlung“ können Sie sich nur eine blutige Nase holen.
Die nimmt kein seriöser Wissenschaftler ernst.
Wer eine „Gegenstrahlung“ von CO2 behauptet, hat eine Strahlung im 15µm von oben nachzuweisen,
das Gegenteil, nämlich eine Transparenz von 0 wird gemessen.
In einer Kamera mit einem Sensor im 15µm-Bereich kommt alsomvon oben 0 an!!!
In welcher Frequenz oder Wellenlänge wollen Sie denn nun messen?
Oder weil das nicht geht und das offene Fenster ja nicht gleichzeitig selbst strahlen kann,
erfinden wir doch einfach eine nicht messbare Strahlung in dem wir die Atmosphäre zum Schwarzkörper machen und dann über die Temperatur nach S&B eine Strahlung errechnen.
Leider ist das scientific misconduct, vulgo grober Betrug,
schlicht der größte Wissenschaftsskandal der Neuzeit.
mfG
„Eine Infrarotthermometer würde hier bestimmt etwas anzeigen“
ha, ha, das ist ja wohl ein Witz mit Ihrem „… ganz normales Infrarotthermomether …“
haben Sie #10 nicht verstanden?
Na klar ist das eine Frage von Wellenlängen, hab ich Ihnen doch vorgeworfen.
Lesen Sie einfach #10 noch einmal ganz in Ruhe durch!
Da hilft auch kein Fred Singer.
Dass Wolken strahlen hat niemand in Zweifel gezogen!!!
Was hat das denn mit einem „Treibhauseffekt“ zu tun? Das ist nun wirklich kindisch,
Wolken kühlen!!!
http://tinyurl.com/ns3jeha
wollen Sie diese MESSUNG bitte zur Kenntnis nehmen?
Das hatten wir doch schon einmal.
http://tinyurl.com/Paul-irrt-im-IR
Satz mit „X“.
der wolkenfreie Himmel fehlt komplett (schwarz!)
also keine Wärmestrahlen!!!
Es gibt keine Gegenstrahlung AUS der Atmosphäre,
————
es strahlt DURCH die Atmosphäre.
Sehr geehrter Dr. Paul
Es sollte Ihnen klar sein, dass IR-Kameras nur im atmosphärischen Fenster arbeiten. Wäre die Sensitivität über das gesamte Spektrum, würde alles im Nebel untergehen.
Die Frage ist, bei welchen Wellenlaengen die IR-Kamera gemessen hat?
MfG
J. Reiter
Ich bin eigentlich ein recht umweltbewegter Mensch und auch ein Interessierter an Erneuerbaren Energien. Mir ist aber immer die wissenschaftliche bzw. empirische Herangehensweise wichtig. Und dann lernt man eben dazu – was geht und was nicht – und was stimmt und was nicht.
So habe ich auch eingesehen, dass die CAGW-Theorie nicht stimmt. Ich bin langsam dabei, auf meinem Klimawandler-Blog meine Erkenntnisse ganz nüchternzu sammeln und blicke schon etwas besser durch als vor einigen Jahren. Es ist schon erstaunnlich wie wenig rein sachliche Informationen und klare Zusammenstellungen im Teutschen Skeptiker Lager vorhanden sind. Noch weniger wenn es um allgemeinverständliche Erklärungen geht.
Wer sich als Normalbürger auf Eike verirrt, bekommt sofort das Gschmäckle mit, das hier vorherrscht. Sieht irgendwie nach einem grantelnden und polternden Altherrenclub aus – wenn man mal von den nebulösen Außerungen von Frau Meinhard absieht.
Irgendwie hat EIKE das nicht verdient. Ich wünsche dieser Website ein besseres Image und Überzeugungsvermögen auch für Andersdenkende.
Wenn sie jedoch genau hinsehen, dann zeigt auch der Wolkenfreie himmel eine tönung an und ist nicht komplett schwarz.
Eine Infrarotthermometer würde hier bestimmt etwas anzeigen.
Hier die schöne Geschichte von Dr Roy Spencer und seinem IR-Thermometer:
Help! Back Radiation has Invaded my Backyard!
August 6th, 2010 by Roy W. Spencer, Ph. D.
Measuring The (Nonexistent) Greenhouse Effect in My Backyard with a Handheld IR Thermometer and The Box
http://tinyurl.com/2wmhvxz
Ein Beweis ist für ihre Tehorie sind die Bilder also nicht.
Hier zwei Bilder von Dr Roy Spencer mit der erklärung von ihm dabei.
http://tinyurl.com/zgektdv
Was mir immer noch fehlt, ist eine für Laien verständliche Erklärung Ihrer Theorie. Gehe ich recht in der Annahme, dass bei ihnen CO2 et al keine Wärmestrahlung aufnehmen und diese Zeitversetzt in eine zufällige Richtung abstrahlen?
Das Ganze wurde doch schon ausgiebig im Labor getestet. Wieso kommen Sie denn da auf eine andere Ansicht?
Wenn man die Emmisitivität eines Gegenstandes weiß, kann man ihn an der Infrarot-Messpistole einstellen. Die meisten Materialien auf der Erde haben eine Emmissitivität von 0,95. Deshalb ist die Grundeinstellung der Thermometer auch so. Für grobe Vergleiche langt das allemal.
Ein IR-Thermometer gegen den Himmelgehalten, misst in einem Bereich von ca. 5 Winkelgraden. Die digitale Gradanzeige zeigt dann einen Wert an, der einem Gegenstand in der Nähe entspricht, der die entsprechende Temperatur hat und eine entsprechende IR-Strahlung aussendet.
Hier noch eine einfache Erklärung in Englich von Dr Roy Spencer, der mit Dr Christy die UAH-Satellitendaten herausgibt:
What is the atmospheric greenhouse effect?
It is the warming of the surface and lower atmosphere caused by downward infrared emission by the atmosphere, primarily from water vapor, carbon dioxide, and clouds.
Greenhouse gases and clouds cause the lower atmosphere to be warmer, and the upper atmosphere to be cooler, than if they did not exist…just as thermal insulation in a house causes the inside of a heated house to be warmer and the outside of the house to be cooler than if the insulation was not there. While the greenhouse effect involves energy transfer by infrared radiation, and insulation involves conduction, the thermodynamic principle is the same.
Without greenhouse gases, the atmosphere would be unable to cool itself in response to solar heating. But because an IR emitter is also an IR absorber, a greenhouse atmosphere results in warmer lower layers — and cooler upper layers — than if those greenhouse gases were not present.
As discussed by Lindzen (1990, “Some Coolness Concerning Global Warming”), most of the surface warming from the greenhouse effect is “short-circuited” by evaporation and convective heat transfer to the middle and upper troposphere. Nevertheless, the surface is still warmer than if the greenhouse effect did not exist: the Earth’s surface emits an average of around 390 W/m2 in the thermal infrared even though the Earth absorbs only 240 W/m2 of solar energy.
I have demonstrated before how you can directly measure the greenhouse effect with a handheld IR thermometer pointed at the sky. I say “directly measure” because an IR thermometer pointed at the sky measures the temperature change of a thermistor exposed to varying levels of IR radiation, just as the temperature of the Earth’s surface changes in response to varying levels of downwelling IR radiation.
I recently purchased a FLIR i7 thermal imager, which instead of measuring just one average temperature, uses a microbolometer sensor array (140 x 140 pixels) to make 19,600 temperature readings in an image format. These are amazing little devices, originally developed for military applications such as night vision, and are very sensitive to small temperature differences, around 0.1 deg. C.
Because these handheld devices are meant to measure the temperature of objects, they are tuned to IR frequencies where atmospheric absorption/emission is minimized. The FLIR i7 is sensitive to the broadband IR emission from about 7.5 to 13 microns. While the atmosphere in this spectral region is relatively transparent, it also includes some absorption from water vapor, CO2, oxygen, and ozone. The amount of atmospheric emission will be negligible when viewing objects only a few feet away, but is not negligible when pointed up at miles of atmosphere.
Everything around us has constantly changing temperatures in response to various mechanisms of energy gain and loss, things that are normally invisible to us, and these thermal imagers give us eyes to view this unseen world. I’ve spent a few days getting used to the i7, which has a very intuitive user interface. I’ve already used it to identify various features in the walls of my house; see which of my circuit breakers are carrying heavy loads; find a water leak in my wife’s car interior; and see how rain water flows on my too-flat back patio.
The above pair of images shows how clouds and clear sky appear. While the FLIR i7 is designed to not register temperatures below -40 deg. F/C (and is only calibrated to -4 deg. F) you can see that sky brightness temperatures well above this are measured (click the above image for full-size version).
This is direct evidence of the greenhouse effect: the surface temperature of the microbolometer within the thermal imager is being affected by downwelling IR radiation from the sky and clouds, which is exactly what the greenhouse effect is. If there was no downward emission, the sky temperature as measured by a perfectly designed thermal imager would read close to absolute zero (-460 deg. F), that is, it would measure the cosmic background radiation if the atmosphere was totally transparent to IR radiation.
Just so there is no confusion: I am not talking about why the indicated temperatures are what they are…I am talking about the fact that the surface temperature of the microbolometer is being changed by IR emission from the sky. THAT IS the greenhouse effect.
Die Bilder dazu hier:
http://tinyurl.com/zgektdv
http://tinyurl.com/oxv7o2s
und das gleiche mit einer IR-Kamera:
http://tinyurl.com/opxxeba
der wolkenfreie Himmel fehlt komplett (schwarz!)
also keine Wärmestrahlen!!!
Es gibt keine Gegenstrahlung AUS der Atmosphäre,
es strahlt DURCH die Atmosphäre.
Der „CO2- Treibhauseffekt“ ist der größte Wissenschaftsskandal der Gegenwart.
denn diese Strahlen von der Sonne werden irgendwie selbständig und sausen in der Atmosphäre so lange hin und her, bis es immer mehr werden, immer mehr,
na klar viel mehr als von der Sonne herein kommen.
Eigentlich könnte man ja ganz auf das bischen Sonnenstrahlen verzichten.
Der empirisch Nachweis für einen Treibhauseffekt ist recht einfach …
——————-
Sehr geehrter Herr Herbst
Ihre Argumentation zielt auf ein Argument wissenschaftlicher Natur. Ihre Meinungsgegener aber haben wahrscheinlich eine ideologische Fixierung. Auch wenn wir gemeinsam die AGW-Hysterie mit jeweils guten Gründen scharf ablehnen, so tun wir uns mit einem Konsens sehr schwer. Warum?
In der Tat ist der physikalische Hintergrund alles andere als leicht verständlich. Aber ich sehe damit keine Rechtfertigung, beliebiges zu behaupten – und damit meine ich jetzt nicht Sie.
Zum Verständnis der Radikalgegner des Treibhauseffektes erinnert mich das an eine religiöse Bewegung. Wer der Lehre nicht völlig folgt, wird als Ketzer angesehen und eigentlich den Feinden zugerechnet. Das ist bedauerlich, denn wiewohl jene moderate AGW-Kritiker scharf zurückweisen, sehen auch diese die radikalen Treibhausgegner als kontraproduktiv an, denn sie diskreditieren die AGW-Kritik als ignorant.
Mir persönlich wäre es lieber, wenn wir schon keinen Konsens in der Sache erreichen können, dass man zumindest die jeweils andere Position respektiert, auch wenn man sie nicht teilt. Allerdings habe ich keine Hoffnung mehr, dass das erreichbar ist.
Nach meinem Kenntnisstand können die digitalen Sensoren nur messen was im rechten Winkel „aufprallt“; hätten Sie da etwas zu (Link, Paper)?
„… ein ganz normales Infrarotthermomether …“
wie bei unserem sehr verehrten Herrn Stehlik gravierende Unkenntnis über die Pyrometer-Funktion.
Es handelt sich dabei leider NICHT um eine Temperaturmessung, weil Wärme und Temperatur an Masse gebunden ist.
Sondern um eine Registrierung von Strahlung, wichtig,
SOWEIT die Detektoren dazu überhaupt geeignet sind!!!
diese Strahlung wird erst UMGERECHNET in Temperatur, mit erforderlichen Zusatzinformationen, die das Gerät NICHT messen kann.
„ein ganz normales Infrarotthermomether“ misst (hoffentlich) keine Sonneneinstrahlung und im IR-Bereich endet die Messung vor 14µm,
größere Wellenlängen, falls vorhanden, werden NICHT erfasst.
Das ist durchaus sinnvoll, weil das offene Fenster ja um 15µm (CO2) schon geschlossen ist und da sowieso keine Distanzmessung möglich wäre.
Wenn Sie nun so ein Gerät möglichst nachts, natürlich bei ganz wolkenfreiem Himmel nach oben halten, schlägt der Zeiger bis rechts zum Skalenende aus, egal, was da drauf steht, da KEINE Strahlung in das Gerät kommen.
„ein ganz normales Infrarotthermomether“,
dass -100° messen könnte gibt es gar nicht!!!!
Lesen Sie einfach die Gebrauchsanleitung.
Wenn am Skalenende nun -50 oder -80°C steht heist das nur ich kann überhaupt keine Strahlen messen!
Ist das denn so schwer zu verstehen?
Merksatz:
Es strahlt nicht AUS der (gasförmigen) Atmosphäre, sonder DURCH diese Atmosphäre.
Den Puristen sei versichert, ja ein ganz ganz klein bischen (pik) Wärmestrahlung aus der Stratosphäre vom Ozon ist auch dabei (gehört zum offenen Fenster).
mfG
Der empirisch Nachweis für einen Treibhauseffekt ist recht einfach: Wer ein ganz normales Infrarotthermomether in Richtung Himmel hält, erhält Werte, die deutlich über dem absoluten Nullpunkt (-273°C oder 0 Kelvin) liegen.
Die Hintergrundstrahlung des Weltalls liegt bei 3 Kelvin / 270°C. Wäre die Atmosphäre für IR-Strahlung völlig durchlässig, dann würden wir diese Werte messen.
Bedeckter Himmel ergibt viel wärmere Werte, genauso, wenn man das Thermometer aus der Senkrechten weg seitlich schwenkt, weil die dicke der Erdatmosphäre für das Terhmometer zunimmt und damit die empfangene Wärme. Und natürlich kommt im Sommer mehr Wärme zurück als im Winter und Tags als Nachts.
Auf meinem Blog habe ich mal eine Testreihe gemacht:
http://tinyurl.com/h22y2qr
Dr Roy Spencer hat noch einen anderen Test gemacht:
http://tinyurl.com/hvsj545
Noch genauer geht es mit der Wärmebildkamera, die für jedes Pixel ein eignes IR-Thermometer besitzt.
http://tinyurl.com/jbdfotu
2. Die Erdoberfläche strahlt im Mittel deutlich mehr Energie ab, als sie von der Sonne durch Einstrahlung empfangen hat. Es gibt also die Rückstrahlung.
Dass es den atmosphärischen Treibhauseffekt gibt, bedeutet noch lange nicht, dass eine erhöhte Konzentration von CO2 in der Atmosphäre automatisch höhere Globaltemperaturen erzeugen. Da gibt es noch viele andere gleichgewichtsfaktoren.
Und die letzten 18 Jahre wurde es einfach nicht wärmer:
http://klimawandler.blogspot.de/
1. (Monckton): Wir haben keinen bedrohlichen Klimawandel. Darum ist alle Aktion sonnlos und schädlich.
2. (Alternativ) Wir haben eine Klimaerwärmung, die möglicherweise auch schädlich sein kann, aber diese wird nicht überwiegend vom Menschen verursacht. Darum ist der Klimaschutz fruchtlos und schädlich.
3. (Alternativ) Wir haben eine möglicherweise vom Menschen verursachte Klimaerwärmung, die schädlich sein kann, aber wir haben keine realistische Möglichkeit, irgend etwas signifikant daran zu ändern.
Monckton kommt von 1. greift aber auch Argument für 2. und 3. auf. Das ist einerseits zwar richtig, führt aber zu einer Argumentation, die unter Umständen nicht ganz konsistent ist und den Verdacht eines performativen Widerspruchs weckt. Es wäre darum vielleicht besser, die Standpunkte von Anfang an etwas besser zu klären.
„Bevor ich jetzt 50 Minuten aufwende, kann mir jemand bitte sagen, ob Monckton da schon wieder weine übliche subtile Propaganda FÜR „Treibhauseffekt“ und „Globaltemperatur“ betreibt, oder sagt er endlich etwas vernünftiges?“
Monckton: (gegen 47:50) „Everyone, who says, the green house effect does not exist, needs his head examined“
Beantwortet das die Frage?
Übrigens, zum „ehem. Science Adviser von Lady Margret Thatcher“, a)es gibt bis heute keine unabhängige Bestätigung und b)das Journalistik-Studium würde niemanden zum Science Adviser eines Regierungsoberhaupt befähigen. Ich empfehle die Lektüre von Monckton’s Lebenslauf, von ihm selbst auf der seieten der UKIP präsentiert. Da findet man schon ein paar interessanten Sachen. Und bitte seine „memeber of the House of Lords without the right to sit and vote“-Geschichte nicht vergessen. Ja, und Lady Thatcher selbst war doch die treibende Kraft hinter dem AGW-Konzept und CO2-Bekämpfung.
die einzige bedauerliche Schwäche von Lord Christopher Monckton, den ich sonst auch toll finde, gerade weil es um (empirischen) Nachweis, nicht um Theorie geht.
Wahrheit ist Ausssage in Übereinstimmung mit den Tatsachen d.h. was Sie Fakten nennen, ist.
Allerdings führt die Aussage von Lord Monckton hinsichtlich des Betruges in Bezug auf die „Klimasensitivität“ des CO2 in die Irre. Da CO2 die Erde nicht erwärmen kann, gibt es auch keine Klimasensitivität des CO2 bzw. dessen Wert ist null.
MfG
Es wäre besser gewesen, er hätte am Ende lediglich gesagt: … und wir haben die Fakten!
Mit der Aussage: … and we have the truth! begibt er sich genau auf die Schleim-Spuren, die die AGWler gelegt haben – so wird daraus ein ideologischer Kampf. „Fakten, wir haben die Fakten“, die ihr nicht widerlegen könnt, und wenn ihr Fakten bringt, die etwas Neues zeigen, akzeptieren wir das, so lange wiederum neue Fakten dies nicht widerlegen …
Schade, aus meiner Sicht macht er damit den ganzen Vortrag hinfällig. Nicht die „Wahrheit“, Fakten sprechen für uns!
Übrigens wäre es gut, wenn Lord Monckton sich diese Menge an Darlegungen tatsächlich für einen Prozeß aufheben und sich für seinen Vortrag auf max. fünf wesentliche Aspekte beschränken würde – so folgt ihm doch niemand, der nicht das alles schon xfach gehört/gesehen hat bzw. zu den Naturwissenschaftlern zählt, die nicht, so stellt es sich für mich dar, korrupt sind.